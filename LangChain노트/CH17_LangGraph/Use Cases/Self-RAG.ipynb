{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-25T05:47:29.595644Z",
     "start_time": "2025-04-25T05:47:29.556445Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH17-LangGraph-Use-Cases\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH17-LangGraph-Use-Cases\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 기본 PDF 기반 Retrieval Chain 생성\n",
   "id": "219e77bed0a7a367"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T05:52:26.240763Z",
     "start_time": "2025-04-25T05:52:10.615552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from rag.pdf import PDFRetrievalChain\n",
    "\n",
    "# PDF 문서를 로드합니다.\n",
    "pdf = PDFRetrievalChain([\"data/SPRI_AI_Brief_2023년12월호_F.pdf\"]).create_chain()\n",
    "\n",
    "# retriever와 chain을 생성합니다.\n",
    "pdf_retriever = pdf.retriever\n",
    "pdf_chain = pdf.chain"
   ],
   "id": "634c39a5a5ed30e9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 문서 검색 평가기 (Retrieval Grader)\n",
   "id": "d6109810b87d29ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T05:52:42.560190Z",
     "start_time": "2025-04-25T05:52:38.844646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_teddynote.models import get_model_name, LLMs\n",
    "\n",
    "# 최신모델 이름 설정\n",
    "MODEL_NAME = get_model_name(LLMs.GPT4o)\n",
    "\n",
    "\n",
    "# 데이터 모델 정의: 검색된 문서의 관련성을 이진 점수로 평가하기 위한 데이터 모델\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"A binary score to determine the relevance of the retrieved documents.\"\"\"\n",
    "\n",
    "    # 문서가 질문에 관련이 있는지 여부를 'yes' 또는 'no'로 나타내는 필드\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "\n",
    "# GradeDocuments 데이터 모델을 사용하여 LLM의 구조화된 출력 생성\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# 시스템 프롬프트 정의: 검색된 문서가 사용자 질문에 관련이 있는지 평가하는 시스템 역할 정의\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "\n",
    "# 채팅 프롬프트 템플릿 생성\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 검색 평가기 생성\n",
    "retrieval_grader = grade_prompt | structured_llm_grader"
   ],
   "id": "547a8646ae766743",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T05:52:47.479885Z",
     "start_time": "2025-04-25T05:52:45.570650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 질문 정의\n",
    "question = \"삼성전자가 개발한 생성형 AI 의 이름은?\"\n",
    "\n",
    "# 문서 검색\n",
    "docs = pdf_retriever.invoke(question)\n",
    "\n",
    "# 검색된 문서 중 두 번째 문서의 페이지 콘텐츠 추출\n",
    "doc_txt = docs[1].page_content\n",
    "\n",
    "# 검색 평가기 호출 및 결과 출력\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ],
   "id": "f7b3a8b1b52dfba1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 답변 생성 체인\n",
   "id": "4f861fe55bfed7ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T05:53:00.130605Z",
     "start_time": "2025-04-25T05:52:57.451552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LangChain Hub에서 프롬프트 가져오기\n",
    "prompt = hub.pull(\"teddynote/rag-prompt\")\n",
    "\n",
    "# 기본 LLM 초기화, 모델 이름과 온도 설정\n",
    "llm = ChatOpenAI(model_name=MODEL_NAME, temperature=0)\n",
    "\n",
    "\n",
    "# 문서 포맷팅 함수\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(\n",
    "        [\n",
    "            f'<document><content>{doc.page_content}</content><source>{doc.metadata[\"source\"]}</source><page>{doc.metadata[\"page\"]+1}</page></document>'\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "# RAG 체인 생성\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 체인 실행\n",
    "generation = rag_chain.invoke({\"context\": format_docs(docs), \"question\": question})\n",
    "print(generation)"
   ],
   "id": "7c71d63afee1c932",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삼성전자가 개발한 생성형 AI의 이름은 '삼성 가우스'입니다.\n",
      "\n",
      "**Source**\n",
      "- data/SPRI_AI_Brief_2023년12월호_F.pdf (page 13)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 답변의 할루시네이션 여부를 평가\n",
   "id": "471dee1d35d8d65a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T05:53:32.569585Z",
     "start_time": "2025-04-25T05:53:31.272454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# 데이터 모델 정의: 생성된 답변이 사실에 기반하고 있는지 여부를 이진 점수로 평가하기 위한 데이터 모델\n",
    "class Groundednesss(BaseModel):\n",
    "    \"\"\"A binary score indicating whether the generated answer is grounded in the facts.\"\"\"\n",
    "\n",
    "    # 답변이 사실에 기반하고 있는지 여부를 'yes' 또는 'no'로 나타내는 필드\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "\n",
    "# 구조화된 출력과 함께 LLM 설정\n",
    "structured_llm_grader = llm.with_structured_output(Groundednesss)\n",
    "\n",
    "# 시스템 프롬프트 정의\n",
    "system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n\n",
    "Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\"\"\"\n",
    "\n",
    "# 채팅 프롬프트 템플릿 생성\n",
    "groundedness_checking_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 답변의 할루시네이션 평가기 생성\n",
    "groundedness_grader = groundedness_checking_prompt | structured_llm_grader"
   ],
   "id": "c2c6b677f2f6c987",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 답변의 관련성 평가\n",
   "id": "2007202b994d9f92"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T05:53:44.262627Z",
     "start_time": "2025-04-25T05:53:43.131412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"A binary score indicating whether the question is addressed.\"\"\"\n",
    "\n",
    "    # 답변의 관련성 평가: 'yes' 또는 'no'로 표기(yes: 관련성 있음, no: 관련성 없음)\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer addresses the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "\n",
    "# llm 에 GradeAnswer 바인딩\n",
    "structured_llm_grader = llm.with_structured_output(GradeAnswer)\n",
    "\n",
    "# 시스템 프롬프트 정의\n",
    "system = \"\"\"You are a grader assessing whether an answer addresses / resolves a question \\n\n",
    "     Give a binary score 'yes' or 'no'. Yes' means that the answer resolves the question.\"\"\"\n",
    "\n",
    "# 프롬프트 생성\n",
    "answer_grader_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 답변 평가기 생성\n",
    "answer_grader = answer_grader_prompt | structured_llm_grader"
   ],
   "id": "cb20e205d57a2b71",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T05:53:49.901474Z",
     "start_time": "2025-04-25T05:53:48.932344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 답변 평가기 호출(yes: 질문을 해결함, no: 질문을 해결하지 않음)\n",
    "answer_grader.invoke({\"question\": question, \"generation\": generation})"
   ],
   "id": "7ee868fb6a34f139",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeAnswer(binary_score='yes')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 질문 재작성기(Question Rewriter)\n",
   "id": "846e0875e5556c04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T05:54:08.290394Z",
     "start_time": "2025-04-25T05:54:05.768350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "\n",
    "# 시스템 프롬프트 정의\n",
    "# 입력 질문을 벡터스토어 검색에 최적화된 형태로 변환하는 시스템 역할 정의\n",
    "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n\n",
    "     for vectorstore retrieval. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "\n",
    "# 시스템 메시지와 초기 질문을 포함한 프롬프트 템플릿 생성\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 질문 재작성기 생성\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
    "# 질문 재작성기 호출\n",
    "question_rewriter.invoke({\"question\": question})"
   ],
   "id": "54e48cc6d99e1208",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'삼성전자가 개발한 생성형 인공지능의 이름은 무엇인가요?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 상태 정의\n",
   "id": "92739497de18bde6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T05:54:18.884043Z",
     "start_time": "2025-04-25T05:54:18.879742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "\n",
    "\n",
    "# 그래프의 상태를 나타내는 클래스 정의\n",
    "class GraphState(TypedDict):\n",
    "    # 질문을 나타내는 문자열\n",
    "    question: Annotated[str, \"Question\"]\n",
    "    # LLM에 의해 생성된 응답을 나타내는 문자열\n",
    "    generation: Annotated[str, \"LLM Generation\"]\n",
    "    # 문서의 목록을 나타내는 문자열 리스트\n",
    "    documents: Annotated[List[str], \"Retrieved Documents\"]"
   ],
   "id": "fca5575e7cf117e8",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 노드 정의\n",
   "id": "3780f05c44875de6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T05:54:28.780808Z",
     "start_time": "2025-04-25T05:54:28.771262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 문서 검색\n",
    "def retrieve(state):\n",
    "    print(\"==== [RETRIEVE] ====\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # 검색 수행\n",
    "    documents = pdf_retriever.invoke(question)\n",
    "    return {\"documents\": documents}\n",
    "\n",
    "\n",
    "# 답변 생성\n",
    "def generate(state):\n",
    "    print(\"==== [GENERATE] ====\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG 생성\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"generation\": generation}\n",
    "\n",
    "\n",
    "# 검색된 문서의 관련성 평가\n",
    "def grade_documents(state):\n",
    "    print(\"==== [GRADE DOCUMENTS] ====\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # 각 문서 점수 평가\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"==== GRADE: DOCUMENT RELEVANT ====\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"==== GRADE: DOCUMENT NOT RELEVANT ====\")\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs}\n",
    "\n",
    "\n",
    "# 질문 변환\n",
    "def transform_query(state):\n",
    "    print(\"==== [TRANSFORM QUERY] ====\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # 질문 재작성\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"question\": better_question}"
   ],
   "id": "1cc44e3986ba961",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 조건부 엣지 정의",
   "id": "f7d58ff6953e843e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T05:54:41.186603Z",
     "start_time": "2025-04-25T05:54:41.180378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 답변 생성 여부 결정\n",
    "def decide_to_generate(state):\n",
    "    print(\"==== [ASSESS GRADED DOCUMENTS] ====\")\n",
    "    state[\"question\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if not filtered_documents:\n",
    "        # 모든 문서가 관련성이 없는 경우\n",
    "        # 새로운 쿼리 생성\n",
    "        print(\n",
    "            \"==== [DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY] ====\"\n",
    "        )\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # 관련 문서가 있는 경우 답변 생성\n",
    "        print(\"==== [DECISION: GENERATE] ====\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "# 생성된 답변의 문서 및 질문과의 관련성 평가\n",
    "def grade_generation_v_documents_and_question(state):\n",
    "    print(\"==== [CHECK HALLUCINATIONS] ====\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    score = groundedness_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "    grade = score.binary_score\n",
    "\n",
    "    # 환각 여부 확인\n",
    "    if grade == \"yes\":\n",
    "        print(\"==== [DECISION: GENERATION IS GROUNDED IN DOCUMENTS] ====\")\n",
    "        # 질문 해결 여부 확인\n",
    "        print(\"==== [GRADE GENERATION vs QUESTION] ====\")\n",
    "        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"==== [DECISION: GENERATION ADDRESSES QUESTION] ====\")\n",
    "            return \"relevant\"\n",
    "        else:\n",
    "            print(\"==== [DECISION: GENERATION DOES NOT ADDRESS QUESTION] ====\")\n",
    "            return \"not relevant\"\n",
    "    else:\n",
    "        print(\"==== [DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY] ====\")\n",
    "        return \"hallucination\""
   ],
   "id": "7e47e62ac89a0d06",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 그래프 생성\n",
   "id": "6d8085185d87b6f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T05:54:56.884929Z",
     "start_time": "2025-04-25T05:54:56.676750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# 그래프 상태 초기화\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# 노드 정의\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "workflow.add_node(\"generate\", generate)  # generatae\n",
    "workflow.add_node(\"transform_query\", transform_query)  # transform_query\n",
    "\n",
    "# 엣지 정의\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "\n",
    "# 문서 평가 노드에서 조건부 엣지 추가\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# 엣지 정의\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
    "\n",
    "# 답변 생성 노드에서 조건부 엣지 추가\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"hallucination\": \"generate\",\n",
    "        \"relevant\": END,\n",
    "        \"not relevant\": \"transform_query\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# 그래프 컴파일\n",
    "app = workflow.compile(checkpointer=MemorySaver())"
   ],
   "id": "7e7df520683c3362",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 그래프 실행",
   "id": "c567b6a572d6a4ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T05:55:23.492438Z",
     "start_time": "2025-04-25T05:55:06.534364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import stream_graph, invoke_graph, random_uuid\n",
    "\n",
    "# config 설정(재귀 최대 횟수, thread_id)\n",
    "config = RunnableConfig(recursion_limit=10, configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "# 질문 입력\n",
    "inputs = {\n",
    "    \"question\": \"삼성전자가 개발한 생성형 AI 의 이름은?\",\n",
    "}\n",
    "\n",
    "# 그래프 실행\n",
    "invoke_graph(\n",
    "    app, inputs, config, [\"retrieve\", \"transform_query\", \"grade_documents\", \"generate\"]\n",
    ")"
   ],
   "id": "c68cb4fd25caa6ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== [RETRIEVE] ====\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mretrieve\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "page_content='SPRi AI Brief |\n",
      "2023-12월호\n",
      "삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
      "KEY Contents\n",
      "n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성\n",
      "AI 모델 ‘삼성 가우스’를 공개\n",
      "n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한\n",
      "삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
      "£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원' metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}\n",
      "page_content='▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ···························································10\n",
      "▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································11\n",
      "▹ IDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망···········································12' metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 1, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}\n",
      "page_content='£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델\n",
      "‘삼성 가우스’를 최초 공개\n",
      "∙ 정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에\n",
      "최적화된 크기의 모델 선택이 가능\n",
      "∙ 삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며,\n",
      "온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유' metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}\n",
      "page_content='어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\n",
      "☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\n",
      "삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
      "TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n",
      "10' metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}\n",
      "page_content='<구글 딥마인드의 범용 AI 분류 프레임워크>\n",
      "성능 특수 AI 예시 범용 AI 예시\n",
      "0단계: AI 아님 계산기 소프트웨어, 컴파일러 아마존 메커니컬 터크\n",
      "1단계: 신진(숙련되지 않은 인간) GOFAI(Good Old Fashioned Artificial Intelligence) 챗GPT, 바드, 라마2\n",
      "스마트 스피커(애플 시리, 아마존 알렉사, 구글\n",
      "2단계: 유능(숙련된 인간의 50% 이상) 미달성\n",
      "어시스턴트), IBM 왓슨\n",
      "3단계: 전문가(숙련된 인간의 90% 이상) 문법 교정기(그래머리), 생성 이미지 모델(달리2) 미달성' metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 18, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}\n",
      "page_content='제작을 포함\n",
      "n 알리바바 클라우드는 급증하는 생성 AI 수요에 대응해 모델 개발과 애플리케이션 구축 절차를\n",
      "간소화하는 올인원 AI 모델 구축 플랫폼 ‘젠AI(GenAI)’도 공개\n",
      "∙ 이 플랫폼은 데이터 관리, 모델 배포와 평가, 신속한 엔지니어링을 위한 종합 도구 모음을 제공하여\n",
      "다양한 기업들이 맞춤형 AI 모델을 한층 쉽게 개발할 수 있도록 지원\n",
      "∙ 생성 AI 개발에 필요한 컴퓨팅과 데이터 처리 요구사항을 지원하기 위해 AI 플랫폼(PAI),\n",
      "데이터베이스 솔루션, 컨테이너 서비스와 같은 클라우드 신제품도 발표' metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 11, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}\n",
      "page_content='처리를 지원\n",
      "∙ 코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며\n",
      "사내 소프트웨어 개발에 최적화\n",
      "∙ 이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며\n",
      "저해상도 이미지의 고해상도 전환도 지원\n",
      "n IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며,\n",
      "2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글' metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}\n",
      "page_content='온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
      "∙ 삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에\n",
      "단계적으로 탑재할 계획\n",
      "n 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는\n",
      "이미지 모델의 3개 모델로 구성\n",
      "∙ 언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의\n",
      "처리를 지원' metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}\n",
      "page_content='▹ 빌 게이츠, AI 에이전트로 인한 컴퓨터 사용의 패러다임 변화 전망································13\n",
      "▹ 유튜브, 2024년부터 AI 생성 콘텐츠 표시 의무화····························································14\n",
      "3. 기술/연구\n",
      "▹ 영국 과학혁신기술부, AI 안전 연구소 설립 발표······························································15' metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 1, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}\n",
      "page_content='£챗GPT와 구글 바드와 같은 AI 챗봇은 범용 AI 1단계 수준\n",
      "n 구글 딥마인드 연구진은 2023년 11월 4일 범용 AI(Artificial General Intelligence, AGI) 모델을 용도와\n",
      "성능에 따라 분류하는 프레임워크를 제시한 논문을 발표\n",
      "∙ 프레임워크의 목적은 AGI의 성능, 범용성, 자율성 수준을 정의하여 모델 간 비교와 위험 평가, AGI\n",
      "달성까지의 진행 상황을 측정할 수 있는 공통 기준을 제공하기 위함\n",
      "n 연구진은 AGI 개념 정의에 필요한 기준을 수립하기 위한 6가지 원칙을 아래와 같이 도출' metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 18, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}\n",
      "==================================================\n",
      "==== [GRADE DOCUMENTS] ====\n",
      "==== GRADE: DOCUMENT RELEVANT ====\n",
      "==== GRADE: DOCUMENT RELEVANT ====\n",
      "==== GRADE: DOCUMENT RELEVANT ====\n",
      "==== GRADE: DOCUMENT RELEVANT ====\n",
      "==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "==== GRADE: DOCUMENT RELEVANT ====\n",
      "==== GRADE: DOCUMENT RELEVANT ====\n",
      "==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "==== [ASSESS GRADED DOCUMENTS] ====\n",
      "==== [DECISION: GENERATE] ====\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mgrade_documents\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "page_content='SPRi AI Brief |\n",
      "2023-12월호\n",
      "삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
      "KEY Contents\n",
      "n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성\n",
      "AI 모델 ‘삼성 가우스’를 공개\n",
      "n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한\n",
      "삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
      "£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원' metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}\n",
      "page_content='▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ···························································10\n",
      "▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································11\n",
      "▹ IDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망···········································12' metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 1, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}\n",
      "page_content='£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델\n",
      "‘삼성 가우스’를 최초 공개\n",
      "∙ 정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에\n",
      "최적화된 크기의 모델 선택이 가능\n",
      "∙ 삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며,\n",
      "온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유' metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}\n",
      "page_content='어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\n",
      "☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\n",
      "삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
      "TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n",
      "10' metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}\n",
      "page_content='처리를 지원\n",
      "∙ 코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며\n",
      "사내 소프트웨어 개발에 최적화\n",
      "∙ 이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며\n",
      "저해상도 이미지의 고해상도 전환도 지원\n",
      "n IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며,\n",
      "2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글' metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}\n",
      "page_content='온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
      "∙ 삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에\n",
      "단계적으로 탑재할 계획\n",
      "n 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는\n",
      "이미지 모델의 3개 모델로 구성\n",
      "∙ 언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의\n",
      "처리를 지원' metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}\n",
      "==================================================\n",
      "==== [GENERATE] ====\n",
      "==== [CHECK HALLUCINATIONS] ====\n",
      "==== [DECISION: GENERATION IS GROUNDED IN DOCUMENTS] ====\n",
      "==== [GRADE GENERATION vs QUESTION] ====\n",
      "==== [DECISION: GENERATION ADDRESSES QUESTION] ====\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mgenerate\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001B[1;32mgeneration\u001B[0m:\n",
      "삼성전자가 개발한 생성형 AI의 이름은 '삼성 가우스'입니다.\n",
      "\n",
      "**Source**\n",
      "- data/SPRI_AI_Brief_2023년12월호_F.pdf (page 12)\n",
      "==================================================\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T05:56:18.185286Z",
     "start_time": "2025-04-25T05:55:43.918844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.errors import GraphRecursionError\n",
    "\n",
    "# config 설정(재귀 최대 횟수, thread_id)\n",
    "config = RunnableConfig(recursion_limit=10, configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "# 질문 입력\n",
    "inputs = {\n",
    "    \"question\": \"테디노트가 개발한 생성형 AI 의 이름은?\",\n",
    "}\n",
    "\n",
    "try:\n",
    "    # 그래프 실행\n",
    "    stream_graph(\n",
    "        app,\n",
    "        inputs,\n",
    "        config,\n",
    "        [\"retrieve\", \"transform_query\", \"grade_documents\", \"generate\"],\n",
    "    )\n",
    "except GraphRecursionError as recursion_error:\n",
    "    print(f\"GraphRecursionError: {recursion_error}\")"
   ],
   "id": "12c4228439ce9ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== [RETRIEVE] ====\n",
      "==== [GRADE DOCUMENTS] ====\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mgrade_documents\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "==== [ASSESS GRADED DOCUMENTS] ====\n",
      "==== [DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY] ====\n",
      "==== [TRANSFORM QUERY] ====\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mtransform_query\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "What is the name of the generative AI developed by TeddyNote?==== [RETRIEVE] ====\n",
      "==== [GRADE DOCUMENTS] ====\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mgrade_documents\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "==== [ASSESS GRADED DOCUMENTS] ====\n",
      "==== [DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY] ====\n",
      "==== [TRANSFORM QUERY] ====\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mtransform_query\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "What is the name of the generative AI created by the company TeddyNote?==== [RETRIEVE] ====\n",
      "==== [GRADE DOCUMENTS] ====\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mgrade_documents\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "{\"binary_score==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "\":\"no\"}{\"binary_score\":\"no\"}==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "==== GRADE: DOCUMENT NOT RELEVANT ====\n",
      "==== [ASSESS GRADED DOCUMENTS] ====\n",
      "==== [DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY] ====\n",
      "{\"binary_score\":\"no\"}==== [TRANSFORM QUERY] ====\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mtransform_query\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "What is the generative AI developed by TeddyNote called?==== [RETRIEVE] ====\n",
      "GraphRecursionError: Recursion limit of 10 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
