{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-25T06:11:25.598468Z",
     "start_time": "2025-04-25T06:11:25.580628Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH17-LangGraph-Use-Cases\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH17-LangGraph-Use-Cases\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T06:11:30.476970Z",
     "start_time": "2025-04-25T06:11:27.733608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_teddynote.models import get_model_name, LLMs\n",
    "\n",
    "# 모델명 정의\n",
    "MODEL_NAME = get_model_name(LLMs.GPT4o)\n",
    "print(MODEL_NAME)"
   ],
   "id": "c60bafd56d85d433",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 도구 정의",
   "id": "9cdf57577b1665e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T06:11:43.624871Z",
     "start_time": "2025-04-25T06:11:42.554686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_teddynote.tools import TavilySearch\n",
    "\n",
    "# Tavily 검색 도구 초기화\n",
    "tools = [TavilySearch(max_results=3)]"
   ],
   "id": "f5242ce73af06887",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 작업 실행 에이전트 정의\n",
   "id": "35789ad93a5c6371"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T06:11:54.475412Z",
     "start_time": "2025-04-25T06:11:53.112870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 프롬프트 정의\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer in Korean.\",\n",
    "        ),\n",
    "        (\"human\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# LLM 정의\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "\n",
    "# ReAct 에이전트 생성\n",
    "agent_executor = create_react_agent(llm, tools, state_modifier=prompt)"
   ],
   "id": "2e11f06cda7b929",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T06:12:11.683118Z",
     "start_time": "2025-04-25T06:12:01.604854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 에이전트 실행\n",
    "agent_executor.invoke(\n",
    "    {\"messages\": [(\"user\", \"랭체인 한국어 튜토리얼에 대해서 설명해줘\")]}\n",
    ")"
   ],
   "id": "c07d914df4b6d919",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='랭체인 한국어 튜토리얼에 대해서 설명해줘', additional_kwargs={}, response_metadata={}, id='88d094e4-fdf8-4a2b-ab43-24a033ad9789'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_RET6frawe4cNUfaxgLEPlIKD', 'function': {'arguments': '{\"query\":\"랭체인 한국어 튜토리얼\"}', 'name': 'tavily_web_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 154, 'total_tokens': 182, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_90122d973c', 'id': 'chatcmpl-BQ6a242CzvVlRV7krkq9mj7Shynv3', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-edb2cdb1-6f88-431e-93da-85a8d5a70505-0', tool_calls=[{'name': 'tavily_web_search', 'args': {'query': '랭체인 한국어 튜토리얼'}, 'id': 'call_RET6frawe4cNUfaxgLEPlIKD', 'type': 'tool_call'}], usage_metadata={'input_tokens': 154, 'output_tokens': 28, 'total_tokens': 182, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='[{\"title\": \"GitHub - teddylee777/langchain-kr: LangChain 공식 Document, Cookbook, 그 ...\", \"url\": \"https://github.com/teddylee777/langchain-kr\", \"content\": \"GitHub - teddylee777/langchain-kr: LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. GitHub Copilot Write better code with AI GitHub Copilot Enterprise-grade AI features Search code, repositories, users, issues, pull requests... LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 🌟 LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 🔥성능이 놀라워요🔥 무료로 한국어🇰🇷 파인튜닝 모델 받아서 나만의 로컬 LLM 호스팅 하기(#LangServe) + #RAG 까지!! 무료로 한국어🇰🇷 파인튜닝 모델 받아서 나만의 로컬 LLM 호스팅 하기(LangServe) + RAG 까지!! 참고 자료는 본 문서 하단의 출처 목록에서 확인하실 수 있습니다. langchain-ai 📖 LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. tutorial cookbook openai huggingface gpt-3 openai-api gpt-4 generative-ai chatgpt langchain chatgpt-api langchain-python\", \"score\": 0.8058924, \"raw_content\": \"GitHub - teddylee777/langchain-kr: LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 본 튜토리얼을 통해 LangChain을 더 쉽고 효과적으로 사용하는 방법을 배울 수 있습니다.\\\\nSkip to content \\\\nNavigation Menu\\\\nToggle navigation\\\\n\\\\nSign in\\\\n\\\\n\\\\nProduct\\\\n\\\\nGitHub Copilot Write better code with AI\\\\nSecurity Find and fix vulnerabilities\\\\nActions Automate any workflow\\\\nCodespaces Instant dev environments\\\\nIssues Plan and track work\\\\nCode Review Manage code changes\\\\nDiscussions Collaborate outside of code\\\\nCode Search Find more, search less\\\\n\\\\nExplore\\\\n\\\\nAll features\\\\nDocumentation\\\\nGitHub Skills\\\\nBlog\\\\n\\\\n\\\\n\\\\nSolutions\\\\nBy company size\\\\n\\\\nEnterprises\\\\nSmall and medium teams\\\\nStartups\\\\nNonprofits\\\\n\\\\nBy use case\\\\n\\\\nDevSecOps\\\\nDevOps\\\\nCI/CD\\\\nView all use cases\\\\n\\\\nBy industry\\\\n\\\\nHealthcare\\\\nFinancial services\\\\nManufacturing\\\\nGovernment\\\\nView all industries\\\\n\\\\nView all solutions\\\\n\\\\n\\\\nResources\\\\nTopics\\\\n\\\\nAI\\\\nDevOps\\\\nSecurity\\\\nSoftware Development\\\\nView all\\\\n\\\\nExplore\\\\n\\\\nLearning Pathways\\\\nWhite papers, Ebooks, Webinars\\\\nCustomer Stories\\\\nPartners\\\\nExecutive Insights\\\\n\\\\n\\\\n\\\\nOpen Source\\\\n\\\\n\\\\nGitHub Sponsors Fund open source developers\\\\n\\\\n\\\\nThe ReadME Project GitHub community articles\\\\n\\\\n\\\\nRepositories\\\\n\\\\nTopics\\\\nTrending\\\\nCollections\\\\n\\\\n\\\\n\\\\nEnterprise\\\\n\\\\nEnterprise platform AI-powered developer platform\\\\n\\\\nAvailable add-ons\\\\n\\\\nAdvanced Security Enterprise-grade security features\\\\nGitHub Copilot Enterprise-grade AI features\\\\nPremium Support Enterprise-grade 24/7 support\\\\n\\\\n\\\\n\\\\nPricing\\\\n\\\\n\\\\nSearch or jump to...\\\\nSearch code, repositories, users, issues, pull requests...\\\\nSearch\\\\nClear\\\\nSearch syntax tips\\\\nProvide feedback\\\\nWe read every piece of feedback, and take your input very seriously.\\\\nInclude my email address so I can be contacted\\\\nCancel Submit feedback\\\\nSaved searches\\\\nUse saved searches to filter your results more quickly\\\\nName  \\\\nQuery \\\\nTo see all available qualifiers, see our documentation.\\\\nCancel Create saved search\\\\nSign in\\\\nSign up Reseting focus\\\\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\\\\n{{ message }}\\\\nteddylee777 / langchain-kr Public\\\\n\\\\nNotifications You must be signed in to change notification settings\\\\nFork 407\\\\nStar 1.4k\\\\n\\\\nLangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 본 튜토리얼을 통해 LangChain을 더 쉽고 효과적으로 사용하는 방법을 배울 수 있습니다.\\\\nwikidocs.net/book/14314\\\\nLicense\\\\nApache-2.0 license\\\\n1.4k stars 407 forks Branches Tags Activity\\\\nStar\\\\nNotifications You must be signed in to change notification settings\\\\n\\\\nCode\\\\nIssues 2\\\\nPull requests 0\\\\nActions\\\\nProjects 0\\\\nSecurity\\\\nInsights\\\\n\\\\nAdditional navigation options\\\\n\\\\nCode\\\\nIssues\\\\nPull requests\\\\nActions\\\\nProjects\\\\nSecurity\\\\nInsights\\\\n\\\\nteddylee777/langchain-kr\\\\nmain\\\\nBranchesTags\\\\n\\\\nGo to file\\\\nCode\\\\nFolders and files\\\\n| Name | Name | \\\\nLast commit message\\\\n| \\\\nLast commit date\\\\n|\\\\n| --- | --- | --- | --- |\\\\n| \\\\nLatest commit\\\\nHistory\\\\n391 Commits\\\\n\\\\n|\\\\n| \\\\n01-Basic\\\\n| \\\\n01-Basic\\\\n| \\\\n| \\\\n|\\\\n| \\\\n02-Prompt\\\\n| \\\\n02-Prompt\\\\n| \\\\n| \\\\n|\\\\n| \\\\n03-OutputParser\\\\n| \\\\n03-OutputParser\\\\n| \\\\n| \\\\n|\\\\n| \\\\n04-Model\\\\n| \\\\n04-Model\\\\n| \\\\n| \\\\n|\\\\n| \\\\n05-Memory\\\\n| \\\\n05-Memory\\\\n| \\\\n| \\\\n|\\\\n| \\\\n06-DocumentLoader\\\\n| \\\\n06-DocumentLoader\\\\n| \\\\n| \\\\n|\\\\n| \\\\n07-TextSplitter\\\\n| \\\\n07-TextSplitter\\\\n| \\\\n| \\\\n|\\\\n| \\\\n08-Embeddings\\\\n| \\\\n08-Embeddings\\\\n| \\\\n| \\\\n|\\\\n| \\\\n09-VectorStore\\\\n| \\\\n09-VectorStore\\\\n| \\\\n| \\\\n|\\\\n| \\\\n10-Retriever\\\\n| \\\\n10-Retriever\\\\n| \\\\n| \\\\n|\\\\n| \\\\n11-Reranker\\\\n| \\\\n11-Reranker\\\\n| \\\\n| \\\\n|\\\\n| \\\\n12-RAG\\\\n| \\\\n12-RAG\\\\n| \\\\n| \\\\n|\\\\n| \\\\n13-LangChain-Expression-Language\\\\n| \\\\n13-LangChain-Expression-Language\\\\n| \\\\n| \\\\n|\\\\n| \\\\n14-Chains\\\\n| \\\\n14-Chains\\\\n| \\\\n| \\\\n|\\\\n| \\\\n15-Agent\\\\n| \\\\n15-Agent\\\\n| \\\\n| \\\\n|\\\\n| \\\\n16-Evaluations\\\\n| \\\\n16-Evaluations\\\\n| \\\\n| \\\\n|\\\\n| \\\\n17-LangGraph\\\\n| \\\\n17-LangGraph\\\\n| \\\\n| \\\\n|\\\\n| \\\\n18-FineTuning\\\\n| \\\\n18-FineTuning\\\\n| \\\\n| \\\\n|\\\\n| \\\\n19-Streamlit\\\\n| \\\\n19-Streamlit\\\\n| \\\\n| \\\\n|\\\\n| \\\\n20-Projects/01-ParsingOutput\\\\n| \\\\n20-Projects/01-ParsingOutput\\\\n| \\\\n| \\\\n|\\\\n| \\\\n22-OpenAI\\\\n| \\\\n22-OpenAI\\\\n| \\\\n| \\\\n|\\\\n| \\\\n99-Projects\\\\n| \\\\n99-Projects\\\\n| \\\\n| \\\\n|\\\\n| \\\\nimages\\\\n| \\\\nimages\\\\n| \\\\n| \\\\n|\\\\n| \\\\n.env_sample\\\\n| \\\\n.env_sample\\\\n| \\\\n| \\\\n|\\\\n| \\\\n.gitignore\\\\n| \\\\n.gitignore\\\\n| \\\\n| \\\\n|\\\\n| \\\\nLICENSE\\\\n| \\\\nLICENSE\\\\n| \\\\n| \\\\n|\\\\n| \\\\nREADME.md\\\\n| \\\\nREADME.md\\\\n| \\\\n| \\\\n|\\\\n| \\\\npoetry.lock\\\\n| \\\\npoetry.lock\\\\n| \\\\n| \\\\n|\\\\n| \\\\npyproject.toml\\\\n| \\\\npyproject.toml\\\\n| \\\\n| \\\\n|\\\\n| \\\\nrequirements-mini.txt\\\\n| \\\\nrequirements-mini.txt\\\\n| \\\\n| \\\\n|\\\\n| \\\\nrequirements-onnx.txt\\\\n| \\\\nrequirements-onnx.txt\\\\n| \\\\n| \\\\n|\\\\n| \\\\nrequirements.txt\\\\n| \\\\nrequirements.txt\\\\n| \\\\n| \\\\n|\\\\n| \\\\nView all files\\\\n|\\\\nRepository files navigation\\\\n\\\\nREADME\\\\nApache-2.0 license\\\\n\\\\n📘 LangChain 한국어 튜토리얼\\\\n\\\\n\\\\n🌟 LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다.\\\\n본 튜토리얼을 통해 LangChain을 더 쉽고 효과적으로 사용하는 방법을 배울 수 있습니다.\\\\n📔 위키독스 전자책(무료)\\\\n\\\\n\\\\n위키독스에 무료 전자책을 등록하였습니다✌️\\\\n위키독스 페이지에서 책 \\\\\"추천\\\\\" 버튼 한 번씩만 눌러 주시면 제작에 큰 힘이 됩니다. 미리 감사 드립니다🫶\\\\n틈나는대로 열심히 업데이트 하고 있습니다. 앞으로도 신규 기능이 추가 될 때마다 빠르게 x100 업데이트 예정입니다.\\\\n\\\\n랭체인LangChain 노트 by 테디노트 구경하러 가기\\\\n\\\\n🍿 유튜브\\\\n\\\\n\\\\n🤗 huggingface 에 공개된 오픈모델을 💻 로컬PC 에서 빠르게 실행🔥 해보고 테스트 하는 방법 + 모델 서빙🚀 + 업무자동화🤖 에 적용하는 방법까지!\\\\n👀 코드 기반 답변하는 💻 GitHub 소스코드 기반 Q&A 챗봇🤖 제작기\\\\nllama3 출시🔥 로컬에서 Llama3-8B 모델 돌려보기👀\\\\n🔥성능이 놀라워요🔥 무료로 한국어🇰🇷 파인튜닝 모델 받아서 나만의 로컬 LLM 호스팅 하기(#LangServe) + #RAG 까지!!\\\\n무료로 한국어🇰🇷 파인튜닝 모델 받아서 나만의 로컬 LLM 호스팅 하기(LangServe) + RAG 까지!!\\\\nStreamlit 으로 ChatGPT 클론 서비스 제작하는 방법\\\\n대화내용을 기록하는 LLM Chain 생성 방법 + 도큐먼트 참조하는 tip!\\\\n(Self Learning GPT) LangSmith 피드백으로 원하는 형식의 답변을 학습하는 GPT\\\\n(LangServe 리뷰) 초간편 LLM 웹앱 제작 & 배포기능까지! 과연, Streamlit 대체할 수 있을까?\\\\nAI vs AI 의대 증원에 대한 모의 찬반토론 (AI 더빙본)\\\\n토론 AI 에이전트 - 의대 입학정원 증원에 대한 찬반토론을 AI 끼리 한다면?\\\\n긴 문서(long context) 에 대한 참신한 RAG 방법론: RAPTOR! 논문 리뷰와 코드를 준비했습니다\\\\nLangChain 밋업 발표 / R.A.G. 우리가 절대 쉽게결과물을 얻을 수 없는 이유\\\\n노코딩으로 쇼핑몰 리뷰 분석 (크롤링 + Q&A 챗봇)\\\\nChatGPT 의 GPTS 에 API 호출기능을 붙이면 어떻게 될까?\\\\nLangChain Agent 를 활용하여 ChatGPT를 업무자동화 에 적용하는 방법🔥🔥\\\\nPrivate GPT! 나만의 ChatGPT 만들기 (HuggingFace Open LLM 활용)\\\\nLangGraph 의 멀티 에이전트 콜라보레이션 찍먹하기\\\\n마법같은 문법 LangChain Expression Language(LCEL)\\\\n이미지를 matplotlib 파이썬 코드로, 원하는 문장을 입력하면 파이썬 코드로 변환하는 방법\\\\nRAG 파이프라인 이해해보기 - 네이버 뉴스기사 기반 Q&A 챗봇 제작\\\\nOpenAI 의 새로운 기능 Assistant API 완벽히 이해해보기\\\\nOpenAI 의 새로운 기능 Assistant API 3가지 도구 활용법\\\\n\\\\n✏️ 블로그 글 목록\\\\n\\\\nGeneral\\\\n\\\\n\\\\nOpenAI API 모델 리스트 / 요금표\\\\n\\\\nOpenAI Python API\\\\n\\\\n\\\\nOpenAI Python API 키 발급방법, 요금체계\\\\n채팅(chat) 함수 사용하기(1)\\\\nDALL·E를 사용하여 이미지 생성, 수정, 다양화하기(2)\\\\nWhisper API를 사용하여 TTS, STT 구현하기(3)\\\\n\\\\nLangChain\\\\n\\\\n\\\\nOpenAI GPT 모델(ChatOpenAI) 사용법\\\\n허깅페이스(HuggingFace) 모델 사용법\\\\n챗(chat) - ConversationChain, 템플릿 사용법\\\\n정형데이터(CSV, Excel) - ChatGPT 기반 데이터분석\\\\n웹사이트 크롤링 - 웹사이트 문서 요약\\\\n웹사이트 정보 추출 - 스키마 활용법\\\\nPDF 문서요약, Map-Reduce\\\\nPDF 기반 질의응답(Question-Answering)\\\\n문장을 파이썬 코드로, 이미지를 파이썬 코드로 변경하는 방법\\\\nLangChain Expression Language(LCEL) 원리 이해와 파이프라인 구축 가이드\\\\nLLMs를 활용한 문서 요약 가이드: Stuff, Map-Reduce, Refine 방법 총정리\\\\n자동화된 메타데이터 태깅으로 문서의 메타데이터(metadata) 생성 및 자동 라벨링\\\\n네이버 뉴스 기반 Q&A 애플리케이션 구축하기 - 기본편\\\\nRAG 파헤치기: 문서 기반 QA 시스템 설계 방법 - 심화편\\\\n에이전트(Agent)와 도구(tools)를 활용한 지능형 검색 시스템 구축 가이드\\\\n\\\\nLangGraph\\\\n\\\\n\\\\nMulti-Agent Collaboration(다중 협업 에이전트) 로 복잡한 테스크를 수행하는 LLM 어플리케이션 제작\\\\nLangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\\\\n\\\\n👥 LangChain 밋업 2024 Q1 발표자료\\\\n\\\\n\\\\nRAG - 우리가 절대 쉽게 원하는 결과물을 얻을 수 없는 이유 - 테디노트\\\\n프름프트 흐름과 LLM 모델 평가 - 이재석님\\\\n인공지능을 통한 게임 제작 파이프라인의 변화 - 김한얼님\\\\nOpenAI SORA 살짝 맛보기 - 박정현님\\\\nSemantic Kernel로 만드는 AI Copilot - 이종인님\\\\nStreamlit 과 langchain으로 나만의 웹서비스 개발하기 - 최재혁님\\\\nLlama2-koen을 만들기까지 - 최태균님\\\\n올바른 한국어 언어 모델 평가를 위해: HAE-RAE Bench, KMMLU - 손규진님\\\\n랭체인 네이버 기사 크롤링 - 우성우님\\\\nGemma와 LangChain을 이용한 SQL 체인만들기 - 김태영님\\\\n\\\\n📜 라이선스\\\\n\\\\n본 프로젝트는 Apache License 2.0에 따라 라이선스가 부여됩니다.\\\\n🚫 라이선스 고지\\\\n\\\\n🔒 본 내용의 저작권은 2024년 테디노트에 있습니다. 모든 권리는 저작권자에게 있으며, teddylee777@gmail.com 으로 문의할 수 있습니다.\\\\n```\\\\nCopyright 2024 테디노트(teddylee777@gmail.com)\\\\nLicensed under the Apache License, Version 2.0 (the \\\\\"License\\\\\");\\\\nyou may not use this file except in compliance with the License.\\\\nYou may obtain a copy of the License at\\\\nhttp://www.apache.org/licenses/LICENSE-2.0\\\\n\\\\nUnless required by applicable law or agreed to in writing, software\\\\ndistributed under the License is distributed on an \\\\\"AS IS\\\\\" BASIS,\\\\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\\\nSee the License for the specific language governing permissions and\\\\nlimitations under the License.\\\\n```\\\\n인용 및 출처 표기\\\\n\\\\n본 저작물의 내용을 블로그, 유튜브 등 온라인 매체에 인용하여 게재하는 경우, 저작권법에 따라 반드시 출처를 명시 해야 합니다.\\\\n\\\\n상업적 사용에 대한 사전 협의\\\\n\\\\n본 저작물(Wikidocs 및 관련 실습 코드 포함)을 강의, 강연 등 상업적 목적으로 활용하고자 하는 경우, 저작권자와의 사전 서면 협의가 필수적으로 요구됩니다.\\\\n\\\\n본 내용의 무단 전재 및 재배포를 금지합니다. 본 내용의 전체 혹은 일부를 인용할 경우, 출처를 명확히 밝혀주시기 바랍니다. 본 문서는 다른 문서의 내용을 참고하여 작성되었을 수 있습니다. 참고 자료는 본 문서 하단의 출처 목록에서 확인하실 수 있습니다.\\\\n📚 출처\\\\n\\\\n\\\\nlangchain-ai 📖\\\\nOpenAI API Reference 🤖\\\\n\\\\n🌐 추가 자료\\\\n\\\\n\\\\n유튜브 채널: LangChain 한국어 튜토리얼 🎥\\\\n블로그: 테디노트 📝\\\\nPlayground: LangChain LLM Playground 🎮\\\\n\\\\n🚀 시작하기\\\\n\\\\n본 튜토리얼을 시작하기 전에, LangChain과 관련된 기본적인 지식을 갖추는 것이 좋습니다. 위의 출처 링크를 통해 기본적인 정보를 얻을 수 있습니다.\\\\nStart History\\\\n\\\\n\\\\n💡 컨트리뷰션\\\\n\\\\n본 튜토리얼에 기여하고자 하는 분들은 언제든지 풀 리퀘스트를 보내주시거나, 이슈를 등록하여 의견을 공유해 주시기 바랍니다. 모든 기여는 본 프로젝트의 발전에 큰 도움이 됩니다. 💖\\\\n\\\\nAbout\\\\nLangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 본 튜토리얼을 통해 LangChain을 더 쉽고 효과적으로 사용하는 방법을 배울 수 있습니다.\\\\nwikidocs.net/book/14314\\\\nTopics\\\\ntutorial cookbook openai huggingface gpt-3 openai-api gpt-4 generative-ai chatgpt langchain chatgpt-api langchain-python\\\\nResources\\\\nReadme\\\\nLicense\\\\nApache-2.0 license\\\\nActivity\\\\nStars\\\\n1.4k stars\\\\nWatchers\\\\n37 watching\\\\nForks\\\\n407 forks\\\\nReport repository\\\\nReleases\\\\nNo releases published\\\\nPackages 0\\\\nNo packages published  \\\\nContributors 5\\\\nLanguages\\\\n\\\\nJupyter Notebook 97.8%\\\\nPython 2.0%\\\\nHTML 0.2%\\\\n\\\\nFooter\\\\n© 2025 GitHub,\\xa0Inc.\\\\nFooter navigation\\\\n\\\\nTerms\\\\nPrivacy\\\\nSecurity\\\\nStatus\\\\nDocs\\\\nContact\\\\nManage cookies\\\\nDo not share my personal information\\\\n\\\\nYou can’t perform that action at this time.\"}, {\"title\": \"#랭체인 한국어 튜토리얼 업데이트 소식 ... - YouTube\", \"url\": \"https://www.youtube.com/watch?v=mVu6Wj8Z7C0\", \"content\": \"#랭체인 한국어 튜토리얼🇰🇷 업데이트 소식🔥 처음 사용자를 위한 친절한 환경설치(Windows, Mac) \\\\n 테디노트 TeddyNote \\\\n 287 likes \\\\n 13316 views \\\\n 19 Jun 2024 \\\\n 📝 환경설정(Windows)\\\\nhttps://teddynote.com/10-RAG%EB%B9%84%EB%B2%95%EB%85%B8%ED%8A%B8/%ED%99%98%EA%B2%BD%20%EC%84%A4%EC%A0%95%20(Windows)/\\\\n\\\\n📝 환경설정(Mac)\\\\nhttps://teddynote.com/10-RAG%EB%B9%84%EB%B2%95%EB%85%B8%ED%8A%B8/%ED%99%98%EA%B2%BD%20%EC%84%A4%EC%A0%95%20(Mac)/\\\\n\\\\n📍[패스트캠퍼스] \\\\\"테디노트의 RAG 비법노트\\\\\" 강의\\\\n링크: https://bit.ly/4e1h8zO\\\\n\\\\n🤖 디스코드 채널\\\\nhttps://discord.gg/q3RvQZ5CfK\\\\n\\\\n📘 랭체인 튜토리얼 무료 전자책(wikidocs)\\\\nhttps://wikidocs.net/book/14314\\\\n\\\\n✅ 랭체인 한국어 튜토리얼 코드저장소(GitHub)\\\\nhttps://github.com/teddylee777/langchain-kr\\\\n\\\\n✅ 줄거리\\\\n00:00 랭체인 한국어 튜토리얼 공지사항\\\\n01:59 langchain-teddynote 패키지\\\\n08:25 감사인사\\\\n09:15 Windows 환경설치\\\\n21:48 Mac 환경설치\\\\n\\\\n#rag #langchain\\\\n---\\\\n📍 \\\\\"테디노트의 RAG 비법노트\\\\\" 랭체인 강의: https://fastcampus.co.kr/data_online_teddy\\\\n📘 랭체인 한국어 튜토리얼(무료 전자책): https://wikidocs.net/book/14314\\\\n📝 테디노트(깃헙 블로그) : https://teddylee777.github.io\\\\n💻 GitHub 소스코드 저장소: https://github.com/teddylee777 \\\\n 76 comments\", \"score\": 0.74273956, \"raw_content\": \"#랭체인 한국어 튜토리얼🇰🇷 업데이트 소식🔥 처음 사용자를 위한 친절한 환경설치(Windows, Mac) \\\\n 테디노트 TeddyNote \\\\n 287 likes \\\\n 13316 views \\\\n 19 Jun 2024 \\\\n 📝 환경설정(Windows)\\\\nhttps://teddynote.com/10-RAG%EB%B9%84%EB%B2%95%EB%85%B8%ED%8A%B8/%ED%99%98%EA%B2%BD%20%EC%84%A4%EC%A0%95%20(Windows)/\\\\n\\\\n📝 환경설정(Mac)\\\\nhttps://teddynote.com/10-RAG%EB%B9%84%EB%B2%95%EB%85%B8%ED%8A%B8/%ED%99%98%EA%B2%BD%20%EC%84%A4%EC%A0%95%20(Mac)/\\\\n\\\\n📍[패스트캠퍼스] \\\\\"테디노트의 RAG 비법노트\\\\\" 강의\\\\n링크: https://bit.ly/4e1h8zO\\\\n\\\\n🤖 디스코드 채널\\\\nhttps://discord.gg/q3RvQZ5CfK\\\\n\\\\n📘 랭체인 튜토리얼 무료 전자책(wikidocs)\\\\nhttps://wikidocs.net/book/14314\\\\n\\\\n✅ 랭체인 한국어 튜토리얼 코드저장소(GitHub)\\\\nhttps://github.com/teddylee777/langchain-kr\\\\n\\\\n✅ 줄거리\\\\n00:00 랭체인 한국어 튜토리얼 공지사항\\\\n01:59 langchain-teddynote 패키지\\\\n08:25 감사인사\\\\n09:15 Windows 환경설치\\\\n21:48 Mac 환경설치\\\\n\\\\n#rag #langchain\\\\n---\\\\n📍 \\\\\"테디노트의 RAG 비법노트\\\\\" 랭체인 강의: https://fastcampus.co.kr/data_online_teddy\\\\n📘 랭체인 한국어 튜토리얼(무료 전자책): https://wikidocs.net/book/14314\\\\n📝 테디노트(깃헙 블로그) : https://teddylee777.github.io\\\\n💻 GitHub 소스코드 저장소: https://github.com/teddylee777 \\\\n 76 comments \\\\n 네 안녕하세요 데데입니다 오늘 영상에서는이 랭킹인 한국어 튜토리얼 관련돼서 몇 가지 공지 사항이 있어요 그래서 그거에 대해서 말씀드리고 처음 시작하시는 분들을 위해서 환경 구축하는 튜토리얼을 제작 했거든요이 소개 영상 끝난 다음에 바로이어서 환경 구축 튜토리얼 영상을 시청하시면서 저 따라서 파이썬 설치하시고 환경 구축 하시면은 앞으로 실스 코드 진행하시는데 전혀 문제가 없으실 거라고 생각이 들어요 그래서 윈도우스 버전이랑 매고 버전이랑 같이 준비해 놨으니까 버전에 맞춰서 진행해 주시면 되겠습니다 자 우선 너무 감사하다는 말씀드리고 싶어요이 위키독스 개제한지 얼마 안 됐는데요 저희가 벌써 순위가 5등까지 올라갔더라면 많은 분들이이 랭킹인 한국어 튜토리얼 좋아해 주시고 추천도 많이 눌러 주셔서 정말 감사한 마음이고요 그 감사한 마음에 보답하고자 제가 최근에 열심히 업데이트를 하고 있습니다 마침 또 제가 최근에 강의를 런칭 했잖아요이 강의에 활용할이 위키독스 교재와 시스 코드를 업데이트 할 겸 그다음에 또 많은 분들이 봐 주시고 계시니까 최근 랭킹인 버전에 맞춰서 업데이트도 할 겸 해서 열심히 업데이트 작업을 진행 중입니다 자 그래서 여기 왼쪽에 랭킹인 시작하기 에 보시면은 그 VIP 이용한 설치 코드도 들어가 있는데요 저는 요거보다 포이트리 아는 패키지 관리자 도구를 사용해서 설치를 한 다음에 진행해 주신 거를 추천드려요 바로 뒤에이어서 설명해 드릴 거니까 그거 따라서 어 진행해 주시면 되겠고요 그리고 오픈에 키 발급하는 것도 새롭게 업데이트를 해 놨습니다요 안에 보시면은가 좀 바뀌었어요 그래서 링크랑 요런 거 변경 사항에 맞춰서 최신 코드로 업데이트를 해 놨으니까 봐 주시고 API 키 발급해 주시면 되겠고요 또 많이 질문 주신는 것 중에 하나가 바로 랭스 미스 설정이에요이 랭스 미스 설정은 생각보다 어렵지 않은데 사실 제대로 된 설명이 없는 거 같아요 그래서 설정 안 하시는 분들도 계신데요 이거 설정하시면 정말 좋아요 추적 설정하는 거 가이드에 따라서 진행한 다음에 API 키 발급만 해 주시면 되니까 그거 발급하셔야 되겠습니다 어 그밖에도 몇 가지 업데이트된 내용들이 있는데요 GPT 45 멀티모달요 내용들도 업데이트를 해 놨고요 그다음에 쭉쭉쭉쭉쭉 차례대로 업데이트된 내용들을 보실 수가 있을 거예요 향후의 아래의 내용들도 앞으로 많이 추가가 될 거니까 기대해 주셔도 좋습니다 우리 코드 저장소에 보시면은 제가 열심히 코드를 또 업데이트를 하고 있어요 하고 있는데 이번에 랭 체인 테디 노트라는 패키지를 별도로 만들었거든요 자 바로요 패키지입니다 제가 별도로 만든 패키지인데 어 랭 체인을 쓰다 보니까 몇 가지 좀 불편한 상황들이 있더라고요 그래서 그런 불편한 점들을 모아 모아서 앞으로요 패키지를 키워 나갈 예정이고요 여기에서 가령 우리가 스트리밍 출력할 때 반복문을 돌려서 출력하거나 그런 부분들이 있는데 제가 만들어 놓은 스트 리스라시르가 있어요 그리고 랭 체인 추적을 하는 것도 렇게 로깅에 랭스 미스의 프로젝트 명을 기입하면 이렇게 쉽게 작이 되고요 여기 오타도 있네요 그다음에로드 프롬프트 부분인데 윈도우 유저분들 중에서로드 프롬프트를 하실 때 오류가 나신 분들이 계십니다 그래서 그런 분들을 위해서 CP 구사하고 인코딩 하는 옵션을 제가 만들어서 추가를 해 놨어요 런 것들을 사용해 보실 수 있고요 이미 튜토리얼 안에 해당 내용들을 반영을 해 놨어요 그래서 오늘은 그 내용을 잠깐 소개해 드리려고 하는데요 먼저 설치하는 코드는요 랭 체인 테디 노트 요걸로 설치를 해 주시면 돼요 설치가 안 되어 있으신 분들은요 설치한 다음에 진행해 주시면 되고요 다음에 나오는 포트로 설정하시는 분들은 별도의 설치 없이 진행 하시면 됩니다 자 요거는 추적해 주는 도구예요 그래서 테디 노트에 로깅을 가져오셔서 로스라고스 프로젝트 명을 넣어 주시면 돼요 저는 ch01 - 베이식이 넣어봤어요 자 이걸 실행하게 되면은 렇게 추적을 시작합니다고 뜨는 거예요 요렇게 추적을 활성화해 놓은 다음에 실행되는 모든 코드들은 다 추적이 돼요 예를 들어서 하나 보여 드릴게요 자 여기에 랭 체인 추적이 잘 되고 있나요 자 이렇게 물어봤어요 요거는 여러분들이 일반적으로 알고 계신 바로 그 코드 입니다 자 요거를 한번 실행하면 이제 답변을 받아서 출력을 하게 되겠죠 렇게 답변이 나왔어요 그런데이 추적이 잘 되고 있는지 확인해 보시려면 여기 랭스 미스로 가셔서요 프로젝트에 들어가 보시면 이제 여러 가지 프로젝트 명으로 기입이 되어 있거든요 저희가 방금 ch01 다시 베이직으로 프로젝트 명을 설정했기 때문에 여기에 들어가면 됩니다 자 여기에 들어가 보시면 어 랭 체인 추적이 잘 되고 있나요라는 인풋이 보이네요 자 요걸 클릭해 보면은 인풋에 랭 체인 추적이 잘 되고 있나요 잘 추적이 되고 있는 것을 볼 수가 있죠 자 자 이번에는 저희가 추적을 다시 꺼 볼게요 자 끌 때는 여기에 셋 이네이블이라는 옵션을 스로 바꿔 주시면 돼요 바꾸고 실행하게 되면은 랭 스미스 추적을 하지 않는다라고 나와 있죠 자 이러면 추적을 하지 않고요 요거를 바꿔서 이번에는 랭 스미스 추적이 잘 되고 있습니까라고 질문을 해 볼게요 자 그러면은 요렇게 답변을 받았어요 자 아까 같으면 추적이 됐을 텐데 이번에는 전혀 추적이 안 되죠 새로 고침 한번 해 볼게요 자 추적이 안 되고 있죠 이렇게 추적 옵션 을요 셋 이네이블 옵션으로 루랑 퍼스를 바꿔 가면서 어 켜고 끌 수가 있습니다 그래서 요거를 하나 넣어 놨고요 그다음에 아래쪽으로 내려 보시면은 저희 스트리밍 출력 부분이에요 원래 같았으면이 대한민국의 아름다운 관광지 열곡과 주소를 알려 주세요요 스트리밍 출력을 받을 때요 랭 체인 문법은 이렇게 서를 받아서 각 토큰을 받아서 하나하나 다 출력을 해 줘야 돼요 그러면 요런 식으로 스트리밍 출력이 잘 되거든요 자 그런데 이렇게 반복문을 매번 쓰기가 너무 귀찮기도 하고 최종 서를 받으려면 문자열에 이렇게 그 문자를 덧셈을 통해서 누적시켜 나가서 답변을 이렇게 합산해 주는 그러한 로직이 필요합니다 그런데 그럴 필요 없이요 저는 요거를 하나 만들어 놨어요 이번에 똑같은 질문을 해 볼 건데 스트림 리스폰스는 걸 만들어 놨거든요 여기 안에다가 서를 받은 애를 넣기만 하면은 이제 스트리밍 출력이 나와요 이렇게 바로 나오죠 그래서 간편하게 써 보실 수 있도록 만들어 놓은 거고요 어 요거에 대한 리턴 값은 없어요 한마디로 출력만 하고 끝나는 겁니다 그런데요 최종 답변 있죠요 전체 답변에 대한 대해서 문자열로 받아보고 싶다 하면은 여기에다가 파이널 서라고 변수를 받아 보고요 여기 안에다 인자로 리턴 아웃풋이 아는 거를 트루로 주시면 돼요 저는 기본값으로 스로 해 놨어요 스로 해놨는데 트루로 해 주면은 자 다시 한번 실행을 해 볼게요 자 이번에도 역시 스트리밍 출력을 해주죠 해주는데이 파이널 서에 여기에 지금 작성된 답변이 담겨 있을 거예요 자 이걸 복사해서 밑에다가 셀을 하나 추가하고 프린트 구문에가 파이널 서를 출력해 보면 이전에 출력한 내용이 그대로 잘 담겨 있는 것을 볼 수가 있어요 요거를 하나 만들어 놨습니다 자 다음으로는 이제 멀티모달인터페이스 하실 때요 요렇게 이미지 주소를 입력하실 수도 있거든요요 주소를 복사를 해서 요렇게 주소창에 입력을 하면은 요런 인터넷에 떠도는 사진이에요 요거를 입력하시려면 또 파이썬 코드로 복잡하게 구현을 하셔야 되는데 저는 모델스 다가 멀티 모델이라는 클래스를 하나 구현을 해 놨어요 그러면 여러분들이 gpt4 오니로 챗 오픈의 객체를 만들어서 얘를 멀티모델 안에다가 넘겨 men 주시면 돼요 자 넘겨 주시고요 이미지 유를 넣으셔도 처리 되게끔 넣어 놨고요 혹은 로컬에 있는 png jpg 파일도 인식하게끔 넣어 놨어요 그래서 편하신 대로 URL 넣거나 파일의 경로를 넣거나 얘가 알아서 인식을 하니까 넣어 주시면 되겠고요 먼저 URL 넣었을 때 이제 스트리밍 출력을 하게 되면은 요렇게 사진이 하나가 출력이 되고요 그다음에 아래쪽에는 내용을 스트리밍 출력을 해 줍니다 그래서 이렇게 쭉 받아 보실 수가 있고요 그다음에 요것도 한번 해 볼게요 요거는 로컬에 있는 사진 파일인데요 샘플 이미지는 이미지스 폴더 안에 넣어 놨어요 요런 이미지 든요요 로컬에 있는 경로만 여기 안에다가 지정해서 넣어 주시면 돼요 그러면요 이미지가 출력이 되고요 그다음에 밑에는 이미지에 대한 설명 구들이 나오죠 그런데 제가요 구현된 내용들을 잠깐 보여 드릴게요 여기에 멀티 모달을 열어서 정의로가 보시면은이 내용들을 제가 구현을 한 거거든요 그런데 아마도 여러분들께서는 프롬프트를 바꿔 보시고 싶으실 거예요 그래서 요렇게 제가 시스템 프롬프트 유저 프롬프트를 간이로 넣어 놨거든요 제가 임의로 넣어 놓은 거죠 자 그런데 그거를 바꾸고 싶으신 분들은 요렇게 바꾸시면 돼요 뭐 가령 지금요 이미지는 뭐냐면 걸 복사해서 붙여 넣기를 하면은 재무 상태표는 이미지예요 우리가이 이미지를 이제 프롬프트로 넣어 줄 때는 재무제표 분석을 해 주세요라고 요청하는게 맞겠죠 그러면은 는 요거를 두 가지를 여러분들이 지정하셔서 넣어 주시면 되는데 시스템 프롬프트 부분에다가 뭐 페르소나 나 아니면은 역할 같은 것들을 지정해 주시면 되고요 유저 프롬프트에 어떤 거를 해야 될지 지정해 주시면 됩니다 자 렇게 시스템 프롬프트와 유저 프롬프트는 여러분들이 문자 열이니 자유롭게 바꿔서 써 보실 수가 있을 것 같아요 이렇게 지정을 해 주고요 멀티모달 이번에 생성해서 llm 넣어 주실 때 시스템 프롬프트와 유저 프롬프트 요렇게 지정해서 넣어 주시면 여러분들이 입력한 프롬프트가 자동으로 지정이 됩니다 그런 다음에 아까 그 이미지 URL 넣어 주시게 되면은 이제 재무제 를 가져온 다음에 우리의 새롭게 지정한 지시 사항들에 맞춰서 얘가 답변을 해 주는 것을 확인해 볼 수가 있어요 자 이걸 사용하게 되면은 어떤 이미지들도 굉장히 쉽게 GPT 45를 사용해서 이렇게 텍스트 형식으로 답변을 받아서 구현이 필요한 방향대로 구현을 해 보실 수가 있으니깐요 그렇게 한번 써 먹어 보시기 바랍니다 앞으로 신규 기능이 있을 때마다이 랭 체인 테드 노트라는 패키지에가 아래 사용법에 추가해 놓을 예정이라서 여기에서 확인해 주시면 될 거 같아요 끝으로 여러분들이 많이 구독해 주시고 영상도 봐 주시고 공유해 주신 덕분에 제 강의까지 제작할 수 있게 되었습니다 사실 뭐 제가 잘라서 제작했다고 절대 생각하지 않아요 저보다 훌륭하신 분들도 많고 한데요 제가 남들보다 개발 실력이 뛰어나다는 아니지만 좀 어려운 내용들을 쉽게 풀어서 설명해 드리는 거를 그래도 소질이 있다라고 생각을 합니다 그래서 강의 제작을 했다라고 생각해 주시면 감사할 것 같아요 어 여러분들 덕분에 제가 이렇게 강의까지 런칭을 했는데 정말 다시 한번 감사하다는 말씀드리고요 앞으로도 유튜브에 도움이 되는 내용들 열심히 업로드하도록 하겠습니다 앞으로 업데이트되는이 랭 아인 노트도 많이 사랑해 해주시길 바랍니다 자 그러면이어서 처음 사용자를 위한 환경 설정 영상 나가니깐 환경 설정이 필요하신 분들은 따라서 진행해 주시면 되겠습니다 오늘 영상이 여기까지였습니다 감사합니다 그럼 윈도우스 환경 설정을 한번 진행해 보도록 할게요 여기에 작성되어 있는 환경 설치 매뉴얼대로 그대로 따라만 하시면 됩니다 자 제가 원활한 진행을 위해서 그 윈도우를 아예 아마존 인스턴스에서 띄워 가지고 깔끔하게 초기화된 그 윈도우 그 상태를 지고 왔어요 그래서 처음 하시는 분들도 어 부담없이 진행해 보실 수 있도록 환경을 아예 똑같이 구성을 해 왔습니다 그래서 여기서 따라해 주시면 되는데요 먼저 저희가 이제 깃 설치부터 진행을 하도록 하겠습니다 여기에 있는이 주소를 복사를 해서 엣지를 열어 가지고요 여기에다가 붙여 넣기 그래서 들어가면은 여기에 보시면은 이제네 가지 옵션이 나와 있어요이 중에서 스탠드 홀론 인스톨러 64비트 짜리를 설치해 주시면 되겠습니다 자 요거를 눌러서 오픈 해 주시면은 요렇게 설치하는 창이 떠요 넥스트 버튼 눌러 주시고요 넥스트 여기에서 어라고 되어 있는 에더 배시 프로파일 2 윈도우스 터미널 체크박스 해주시고요 그다음에 넥스트 넥스트 넥스트 넥스트 쭉 눌러 주시면 됩니다 나머지는 전부 다 넥스트에 이렇게 해서 설치를 한번 기다려 볼게요네 릴리스 노트 안 봐도 되니까 요거 체크박스 해제한 다음에 피니시 눌러 주시면 되겠습니다 자 다음 과정으로 한번 넘어가 보죠 여기 밑에 요거를 전부 다 설치를 했고요 그다음에 윈도우스 키를 눌러서 파워을 반드시 관리 자원으로 실행을 해서 기술 입력해서 아래 이미지처럼 뜨는지 확인해 주시면 됩니다 자 파워은정 권한으로 윈도우스 파워을 실행시켰는데 같이 진행 해 볼 건데 명령어를 입력하라고 돼 있으니까 명령어 한번 입력해 보도록 할게요 눌러서 렇게 뜨면 됩니다 뭐라고 뭐라고 이렇게 저처럼 똑같이 뜨면 돼요 자 다음으로는 밑으로 쭉 내려 볼게요 내려서 py를 설치할 건데요 여기에 나와 있는이 명령어를 복사를 해서 여기에다가 클리어해 줄 건데 CLS 누르면은 클리어가 돼요 CLS n 클리어해 주는 명령하니 어 출력을 깔끔하게 정리하고 싶으신 분들은 CLS 눌러주시면 되고요 자 여기다가 마우스 우클릭을 해서 붙여 넣기를 하면 됩니다이 터미널 창에 붙여 넣기를 할 적에 컨트롤 V 다 마우스 우클릭 잘 먹거든요 그래서 마우스 클릭으로 이렇게 붙여 넣으시면 되고요 엔터 눌러 볼게요 누르면은 이제 py를 어 깃에서 클론에서 가져옵니다 자 그다음에 이제 환경 변수를 추가해 줄 건데 여기에 있는 세 개 복사해서 여기에다가 우클릭 해주고 엔터 눌러 주시면 되겠고요 그다음에요 아래 있는 내용도 복사를 해서 여기다가 우클릭 엔터 눌러 주시면 되겠습니다 다음으로는 pyb 명령어를 쳐서 잘 동작하는지 볼 거예요 자 우리 깔끔하게 다시 한번 초기해 볼게요 CLS 눌러서 엔터키 이렇게 오시면 어 여기에 pyv 명령어를 입력해 주시면은 자 처음에 좀 오래 걸릴 수가 있어요 어 pyv 찍었는데 요게 뭐 오류가 나면서 제대로 안 뜨죠 이런 경우에는이 파워을 끕니다 꺼요 그다음에 여기에다가 다시 파워셀 입력을 해주고요 우클릭해서 R AS 어드미니스트레이터 요거를 클릭을 해주고 다시 한번 입력해 볼게요 PB 자 이제는 제대로 뜨죠 혹시라도 명령어를 입력해서 적용이 안 됐다 하시는 분들은 방금처럼 파워쉘을 껐다가 다시 관리자 권한으로 실행해서 켜주시면 됩니다 자 그러면 뜨는 것까지 확인 됐으니까 다시 깔끔하게 출력 지워 볼게요 CLS 눌러서 지워 보시고 고요 아 혹시라도이 파워쉘을 하시다가 오류가 나신 분들은 여기 있는 요거 있죠 명령어 복사해서 어 여기다가 이제 붙여 넣으시면 돼요 이렇게 붙여 넣어서 적용까지 해 주신 다음에 혹시라도 그래도 안 된다 그러면 껐다가 켜서 다시 한번 해 보시기 바랍니다 자 다음으로는 이제 파이썬 설치를 해 볼 건데 py는 파이썬의 여러 가지 버전을 내가 골라서 선택할 수 있도록 도와주는 도구예요 저희는이 3.11 버전 3.11 버전으로 모든 실습 코드들이 만들어져 있기 때문에이 3.11 버전에 맞춰서 설치해 보도록 하겠습니다 해서 여기에다가 우클릭 실행네 3.11.0 버전이 설치가 완료가 됐죠 자 다음으로 한번 넘어가 볼게요 pyb 글로벌에 3.1을 하게 되면은 전역으로 3.11 버전을 설정을 해 주는 거예요 요거를 복사를 해서 여기다가 붙여 넣고요 글로벌로 설정을 해 주도록 하겠습니다 자 그다음에 파이썬의 빼기 빼기 버전 자 이렇게 입력해 보시면 저희가 3.1.9 버전이 떠야지 정상이다 이렇게 보시면 되겠습니다 자 다음으로는 우리가 포에트리 아는 거를 설치를 해 볼 거예요이 포에트리 파이썬 패키지 관리 도구인데 이제 파이썬 패키지 관리 도구에 대해서 익숙하지 않으신 분들도 계실 것 같아요 요거는 뭐냐면 저희가 이제 랭 체인이라 거 할 때는 굉장히 많은 패키지들을 설치를 합니다 뭐 PDF 문서 로드하는 거 다양한 llm 굉장히 설치하는게 많아요 그런데이 각각의 의존성이 있어요 뭐 예를 들어서 a 아는 패키지가 3.10 버전을 써야 되는데 B 아는 패키지는 뭐 3.11 버전을 써야 되고 막 이렇게 각각 요구 사항들이 다 는 거죠 그래서이 의존성을 우리가 각각 맞춰서 설치를 하려면 굉장히 머리가 아파요 우리가 하나하나 설치할 때는이 모든 패키지들이 서로 충돌이 일어나지 않도록 버전 설치를 해 줘야 되거든요 근데 우리가 이제 아나콘다 가상환경으로 요거를 진행했을 때에는 다 각각 설치를 하겠다는 거예요 그런데 이렇게 하면은 사실 의존성이 깨져 가지고 뭐가 안 돼요 저게 안 돼요 하신 분들이 많이 나오실 것 같아서 이번에는 제가 포에트리 만들어서 이제 배포를 하게 됐습니다요 포이트리 설치하면 제가 모든 버전에 대해서 의존성 해결을 한게 올라가기 때문에 여러분들이 그냥 요거 명령 하나만 입력하시면 바로 되고요 일단 포에트리 설치부터 한번 해 볼게요 자 요거를 복사해서 여기다가 붙여 넣고 pip 3 인스톨 포에트리 자 설치가 됐죠 다시 출력값 한번 지어 볼게요 CLS 지어 봤고요 그다음에는 어 우리 도큐먼트로 갈 거예요 처음 하시는 분들은 뭐 폴더를 다른 곳으로 지정하면 경로 설정에 오류가 있고 이래서 저희가 다 맞춰 보도록 하겠습니다 만약에 다른 경로에 그 실스 코드를 다운로드 받고 싶다 하시는 분들은 여기에 나와 있는요 폴더 경로를 바꿔 주시면 돼요 저희는 도큐먼츠 폴더는 무조건 있으니까 요거를 복사를 해서 여기에 붙여 넣고 이동을 해 볼게요 그러면 도큐먼트 폴더로 현재 이동이 되어 있는 상태입니다 여기에다가 우리 실스 코드를 받을 거예요 여기 밑에 나와 있는요 코드를 복사가 붙여 넣기 하고 엔터 눌러 주시면은 최신 코드들이 자동으로 다운로드가 받아집니다 기시하는 명령어를 그것 때문에 설치를 한 거예요 나중에 제가 실스 코드를 업데이트를 하더라도 여러분들께서요 풀이라는 명령으로 최신 코드로 받아보실 수도 있어요 자 여기까지 해서 이제 받았고요 그러면 랭 체인 빼 KR이라는 폴더가 생성이 됐습니다 여기에 가서 LS 아는 명령어를 입력해 보시면 여기 랭 체인 KR이라는 폴더 요거 디렉토리 든요 폴더가 새롭게 생성이 됐어요이 디렉토리 안쪽으로 진입을 하려면 CD 한 다음에 CD 체인지 디렉토리 한 다음에 한 칸 띄고요요 폴더 명을 주시면 돼요 랭 체인 KR 이렇게 입력을 하면은 랭 체인 KR 안쪽으로 진입을 했고 LS 입력해 보면은요 안에 있는 폴더 목록들이 이제 뜰 겁니다 자 여기에 보시면은 이제 포에트리 락이랑 파이 프로젝트 투물요 파일이 이제 어 패키지 관리를 도와주는 그런 파일인데요 저희가 여기서 이제 얼마나 간단하면 포에트리 셀이라는 명령어로 바로 가상환경 설정이 가능해요 자 여기에 CLS 한번 깔끔하게 초기화를 해 줄게요 자요 상태에서 포에트리 쉘 입력을 하면은 가상환경을 얘가 생성을 하게 됩니다 저희는 파이썬 11 버전에 파이썬을 선택해 놨기 때문에 자동으로 파이썬 11 버전의 가상환경을 만들어서 여기 왼쪽에 보시면은 이제 가상환경이 활성화된 것을 볼 수가 있죠 우리는 여기 환경에다 새롭게 어 파이썬 패키지들을 설치를 쫙 다 해 줄 거예요 지금 현재는 아무것도 설치가 안 돼 있습니다 pip 리스트라는 명령어를 입력해 보시면 아마도 비어 있을 거예요 뭐 요거 하나 정도 한두 개 정도만 설치가 되어 있는데 우리가 필요한 패키지들이 엄청 많거든요 그거를 하나하나 설치하는게 아니라이 포에트리 업데이트라는 명령으로 최신 패키지로 업데이트까지 해 줄 거예요 자 요거를 우클릭해서 포에트리 업데이트라는 명령을 입력하고 엔터를 눌러 주시면 쫙 다 설치가 될 겁니다 자요 설치하는 과정에서 패키지들을 워낙 많이 설치하다 보니까 시간이 좀 오래 걸리실 수 있어요네 오래 걸려서 드디어 설치가 완료가 됐습니다 자 다시 출력값을 지워 볼게요 CLS 눌러서 소개를 해 주고요 VIP 리스트라고 입력을 해 보시면 설치된 파이썬 패키지들이 전부 다 보이실 거예요 자 이렇게 많이 설치가 되어 있죠 자 그다음에는 저희 비주얼 스튜디오 코드 설치로 바로 한번가 볼게요 여기 다운로드 링크를 넣어 놨거든요 요거 링크를 쭉 복사해서 엣지로 한번 가보 습니다 자 여기다가 비주얼 스튜디오 코드 다운로드 사이트로 가면은 윈도우스니까 윈도우스 버전을 다운로드 해 볼게요 거 눌러서 기다리면 금방 다운로드가 시작될 거예요네 다운로드가 완료가 됐습니다 요거 비주얼 스튜디오 코드를 한번 설치를 해 볼 건데 자 여기 어트 어그리먼트 눌러 주시고 넥스트 넥스트 그다음에 넥스트 저는 데스크톱 아이콘을 하나 만들게요 요거 체크 표시해주고 넥스트 인스톨 자 런치 비주얼 스튜디오 코드가 떴습니다 피니시 버튼을 눌러서 열어 주시면 됩니다 자 렇게 떴고 뭐 테마 같은 경우에는네 가지 중에 원하시는 테마를 설치하시면 됩니다 이렇게 눌러 주시고 저는 나머지 거는 전부 다 필요가 없어서 마크 던을 누르고 종료를 해 줄게요 자 요거를 x 표시 눌러 주시고요 그다음에 오픈 폴더를 눌러서 우리가 다운로드 받은 실습 코드 쪽으로가 볼게요 여기에 도큐먼트는 부분에 랭 체인 빼 KR요 폴더가 진입을 해서 폴더 선택을 해서 셀렉트 폴더를 눌러서 열어 주시면은 되고요 요런 창이 처음에 뜨실 거예요 그러면요 체크박스를 눌러 주시고 예스 버튼을 눌러 주시면 됩니다 자 그러면은 이제 설치는 완료가 됐는데 자 여기서 끝이 아니에요 왼쪽에 익스텐션가 보시면은 저희가 두 가지를 설치를 할 겁니다 첫 번째로는 파이썬을 검색을 해 가지고 파이썬을 설치를 해 줄 거고요 첫 번째 나오는요 마이크로소프트에서 어 개발한요 파이썬이 아는 거 있죠 요거를 인스톨 버튼 눌러서 설치를 해 주도록 하겠습니다 자 설치가 완료가 됐고요 그다음에는 저희가 주피터 검색을 해 볼게요 주피터고 검색을 하셔서 나오는 첫 번째 거 있죠 요거 79 밀리언짜리 인스톨 버튼 눌러서 설치해 줄게요 자 설치가 완료가 됐습니다 웰컴 창을 전부 다 닫아 주시고 왼쪽에 있는요 베이직 있죠 요거를 열어서 보시면 이제 실스 파일들이 로드가 될 거예요 그죠 자 렇게 나오는데 그 전에 오른쪽 상단에 보시면은 파이썬 3.1.9 잡혀 있거든요 이러면 안 됩니다 요거는 우리가 만든 환경이 아니에요 요거를 누르셔서 파이썬 3.1 11.9 요게 아니라 셀렉트 another 너이고 버튼을 눌러 보세요 그다음에 파이썬 인먼 요거를 눌러 보시고 그러면은 우리가 만든 가상환경이 지금 안 뜨네요 안 뜨는 문제가 있습니다요 우측 상단에 새로고침을 눌렀는데도 만약에 안 뜬다 하시면은이 비주얼 스튜디오를 닫았다가 다시 열어 주시면 돼요 자 여기 닫았다가 다시 한번 열어 보겠습니다 자 디텍팅 널스라이프 바먼트 자 이제 뜹니다 저희 랭 체인 빼 KR 어쩌고 저쩌고 요거는 다 다를 거예요 아마 여러분들 다를 건데 랭 체인 빼 KR 시작하는 요놈이 앞으로 여러분들께서 쭉 사용하실 그런 파이썬 가상 환경이다라고 보시면 됩니다 자 요거를 눌러서 코너를 활성화시켜 주시고요 그다음에로드 실행해 주시면 되는데 지금 emb 파일이 없어요 embb 파일이 없기 때문에 요게 스가 뜨죠 자이 embb 파일은 여기 맨 아래쪽에 있는 EM 언더바 샘플이라는 파일이 있는데 저희가 API 키를 세팅을 안 해서 그래요 그래서 저희 어떻게 할 거냐면 얘를 복사해 페이스트 하면은 이렇게 카피본이 만들어집니다 얘를 우 그 우클릭을 하셔 가지고 리네임 하실 수가 있어요 리네임 해서 점 env.env 앞에 점이 붙습니다 요거를 엔터키를 눌러서 설정해 주시면 되고 제가 예제들을 좀 넣어 놨어요 넣어 놨는데 나머지 거를 일단 당장은 안 쓸 거라서 지워 볼게요 그리고 얘를 저장을 해보겠습니다 자 여기에서도 보시면은이 동글뱅이 떴다는 것은 저장이 안 되었다는 거예요 반드시 여러분들이 저장을 해 주셔야 됩니다 그래서 컨트롤 s 를 눌러 주시면 이제 동굴 뱅이가 사라지죠 그러면 저장이 됐다라는 뜻이에요 여러분들이 발급받은 오픈에 API 키를 여기다가 넣어 주시고 저장을 해 주시면 되겠고요 그다음에 01 빼기 베이직 폴더에 가서요 API 키를 가져와서 자 얘를 이렇게 실행하면 루라고 뜨죠 그러면은 다 enb 파일이 인식이 됐다라는 거고요 자 거를 실행해서 잘 나오는지 확인해 주시면 돼요 저는 아직 키를 안 넣었기 때문에 지금 제대로 안 떴는데 만약에 여러분들이 키를 제대로 넣으셨으면 올바르게 뜰 겁니다 그다음부터는 여러분들이 별도의 설치 없이 가시면 되는데요 다른 파일을 열었을 때 또 셀렉트 커널리 아고 뜨죠 이번에는 자동 완성을 제공할 거예요 요거를 눌러 보시면 바로 상단에 저희가 최근 사용했던 환경이 뜹니다 요걸 클릭을 해서 걸 실행하고 그다음에 얘도 실행하고 이렇게 하시면 돼요 자 그래서 렇게 밑에 쭉 진행하시면 아마도 무리없이 될 거 같습니다 여기까지 윈도우 윈도우 환경 설치 어 한번 같이 진행을 해 봤습니다 이번에는 맥 OS 유저분들을 위해서 환경 설정을 진행해 보도록 하겠습니다 먼저 OS 환경 설정은 터미널을 여는 것으로부터 시작을 합니다 스파트 라이트에 가시면 되는데요 스파트 라이트는 우측 상단에 독보기 모양을 클릭하시는 ka 아니면 커맨드 스페이스를 눌러서 터미널이라고 입력을 해 주시면 돼요 자 여기에서 이제 홈브루를 설치를 할 거예요 그런데 만약에 여기에 여러분들이 부루라고 명령어를 입력을 해서 저는 이미 설치가 되어 있거든요 근데 여러분들도 저처럼 이미 설치가 되어 있는 것처럼 나오면 전부 다 스킵을 하셔도 됩니다요 설치하는 과정을 스킵하셔도 돼요 그런데 저는 설치가 안 되 있다는 가정하에 한번 진행해 보도록 하겠습니다 자 여기에 브루를 설치하는 명령어가 있어요 요거를 복사를 해서 여기다가 붙여 넣기를 해 줄게요 붙여 넣기 하실 때에는 커맨드를 눌러서 붙여 넣기 해 주시면 됩니다 자 이러면은 비밀번호를 입력하라고 나오는데요 비밀번호는 여러분들이 그 로그인할 때 쓰시는 비밀 번호 있죠 그거를 입력해 주시면 되고요 그다음에 엔터 키를 입력해서 확인을 해 주시면 됩니다 자 설치가 다 됐습니다 자 여기에 클리어라는 명령어를 주시면요 화면을 깔끔하게 정리해 주는 명령어 클리어 줘서 깔끔하게 정리를 해주고요 자 다음으로는 유저 네임을 확인해 볼 차례입니다 자 유저 네임은 계정 인데라고 입력을 해 준 다음에 엔터키를 치면 계정 명이 뜨게 돼요 그래서 E2 유저가 지금 현재의 제 계정 명이라고 보시면 됩니다 자 요거를 꼭 기억해 주시고요 밑에 보시면은 이제 부루의 위치를 다시 한번 확인할 거예요 부루의 위치는 위치 부루 요렇게 입력해 주시면 됩니다 위치 부루 요거를 입력해서 엔터키를 눌러 보시면이 부르가 실행되고 있는 위치가 나오게 돼요 그래서 요거를 기억해 놨다가 어디다가 복사 붙여 넣게 해서 저장하고 계시면 돼요 그래서 두 가지죠 계정의 이름과 그다음에 부르가 실행되고 있는 위치요 두 가지를 꼭 기억해 주세요 자 다음으로는요 두 가지를 통해서 우리가 명령을 조합을 해 볼 건데요 지금 여기에 보시면은 케이스 1이 있고 케이스 2가 있습니다 우리 부르가 보통은 여기에 깔려 있거나 아니면은 여기에 깔려 있거나 둘 중에 한 군데에 깔려 있을 거예요 그래서 여러분들이 선택해서 진행을 해 주시면 되는데요 어 저의 경우에는요 케이스 2에 해당하고 개인용 맥북 같은 경우에는 케이스 1에 해당이 됐어요 그래서 여러분들의 상황에 따라 좀 달라질 수 있어서 두 가지 케이스를 드립니다 자 그러면 제가 확인해 봤더니요 두 번째 케이스에 해당이 되네요 그러면 저는 요거를 선택하면 되겠고요 자 얘를 어떻게 보시면 요거를 그냥 복사해서 입력하는게 아니라요 케이스 2인 경우에는요 명령어를 택하는 거예요 그런데 여기서 또 하나 여기 홈이라고 되어 있는 부분에 저희가 방금 확인했었던 계정명 있죠 요거를 넣어 주시는 거예요 한마디로 정리하면 이렇게 되는 겁니다 메모장에 여러분들이 그 복사를 하셔서요 어 나는 두 번째 케이스니 요거를 복사를 해서 자 여기다가 넣어 줄래 이렇게 완성을 해 주시고요 그다음에 내가 쓰는 계정 명은 아까 확인을 해봤더니 아 요게 내 계정명이 있구나 요거를 복사를 해서 여기 홈이라는 부분에다가 렇게 바꿔 껴 주시면 되는 거예요 자 그러면 요렇게 명령어가 완성이 되네요 요거를 복사를 해서 여기에다가 이제 붙여 넣어 주시면 되는 거예요 자 됐죠 그다음에 넘어갈게요 코드 설치 확인인요 자 엑스코드 설치 확인은 요거 복사를 해서 여기다가 붙여 넣으면은 이제 설치가 만약에 되어 있으면 이미 설치가 되었다라고 나올 거예요 다음으로 넘어가 주시면 됩니다 자 다음으로는 우리 실습 코드 다운로드 할 건데요 깃이 설치가 되어 있는지 아니면 설치가 안 되었는지 확인을 해 주셔야 됩니다 자 요것도 굳이 설치가 되 있는데 또 설치하실 필요가 없어요 그래서 어떻게 확인 하시냐면 자 일단 클리어라는 명령어로 깔끔하게 정리를 한번 해 보겠습니다 여기에다가 기시하는 명령어를 주시고요 저처럼 이렇게 뜨면은 이미 기시 설치가 된 거예요 그런데 만약에 기시이 설치가 안 돼 있으면요 브루 인스톨기로 설치를 해 주시면 됩니다 자 얘를 명령을 복사를 해서 전는 이미 설치가 되어 있지만 한 번 더 설치를 해 볼게요 자 여기다가 붙여 놓고 실행을 하면은 한 번 더 설치가 진행이 될 겁니다 자 요렇게 이미 설치가 되어 있다라고 나오죠 자 다음으로는 기세 버전 한번 확인해 볼게요 복사를 해서 자 여기다가 붙여 넣고요 버전을 확인해 보면 2.45.2 버전이 설치된 걸 보 보 수가 있는데 여러분들의 버전과 제 버전이 맞지 않아도 전혀 상관없어요 그냥 설치만 되어 있는지만 확인해 주시면 되겠습니다 자 클리어 버튼을 눌러 가지고 다시 한번 깔끔하게 리셋을 해 주고요 그다음에 실스 코드를 다운로드 받아 볼게요 저이 처음 하시는 분들은 이제 경로가 바뀌거나 하면은 되게 그것 때문에 많이 고생을 하세요 그래서 이왕이면은 저와 경로를 맞춰 주시는 거를 권장 드리고요 이미 익숙하신 분들은 얼마든지 다른 경로에 설치하셔도 됩니다 자이 실스 코드 다운로드를 위해서이 도큐먼트는 폴더로 이동을 해 볼게요 자요 명령어를 복사를 해서 자 여기다가 CD 도큐먼트 이동을 하게 되면은 현재 도큐먼트 폴더로 이동을 했습니다 여기에 LS 아는 명령어를 주시면 현재 도큐먼트 안에 어떤 파일들이 있는지 나오는데 저는 아무런 파일도 없기 때문에 지금 아무것도 안 띄는 거예요 이렇게 보시면 되고요 자 이제 클론이라는 명령어을 통해서 저희 업로드되어 있는 실스 코드를 다운로드 받아 볼게요 자이 명령어를 복사를 해서 자 여기다가 붙여 넣고 엔더 키를 누르면은 이제 소스 코드를 다운로드를 받게 됩니다 금방 받죠 자 다운로드가 완료가 됐고요 밑으로 쭉 내려서 다음 명령어를 입력해서 폴더 안쪽으로 진입을 해 볼게요 자 여기서 이제 CD 아는 명령어를 쓰는데요 CD n 체인지 디렉토리 해서 폴더 이동을 합니다 자 그다음에 여기에 랭 체인 KR 엔터키를 주면은 랭 체인 KR 폴더로 이동해 있는 것을 볼 수가 있죠 다시 한번 클리어 명령어를 줘서 깔끔하게 정리를 해 주고요 여기에 LS 아는 명령어를 주시게 되면은 자 이제 여기에 저희가 다운로드 받은 실스 코드들이 쭉 나와 있는 것을 확인해 볼 수가 있습니다 자 다음으로는 우리 pyem 설치를 해 볼 건데요 여러분들은 블루를 방금 설치하셨으면 업데이트 하실 필요가 없겠죠 그래서요 명령어만 입력하시면 되고요 브루를 기존에 설치되어 있으셨던 분들은 부루 업데이트를 해 주신 다음에 그다음에 설치해 주신 것을 권장드립니다 자 저 저는 아까 설치를 했기 때문에요 두 번째 명령어만 복사를 해서 여기에다가 붙여 넣기 해 줄게요 자 이러면은 py를 설치를 해 주게 되는 거고요이 piy는 뭐냐면 파이썬의 버전을 선택해서 실행할 수 있게끔 도와주는 도구예요 그래서 py를 통해서 저희는 파이썬의 어떤 특정 버전을 설정을 해 줄 겁니다 자 이렇게 기다리는 동안에 설치가 완료가 됐고요 클리어라는 명령어을 줘서 다시 한번 깔끔하게 정리를 해 줄게요 그다음에어요 아래의 내용 있죠 요거를 복사를 해서요 여기다가 붙여 넣기를 해주고 엔터 키를 눌러서 환경 변수 설정을 해주도록 하겠고요 그다음에요 명령어를 입력을 해서 터미널 쇠를 재시작하고 하겠습니다 자 재시작이 됐어요 다시 한번 클리어 줘서 깔끔하게 정리를 해 줄게요 다음으로는 우리 파이썬 버전을 설치해 줄 차례인데 저희가 방금 설치한 py로 특정 버전을 설치해 줄 거예요 저희는 3.1.9 버전을 설치를 해 줄 겁니다 이렇게 3.11이라고 입력하면 3.11.0 버전이 설치가 될 거예요 요거를 복사를 해서 여기에다가 붙여 넣기를 해 주고요 그다음에 설치를 기다려 보도록 할게요네 이제 3.1.9 버전이 설치가 됐습니다 여기 노 모듈 임들 어쩌고저쩌고 뜨는데 괜찮아요 무시하시고 넘어가셔도 됩니다 나중에 필요하면 저희가 따로 설치해 주시면 돼요 자 여기까지 되셨으면 이제 클리어 버튼을 눌러서 어 깔끔하게 정리를 한번 해 주고요 자 그다음에 저희가 저역 설정으로 버전을 지정을 해 줄 거예요 자 이거는 파이썬 전역으로 3.1.9 버전을 디폴트로 설정을 해 주는 거예요 자 요거를 복사를 해서 여기다 붙여 놓고 설정을 해 주고요 다음으로는 큐트 zsh 해 가지고 터미널 실행 해 줄게요 자 그다음에 파이썬의 버전을 한번 확인해 보겠습니다 요거를 복사를 해서 버전 확인해 보면은 현재 전역 설정으로 설정된 파이썬의 버전이 3.11.0 버전이다 이렇게 확인해 볼 수가 있어요 자 다음으로는 포이트리 설치입니다 포이트리 파이썬의 패키지 관리를 도와주는 도구예요 저희가 랭 체인을 배우게 되면은 굉장히 많은 파이썬 패키지들을 설치하게 되어 있거든요 뭐 문서 로드부터 시작해서 l&m이나 뭐 그 밖에 기타 등등 다양한 기능들을 써야 되니까 여러 패키지들을 설치하게끔 되어 있어요 그런데 이렇게 여러 패키지를 설치할 경우에 가장 크게 나타나는 문제 중에 하나가 바로 패키지의 충돌입니다 그런데이 패키지의 충돌이 일어나지 않도록 잘 관리 주는게 바로 포에트리 아는 파이썬 패키지 관리자 얘는 의존성이란 거를 적절하게 해결을 해 줌으로써 서로 패키지들을 설치함에 있어서 충돌이 일어나지 않도록 도와주는 도구예요 우리가 아나콘다 가상환경을 사용해 가지고 각각을 설치하게 되면은 충돌이 일어나는 경우가 굉장히 많거든요 그래서 이거 설치했더니 저게 안 되고 저거 설치했더니 이게 또 안 되고 막 그런 경우들이 굉장히 많아요 때로는 설치가 안 될 때도 많고요 그런데 우리는 포에트리는 걸 설치해서 제가 직접 여러분들을 위해서 모든 의존성을 해결됨 그 버전들을 배포를 해 드릴 거예요 그러면 여러분들은 명령어 요거 업데이트라는 명령어 하나로 이미 의존성이 깔끔히 해결된 파이썬 패키지들을 받아보실 수가 있어요 그리고 추후에이 파이썬 패키지의 버전이 업데이트 되더라도 여러분들은 포에트리 업데이트라는 명령어 하나만 입력해 주시면 깔끔하게 오류가 나지 않도록 업데이트를 해 주기도 합니다 자 그래서 저희 pp3 인스톨 포트로 여기에다가 입력을 해서 설치를 해 줄게요 자 설치가 완료됐고 클리어라는 버튼을 눌러서 깔끔하게 초기화를 해 주시면 됩니다 자 그다음에 다운로드 받은 폴 폴더로 이동을 할 거예요 여기에 LS고 입력하면 저희가 이미 폴 폴더 안쪽으로 들어와 있는 상태죠 만약에이 폴더로 들어와 있지 않으신 분들이라면 CD 물결 슬래시 한 다음에 도큐먼트 그다음에 랭 체인 KR 요걸로 입력해 주시면요 폴더로 이동을 할 겁니다 자 다시 클리어 버튼을 눌러 주시고요 자 여기에다가 우리가 포에트리 셀이라는 명령어을 줘서 이제 파이썬 가상환경이란 걸 만들어 보도록 하겠습니다 자 이렇게 만들어졌고요 자 왼쪽에 보시면은 체인이라는 파이썬 가상환경이 만들어졌어요요 공간은 저희가 프로젝트를 하기 위한 별도의 공간이라고 보시면 돼요 그래서 우리가 이파 성 가상 환경에다 필요한 패키지들을 전부 설치할 예정입니다 자 설치하는 코드는 요거 한 줄이면 끝나요 포에트리 a 업데이트라고 입력을 해 주시게 되면은 저희가 필요한 모든 패키지들을 설치하게 됩니다 자 드디어 끝났습니다 축하드립니다 이렇게나 많은 패키지들이 다 설치가 문제 없이 완료가 됐어요 여기다가 클리어 명령어를 주시고요 VIP 리스트라는 명령어를 주시게 되면은 우리가 현재 설치된 패키지 목록들을 쭉 보실 수가 있어요 우리가 이제 랭 체인을 쓰게 되면서이 패키지들을 대부분 다 쓰시게 될 겁니다 자 이렇게 간단하게 설치가 완료가 됐고요 다음 으로는 비주얼 스튜디오 코드를 설치하러 갈 차례예요 여기에 있는 다운로드 링크를 복사를 해서 크롬을 열어 줄게요 여기에다가 주소 창에 붙여 넣고 여기에 다운로드 받을 수 있는 옵션들이 뜨죠 저는 맥이기 때문에 맥 S 이렇게 눌러서 다운로드를 받아 볼게요 다운로드가 받아줬고요 다운로드 받은 폴더를 열어 볼게요 자 요렇게 다운로드가 받아져 있는 집 파일이 하나 보이실 거예요 집 파일 하나 보이시죠요 압축 파일을 해제해 줄게요 자 압축 파일을 해제를 했습니다 이제이 파일을 드래그 앤 드랍을 어디로 할 거냐면 어플리케이션 스라는 공간에다가 렇게 드래그 앤 드랍을 해 줄게요 그러면 여기 하단에 비주얼 스튜디오 코드가 추가 됐고요 비주얼 스튜디오 코드가 잘 추가가 되어 있죠 자 요거를 눌러 가지고 열어 줄게요 자 요렇게 나오면은 오픈 버튼 눌러서 열어 주시면 됩니다 자 이렇게 떴어요 요거를 조금만 확대를 해 볼게요 자 이제 테마를 선택하는 창이 나오는데 여러분들이 좋아하시는 테마에 맞게 선택을 해 주시면 돼요 그다음에 나머지 것들은 그대로 두시 맨 아래쪽에 마크 던이라는 표시가 있어요 요걸 눌러서 꺼 주시면 돼요 자 웰컴 단 종료해 주시고 왼쪽에 하나 둘 셋 넷 다섯 개의 메뉴가 있거든요 먼저 다섯 번째 익스텐션 메뉴를 눌러서 열어 주신 다음에 두 개를 설치를 할 거예요 첫 번째로는 파이썬이 검색을 해 보시면은 가장 상단에 위치한 요놈 있죠 126m 다운로드가 있는 요거를 인스톨 버튼을 눌러서 설치를 해주실게 자 설치가 됐죠 그다음에 요거를 지워 주시고요 주피터 아고 입력을 해 볼게요 자 그런 다음에 첫 번째로 나오는요 79m짜리 있죠 얘를 인스톨 버튼 눌러서 설치를 해 주시면 됩니다 자 설치가 다 됐습니다 자 이제 두 개다 꺼 보시고요 그다음에 첫 번째 익스플로러요 메뉴를 눌러서 오픈 폴더라고 나와 있어요 요거를 클릭을 해서 저희가 다운로드 받은 폴더가 도큐먼트는 폴더입니다 여기에 랭배 KR 선택해 주신 다음에 오픈 버튼 눌러서 열어 주시면 돼요 자 그러면 요런 창이 뜰 건데요 여기 왼쪽에 체크박스를 눌러 주시고 파란색 버튼을 눌러 주시면 됩니다 자 이러면 세팅이 완료가 됐어요요 웰컴 창 닫아 주셔도 좋고요 왼쪽에 보이시는요 01 - 베이직에요 01 파일이 있습니다 01번 자 요거를 열어 주시면 돼요 자 그러면 이렇게 뜨거든요 그럼 그런데 우측 상단에 보시면은 셀렉트 커널이 아는 메뉴가 보이실 거예요 요거를 클릭을 해서 파이썬 인먼 그걸 눌러 주시면 되는데요 자 여기에 저희가 설치한 가상환경이 지금 안 뜹니다 여기에는 아무것도 사실 설치가 안 되어 있는 환경들이 든요 그래서 저희가 힘들게 설치한 그 가상환경을 불러와야 되는데 우측 상단에요 새로 고친 버튼이 있거든요 요걸 눌러서 만약에 뜬다면 다행이지만 지금 저도 안 뜹니다 그러면은이 비주얼 스튜디오 창을 한번 닫아 볼게요 이렇게 X 표를 눌러서 일단 끄겠습니다 끄고요 자 얘를 다시 한번 실행을 해 줄게요 실행을 해서 자 왼쪽 상단에 익스플로러에 오픈 폴더를 다시 한번 눌러서 우리 도큐먼츠 폴더 있죠 요거에 랭 체인 백기 KR 눌러서 열어 줄게요 자 다시 열렸습니다 그러면은 얘가 우측에 뱅글뱅글 돌면서 뭔가 일을 하고 있는 거 같아요 여기에 셀렉트 코너를 다시 한번 눌러 보시죠 자 그다음에 파이썬 바먼트 눌러서 자 이제 별표로 뜨죠 우리 레커맨드 해 가지고 우리가 만든 가상환경이 뜹니다 자 요거를 선택해 주시는 거예요 그래서 랭 체인 빼 KR 시작하는 가상환경을 선택해 주시면 되고요 앞으로 여러분들 를 무조건 요걸로 진행해 주시면 돼요 그리고 밑에 내려 보시면은 요라고 나와 있는 요거 셀을 실행해 보시면 스라고 뜰 겁니다 자 요거 실행하는 거는요 왼쪽에 있는 요거 요거를 눌러서 실행해 주시면 되죠 퍼스트로 뜨는 이유는 여러분들이 이제 오픈 a GPT 키 있죠 오픈 a API 키를 설정을 안 해서 그런데 그 키는 어디서 설정하시는 거냐면 여기 왼쪽에 아래로 내려보시면 .bb 언더바 샘플이라고 나와 있어요 자 얘를 오른쪽 클릭하셔 가지고 카피 그다음에 여기다가 페이스트 하시면은 카피본이 하나 만들어지거든요 자 얘를 오른쪽 클릭하셔서 리네임 버튼 눌러 주시면 이름을 바꿀 수가 있는데 점을 붙여 주시고 env.env 파일입니다 요렇게 바꿔 주실까요 그러면 여러분들은 앞으로 키를이 .bb 파일에다가 세팅을 해 주시는 거예요 제가 여기에 예제로 넣어 놨거든요 저희가 처음에는 다른 키 값들은 일단 다 지워 보도록 하겠습니다 자 이거를 전부 다 지워 주시고요 그리고 오픈에 API 키만 남겨 주시면 되는데이 오픈의 API 키는 API 키 발급받는 사이트에서 발급받아 주시면 되고 저희 체인 토리얼 위키독스도 발급받는 방법 나와 있습니다 그러면 키값이 나올 건데요 저는 요거 샘플로 그냥 진행을 해 볼게요 자 여기에 여러분들이 이걸 지우시고 여기다가 이제 키값을 붙여 넣기 해 주시면 되는 거예요 그다음에 요거를 수정하거나 그러면은 여기 상단에 보시면 동글뱅이 뜨죠 이거는 아직 해당 파일이 저장되지 않았다라는 뜻이에요 그래서 여러분들이 반드시 저장을 해 주셔야 되는데 맥에서는 저장하는 버튼이 커맨드 S 그래요 자 이렇게 커맨드 S 눌러서 저장하면 동글뱅이 사라집니다 자 요거를 전부 다 닫아 주시고요 자 그다음에 여기 01 01 파일에 다시 오셔가 시고 리스타트 버튼을 한번 눌러 볼게요 리스타트는 초기화를 해 주시는 거고요 자 그다음에 다시 셀을 실행을 해주실게 자 실행하는 거 요거 클릭해서 실행하셔도 되고요 자 실행을 하면은 이제 트라고 뜨죠 그럼 저희가 입력한 키가 정상적으로 잘 인식이 됐다라는 뜻입니다 그다음에요 다음에 있는 셀을 실행을 해 가지고 저희 키값이 잘 나오는지 확인해 주시면 됩니다 저는 이제 제대로 된 키를 안 넣어서 지금 별표 밖에 출력이 안 되는데 아마 여러분들이 제대로 설정을 하셨으면 키플러스 별표 이렇게 뜰 거예요 그래서 그렇게 확인해 주시면 되고요 저희 02번 8일부터는 동 동일하게 진행하시면 되는데 여기 우측 상단에 파일을 바꿀 때 보시면 셀렉트 커널이 아고 안 잡혀 있어요 얘를 다시 클릭해 보시면 저희가 최근 사용한 파이썬 가상환경이 뜹니다 요거를 그냥 바로 선택해 주시면 돼요 그런 다음에 요거 실행하고 실행하고 요런 식으로 진행하시면 되는 거죠 그래서 아래도 쭉쭉쭉쭉쭉 실행하시면 됩니다 아마도 여러분들께서 입력하실 코드는 따로 없으실 거예요 그래서 실행만 하더라도 제대로 나와야 정상이다 이렇게 보시면 되겠습니다 자 그러면 여기까지 저희 맥에서 그 환경 설정하는 거 같이 한번 알아봤습니다 [음악] t\"}, {\"title\": \" - LangChain 한국어 튜토리얼 - WikiDocs\", \"url\": \"https://wikidocs.net/book/14314\", \"content\": \"대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL) 01. 구조화된 출력 체인(with_structered_output) CH15 평가(Evaluations) 01. 온라인 평가를 활용한 평가 자동화 CH16 에이전트(Agent) 01. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH17 LangGraph 01. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 - shcheon99@naver.com, Jan. 9, 2025, 12:28 p.m. 출력된 결과를 비교했을 때, kiwi tokenizer을 사용한 결과와 kkma, okt 를 사용한 결과가 큰 차이가 없다고 봐도 되는 건가요? CH01 LangChain 시작하기 - NamHyeon, Dec. 8, 2024, 1:17 p.m. 좋은 자료를 무료로 공유해 주셔서, 감사한 마음에 \\'테디노트의 RAG 비법노트\\' 강의 등록했습니다 ! 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) - Jan. 16, 2025, 12:23 a.m. 멀티 에이전트 감독자(Multi-Agent Supervisor) - Dec. 23, 2024, 3:04 a.m. 계층적 멀티 에이전트 팀(Hierarchical Multi-Agent Teams) - Dec. 23, 2024, 3:04 a.m.\", \"score\": 0.7316155, \"raw_content\": \"<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 - WikiDocs\\\\n<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기 01. 설치 영상보고 따라하기 02. OpenAI API 키 발급 및 테스트 03. LangSmith 추적 설정 04. OpenAI API 사용(GPT-4o 멀티모달) 05. LangChain Expression Language(LCEL) 06. LCEL 인터페이스 07. Runnable CH02 프롬프트(Prompt) 01. 프롬프트(Prompt) 02. 퓨샷 프롬프트(FewShotPromptTemplate) 03. LangChain Hub 04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers) 01. Pydantic 출력 파서(PydanticOutputParser) 02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser) 03. 구조화된 출력 파서(StructuredOuputParser) 04. JSON 출력 파서(JsonOutputParser) 05. 데이터프레임 출력 파서(PandasDataFrameOutputParser) 06. 날짜 형식 출력 파서(DatetimeOutputParser) 07. 열거형 출력 파서(EnumOutputParser) 08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model) 01. 다양한 LLM 모델 활용 02. 캐싱(Cache) 03. 모델 직렬화(Serialization) - 저장 및 불러오기 04. 토큰 사용량 확인 05. 구글 생성 AI(Google Generative AI) 06. 허깅페이스 엔드포인트(HuggingFace Endpoints) 07. 허깅페이스 로컬(HuggingFace Local) 08. 허깅페이스 파이프라인(HuggingFace Pipeline) 09. 올라마(Ollama) 10. GPT4ALL 11. 비디오(Video) 질의 응답 LLM (Gemini) CH05 메모리(Memory) 01. 대화 버퍼 메모리(ConversationBufferMemory) 02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory) 03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) 04. 대화 엔티티 메모리(ConversationEntityMemory) 05. 대화 지식그래프 메모리(ConversationKGMemory) 06. 대화 요약 메모리(ConversationSummaryMemory) 07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory) 08. LCEL Chain 에 메모리 추가 09. SQLite 에 대화내용 저장 10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader) 01. 도큐먼트(Document) 의 구조 02. PDF 03. 한글(HWP) 04. CSV 05. Excel 06. Word 07. PowerPoint 08. 웹 문서(WebBaseLoader) 09. 텍스트(TextLoader) 10. JSON 11. Arxiv 12. UpstageLayoutAnalysisLoader 13. LlamaParser CH07 텍스트 분할(Text Splitter) 01. 문자 텍스트 분할(CharacterTextSplitter) 02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter) 03. 토큰 텍스트 분할(TokenTextSplitter) 04. 시멘틱 청커(SemanticChunker) 05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등) 06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter) 07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter) 08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding) 01. OpenAIEmbeddings 02. 캐시 임베딩(CacheBackedEmbeddings) 03. 허깅페이스 임베딩(HuggingFace Embeddings) 04. UpstageEmbeddings 05. OllamaEmbeddings 06. GPT4ALL 임베딩 07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore) 01. Chroma 02. FAISS 03. Pinecone CH10 검색기(Retriever) 01. 벡터스토어 기반 검색기(VectorStore-backed Retriever) 02. 문맥 압축 검색기(ContextualCompressionRetriever) 03. 앙상블 검색기(EnsembleRetriever) 04. 긴 문맥 재정렬(LongContextReorder) 05. 상위 문서 검색기(ParentDocumentRetriever) 06. 다중 쿼리 검색기(MultiQueryRetriever) 07. 다중 벡터저장소 검색기(MultiVectorRetriever) 08. 셀프 쿼리 검색기(SelfQueryRetriever) 09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever) 10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 11. Convex Combination(CC) 적용된 앙상블 검색기(EnsembleRetriever) CH11 리랭커(Reranker) 01. Cross Encoder Reranker 02. Cohere Reranker 03. Jina Reranker 04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG) 01. PDF 문서 기반 QA(Question-Answer) 02. 네이버 뉴스기사 QA(Question-Answer) 03. RAG 의 기능별 다양한 모듈 활용기 04. RAPTOR: 긴 문맥 요약(Long Context Summary) 05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL) 01. RunnablePassthrough 02. Runnable 구조(그래프) 검토 03. RunnableLambda 04. LLM 체인 라우팅(RunnableLambda, RunnableBranch) 05. RunnableParallel 06. 동적 속성 지정(configurable_fields, configurable_alternatives) 07. @chain 데코레이터로 Runnable 구성 08. RunnableWithMessageHistory 09. 사용자 정의 제네레이터(generator) 10. Runtime Arguments 바인딩 11. 폴백(fallback) 모델 지정 CH14 체인(Chains) 01. 문서 요약 02. SQL 03. 구조화된 출력 체인(with_structered_output) CH15 평가(Evaluations) 01. 합성 테스트 데이터셋 생성(RAGAS) 02. RAGAS 를 활용한 평가 03. 생성한 평가용 데이터셋 업로드(HuggingFace Dataset) 04. LangSmith 데이터셋 생성 05. LLM-as-Judge 06. 임베딩 기반 평가(embedding_distance) 07. 사용자 정의(Custom) LLM 평가 08. Rouge, BLEU, METEOR, SemScore 기반 휴리스틱 평가 09. 실험(Experiment) 평가 비교 10. 요약(Summary) 방식의 평가 11. Groundedness(할루시네이션) 평가 12. 실험 비교(Pairwise Evaluation) 13. 반복 평가 14. 온라인 평가를 활용한 평가 자동화 CH16 에이전트(Agent) 01. 도구(Tools) 02. 도구 바인딩(Binding Tools) 03. 에이전트(Agent) 04. Claude, Gemini, Ollama, Together.ai 를 활용한 Agent 05. Iteration 기능과 사람 개입(Human-in-the-loop) 06. Agentic RAG 07. CSVExcel 데이터 분석 Agent 08. Toolkits 활용 Agent 09. RAG + Image Generator Agent(보고서 작성) 10. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH17 LangGraph 01. 핵심 기능 01. LangGraph 에 자주 등장하는 Python 문법이해 02. LangGraph를 활용한 챗봇 구축 03. LangGraph를 활용한 Agent 구축 04. Agent 에 메모리(memory) 추가 05. 노드의 단계별 스트리밍 출력 06. Human-in-the-loop(사람의 개입) 07. 중간단계 개입 되돌림을 통한 상태 수정과 Replay 08. 사람(Human)에게 물어보는 노드 추가 09. 메시지 삭제(RemoveMessage) 10. ToolNode 를 사용하여 도구를 호출하는 방법 11. 병렬 노드 실행을 위한 분기 생성 방법 12. 대화 기록 요약을 추가하는 방법 13. 서브그래프 추가 및 사용 방법 14. 서브그래프의 입력과 출력을 변환하는 방법 15. LangGraph 스트리밍 모드의 모든 것 02. 구조 설계 01. 기본 그래프 생성 02. Naive RAG 03. 관련성 체커(Relevance Checker) 모듈 추가 04. 웹 검색 모듈 추가 05. 쿼리 재작성 모듈 추가 06. Agentic RAG 07. Adaptive RAG 03. Use Cases 01. 에이전트 대화 시뮬레이션 (고객 응대 시나리오) 02. 사용자 요구사항 기반 메타 프롬프트 생성 에이전트 03. CRAG(Corrective RAG) 04. Self-RAG 05. 계획 후 실행(Plan-and-Execute) 06. 멀티 에이전트 협업 네트워크(Multi-Agent Collaboration Network) 07. 멀티 에이전트 감독자(Multi-Agent Supervisor) 08. 계층적 멀티 에이전트 팀(Hierarchical Multi-Agent Teams) 09. SQL 데이터베이스와 상호작용하는 에이전트 10. STORM 개념을 도입한 연구를 위한 멀티 에이전트 CH18 기타 정보 01. StreamEvent 타입별 정리\\\\nPublished with WikiDocs\\\\n\\\\n\\\\n<랭체인LangChain 노트> - Lang…\\\\n\\\\n\\\\n도서 증정 이벤트 !!\\\\n\\\\nWikiDocs\\\\n\\\\n<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷\\\\n\\\\nAuthor: 테디노트\\\\nLast edited by : Jan. 16, 2025, 12:23 a.m.\\\\nCopyright : \\\\n2,553 Like; \\\\\"추천\\\\\")\\\\n추천은 공유할 수 있는 무료 전자책을 집필하는데 정말 큰 힘이 됩니다. \\\\\"추천\\\\\" 한 번씩만 부탁 드리겠습니다🙏🙏\\\\n✅ 랭체인 한국어 튜토리얼 강의\\\\n패스트캠퍼스 - RAG 비법노트\\\\n✅ 랭체인 한국어 튜토리얼 코드저장소(GitHub) 📘🖥️\\\\nhttps://github.com/teddylee777/langchain-kr\\\\n✅ 유튜브 \\\\\"테디노트\\\\\" 🎥📚\\\\nhttps://www.youtube.com/c/@teddynote\\\\n✅ 데이터 분석 블로그 https://teddylee777.github.io\\\\n✅ 문의 teddylee777@gmail.com\\\\nLICENSE\\\\n인용 및 출처 표기\\\\n\\\\n본 저작물을 블로그, 유튜브 등 온라인 매체에 인용하여 게재할 경우, Creative Commons Attribution-NonCommercial-NoDerivs 2.0 Korea 라이선스에 따라 반드시 출처를 명시해야 합니다.\\\\n\\\\n상업적 사용에 대한 사전 협의\\\\n\\\\n본 저작물(Wikidocs 및 관련 실습 코드 포함)을 강의, 강연 등 상업적 목적으로 활용하고자 하는 경우, 저작권자와의 사전 서면 협의가 필수적으로 요구됩니다. 해당 협의는 teddylee777@gmail.com으로 문의하여 진행하실 수 있습니다.\\\\n\\\\n본 저작물은 2024년 테디노트에 의해 작성되었습니다. \\\\n모든 권리는 저작권자에게 있으며, 본 저작물은 Creative Commons Attribution-NonCommercial-NoDerivs 2.0 Korea 라이선스에 따라 배포됩니다.\\\\n본 저작물의 무단 전재 및 재배포를 금지하며, 전체 혹은 일부를 인용할 경우 출처를 명확히 밝혀주시기 바랍니다.\\\\n본 문서는 다른 문서의 내용을 참고하여 작성되었을 수 있습니다. 참고 자료는 본 문서 하단의 출처 목록에서 확인하실 수 있습니다.\\\\nCopyright (c) 테디노트.\\\\nReference\\\\n\\\\nLangChain Github\\\\nLangGraph Github\\\\nLangChain Document\\\\n\\\\nRecent Comments (8) Recent Modifications (10) RSS\\\\n02. 네이버 뉴스기사 QA(Question-Answer) - 김민겸, Feb. 2, 2025, 12:17 p.m.\\\\n\\\\\"bullet points 형식으로 정리\\\\\"에서 \\\\\"주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다.\\\\\" 라고 나오는데 이유를 알려주실 수 있나요? kmk582@naver.com\\\\n10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 - shcheon99@naver.com, Jan. 9, 2025, 12:28 p.m.\\\\n출력된 결과를 비교했을 때, kiwi tokenizer을 사용한 결과와 kkma, okt 를 사용한 결과가 큰 차이가 없다고 봐도 되는 건가요?\\\\nCH01 LangChain 시작하기 - NamHyeon, Dec. 8, 2024, 1:17 p.m.\\\\n좋은 자료를 무료로 공유해 주셔서, 감사한 마음에 \\'테디노트의 RAG 비법노트\\' 강의 등록했습니다 ! 물론 제 현업에 필요한 기술이라서, 강의 또한 기쁜 마음에 신청했구요 ~ 정주행 해서, 창공을 날아가 보겠습니다 ^^\\\\n06. Word - Paul, Oct. 27, 2024, 5:38 p.m.\\\\npython-docx도 설치해야 할까요?\\\\n10. JSON - Paul, Oct. 27, 2024, 5:37 p.m.\\\\n!pip install jq 부분이 들어가야 할 것 같습니다.\\\\n02. PDF - Paul, Oct. 27, 2024, 3:29 p.m.\\\\n<html><head> <meta http-equiv=\\\\\"Content-Type\\\\\" content=\\\\\"text/html\\\\\"> </head><body> <span style=\\\\\"position:absolute; border: gray 1px solid; left:0px; top:50px; width:612px; height:858px;\\\\\"></span> <div style=\\\\\"position:absolute; top:50px;\\\\\"><a name=\\\\\"1\\\\\">Page 1</a></div> <div style=\\\\\"position:absolute; border 이 부분이 출력 결과가 아니라 코드인 것처럼 표시되어 있네요~\\\\n12. UpstageLayoutAnalysisLoader - Paul, Oct. 27, 2024, 10:59 a.m.\\\\n감사히 잘 참고하고 있습니다. 아주 사소한 오기이지만... 11번 Arxiv 다음에 12번이 와야 할 텐데, 원래 넣으시려던 다른 목차가 빠진 것인지 바로 13번이 나왔네요^^\\\\n03. 모델 직렬화(Serialization) - 저장 및 불러오기 - 동구, Sept. 20, 2024, 12:58 p.m.\\\\nloads는 뭐에요?\\\\n10. JSON - Jan. 16, 2025, 12:23 a.m.\\\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\\\n03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) - Jan. 16, 2025, 12:23 a.m.\\\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\\\n05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등) - Jan. 16, 2025, 12:19 a.m.\\\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\\\n04. Self-RAG - Dec. 23, 2024, 3:48 a.m.\\\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\\\n10. STORM 개념을 도입한 연구를 위한 멀티 에이전트 - Dec. 23, 2024, 3:16 a.m.\\\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\\\n03. CRAG(Corrective RAG) - Dec. 23, 2024, 3:04 a.m.\\\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\\\n05. 계획 후 실행(Plan-and-Execute) - Dec. 23, 2024, 3:04 a.m.\\\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\\\n07. 멀티 에이전트 감독자(Multi-Agent Supervisor) - Dec. 23, 2024, 3:04 a.m.\\\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\\\n08. 계층적 멀티 에이전트 팀(Hierarchical Multi-Agent Teams) - Dec. 23, 2024, 3:04 a.m.\\\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\\\n09. SQL 데이터베이스와 상호작용하는 에이전트 - Dec. 23, 2024, 3:04 a.m.\\\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\\\n\\\\nNext : CH01 LangChain 시작하기\\\\n\\\\n\\\\n×\\\\n책갈피\\\\n추가 닫기\\\\n\\\\n×\\\\nLeave feedback on this page\\\\nEmail address to reply to\\\\nWhat you want to say\\\\n※ Feedback is delivered to the author by email.\\\\nClose Send\"}]', name='tavily_web_search', id='c4a28abd-de21-4d8b-91b9-a537de67f8ec', tool_call_id='call_RET6frawe4cNUfaxgLEPlIKD'),\n",
       "  AIMessage(content='랭체인 한국어 튜토리얼에 대한 정보는 여러 출처에서 확인할 수 있습니다. 주요 출처는 다음과 같습니다:\\n\\n1. **GitHub - teddylee777/langchain-kr**: 이 저장소는 LangChain의 공식 문서, Cookbook, 그리고 다양한 실용 예제를 바탕으로 작성된 한국어 튜토리얼을 제공합니다. 이 튜토리얼을 통해 LangChain을 더 쉽고 효과적으로 사용하는 방법을 배울 수 있습니다. [GitHub 링크](https://github.com/teddylee777/langchain-kr)\\n\\n2. **YouTube - 테디노트**: 테디노트는 LangChain 한국어 튜토리얼의 업데이트 소식과 환경설치 방법 등을 동영상으로 제공합니다. [YouTube 링크](https://www.youtube.com/watch?v=mVu6Wj8Z7C0)\\n\\n3. **WikiDocs - LangChain 한국어 튜토리얼**: WikiDocs에서는 LangChain의 다양한 기능과 사용법을 한국어로 설명하는 전자책을 제공합니다. [WikiDocs 링크](https://wikidocs.net/book/14314)\\n\\n이 자료들은 LangChain을 처음 접하는 사용자부터 고급 사용자까지 모두에게 유용한 정보를 제공합니다. 각 링크를 통해 더 자세한 내용을 확인할 수 있습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 284, 'prompt_tokens': 23042, 'total_tokens': 23326, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_90122d973c', 'id': 'chatcmpl-BQ6a6BnUEoW6DUovhiegBTYtPV9Oi', 'finish_reason': 'stop', 'logprobs': None}, id='run-17b35fae-7953-450f-b344-69488ef110a7-0', usage_metadata={'input_tokens': 23042, 'output_tokens': 284, 'total_tokens': 23326, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 상태 정의\n",
   "id": "c6755e4d4dbb67c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T06:12:57.884359Z",
     "start_time": "2025-04-25T06:12:57.878378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import operator\n",
    "from typing import Annotated, List, Tuple\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "# 상태 정의\n",
    "class PlanExecute(TypedDict):\n",
    "    input: Annotated[str, \"User's input\"]\n",
    "    plan: Annotated[List[str], \"Current plan\"]\n",
    "    past_steps: Annotated[List[Tuple], operator.add]\n",
    "    response: Annotated[str, \"Final response\"]"
   ],
   "id": "a54e9f57bde72309",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 계획(Plan) 단계",
   "id": "cd956b0945b83e8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T06:13:16.711082Z",
     "start_time": "2025-04-25T06:13:16.704790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "# Plan 모델 정의\n",
    "class Plan(BaseModel):\n",
    "    \"\"\"Sorted steps to execute the plan\"\"\"\n",
    "\n",
    "    steps: Annotated[List[str], \"Different steps to follow, should be in sorted order\"]"
   ],
   "id": "8fc7a1dbfdd10e28",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T06:13:29.258733Z",
     "start_time": "2025-04-25T06:13:28.517352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 계획 수립을 위한 프롬프트 템플릿 생성\n",
    "planner_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"For the given objective, come up with a simple step by step plan. \\\n",
    "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
    "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
    "Answer in Korean.\"\"\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "planner = planner_prompt | ChatOpenAI(\n",
    "    model=MODEL_NAME, temperature=0\n",
    ").with_structured_output(Plan)"
   ],
   "id": "abcfdaf2ff6795bd",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T06:13:39.594957Z",
     "start_time": "2025-04-25T06:13:38.289414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Planner 실행\n",
    "planner.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\n",
    "                \"user\",\n",
    "                \"LangGraph 의 핵심 장단점과 LangGraph 를 사용하는 이유는 무엇인가?\",\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    ")"
   ],
   "id": "af5b2014a55e6021",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Plan(steps=['LangGraph의 정의와 목적을 이해한다.', 'LangGraph의 주요 장점을 나열한다.', 'LangGraph의 주요 단점을 나열한다.', 'LangGraph를 사용하는 이유를 설명한다.'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 재계획(Re-Plan) 단계",
   "id": "d863d183ff3ec732"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T06:14:19.576932Z",
     "start_time": "2025-04-25T06:14:18.882442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "class Response(BaseModel):\n",
    "    \"\"\"Response to user.\"\"\"\n",
    "\n",
    "    # 사용자 응답\n",
    "    response: str\n",
    "\n",
    "\n",
    "class Act(BaseModel):\n",
    "    \"\"\"Action to perform.\"\"\"\n",
    "\n",
    "    # 수행할 작업: \"Response\", \"Plan\". 사용자에게 응답할 경우 Response 사용, 추가 도구 사용이 필요할 경우 Plan 사용\n",
    "    action: Union[Response, Plan] = Field(\n",
    "        description=\"Action to perform. If you want to respond to user, use Response. \"\n",
    "        \"If you need to further use tools to get the answer, use Plan.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# 계획을 재수립하기 위한 프롬프트 정의\n",
    "replanner_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"For the given objective, come up with a simple step by step plan. \\\n",
    "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
    "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
    "\n",
    "Your objective was this:\n",
    "{input}\n",
    "\n",
    "Your original plan was this:\n",
    "{plan}\n",
    "\n",
    "You have currently done the follow steps:\n",
    "{past_steps}\n",
    "\n",
    "Update your plan accordingly. If no more steps are needed and you can return to the user, then respond with that. Otherwise, fill out the plan. Only add steps to the plan that still NEED to be done. Do not return previously done steps as part of the plan.\n",
    "\n",
    "Answer in Korean.\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# Replanner 생성\n",
    "replanner = replanner_prompt | ChatOpenAI(\n",
    "    model=MODEL_NAME, temperature=0\n",
    ").with_structured_output(Act)"
   ],
   "id": "ce2b4cc6addab2e8",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 그래프 생성\n",
   "id": "897e989ad76a4f33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T06:14:32.459604Z",
     "start_time": "2025-04-25T06:14:31.673823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "# 사용자 입력을 기반으로 계획을 생성하고 반환\n",
    "def plan_step(state: PlanExecute):\n",
    "    plan = planner.invoke({\"messages\": [(\"user\", state[\"input\"])]})\n",
    "    # 생성된 계획의 단계 리스트 반환\n",
    "    return {\"plan\": plan.steps}\n",
    "\n",
    "\n",
    "# 에이전트 실행기를 사용하여 주어진 작업을 수행하고 결과를 반환\n",
    "def execute_step(state: PlanExecute):\n",
    "    plan = state[\"plan\"]\n",
    "    # 계획을 문자열로 변환하여 각 단계에 번호를 매김\n",
    "    plan_str = \"\\n\".join(f\"{i+1}. {step}\" for i, step in enumerate(plan))\n",
    "    task = plan[0]\n",
    "    # 현재 실행할 작업을 포맷팅하여 에이전트에 전달\n",
    "    task_formatted = f\"\"\"For the following plan:\n",
    "{plan_str}\\n\\nYou are tasked with executing [step 1. {task}].\"\"\"\n",
    "    # 에이전트 실행기를 통해 작업 수행 및 결과 수신\n",
    "    agent_response = agent_executor.invoke({\"messages\": [(\"user\", task_formatted)]})\n",
    "    # 이전 단계와 그 결과를 포함하는 딕셔너리 반환\n",
    "    return {\n",
    "        \"past_steps\": [(task, agent_response[\"messages\"][-1].content)],\n",
    "    }\n",
    "\n",
    "\n",
    "# 이전 단계의 결과를 바탕으로 계획을 업데이트하거나 최종 응답을 반환\n",
    "def replan_step(state: PlanExecute):\n",
    "    output = replanner.invoke(state)\n",
    "    # 응답이 사용자에게 반환될 경우\n",
    "    if isinstance(output.action, Response):\n",
    "        return {\"response\": output.action.response}\n",
    "    # 추가 단계가 필요할 경우 계획의 단계 리스트 반환\n",
    "    else:\n",
    "        next_plan = output.action.steps\n",
    "        if len(next_plan) == 0:\n",
    "            return {\"response\": \"No more steps needed.\"}\n",
    "        else:\n",
    "            return {\"plan\": next_plan}\n",
    "\n",
    "\n",
    "# 에이전트의 실행 종료 여부를 결정하는 함수\n",
    "def should_end(state: PlanExecute):\n",
    "    if \"response\" in state and state[\"response\"]:\n",
    "        return \"final_report\"\n",
    "    else:\n",
    "        return \"execute\"\n",
    "\n",
    "\n",
    "final_report_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are given the objective and the previously done steps. Your task is to generate a final report in markdown format.\n",
    "Final report should be written in professional tone.\n",
    "\n",
    "Your objective was this:\n",
    "\n",
    "{input}\n",
    "\n",
    "Your previously done steps(question and answer pairs):\n",
    "\n",
    "{past_steps}\n",
    "\n",
    "Generate a final report in markdown format. Write your response in Korean.\"\"\"\n",
    ")\n",
    "\n",
    "final_report = (\n",
    "    final_report_prompt\n",
    "    | ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "def generate_final_report(state: PlanExecute):\n",
    "    past_steps = \"\\n\\n\".join(\n",
    "        [\n",
    "            f\"Question: {past_step[0]}\\n\\nAnswer: {past_step[1]}\\n\\n####\"\n",
    "            for past_step in state[\"past_steps\"]\n",
    "        ]\n",
    "    )\n",
    "    response = final_report.invoke({\"input\": state[\"input\"], \"past_steps\": past_steps})\n",
    "    return {\"response\": response}"
   ],
   "id": "249fcf7843b78fe8",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 그래프 생성",
   "id": "d52c932d1bff820b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T06:15:11.305440Z",
     "start_time": "2025-04-25T06:15:11.202127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "\n",
    "# 그래프 생성\n",
    "workflow = StateGraph(PlanExecute)\n",
    "\n",
    "# 노드 정의\n",
    "workflow.add_node(\"planner\", plan_step)\n",
    "workflow.add_node(\"execute\", execute_step)\n",
    "workflow.add_node(\"replan\", replan_step)\n",
    "workflow.add_node(\"final_report\", generate_final_report)\n",
    "\n",
    "# 엣지 정의\n",
    "workflow.add_edge(START, \"planner\")\n",
    "workflow.add_edge(\"planner\", \"execute\")\n",
    "workflow.add_edge(\"execute\", \"replan\")\n",
    "workflow.add_edge(\"final_report\", END)\n",
    "\n",
    "# 조건부 엣지: replan 후 종료 여부를 결정하는 함수 사용\n",
    "workflow.add_conditional_edges(\n",
    "    \"replan\",\n",
    "    should_end,\n",
    "    {\"execute\": \"execute\", \"final_report\": \"final_report\"},\n",
    ")\n",
    "\n",
    "# 그래프 컴파일\n",
    "app = workflow.compile(checkpointer=MemorySaver())"
   ],
   "id": "e69b3fb67b7ae2c8",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 그래프 실행\n",
   "id": "ab73f1e9b06e9d40"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T06:16:10.269801Z",
     "start_time": "2025-04-25T06:15:20.692960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_teddynote.messages import invoke_graph, random_uuid\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "config = RunnableConfig(recursion_limit=50, configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "inputs = {\n",
    "    \"input\": \"Modular RAG 가 기존의 Naive RAG 와 어떤 차이가 있는지와 production level 에서 사용하는 이점을 설명해줘\"\n",
    "}\n",
    "\n",
    "invoke_graph(app, inputs, config)"
   ],
   "id": "768ab66933f39763",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mplanner\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Modular RAG와 Naive RAG의 정의를 각각 설명한다.\n",
      "Modular RAG의 구조적 특징을 설명한다.\n",
      "Naive RAG의 구조적 특징을 설명한다.\n",
      "Modular RAG가 Naive RAG와 비교하여 가지는 장점을 설명한다.\n",
      "Production level에서 Modular RAG를 사용할 때의 이점을 설명한다.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36magent\u001B[0m in [\u001B[1;33mexecute\u001B[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "1. **Modular RAG (Retrieval-Augmented Generation)**:  \n",
      "   Modular RAG는 정보 검색과 생성 모델을 결합하여 정보를 생성하는 시스템입니다. 이 시스템은 검색 모듈과 생성 모듈로 구성되어 있으며, 검색 모듈은 외부 데이터베이스에서 관련 정보를 검색하고, 생성 모듈은 검색된 정보를 바탕으로 자연어 응답을 생성합니다. 이러한 모듈화된 접근 방식은 각 모듈을 독립적으로 최적화할 수 있는 유연성을 제공합니다.\n",
      "\n",
      "2. **Naive RAG (Retrieval-Augmented Generation)**:  \n",
      "   Naive RAG는 기본적인 형태의 RAG 시스템으로, 검색과 생성 과정을 단순히 결합한 형태입니다. 이 시스템은 검색된 정보를 그대로 생성 모듈에 전달하여 응답을 생성합니다. 구조적으로 단순하며, 모듈 간의 상호작용이 깊이 있게 설계되지 않은 것이 특징입니다. \n",
      "\n",
      "이 두 가지 정의는 RAG 시스템의 기본적인 개념을 이해하는 데 도움을 줍니다.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mexecute\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "('Modular RAG와 Naive RAG의 정의를 각각 설명한다.', '1. **Modular RAG (Retrieval-Augmented Generation)**:  \\n   Modular RAG는 정보 검색과 생성 모델을 결합하여 정보를 생성하는 시스템입니다. 이 시스템은 검색 모듈과 생성 모듈로 구성되어 있으며, 검색 모듈은 외부 데이터베이스에서 관련 정보를 검색하고, 생성 모듈은 검색된 정보를 바탕으로 자연어 응답을 생성합니다. 이러한 모듈화된 접근 방식은 각 모듈을 독립적으로 최적화할 수 있는 유연성을 제공합니다.\\n\\n2. **Naive RAG (Retrieval-Augmented Generation)**:  \\n   Naive RAG는 기본적인 형태의 RAG 시스템으로, 검색과 생성 과정을 단순히 결합한 형태입니다. 이 시스템은 검색된 정보를 그대로 생성 모듈에 전달하여 응답을 생성합니다. 구조적으로 단순하며, 모듈 간의 상호작용이 깊이 있게 설계되지 않은 것이 특징입니다. \\n\\n이 두 가지 정의는 RAG 시스템의 기본적인 개념을 이해하는 데 도움을 줍니다.')\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mreplan\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Modular RAG의 구조적 특징을 설명한다.\n",
      "Naive RAG의 구조적 특징을 설명한다.\n",
      "Modular RAG가 Naive RAG와 비교하여 가지는 장점을 설명한다.\n",
      "Production level에서 Modular RAG를 사용할 때의 이점을 설명한다.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36magent\u001B[0m in [\u001B[1;33mexecute\u001B[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Modular RAG(모듈형 RAG, Retrieval-Augmented Generation)의 구조적 특징은 다음과 같습니다:\n",
      "\n",
      "1. **모듈화된 아키텍처**: Modular RAG는 여러 개의 독립적인 모듈로 구성되어 있으며, 각 모듈은 특정한 기능을 수행합니다. 이러한 모듈화는 시스템의 유연성을 높이고, 각 모듈을 독립적으로 개발 및 개선할 수 있게 합니다.\n",
      "\n",
      "2. **정보 검색 모듈**: Modular RAG는 외부 데이터베이스나 문서에서 관련 정보를 검색하는 모듈을 포함합니다. 이 모듈은 주어진 질문이나 요청에 대해 가장 관련성이 높은 정보를 찾아내는 역할을 합니다.\n",
      "\n",
      "3. **생성 모듈**: 검색된 정보를 바탕으로 자연어 응답을 생성하는 모듈이 포함되어 있습니다. 이 모듈은 검색된 정보를 활용하여 사용자에게 유용한 답변을 생성합니다.\n",
      "\n",
      "4. **통합 및 조정**: 각 모듈 간의 통합과 조정이 중요합니다. Modular RAG는 검색된 정보와 생성된 응답을 효과적으로 결합하여 최종 결과를 사용자에게 제공합니다.\n",
      "\n",
      "5. **확장성 및 유지보수 용이성**: 모듈화된 구조 덕분에 시스템의 확장성과 유지보수가 용이합니다. 새로운 기능을 추가하거나 기존 기능을 개선할 때, 전체 시스템에 영향을 주지 않고 특정 모듈만 수정할 수 있습니다.\n",
      "\n",
      "이러한 구조적 특징들은 Modular RAG가 다양한 응용 분야에서 효과적으로 사용될 수 있도록 합니다.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mexecute\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "('Modular RAG의 구조적 특징을 설명한다.', 'Modular RAG(모듈형 RAG, Retrieval-Augmented Generation)의 구조적 특징은 다음과 같습니다:\\n\\n1. **모듈화된 아키텍처**: Modular RAG는 여러 개의 독립적인 모듈로 구성되어 있으며, 각 모듈은 특정한 기능을 수행합니다. 이러한 모듈화는 시스템의 유연성을 높이고, 각 모듈을 독립적으로 개발 및 개선할 수 있게 합니다.\\n\\n2. **정보 검색 모듈**: Modular RAG는 외부 데이터베이스나 문서에서 관련 정보를 검색하는 모듈을 포함합니다. 이 모듈은 주어진 질문이나 요청에 대해 가장 관련성이 높은 정보를 찾아내는 역할을 합니다.\\n\\n3. **생성 모듈**: 검색된 정보를 바탕으로 자연어 응답을 생성하는 모듈이 포함되어 있습니다. 이 모듈은 검색된 정보를 활용하여 사용자에게 유용한 답변을 생성합니다.\\n\\n4. **통합 및 조정**: 각 모듈 간의 통합과 조정이 중요합니다. Modular RAG는 검색된 정보와 생성된 응답을 효과적으로 결합하여 최종 결과를 사용자에게 제공합니다.\\n\\n5. **확장성 및 유지보수 용이성**: 모듈화된 구조 덕분에 시스템의 확장성과 유지보수가 용이합니다. 새로운 기능을 추가하거나 기존 기능을 개선할 때, 전체 시스템에 영향을 주지 않고 특정 모듈만 수정할 수 있습니다.\\n\\n이러한 구조적 특징들은 Modular RAG가 다양한 응용 분야에서 효과적으로 사용될 수 있도록 합니다.')\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mreplan\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Naive RAG의 구조적 특징을 설명한다.\n",
      "Modular RAG가 Naive RAG와 비교하여 가지는 장점을 설명한다.\n",
      "Production level에서 Modular RAG를 사용할 때의 이점을 설명한다.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36magent\u001B[0m in [\u001B[1;33mexecute\u001B[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Naive RAG(Retrieval-Augmented Generation)의 구조적 특징을 설명하겠습니다.\n",
      "\n",
      "Naive RAG는 정보 검색과 생성 모델을 결합한 구조로, 주어진 질문에 대한 답변을 생성하기 위해 외부 지식 소스를 활용합니다. Naive RAG의 주요 구조적 특징은 다음과 같습니다:\n",
      "\n",
      "1. **정보 검색 단계**: Naive RAG는 먼저 질문에 관련된 문서를 검색합니다. 이 단계에서는 주로 검색 엔진이나 사전 구축된 인덱스를 사용하여 질문과 관련된 문서를 찾습니다.\n",
      "\n",
      "2. **문서 선택**: 검색된 문서 중에서 가장 관련성이 높은 문서를 선택합니다. 이 과정은 문서의 점수를 매기고 상위 문서를 선택하는 방식으로 이루어집니다.\n",
      "\n",
      "3. **생성 모델**: 선택된 문서를 바탕으로 생성 모델이 답변을 생성합니다. 이 모델은 주로 Transformer 기반의 언어 모델을 사용하며, 입력된 문서와 질문을 함께 고려하여 자연어로 된 답변을 생성합니다.\n",
      "\n",
      "4. **결합된 학습**: Naive RAG는 검색과 생성을 결합하여 학습할 수 있습니다. 이를 통해 검색된 문서의 품질과 생성된 답변의 품질을 동시에 개선할 수 있습니다.\n",
      "\n",
      "이러한 구조적 특징을 통해 Naive RAG는 단순한 생성 모델보다 더 풍부하고 정확한 답변을 제공할 수 있습니다.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mexecute\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "('Naive RAG의 구조적 특징을 설명한다.', 'Naive RAG(Retrieval-Augmented Generation)의 구조적 특징을 설명하겠습니다.\\n\\nNaive RAG는 정보 검색과 생성 모델을 결합한 구조로, 주어진 질문에 대한 답변을 생성하기 위해 외부 지식 소스를 활용합니다. Naive RAG의 주요 구조적 특징은 다음과 같습니다:\\n\\n1. **정보 검색 단계**: Naive RAG는 먼저 질문에 관련된 문서를 검색합니다. 이 단계에서는 주로 검색 엔진이나 사전 구축된 인덱스를 사용하여 질문과 관련된 문서를 찾습니다.\\n\\n2. **문서 선택**: 검색된 문서 중에서 가장 관련성이 높은 문서를 선택합니다. 이 과정은 문서의 점수를 매기고 상위 문서를 선택하는 방식으로 이루어집니다.\\n\\n3. **생성 모델**: 선택된 문서를 바탕으로 생성 모델이 답변을 생성합니다. 이 모델은 주로 Transformer 기반의 언어 모델을 사용하며, 입력된 문서와 질문을 함께 고려하여 자연어로 된 답변을 생성합니다.\\n\\n4. **결합된 학습**: Naive RAG는 검색과 생성을 결합하여 학습할 수 있습니다. 이를 통해 검색된 문서의 품질과 생성된 답변의 품질을 동시에 개선할 수 있습니다.\\n\\n이러한 구조적 특징을 통해 Naive RAG는 단순한 생성 모델보다 더 풍부하고 정확한 답변을 제공할 수 있습니다.')\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mreplan\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Modular RAG가 Naive RAG와 비교하여 가지는 장점을 설명한다.\n",
      "Production level에서 Modular RAG를 사용할 때의 이점을 설명한다.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36magent\u001B[0m in [\u001B[1;33mexecute\u001B[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Modular RAG (Retrieval-Augmented Generation)는 Naive RAG와 비교하여 여러 가지 장점을 가지고 있습니다. 다음은 그 주요 장점들입니다:\n",
      "\n",
      "1. **유연성**: Modular RAG는 다양한 모듈을 조합하여 사용할 수 있기 때문에, 특정 요구사항이나 환경에 맞게 시스템을 쉽게 조정할 수 있습니다. 이는 Naive RAG가 고정된 구조를 가지는 것과 대조적입니다.\n",
      "\n",
      "2. **확장성**: Modular RAG는 새로운 기능이나 데이터 소스를 추가할 때, 기존 시스템을 크게 변경하지 않고도 확장이 가능합니다. 이는 시스템의 유지보수와 업그레이드를 용이하게 합니다.\n",
      "\n",
      "3. **성능 최적화**: 각 모듈을 독립적으로 최적화할 수 있기 때문에, 전체 시스템의 성능을 보다 효율적으로 개선할 수 있습니다. 예를 들어, 검색 모듈과 생성 모듈을 각각 최적화하여 더 나은 결과를 얻을 수 있습니다.\n",
      "\n",
      "4. **재사용성**: 모듈화된 구조 덕분에, 특정 모듈을 다른 프로젝트나 시스템에서 재사용할 수 있습니다. 이는 개발 시간을 단축하고 비용을 절감하는 데 기여합니다.\n",
      "\n",
      "5. **유지보수 용이성**: 모듈별로 문제를 진단하고 수정할 수 있기 때문에, 시스템의 유지보수가 용이합니다. 이는 Naive RAG의 경우 전체 시스템을 점검해야 하는 것과 비교됩니다.\n",
      "\n",
      "이러한 장점들 덕분에 Modular RAG는 보다 복잡하고 다양한 요구사항을 가진 환경에서 효과적으로 사용될 수 있습니다.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mexecute\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "('Modular RAG가 Naive RAG와 비교하여 가지는 장점을 설명한다.', 'Modular RAG (Retrieval-Augmented Generation)는 Naive RAG와 비교하여 여러 가지 장점을 가지고 있습니다. 다음은 그 주요 장점들입니다:\\n\\n1. **유연성**: Modular RAG는 다양한 모듈을 조합하여 사용할 수 있기 때문에, 특정 요구사항이나 환경에 맞게 시스템을 쉽게 조정할 수 있습니다. 이는 Naive RAG가 고정된 구조를 가지는 것과 대조적입니다.\\n\\n2. **확장성**: Modular RAG는 새로운 기능이나 데이터 소스를 추가할 때, 기존 시스템을 크게 변경하지 않고도 확장이 가능합니다. 이는 시스템의 유지보수와 업그레이드를 용이하게 합니다.\\n\\n3. **성능 최적화**: 각 모듈을 독립적으로 최적화할 수 있기 때문에, 전체 시스템의 성능을 보다 효율적으로 개선할 수 있습니다. 예를 들어, 검색 모듈과 생성 모듈을 각각 최적화하여 더 나은 결과를 얻을 수 있습니다.\\n\\n4. **재사용성**: 모듈화된 구조 덕분에, 특정 모듈을 다른 프로젝트나 시스템에서 재사용할 수 있습니다. 이는 개발 시간을 단축하고 비용을 절감하는 데 기여합니다.\\n\\n5. **유지보수 용이성**: 모듈별로 문제를 진단하고 수정할 수 있기 때문에, 시스템의 유지보수가 용이합니다. 이는 Naive RAG의 경우 전체 시스템을 점검해야 하는 것과 비교됩니다.\\n\\n이러한 장점들 덕분에 Modular RAG는 보다 복잡하고 다양한 요구사항을 가진 환경에서 효과적으로 사용될 수 있습니다.')\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mreplan\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Production level에서 Modular RAG를 사용할 때의 이점을 설명한다.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36magent\u001B[0m in [\u001B[1;33mexecute\u001B[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Production level에서 Modular RAG(모듈형 RAG, Retrieval-Augmented Generation)를 사용할 때의 이점은 다음과 같습니다:\n",
      "\n",
      "1. **확장성**: Modular RAG는 다양한 데이터 소스와 모듈을 결합하여 사용할 수 있어, 시스템의 확장성이 뛰어납니다. 이는 대규모 데이터 처리 및 다양한 요구 사항에 유연하게 대응할 수 있게 합니다.\n",
      "\n",
      "2. **유연한 아키텍처**: 모듈형 구조를 통해 각 구성 요소를 독립적으로 개발, 테스트 및 배포할 수 있습니다. 이는 시스템의 유지보수성을 높이고, 새로운 기능을 쉽게 추가할 수 있게 합니다.\n",
      "\n",
      "3. **효율적인 정보 검색**: RAG는 검색과 생성의 조합을 통해 더 정확하고 관련성 높은 정보를 제공합니다. 이는 사용자에게 더 나은 답변을 제공하고, 검색 효율성을 높입니다.\n",
      "\n",
      "4. **개선된 성능**: 다양한 모듈을 최적화하여 성능을 개선할 수 있습니다. 예를 들어, 검색 모듈을 최적화하여 더 빠른 검색 결과를 제공하거나, 생성 모듈을 개선하여 더 자연스러운 응답을 생성할 수 있습니다.\n",
      "\n",
      "5. **데이터 보안 및 프라이버시**: 민감한 데이터를 처리할 때, 모듈별로 보안 정책을 적용할 수 있어 데이터 보안 및 프라이버시를 강화할 수 있습니다.\n",
      "\n",
      "6. **비용 효율성**: 필요한 모듈만 사용하여 비용을 절감할 수 있으며, 클라우드 기반의 모듈을 활용하여 초기 투자 비용을 줄일 수 있습니다.\n",
      "\n",
      "이러한 이점들은 Production 환경에서 Modular RAG를 사용하는 것을 매력적으로 만듭니다.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mexecute\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "('Production level에서 Modular RAG를 사용할 때의 이점을 설명한다.', 'Production level에서 Modular RAG(모듈형 RAG, Retrieval-Augmented Generation)를 사용할 때의 이점은 다음과 같습니다:\\n\\n1. **확장성**: Modular RAG는 다양한 데이터 소스와 모듈을 결합하여 사용할 수 있어, 시스템의 확장성이 뛰어납니다. 이는 대규모 데이터 처리 및 다양한 요구 사항에 유연하게 대응할 수 있게 합니다.\\n\\n2. **유연한 아키텍처**: 모듈형 구조를 통해 각 구성 요소를 독립적으로 개발, 테스트 및 배포할 수 있습니다. 이는 시스템의 유지보수성을 높이고, 새로운 기능을 쉽게 추가할 수 있게 합니다.\\n\\n3. **효율적인 정보 검색**: RAG는 검색과 생성의 조합을 통해 더 정확하고 관련성 높은 정보를 제공합니다. 이는 사용자에게 더 나은 답변을 제공하고, 검색 효율성을 높입니다.\\n\\n4. **개선된 성능**: 다양한 모듈을 최적화하여 성능을 개선할 수 있습니다. 예를 들어, 검색 모듈을 최적화하여 더 빠른 검색 결과를 제공하거나, 생성 모듈을 개선하여 더 자연스러운 응답을 생성할 수 있습니다.\\n\\n5. **데이터 보안 및 프라이버시**: 민감한 데이터를 처리할 때, 모듈별로 보안 정책을 적용할 수 있어 데이터 보안 및 프라이버시를 강화할 수 있습니다.\\n\\n6. **비용 효율성**: 필요한 모듈만 사용하여 비용을 절감할 수 있으며, 클라우드 기반의 모듈을 활용하여 초기 투자 비용을 줄일 수 있습니다.\\n\\n이러한 이점들은 Production 환경에서 Modular RAG를 사용하는 것을 매력적으로 만듭니다.')\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mreplan\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001B[1;32mresponse\u001B[0m:\n",
      "현재까지의 진행 상황을 고려할 때, 추가적인 단계는 필요하지 않습니다. Modular RAG와 Naive RAG의 차이점과 Production 환경에서 Modular RAG를 사용할 때의 이점에 대한 설명이 완료되었습니다. 따라서, 사용자에게 최종 답변을 제공할 수 있습니다.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mfinal_report\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001B[1;32mresponse\u001B[0m:\n",
      "# Modular RAG와 Naive RAG 비교 및 Production Level에서의 이점\n",
      "\n",
      "## 서론\n",
      "\n",
      "Retrieval-Augmented Generation(RAG)은 정보 검색과 자연어 생성 모델을 결합하여 사용자에게 보다 정확하고 관련성 높은 정보를 제공하는 시스템입니다. RAG는 크게 Modular RAG와 Naive RAG로 구분할 수 있으며, 이 두 가지 접근 방식은 구조적 차이와 그에 따른 장점을 가지고 있습니다. 본 보고서는 Modular RAG와 Naive RAG의 차이점과 Modular RAG가 Production 환경에서 가지는 이점을 설명합니다.\n",
      "\n",
      "## Modular RAG와 Naive RAG의 정의\n",
      "\n",
      "### Modular RAG\n",
      "\n",
      "Modular RAG는 정보 검색과 생성 모델을 모듈화하여 결합한 시스템입니다. 이 시스템은 검색 모듈과 생성 모듈로 구성되어 있으며, 각 모듈은 독립적으로 최적화가 가능합니다. 이러한 모듈화된 접근 방식은 시스템의 유연성을 높이고, 다양한 요구사항에 맞게 조정할 수 있는 장점을 제공합니다.\n",
      "\n",
      "### Naive RAG\n",
      "\n",
      "Naive RAG는 기본적인 형태의 RAG 시스템으로, 검색과 생성 과정을 단순히 결합한 구조입니다. 검색된 정보를 그대로 생성 모듈에 전달하여 응답을 생성하며, 구조적으로 단순한 것이 특징입니다. 모듈 간의 상호작용이 깊이 있게 설계되지 않았습니다.\n",
      "\n",
      "## Modular RAG의 구조적 특징\n",
      "\n",
      "1. **모듈화된 아키텍처**: 독립적인 모듈로 구성되어 각 모듈을 독립적으로 개발 및 개선할 수 있습니다.\n",
      "2. **정보 검색 모듈**: 외부 데이터베이스에서 관련 정보를 검색하는 역할을 합니다.\n",
      "3. **생성 모듈**: 검색된 정보를 바탕으로 자연어 응답을 생성합니다.\n",
      "4. **통합 및 조정**: 각 모듈 간의 효과적인 통합과 조정이 중요합니다.\n",
      "5. **확장성 및 유지보수 용이성**: 모듈화된 구조 덕분에 시스템의 확장성과 유지보수가 용이합니다.\n",
      "\n",
      "## Naive RAG의 구조적 특징\n",
      "\n",
      "1. **정보 검색 단계**: 질문에 관련된 문서를 검색합니다.\n",
      "2. **문서 선택**: 검색된 문서 중 가장 관련성이 높은 문서를 선택합니다.\n",
      "3. **생성 모델**: 선택된 문서를 바탕으로 답변을 생성합니다.\n",
      "4. **결합된 학습**: 검색과 생성을 결합하여 학습할 수 있습니다.\n",
      "\n",
      "## Modular RAG의 장점\n",
      "\n",
      "1. **유연성**: 다양한 모듈을 조합하여 시스템을 쉽게 조정할 수 있습니다.\n",
      "2. **확장성**: 새로운 기능이나 데이터 소스를 추가할 때 용이합니다.\n",
      "3. **성능 최적화**: 각 모듈을 독립적으로 최적화할 수 있습니다.\n",
      "4. **재사용성**: 특정 모듈을 다른 프로젝트나 시스템에서 재사용할 수 있습니다.\n",
      "5. **유지보수 용이성**: 모듈별로 문제를 진단하고 수정할 수 있습니다.\n",
      "\n",
      "## Production Level에서 Modular RAG의 이점\n",
      "\n",
      "1. **확장성**: 대규모 데이터 처리 및 다양한 요구 사항에 유연하게 대응할 수 있습니다.\n",
      "2. **유연한 아키텍처**: 각 구성 요소를 독립적으로 개발, 테스트 및 배포할 수 있습니다.\n",
      "3. **효율적인 정보 검색**: 더 정확하고 관련성 높은 정보를 제공합니다.\n",
      "4. **개선된 성능**: 다양한 모듈을 최적화하여 성능을 개선할 수 있습니다.\n",
      "5. **데이터 보안 및 프라이버시**: 모듈별로 보안 정책을 적용할 수 있습니다.\n",
      "6. **비용 효율성**: 필요한 모듈만 사용하여 비용을 절감할 수 있습니다.\n",
      "\n",
      "## 결론\n",
      "\n",
      "Modular RAG는 Naive RAG에 비해 구조적 유연성과 확장성을 제공하며, Production 환경에서의 다양한 요구사항에 효과적으로 대응할 수 있는 장점을 가지고 있습니다. 이러한 이점들은 Modular RAG를 복잡하고 다양한 환경에서 매력적인 선택지로 만듭니다.\n",
      "==================================================\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T06:16:17.746105Z",
     "start_time": "2025-04-25T06:16:17.741607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "snapshot = app.get_state(config).values\n",
    "print(snapshot[\"response\"])\n"
   ],
   "id": "5c260ec726e03d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Modular RAG와 Naive RAG 비교 및 Production Level에서의 이점\n",
      "\n",
      "## 서론\n",
      "\n",
      "Retrieval-Augmented Generation(RAG)은 정보 검색과 자연어 생성 모델을 결합하여 사용자에게 보다 정확하고 관련성 높은 정보를 제공하는 시스템입니다. RAG는 크게 Modular RAG와 Naive RAG로 구분할 수 있으며, 이 두 가지 접근 방식은 구조적 차이와 그에 따른 장점을 가지고 있습니다. 본 보고서는 Modular RAG와 Naive RAG의 차이점과 Modular RAG가 Production 환경에서 가지는 이점을 설명합니다.\n",
      "\n",
      "## Modular RAG와 Naive RAG의 정의\n",
      "\n",
      "### Modular RAG\n",
      "\n",
      "Modular RAG는 정보 검색과 생성 모델을 모듈화하여 결합한 시스템입니다. 이 시스템은 검색 모듈과 생성 모듈로 구성되어 있으며, 각 모듈은 독립적으로 최적화가 가능합니다. 이러한 모듈화된 접근 방식은 시스템의 유연성을 높이고, 다양한 요구사항에 맞게 조정할 수 있는 장점을 제공합니다.\n",
      "\n",
      "### Naive RAG\n",
      "\n",
      "Naive RAG는 기본적인 형태의 RAG 시스템으로, 검색과 생성 과정을 단순히 결합한 구조입니다. 검색된 정보를 그대로 생성 모듈에 전달하여 응답을 생성하며, 구조적으로 단순한 것이 특징입니다. 모듈 간의 상호작용이 깊이 있게 설계되지 않았습니다.\n",
      "\n",
      "## Modular RAG의 구조적 특징\n",
      "\n",
      "1. **모듈화된 아키텍처**: 독립적인 모듈로 구성되어 각 모듈을 독립적으로 개발 및 개선할 수 있습니다.\n",
      "2. **정보 검색 모듈**: 외부 데이터베이스에서 관련 정보를 검색하는 역할을 합니다.\n",
      "3. **생성 모듈**: 검색된 정보를 바탕으로 자연어 응답을 생성합니다.\n",
      "4. **통합 및 조정**: 각 모듈 간의 효과적인 통합과 조정이 중요합니다.\n",
      "5. **확장성 및 유지보수 용이성**: 모듈화된 구조 덕분에 시스템의 확장성과 유지보수가 용이합니다.\n",
      "\n",
      "## Naive RAG의 구조적 특징\n",
      "\n",
      "1. **정보 검색 단계**: 질문에 관련된 문서를 검색합니다.\n",
      "2. **문서 선택**: 검색된 문서 중 가장 관련성이 높은 문서를 선택합니다.\n",
      "3. **생성 모델**: 선택된 문서를 바탕으로 답변을 생성합니다.\n",
      "4. **결합된 학습**: 검색과 생성을 결합하여 학습할 수 있습니다.\n",
      "\n",
      "## Modular RAG의 장점\n",
      "\n",
      "1. **유연성**: 다양한 모듈을 조합하여 시스템을 쉽게 조정할 수 있습니다.\n",
      "2. **확장성**: 새로운 기능이나 데이터 소스를 추가할 때 용이합니다.\n",
      "3. **성능 최적화**: 각 모듈을 독립적으로 최적화할 수 있습니다.\n",
      "4. **재사용성**: 특정 모듈을 다른 프로젝트나 시스템에서 재사용할 수 있습니다.\n",
      "5. **유지보수 용이성**: 모듈별로 문제를 진단하고 수정할 수 있습니다.\n",
      "\n",
      "## Production Level에서 Modular RAG의 이점\n",
      "\n",
      "1. **확장성**: 대규모 데이터 처리 및 다양한 요구 사항에 유연하게 대응할 수 있습니다.\n",
      "2. **유연한 아키텍처**: 각 구성 요소를 독립적으로 개발, 테스트 및 배포할 수 있습니다.\n",
      "3. **효율적인 정보 검색**: 더 정확하고 관련성 높은 정보를 제공합니다.\n",
      "4. **개선된 성능**: 다양한 모듈을 최적화하여 성능을 개선할 수 있습니다.\n",
      "5. **데이터 보안 및 프라이버시**: 모듈별로 보안 정책을 적용할 수 있습니다.\n",
      "6. **비용 효율성**: 필요한 모듈만 사용하여 비용을 절감할 수 있습니다.\n",
      "\n",
      "## 결론\n",
      "\n",
      "Modular RAG는 Naive RAG에 비해 구조적 유연성과 확장성을 제공하며, Production 환경에서의 다양한 요구사항에 효과적으로 대응할 수 있는 장점을 가지고 있습니다. 이러한 이점들은 Modular RAG를 복잡하고 다양한 환경에서 매력적인 선택지로 만듭니다.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T06:16:27.822093Z",
     "start_time": "2025-04-25T06:16:27.816539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(snapshot[\"response\"])"
   ],
   "id": "b0cea7efd1e583c3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "# Modular RAG와 Naive RAG 비교 및 Production Level에서의 이점\n\n## 서론\n\nRetrieval-Augmented Generation(RAG)은 정보 검색과 자연어 생성 모델을 결합하여 사용자에게 보다 정확하고 관련성 높은 정보를 제공하는 시스템입니다. RAG는 크게 Modular RAG와 Naive RAG로 구분할 수 있으며, 이 두 가지 접근 방식은 구조적 차이와 그에 따른 장점을 가지고 있습니다. 본 보고서는 Modular RAG와 Naive RAG의 차이점과 Modular RAG가 Production 환경에서 가지는 이점을 설명합니다.\n\n## Modular RAG와 Naive RAG의 정의\n\n### Modular RAG\n\nModular RAG는 정보 검색과 생성 모델을 모듈화하여 결합한 시스템입니다. 이 시스템은 검색 모듈과 생성 모듈로 구성되어 있으며, 각 모듈은 독립적으로 최적화가 가능합니다. 이러한 모듈화된 접근 방식은 시스템의 유연성을 높이고, 다양한 요구사항에 맞게 조정할 수 있는 장점을 제공합니다.\n\n### Naive RAG\n\nNaive RAG는 기본적인 형태의 RAG 시스템으로, 검색과 생성 과정을 단순히 결합한 구조입니다. 검색된 정보를 그대로 생성 모듈에 전달하여 응답을 생성하며, 구조적으로 단순한 것이 특징입니다. 모듈 간의 상호작용이 깊이 있게 설계되지 않았습니다.\n\n## Modular RAG의 구조적 특징\n\n1. **모듈화된 아키텍처**: 독립적인 모듈로 구성되어 각 모듈을 독립적으로 개발 및 개선할 수 있습니다.\n2. **정보 검색 모듈**: 외부 데이터베이스에서 관련 정보를 검색하는 역할을 합니다.\n3. **생성 모듈**: 검색된 정보를 바탕으로 자연어 응답을 생성합니다.\n4. **통합 및 조정**: 각 모듈 간의 효과적인 통합과 조정이 중요합니다.\n5. **확장성 및 유지보수 용이성**: 모듈화된 구조 덕분에 시스템의 확장성과 유지보수가 용이합니다.\n\n## Naive RAG의 구조적 특징\n\n1. **정보 검색 단계**: 질문에 관련된 문서를 검색합니다.\n2. **문서 선택**: 검색된 문서 중 가장 관련성이 높은 문서를 선택합니다.\n3. **생성 모델**: 선택된 문서를 바탕으로 답변을 생성합니다.\n4. **결합된 학습**: 검색과 생성을 결합하여 학습할 수 있습니다.\n\n## Modular RAG의 장점\n\n1. **유연성**: 다양한 모듈을 조합하여 시스템을 쉽게 조정할 수 있습니다.\n2. **확장성**: 새로운 기능이나 데이터 소스를 추가할 때 용이합니다.\n3. **성능 최적화**: 각 모듈을 독립적으로 최적화할 수 있습니다.\n4. **재사용성**: 특정 모듈을 다른 프로젝트나 시스템에서 재사용할 수 있습니다.\n5. **유지보수 용이성**: 모듈별로 문제를 진단하고 수정할 수 있습니다.\n\n## Production Level에서 Modular RAG의 이점\n\n1. **확장성**: 대규모 데이터 처리 및 다양한 요구 사항에 유연하게 대응할 수 있습니다.\n2. **유연한 아키텍처**: 각 구성 요소를 독립적으로 개발, 테스트 및 배포할 수 있습니다.\n3. **효율적인 정보 검색**: 더 정확하고 관련성 높은 정보를 제공합니다.\n4. **개선된 성능**: 다양한 모듈을 최적화하여 성능을 개선할 수 있습니다.\n5. **데이터 보안 및 프라이버시**: 모듈별로 보안 정책을 적용할 수 있습니다.\n6. **비용 효율성**: 필요한 모듈만 사용하여 비용을 절감할 수 있습니다.\n\n## 결론\n\nModular RAG는 Naive RAG에 비해 구조적 유연성과 확장성을 제공하며, Production 환경에서의 다양한 요구사항에 효과적으로 대응할 수 있는 장점을 가지고 있습니다. 이러한 이점들은 Modular RAG를 복잡하고 다양한 환경에서 매력적인 선택지로 만듭니다."
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
