{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-27T12:44:39.737228Z",
     "start_time": "2025-04-27T12:44:34.968497Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH17-LangGraph-Use-Cases\")\n",
    "from langchain_teddynote.models import get_model_name, LLMs\n",
    "\n",
    "MODEL_NAME = get_model_name(LLMs.GPT4o)\n",
    "print(f\"사용하는 모델명: {MODEL_NAME}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH17-LangGraph-Use-Cases\n",
      "사용하는 모델명: gpt-4o\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 데이터베이스 설정",
   "id": "fa7d8e4455bb47d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:44:45.319050Z",
     "start_time": "2025-04-27T12:44:44.934336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://storage.googleapis.com/benchmarks-artifacts/chinook/Chinook.db\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open(\"Chinook.db\", \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    print(\"File downloaded and saved as Chinook.db\")\n",
    "else:\n",
    "    print(f\"Failed to download the file. Status code: {response.status_code}\")"
   ],
   "id": "5814e66e7b2ba28c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as Chinook.db\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:45:02.633973Z",
     "start_time": "2025-04-27T12:45:02.231336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "# SQLite 데이터베이스 파일에서 SQLDatabase 인스턴스 생성\n",
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n",
    "\n",
    "# DB dialect 출력(sqlite)\n",
    "print(db.dialect)\n",
    "\n",
    "# 데이터베이스에서 사용 가능한 테이블 이름 목록 출력\n",
    "print(db.get_usable_table_names())\n",
    "\n",
    "# SQL 쿼리 실행\n",
    "db.run(\"SELECT * FROM Artist LIMIT 5;\")"
   ],
   "id": "2a1b9d351edc98fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains')]\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 유틸리티 함수\n",
   "id": "a84375565b529f40"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:54:42.964155Z",
     "start_time": "2025-04-27T12:54:42.959191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Any\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.runnables import RunnableLambda, RunnableWithFallbacks\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "# 오류 처리 함수\n",
    "def handle_tool_error(state) -> dict:\n",
    "    # 오류 정보 조회\n",
    "    error = state.get(\"error\")\n",
    "    # 도구 정보 조회\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    # ToolMessage 로 래핑 후 반환\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=f\"Here is the error: {repr(error)}\\n\\nPlease fix your mistakes.\",\n",
    "                tool_call_id=tc[\"id\"],\n",
    "            )\n",
    "            for tc in tool_calls\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "# 오류를 처리하고 에이전트에 오류를 전달하기 위한 ToolNode 생성\n",
    "def create_tool_node_with_fallback(tools: list) -> RunnableWithFallbacks[Any, dict]:\n",
    "    \"\"\"\n",
    "    Create a ToolNode with a fallback to handle errors and surface them to the agent.\n",
    "    \"\"\"\n",
    "    # 오류 발생 시 대체 동작을 정의하여 ToolNode에 추가\n",
    "    return ToolNode(tools).with_fallbacks(\n",
    "        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
    "    )"
   ],
   "id": "9c0b89c9a33c04a3",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SQL 쿼리 실행 도구",
   "id": "57bf97ada7c6ee2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:54:46.718555Z",
     "start_time": "2025-04-27T12:54:45.965440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# SQLDatabaseToolkit 생성\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=ChatOpenAI(model=MODEL_NAME))\n",
    "\n",
    "# SQLDatabaseToolkit에서 사용 가능한 도구 목록\n",
    "tools = toolkit.get_tools()\n",
    "tools"
   ],
   "id": "7782f18bf9006437",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[QuerySQLDatabaseTool(description=\"Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use sql_db_schema to query the correct table fields.\", db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x0000027202B1B5D0>),\n",
       " InfoSQLDatabaseTool(description='Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: table1, table2, table3', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x0000027202B1B5D0>),\n",
       " ListSQLDatabaseTool(db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x0000027202B1B5D0>),\n",
       " QuerySQLCheckerTool(description='Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x0000027202B1B5D0>, llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000002720B61F6D0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000027204DAB790>, root_client=<openai.OpenAI object at 0x0000027203910FD0>, root_async_client=<openai.AsyncOpenAI object at 0x000002720B622690>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********')), llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['dialect', 'query'], input_types={}, partial_variables={}, template='\\n{query}\\nDouble check the {dialect} query above for common mistakes, including:\\n- Using NOT IN with NULL values\\n- Using UNION when UNION ALL should have been used\\n- Using BETWEEN for exclusive ranges\\n- Data type mismatch in predicates\\n- Properly quoting identifiers\\n- Using the correct number of arguments for functions\\n- Casting to the correct data type\\n- Using the proper columns for joins\\n\\nIf there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.\\n\\nOutput the final SQL query only.\\n\\nSQL Query: '), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000002720B61F6D0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000027204DAB790>, root_client=<openai.OpenAI object at 0x0000027203910FD0>, root_async_client=<openai.AsyncOpenAI object at 0x000002720B622690>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:54:46.733686Z",
     "start_time": "2025-04-27T12:54:46.726160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 데이터베이스에서 사용 가능한 테이블을 나열하는 도구 선택\n",
    "list_tables_tool = next(tool for tool in tools if tool.name == \"sql_db_list_tables\")\n",
    "\n",
    "# 특정 테이블의 DDL을 가져오는 도구 선택\n",
    "get_schema_tool = next(tool for tool in tools if tool.name == \"sql_db_schema\")\n",
    "\n",
    "# 데이터베이스의 모든 테이블 목록 출력\n",
    "print(list_tables_tool.invoke(\"\"))\n",
    "\n",
    "# Artist 테이블의 DDL 정보 출력\n",
    "print(get_schema_tool.invoke(\"Artist\"))"
   ],
   "id": "751d9e08057b68dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\n",
      "\n",
      "CREATE TABLE \"Artist\" (\n",
      "\t\"ArtistId\" INTEGER NOT NULL, \n",
      "\t\"Name\" NVARCHAR(120), \n",
      "\tPRIMARY KEY (\"ArtistId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Artist table:\n",
      "ArtistId\tName\n",
      "1\tAC/DC\n",
      "2\tAccept\n",
      "3\tAerosmith\n",
      "*/\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:54:46.760385Z",
     "start_time": "2025-04-27T12:54:46.752389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "# Query 실행 도구\n",
    "@tool\n",
    "def db_query_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Run SQL queries against a database and return results\n",
    "    Returns an error message if the query is incorrect\n",
    "    If an error is returned, rewrite the query, check, and retry\n",
    "    \"\"\"\n",
    "    # 쿼리 실행\n",
    "    result = db.run_no_throw(query)\n",
    "\n",
    "    # 오류: 결과가 없으면 오류 메시지 반환\n",
    "    if not result:\n",
    "        return \"Error: Query failed. Please rewrite your query and try again.\"\n",
    "    # 정상: 쿼리 실행 결과 반환\n",
    "    return result"
   ],
   "id": "c9c195d6cfea30a2",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:54:46.789921Z",
     "start_time": "2025-04-27T12:54:46.781882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Artist 테이블에서 상위 10개 행 선택 및 실행 결과 출력\n",
    "print(db_query_tool.invoke(\"SELECT * FROM Artist LIMIT 10;\"))"
   ],
   "id": "9844400ec8f4e5bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains'), (6, 'Antônio Carlos Jobim'), (7, 'Apocalyptica'), (8, 'Audioslave'), (9, 'BackBeat'), (10, 'Billy Cobham')]\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:54:46.836252Z",
     "start_time": "2025-04-27T12:54:46.830732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Artist 테이블에서 상위 10개 행 선택 및 실행 결과 출력\n",
    "print(db_query_tool.invoke(\"SELECT * FROM Artist LIMITS 10;\"))"
   ],
   "id": "bc75b46444bc1e5e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: (sqlite3.OperationalError) near \"10\": syntax error\n",
      "[SQL: SELECT * FROM Artist LIMITS 10;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:54:48.294239Z",
     "start_time": "2025-04-27T12:54:47.627211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# SQL 쿼리의 일반적인 실수를 점검하기 위한 시스템 메시지 정의\n",
    "query_check_system = \"\"\"You are a SQL expert with a strong attention to detail.\n",
    "Double check the SQLite query for common mistakes, including:\n",
    "- Using NOT IN with NULL values\n",
    "- Using UNION when UNION ALL should have been used\n",
    "- Using BETWEEN for exclusive ranges\n",
    "- Data type mismatch in predicates\n",
    "- Properly quoting identifiers\n",
    "- Using the correct number of arguments for functions\n",
    "- Casting to the correct data type\n",
    "- Using the proper columns for joins\n",
    "\n",
    "If there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.\n",
    "\n",
    "You will call the appropriate tool to execute the query after running this check.\"\"\"\n",
    "\n",
    "# 프롬프트 생성\n",
    "query_check_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", query_check_system), (\"placeholder\", \"{messages}\")]\n",
    ")\n",
    "\n",
    "# Query Checker 체인 생성\n",
    "query_check = query_check_prompt | ChatOpenAI(\n",
    "    model=MODEL_NAME, temperature=0\n",
    ").bind_tools([db_query_tool], tool_choice=\"db_query_tool\")"
   ],
   "id": "e5d4d256f515000e",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:54:52.045220Z",
     "start_time": "2025-04-27T12:54:50.607951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 사용자 메시지를 사용하여 쿼리 점검 노드 실행\n",
    "response = query_check.invoke(\n",
    "    {\"messages\": [(\"user\", \"SELECT * FROM Artist LIMITS 10;\")]}\n",
    ")\n",
    "print(response.tool_calls[0])"
   ],
   "id": "848883cae211cd1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_BT9N36Nd9vTgJaFj7XTaRI00', 'type': 'tool_call'}\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 그래프 정의",
   "id": "78a9f2c5a2f9f412"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:54:54.952213Z",
     "start_time": "2025-04-27T12:54:52.156253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Annotated, Literal\n",
    "\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "\n",
    "# 에이전트의 상태 정의\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "\n",
    "# 새로운 그래프 정의\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "\n",
    "# 첫 번째 도구 호출을 위한 노드 추가\n",
    "def first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            AIMessage(\n",
    "                content=\"\",\n",
    "                tool_calls=[\n",
    "                    {\n",
    "                        \"name\": \"sql_db_list_tables\",\n",
    "                        \"args\": {},\n",
    "                        \"id\": \"initial_tool_call_abc123\",\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "# 쿼리의 정확성을 모델로 점검하기 위한 함수 정의\n",
    "def model_check_query(state: State) -> dict[str, list[AIMessage]]:\n",
    "    \"\"\"\n",
    "    Use this tool to check that your query is correct before you run it\n",
    "    \"\"\"\n",
    "    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n",
    "\n",
    "\n",
    "# 첫 번째 도구 호출 노드 추가\n",
    "workflow.add_node(\"first_tool_call\", first_tool_call)\n",
    "\n",
    "# 첫 번째 두 도구를 위한 노드 추가\n",
    "workflow.add_node(\n",
    "    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n",
    ")\n",
    "workflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n",
    "\n",
    "# 질문과 사용 가능한 테이블을 기반으로 관련 테이블을 선택하는 모델 노드 추가\n",
    "model_get_schema = ChatOpenAI(model=MODEL_NAME, temperature=0).bind_tools(\n",
    "    [get_schema_tool]\n",
    ")\n",
    "workflow.add_node(\n",
    "    \"model_get_schema\",\n",
    "    lambda state: {\n",
    "        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "# 최종 상태를 나타내는 도구 설명\n",
    "class SubmitFinalAnswer(BaseModel):\n",
    "    \"\"\"쿼리 결과를 기반으로 사용자에게 최종 답변 제출\"\"\"\n",
    "\n",
    "    final_answer: str = Field(..., description=\"The final answer to the user\")\n",
    "\n",
    "\n",
    "# 질문과 스키마를 기반으로 쿼리를 생성하기 위한 모델 노드 추가\n",
    "QUERY_GEN_INSTRUCTION = \"\"\"You are a SQL expert with a strong attention to detail.\n",
    "\n",
    "You can define SQL queries, analyze queries results and interpretate query results to response an answer.\n",
    "\n",
    "Read the messages bellow and identify the user question, table schemas, query statement and query result, or error if they exist.\n",
    "\n",
    "1. If there's not any query result that make sense to answer the question, create a syntactically correct SQLite query to answer the user question. DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n",
    "\n",
    "2. If you create a query, response ONLY the query statement. For example, \"SELECT id, name FROM pets;\"\n",
    "\n",
    "3. If a query was already executed, but there was an error. Response with the same error message you found. For example: \"Error: Pets table doesn't exist\"\n",
    "\n",
    "4. If a query was already executed successfully interpretate the response and answer the question following this pattern: Answer: <<question answer>>. For example: \"Answer: There three cats registered as adopted\"\n",
    "\"\"\"\n",
    "\n",
    "query_gen_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", QUERY_GEN_INSTRUCTION), (\"placeholder\", \"{messages}\")]\n",
    ")\n",
    "query_gen = query_gen_prompt | ChatOpenAI(model=MODEL_NAME, temperature=0).bind_tools(\n",
    "    [SubmitFinalAnswer, model_check_query]\n",
    ")\n",
    "\n",
    "\n",
    "# 조건부 에지 정의\n",
    "def should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    last_message = messages[-1]\n",
    "    if last_message.content.startswith(\"Answer:\"):\n",
    "        return END\n",
    "    if last_message.content.startswith(\"Error:\"):\n",
    "        return \"query_gen\"\n",
    "    else:\n",
    "        return \"correct_query\"\n",
    "\n",
    "\n",
    "# 쿼리 생성 노드 정의\n",
    "def query_gen_node(state: State):\n",
    "    message = query_gen.invoke(state)\n",
    "\n",
    "    # LLM이 잘못된 도구를 호출할 경우 오류 메시지를 반환\n",
    "    tool_messages = []\n",
    "    message.pretty_print()\n",
    "    if message.tool_calls:\n",
    "        for tc in message.tool_calls:\n",
    "            if tc[\"name\"] != \"SubmitFinalAnswer\":\n",
    "                tool_messages.append(\n",
    "                    ToolMessage(\n",
    "                        content=f\"Error: The wrong tool was called: {tc['name']}. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\",\n",
    "                        tool_call_id=tc[\"id\"],\n",
    "                    )\n",
    "                )\n",
    "    else:\n",
    "        tool_messages = []\n",
    "    return {\"messages\": [message] + tool_messages}\n",
    "\n",
    "\n",
    "# 쿼리 생성 노드 추가\n",
    "workflow.add_node(\"query_gen\", query_gen_node)\n",
    "\n",
    "# 쿼리를 실행하기 전에 모델로 점검하는 노드 추가\n",
    "workflow.add_node(\"correct_query\", model_check_query)\n",
    "\n",
    "# 쿼리를 실행하기 위한 노드 추가\n",
    "workflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n",
    "\n",
    "# 노드 간의 엣지 지정\n",
    "workflow.add_edge(START, \"first_tool_call\")\n",
    "workflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\n",
    "workflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\n",
    "workflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\n",
    "workflow.add_edge(\"get_schema_tool\", \"query_gen\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"query_gen\",\n",
    "    should_continue,\n",
    ")\n",
    "workflow.add_edge(\"correct_query\", \"execute_query\")\n",
    "workflow.add_edge(\"execute_query\", \"query_gen\")\n",
    "\n",
    "# 실행 가능한 워크플로우로 컴파일\n",
    "app = workflow.compile(checkpointer=MemorySaver())\n",
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(app, xray=True)"
   ],
   "id": "1ad02d0e22baa4c9",
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaMAAALoCAIAAABagA2RAAAQAElEQVR4nOzdB1hT59sG8DcEwgh77ykoLhyIoiDi3qPirKvuamudtcOqrXW0tmqttq7W1lGt2zrqFnEPHKiIbEGQvSGQBPiecFr+flYRlJEc7t/FlevknCzWned93pNz1EtLSxkAAK+pMwAAvkPSAQD/IekAgP+QdADAf0g6AOA/JB0A8J9w8eLFDACqT3JRwZWMpHy5LDQ3Iyg90UhD01BD83zq0/Llc2XLxiItAw3R2yyfSYm/mP7MVKSl/6bLZpra+uqKxwzJSbfUEmsJhYynUNMBVANpScnx5NjC4uJ+lo53s9LiJHk6QqGkuFhWUpwtl6ZLC///spyWc2RF6UL1t1kuLPnnMbWlhW+2TI+jpSYsKJZnyAopoNUEbN79y05ig+nOzfTUNRiPCLDnMMDbKCopVheoUYmUIpW0M7Y01tBkKu5+Trq9jp6Vps7JlLiBVs6MF5B0AG/uQnrirrjHS5t4Mz7amxCZJpV87uYpEAiYikPSAbyh4tLSX56EDrZ2YfyVKSuy0NR5UpDTVN+EqTIkHcCbCM5KMRZRO59XzaxXOfgs2tfEuqGuIVNZagwAquj7iDvU0a8nMUcGWTknSvKi8rOZykJNB1A1mTKppFimqcbbHTJeRV1NTV9dpKIdO9R0AFWQI5MmFebXw5gj8pKS8cFnVLQyQtIBVMFXYTcMRCJWX413bLw/MZKpIIxeASrrbnZqjlzWRM+Y1WMiNTU9ddXLeiQdQGUVFsvzi+WsfostyM2VSTuZ2TCVgtErQKVE5GUdehbDat3yL+ft+O0nVnVD+/s8enCXVTdHHb3DSTElTMUg6QAqJTAtQVejtncryc/PO3n8QAPXxqyKgm9cjouNcmrQkNWAAVZOyYUFTKUg6QAqxU3XsJWBGasZT2Ii58+c0NOvqW8r++EDOh49tJtWXgw82bldA0lB/kdThy+YN4XWJDx9smDe5N6dPTp6Oo4O6Hrxwinu7tSD8mvjtG/X1g8nD/Vv12DVN19MmzCYW3lwzzZW3Zrpm1hq6TCVgmOZAFSKp5FFYc006aQy6fSJQ1q08vp56wEdHfG500eXfDHTxdXdy9vv3bHvnzi2f+eB85qaWnK5/KMpw03NLL5b+5u+gfGxw7s/mzXxwInrZuZWSYlPCwslJ47te2/KLLeGTXXE4tD7t03NrOYv/Easq8eq27PC/LOpT4faNGCqA0kH8HrJRQV7EyJH2LqxGpCVkZaa8qx3v6FOzorHHzF6Sqs27e3snSndnsbHujVqYmSk+Mwp1Wirf/pDV1+fu0q3/3Xj6pioCEq6qKgwWtNn4PAOvl25x4yNiero34u7ZbXTUBPez05D0gHwTZq0kL5YzTC3sG7ewvPrRbNGjnu/e88BdLVho2bcpojwh1269+eWCwry/j6698qlcynJz+QyqVxeTCtNTBUD6ojHodraOn0GDONuSSVebk5WA7cqd/cqyUhD09/MlqkU9OkAXs9Rx2CwdQ0eqW3tpj0Bw9/bs3NL/26tv5j/fn5+Lq3Mz8tJfBrn1qgpLRcXF097b/DfR/dNmDr71x3Htu8906ffEA0NDXtHRWEV+fiBe9MWIo1/dnOjfKRLKgZZzRAKBO1NrJhKQdIBvJ5YKHTWMWA1hiqy8VNmHT55i8anN69dXPvdV7Qy/HEo+zew7ty8EvYo5JMvVvr6dbe0trWwtImLi3J2aaRRNh1Mt6T2XPmjhYc9NDYxo44eqxnZcunK8NtMpSDpAF6voFj+aehVVjNC7tyUyWS0IBAIvH38/Tr3ehx2n65GhodSmWbvoDj+XXp6Kl3a2Ttxd4mODKNAdC0LQZqLiH8S7drwf2PVyPBHDdzcWY1JLZKo3OcNkHQAr6cjVC8pLaVahlU3GqLOnPbuN0s+fhIblZ6WcinodODZYz4du9GmzIy0UlZ6/+4tWmjUxENNTe3IoV00UXsn+Nq6VV/r6xtqaWvTNEVUxCO6bPBc0mVmpGZlZDwKvSeVFrEaYK6pPdGxpobGNQTnBgOolDbGlgKawhNUc3EgEmm2bN3uzMnDv2xctXv7pkcP7gYMHzd24gyq73TEuoFnjx85tNurXUf3Jh5m5pZ/7ty85efv01KSP120kmLxyIE/qBAskORfvXRu1vwlQuE/E4wyuezksQNnT/419N2JGjWwt7OeushUpMVUCj73ClBZOXKprETlPgdV/ZY+vrmsSXstlTp0FfYyAaisD+9dWNXMt4IbfL1wVklx8QsrC4sKtTRfXgFpaGp+unAlqxmxMRHbtvz40k1pacmmpi+fr6De34jRU9ir3clOtdISq1bMMdR0AJX3e1wY/Yd3Nbdj9VhRSbGZpraGQMVa/Eg6gCqg//M8uYzVV7LSEupUqlyTjmHuFaBKMqRFiYX5rL76LuI2U80TSSDpAKrASksnMC3hfk4aq39uZaZMdGxiqqF6BR3D6BXgDdzMTLbR0dNUtV7V24gpyGllYKYmUNFTg6GmA6i6NkYWspKSqPwcVj/8nfyksKRYdWOOIekA3oyDtu6Z1LioAv6HnVBAtavAx1jFPtL/AoxeAd7c3exUV7Hhw9wMF3ENfv6/rlxKfyYWqvNjrxrUdABvroWBmVhd40JawjfhwQIVnZX8j0xZEdVxV9KfZckKu/Bl50HUdADVICwvs5GuUaZM+nXYDSex/ghbN0lJ8cPsDA01gYeBaUGx/F52mo5Q/c2X1dU99E3z5fKQnLdaFqurN9c3zZPL7z+3/Cg3XSQUttA3e1qYt/tpuKWmzgwXD2lJiUiNP5UQajqAakAxxxQH4xVNcWrqpmtoItLSVhNGFWSH52Xpa4jU1QR3slLfZjkyL5uW09NSfj1/ilsWqrHy9ZVfplkUWlYTlD6/TPOqmdIiY5GmlZbOBy4eFHOs7AzWjEdQ0wGojNjY2Dlz5uzfv59BFeET/gDAf0g6AOA/JB0A8B+SDgD4D0kHAPyHpAMA/kPSAQD/IekAgP+QdADAf0g6AOA/JB0A8B+SDgD4D0kHAPyHpAMA/kPSAQD/IekAgP+QdADAf0g6AOA/JB0A8B+SDgD4D0kHAPyHpAMA/kPSAQD/IekAVIZAIDA2NmZQdUg6AJVRWlqakZHBoOqQdADAf0g6AOA/JB0A8B+SDgD4D0kHAPyHpAMA/kPSAQD/IekAgP+QdADAf0g6AOA/JB0A8B+SDgD4D0kHAPyHpAMA/kPSAQD/CUpLSxkAKLGRI0fm5eWpqanJZLK0tDRLS0uBQFBYWHjixAkGlaPGAEC5DRs2LD09/enTp8nJycXFxQkJCbSsq6vLoNKQdADKbsCAAfb29s+vofrO19eXQaUh6QBUAA1gRSJR+VU7O7uAgAAGlYakA1AB/fr1Ky/rqEnn5+dnY2PDoNKQdACqYdSoUVxZR5E3ePBgBlWBpANQDX379qVBKxV0nTp1QkFXVdifDuoXaWlJdH72s8ICWUkxUzWtJ7ybdfasZc9Op1LimKrREWo46OjZadfNlDH2p4N65GRK3PGk2IJieQOxYY5MyqAWidXVH+VmWGiJZzdoYa0lZrULSQf1xfHkJyeT40bYujKoO5myor0JkYvc2zrUbnGHPh3UC9cyko8lxSLm6pyRhuYEh8ZTbp9jtQtJB/XC3sSI3paODJSAUCDoaWG/I/4xq0VIOuC/EsYeZKebaGgyUA6GIs3QnAxWizD3CvyXWiSx19FjoDSMNLRoXojVIiQd1AeluXLMtCqRktKS/GIZq0VIOgDgPyQdAPAfkg4A+A9JBwD8h6QDAP5D0gEA/yHpAID/kHQAwH9IOgDgPyQdAPAfkg4A+A/HMgF4uUO/bfigX8dxHZvtXLsiOf7JKO9G9JWfm81UwU+L59Gr3b56GasB5w/voQf/bMxA7uqH/fzo6q0Lp5kSQ9IBvERSXOy+jWuy0lJ6j3jPw7ujprZO645d6Eso1GBVNzug2+r50ytzy01LP5/UtQ2D6obRK8BLZKal0KW2ju7Q92dza2Z9s569kejQBykJ8XYubq+9pVwmu3XhDIMagKQDeFFw0FmuBJMU5NG4zK9fQP/Rk+YM7UFrNp66LtYz+OHTGTcDT7370SdRD0NuBZ1d8NM2R7fGR7ZtunL6aFrSMy0dHfcWbYZOm2Npa0/jx5N7tnGPSQ81b9VmD2/flz4pjf7WfPIht0y37Dt60vBpc6SFkoNbf75+5u/0lGfaYt3GrdoOmTLTysGJu1laUsLejWtCrl8uyM0xNDHz9OsWMPlDbXHVjsQnyc/98+dVlLB5OTmWdg7d3hnZ5Z3h3KZHt2/s27w2PjJcTajm2qzl8OlzbRxdmGrC6BXgRRZ2Dm279KQFDQ0RjV6btfV54QYamorDFwcdOxh6+7p7C08NkWjvph/2b/lRJNLq+s7wxq28bpw/uXz6WKrRGrdu69q8leIxbe3pocysXnmeVks7x3Zde5c/aaMWnqWlpas/+YACVCLJb9+9n4mFNT3sl1NGUOrRzXIyM76cNPLyiSMGhsYdevQvKS6hSP121uTi4iqc3bGkpGTlnKln9u+i4XmHHv1y0lO3rlx8dPtm2vQ0OuKbWZPC7wX79Ozv1KjJnUvnV817X6ayJ1RDTQfwIlunBl0Gjbh+9oS6SHPkjPm0hmYk/nuztGeJ3/35t4GJKS1vXrqALkfP/qxRC0WXrXHrP6kcK8jPpdZefFR4RMhtW2dX7qFe+aTOrt0CRl47c7z8SUOuX7p//bKaULho024qD+Vy+cLxAXERYSd2//7ujE/+3v1bZloy1XdLftuvIdKk+JsT0D3i/p17Vy608u3MKifk2kXKMg1NrUWbdukbGofe6rty9uQTe7b3HPEePbuZlbVrs1Zj5iwokhRM6dE2+WlcfES4c+OmTAUh6QDeUDOv9lzMEUqc2McPV8//oJVPZ/dWbVr5+BuZmbO3Q0NjunRxb0YxRwvq6uoUYZR0MWEPFVtDFVtpxEoxRwsm5lYuTTwe370V8/hh5ZPu0Z2bdOns3pRijhYae7bbGhTCbaK6kr5ogeo4gZqavqFJRmoSfTkzJB1AfWJgbFq+PHrmZ5K83LtXLlw8fpC+qBDrMnA4VUMCgYC9qcyUJLrUNTQqX6NnYEiXGcmK9RllW/We26qrr9iaXra1kqjBR5diPf3/bkpPTtyxZsWDG1eoWfncalU9PTSSDuANUZyVL+sbGc/9fmN2Rnp4SPD9G5eDjh06vX9nwxae7br2Ym9KR9+ALnMy0svXcMu6ZXkn1lXEE3Xr/rc1S7H8fPa9Fld45uX8s5MgdQaz09MUD2JkvG7hXBp0t2jv13P4WOrirZ73fk5WJlNZmJEAeFvUxjq685c/f/7ewNikTafu4z/+krr7TBFDitRgZWWdpKDgtY8jYIpbyqVF3KyCh3dHuqTRaHJCPHtuHxQaNdMlZRBTTOme4WYJUhOfRpeNZ7mtleTS2EPxFKH3uYCjNt8H/XznDO0ul0m5R+vyN/LR3QAAEABJREFUzoimbdrr6hlwMVel6Q6lgpoO4G1RyXP9zHFqn8WGhTo2apyblXX19FFq8zdpowgd47K6KezOjQ1fzffrF+De8pU7BhuW3ZKS6/u5Uygx/QcMbd2xK2XZ11NHNff2jQl7kBAbZWRq0WP4WLpZz+HjAv/a9+xJzOKJwx3c3GluoVgub97Op4mnN6s0D2/fhh6tH98Lpild91Zt71w+Tyv7vjtRU0vbwsY+8Un0gV/WUZV65eRRmkGmEu/0vp2U5kwFoaYDqAZzv9/k23tQfHT48T+23g4649as1cerN3N7n3n596SySKgmDLkaJJVIKngQc2s7mgTQ0tEJD7nN7bo8/cuVfUdPUlMXXvr7EK3x6TVg8ZZd3OyBtlj8xcYd3t37ZqQkXj5xWCTSHDB2yswV66raGZz17U+dBwylieIrp45S53Hc3EUD3nuf1k9Z+I1jwybxURFUSI6e9em4uV+YWFhFhd5PiotlKkhAI3MGwGvJRQUfhQTNdGnBQDk8K8w/nvxkc8vKzhG/PYxeAWrPqX07Ix/cfemmVj7+3J7D1evhzasXjh146SYLW/vBEz9k9QOSDqD2dA94l75YLWrSxpu+WL2HpAMA/kPSAQD/IekAgP+QdADAf0g6AOA/JB0A8B+SDgD4D0kHAPyHpAMA/kPSAQD/IekAgP+QdMB/IjWhqYY2A6VRXMqstcSsFuH4dMB/RhqaKVJJjlxVz+DHP4mFecYiLVaLkHRQL3Q3t4/Mz2agHBIK8zuZ2rJahKSDemGiY+Pw3KxHuSp8zhfeOJIU08LA1MOgVo/SjmMOQ31Rwkpnh1xy1NFTV1Oz1BIXl+Avv3YJShIk+enSoiZ6xiPt3FjtQtJB/XIyJe5hToakWJ5UlM9UjVwmS05OsbG1YSrIRkuXenPexpbN9OvgnDtIOgCVERsbO2fOnP379zOoIuxlAgD8h6QDAP5D0gEA/yHpAID/kHQAwH9IOgDgPyQdAPAfkg4A+A9JBwD8h6QDAP5D0gEA/yHpAID/kHQAwH9IOgDgPyQdAPAfkg4A+A9JBwD8h6QDAP5D0gEA/yHpAID/kHQAwH9IOgDgPyQdAPAfkg5AZQgEAhsblTytdZ1D0gGojNLS0oSEBAZVh6QDAP5D0gEA/yHpAID/kHQAwH9IOgDgPyQdAPAfkg4A+A9JBwD8h6QDAP5D0gEA/yHpAID/kHQAwH9IOgDgPyQdAPAfkg4A+E9QWlrKAECJjRkzJj09XSAQyOXyjIwMMzMzWpZKpadOnWJQOWoMAJRbnz59srKykpKS0tLSSkpKkpOTaVlDQ4NBpSHpAJTd4MGDbW1tX1jp5eXFoNKQdADKTl1dPSAgQFNTs3yNubn5qFGjGFQakg5ABQwaNKj8XDnUW6eCzsXFhUGlIekAVACVdcOGDRMKhbRsYWExevRoBlWBpANQDQMHDrS2tkZB92awPx3wWQkrTSosSC4qYLzYmarDqGG5J060HT74TlYqU31qampOOnr66iJW87A/HfDW0aSYo89ic+QyO21xnlzOQMmYaWrfy0511zOe4NjYRWzAahKSDvhpV0LEvazU3paOIgFaNEotS1a0Pf7x143bOenosxqDpAMe2p8QFZyV0t/KiYGKWBV5d52Hn7mmNqsZeLsDviksKTmbFo+YUy2DrF22PnnEagySDvgmriCnqLiYgUoxEWnezkphNQZJB3yTVFRgq63HQKXQDKyehqiwpKbeorCXCfBNSWlpQbGMgapJlOSrMQGrGUg6AOA/JB0A8B+SDgD4D0kHAPyHpAMA/kPSAQD/IekAgP+QdADAf0g6AOA/JB0A8B+SDgD4D5/wB2A/LZ43yrvR9tXLaPn84T20/NmYgawuPP9KqrpVeXzYz49e560Lp5nSQNIB/D9m1ratO3Zxb/X680anJyfS//Pfu39jlTA7oNvq+dOZclOJF/lmMHoF+H+atmlPX5W55dUzf7PKiQ59kJIQb+fixpSYSrzIN4akA/h/aPT6y4qF9q6Nlm07RFczU1P2bV774MblnIx0fRNTT7+uQ6fM1NTWoeFtXEQY3WDnDyvo69fAuyJNrZc+IA02T+7ZRgvBQWepBpy3arOHt++j2zfoYeMjw9WEaq7NWg6fPtfG8X8nNhSoCY7t2HLiz+25OVlNPNtO+nSpoanZfx85Njx036a1MWEPCgvy3Zq3GjNrgZXDP0davnLq6Indvz97EkPL9m6NBo2fVnF8v/RFpiUl7N24JuT65YLcHEMTM0+/bgGTP9QW/3Psv8f3bh3Y8lNU6L1imczczsG/f0CPoWMEgpo67NJbwugVoCI0mrtwZJ9dg4ZdA0Yam1ue/HPb5mULaL1vr4EmFla00Lh1294j3lMTvrJooBu4Nm9FCxa29nRLMyubp9ER38yaFH4v2Kdnf6dGTe5cOr9q3vsymbT8LveuBp099GfDFq3U1dXvXQnasuKL/z5s0tO4r98fffdyYHMvH7++AQ9uXFn2wThJfi5tunvlwk+L5makJvn0GuDdrfeT8EcrZ0+Ojwqv4Nv874vMycz4ctLIyyeOGBgad+jRv6S4hKLw21mTi8uO50xJTU/38NYV58bNvbr0oGJwx5rlu3/6nikr1HQAr1SQnxf96L66SHPm8h/VNTTkcvnBX9ebmFvSpl4jxt25ciE9+VlLH/9ew8dV8CDU9aOUiQi5bevsOnLGfFpzfNdWMytr12atxsxZUCQpmNKjbfLTuPiIcOfGTbm75GZlrt5/mqqnWxfOrPnkg3tXLmSlpb5Q1p3YvZVKOaq8pixcQVflcum5g38GHTtIhdXDW1dpTZdBI6iUU7yATt2ePH5UWlJSpRf558+rMtOSqUhc8tt+DZFmesqzOQHdI+7foRfTyrfznp9XFcvlvr0HTfliOd24pc+JdQtmntj9W993J+gZGjHlg6QDeCUdsa6RqQX9w88f2adFh07uLb36vjtRWyxmb4eKJvqiBarjBGpq+oYmVH/RlzP7J+ladvDnBon0pDQeLC0tTYyNeiHpIh+E0KWNYwPKIFqwdVb01yiJKOm4MeyhrT/FPn7YqGWbZl4dPNr5siqKClU8Po1YKeZowcTcyqWJx+O7t2IeP/Ro70eXtNK7ex/uxjSoV1NTo+yjuKTykCkfJB1ARWZ+8yMNV59GhdO4lb4ogEbP+rRjn3fYW6BJ2x1rVtB4U1KQ99zq/52PVN/ImFug0auWtphuRg27Fx6kIC+HlZWH9FW+MiNVcdKZTv2GJMZGnzmwm5pu9EVraCr5o+U/6upX4ezRGSlJdPl8gaarb1j24pOoZSmXKY5fr2dg+L/XKdYryM2mrUwpIekAKuLSuPmKHX8lxcU+Dgmm1Lh98dyWZQuaefkYmZmzN7Vu4VwaJ7Zo79dz+Fia3Fg97/2crMznb5CXk80tUKBwaahvZPLCg4j19VkCo8z17NStfKW2WJcuqbwa9dGnQyZ/FPHg7qM7N6nPSG21vRtXvzdvMas0sa7iPNPUrStfk5OlWKbs09HV5SrNnMx/XjYVpxRziteplENXhhkJgApQ1//gL+sD/9prae/o13fw7G9/MrexKykpyctW/IcLyk7vUiSRvP6BymYkJQUFdEkBEV02MOzyzgiaD9XVM+Birvi5MzfeuXy+sOzGd68E0qVQXd3GyeWFh3Rt0lLxmPl5rXz86cvIxExaKBHrKsa8QccP/f7dkqKiQnp8yrvh0+bSyuz0dFbpF0koiJliKvYMN1WSmviUe9nNvNpTOnP7G14/+89+NjfOnqBLkZaWa/MWTCmhpgN4JS0t7aM7t8ik0sd3gw3NzBJjY2iS0cLOwdqpAW01LivrTu3ZlvosYdj7s8uHnP/F3TLszo0NX8336xdgYWOf+CT6wC/rwkOCr5w8SpOeVOKd3rfTwNikpGzegFpjiyYMcXZvRjMSdLVNp+76hi8+eI/hY4OOH7wZeGrl7EmGphaUNYWS/LnfbbR3bRQfGXZ6/87Q4GvU5qOq8Fag4rMKrTp2qfB7ffFF9hw+LvCvfc+exCyeONzBzT3k2kVqwzVv59PE05tuNmL6vMWThwcdO5CTma6jp3/z3ElaOXDcNJ2ySlAJoaYDeCWaBPh83fambbyDL50//sfW6ND7Pr0GfLLmF6FQSFt7vzvextElPy+X5jorntn08u9J5ZVQTRhyNUgqkUxZ+I1jwybxUREUZNT1Gzf3CxMLq6jQ+zRGLi7rf3XqF9Cmc497Vy8Ul8i9OvccN3fhfx/Twsbu85+2NfFsH3b31uUThy0dHOd8t8GjfUfaNGza3EETpsvlspN7dwQdPaBnZDzx0yUde7/m820vvEiaePli4w7v7n0zUhLp8UUizQFjp8xcsY7bY87Jveln636jyYewuzdvnD9l4+w6ecGy/mMnM2WlGGwzAB4JTEs4lhQ72NqFgUr5KuzmoXZ9RGo1Un5h9ApQDX777iuaIH3ppr7vTqARJVMCKvEiawiSDqAavHSAqWxU4kXWECQdAPAfkg4A+A9JBwD8h6QDAP5D0gEA/yHpAID/kHQAwH9IOgDgPyQdAPAfkg4A+A9JBwD8h6QDvtFSU9dVFzFQNU5ifaFaTZ1EEcenA75x0NELy81goFKSiwoKi+VChqQDqBwrLR0bbd1suYyB6nhamO9jYs1qDJIOeGiGS/Nd8Y8ZqIiI/Ky7WanvObizGoNjDgM/PZXkT75zdoB1A0N1kYmmZgn+zJVSUmF+lkwakp26qVWXGi27kHTAW7LSkq1PQkOy02khU1rEVF9JSUlhYaGOjg7jBUexnqBU4GVsUQuHwkfSAaiM2NjYOXPm7N+/n0EVYS8TAOA/JB0A8B+SDgD4D0kHAPyHpAMA/kPSAQD/IekAgP+QdADAf0g6AOA/JB0A8B+SDgD4D0kHAPyHpAMA/kPSAQD/IekAgP+QdADAf0g6AOA/JB0A8B+SDgD4D0kHAPyHpAMA/kPSAQD/IekAgP+QdAAqQyAQODs7M6g6JB2AyigtLY2OjmZQdUg6AOA/JB0A8B+SDgD4D0kHAPyHpAMA/kPSAQD/IekAgP+QdADAf0g6AOA/JB0A8B+SDgD4D0kHAPyHpAMA/kPSAQD/IekAgP8EpaWlDACU2Hvvvffs2TOBQCCXy7OyskxMTGhZJpOdOXOGQeWoMQBQbp06daKAS01NzczMpNIkLS2NlrW0tBhUGpIOQNm98847tra2z6+hvGvZsiWDSkPSASg7PT29vn37qqv/r6tuZWU1cuRIBpWGpANQAYMHD7azs+OWqaBr3ry5u7s7g0pD0gGoACrr+vTpw5V1KOjeAJIOQDVQWWdvb08LVNA1bdqUQVVgfzpQMfLS0uSiAgGrfzTUfPr3yTxypOfIYYmF+aweEjBrTTF7I9ifDlTGtYyk3QkRYTmZ9jq6uXIZg3rGRlv3UU5GOxPLmS4t9NQ1qnRfJB2ohnNpCfsSIvpZOhlpaPm8ZssAABAASURBVDKor2SlJUlFBTviHv/auouJRhX2KETSgQo4mxJ/KCnmXVs3BlDmq7Abh9r1FalVdqYBMxKg7EoYO/QMMQf/z0i7huujQyp/eyQdKLvo/Ow8uZQBPMdUpH0jM7nyt0fSgbJLkOQ7iw0YwHMMNURmIu2CEnklb4+9TEDZyUuL84ox0woviinIEVR6lgFJBwD8h6QDAP5D0gEA/yHpAID/kHQAwH9IOgDgPyQdAPAfkg4A+A9JBwD8h6QDAP5D0gEA/+ET/gCVdfvS+VHejT7s51fxzZLjn9DN6Cs/N5upIFV//S+FpANQPRePH6Ykig0PZVA5GL0CqJ7rZ48zqAokHfDQD5/OuBl4atTMT/Nysk/t3Ulrug4aNmjC9G2rll49fUwkEg3/YF7HPu9wN35879aBLT9Fhd4rlsnM7Rz8+wf0GDpGIFCcfay0tHTfxjXn/torLZQ0b+vb0rfz888il8uP7dxy5dSxlIR4fSPj7oNH9hk1kVUFvbzfVn5590qghkjk33+orqHRH2u/8ercc8bSNa96fBpRTunelrv7grHvuDRu/uUveyp4iszUlH2b1z64cTknI13fxNTTr+vQKTM1tXW47+7v3b+dO/Rn2rMEYzNLz07dBo6fpiPWLb9vbnb2z4s/Dr19XVfPcMSH87y79eHWUy25b9PamLAHhQX5bs1bjZm1wMrBidaf2rdj2/dft+7Y1adX/51rv8nJTG/m1WHqwhVBxw4e2b65IC+3U78h9EtRKzskekpi/J8/ff/4XjA9iLWDy+CJH3q078hqjHDx4sUMQInFFORE5ee46xlV/i63L52LjwpPT0mW5OZa2Ts9CQ+l/6iohyHSokJTK5snEWF3Lp3v2O8dHbHeo9s3ls94L/npEzcPzwZNm4eH3Ll7OVBaVNTMqz09zrmDf+7+6XtZUWG7rr1lUunF4weKJAXaOrq9R75HW7etWnJ0+xYtbZ1uASNTE59ePnlESyx2bdYyXxGvO+gG/UZPEmlWdFaXTV9/du3McaG6ukf7TqHB16Ie3svPzbF3beTl3/2Vj9+0hayoKOLBXbqBT68BHt6+Lk08KniK5R+Oo++oYQtPuqWkIP/GuROUm16de9CmvRtWU2CVlJR6+ffIycq4HXQ2LuJRhx79y1//0+jw7Mz0kpLizLSU4Atn6OnEevpJT+MWTxz2NDrCq1P3Bk1bXjt97Gbgaf8BARoizbiyH2xJsZxeXhNP76jQkMTYqJhHD+mH37SNN/386RukTLRzcaNfxJdTRj6+G0w3c23SghqgN86faOPfQ9/QmFXaxfTEITYNNCp3KgnUdMBbssLCeas3UwUxZ0h3+vfOykhbvv1wSUnJjAF+2elpobeu+fYetOfnVcVyOS1M+WI53aWlz4l1C2ae2P1b33cn6BkanTm4i1b2Gj5u5Iz5tPDjgpnXz57gHjwrLZVykBY+WLKKCqtO/QNmDupyZNvGnsPGVvLlZWek3zh/khYmfb68XZeekvz82UO60VWunKzg8enFnPjzd/pGeg4f6+jWuIKnKMjPi350X12kOXP5j+oaGlQkHvx1vYm5JW3Ky876e9dvtDBt8bct2vtJ8nNnvtM19NZ1qte0tf85p6qts9uY2Z9T4Tk7oHtBbnbItUtd3hl+YvdWqsIoN6csXMEUhaeUXidVbVQIc/dKfhr3/b7TFjZ20sLCoGMHqCT84eB5IzPzvOxsytn71y+3796X6kH6vTi4us9YtlYoFD6NjQq/F3zncqCNowurGZiRAN5q6NGa/osoOKiIoKvuLdrQMq2xcXKlqzSaKy4ujnn8kJa9u/8zLqPBHf0HUvZRSUhRkhATSSubtfPhtrbp1L38wSlB6AZ0YwNjk/SUZzQSNLWwzs3KehYXwyon8Ul0SXExLbT29adLbbHYs2PXanx8QkNRI1MLubRo/sg+29cso+Ku77sTOw8cRpuowpLJpPQDaerVoezZ9TaevL41KOT56KRco0tdfQO3Zi1oITM9hS4jHyjOU2Pj2IBeFX1RGtLViPt3yu9lYmlNMUcLdg0Um6wcnCnmaMG+QUO6zMlKZ4pfjefK3X8v3XaQvi+q70wsrBSPn1qF80JUFWo64C0dPX1ugbpgiqu6/3SgRGVXi4tLKOzkMsVx2/UMDLlN6urqWmI9ql/Sk5Oor8QlkY7uP4+jratX/uC0lS4pjKjUev5J6d/VzNKGVUJ+TqbixWhp0biPW6NrYFCZx69S4TPzmx83L1vwNCr85J/b6IsSbfSsT6lHye1BoqUtpm/5Vfc1MDblFrR0yvp6ZT+Ngrwcujy+ayt9ld8yIzWlfFn8749dJFKM3HX+/aGpl/3YuR8phSw16a6cOkq/gv89X02ekBVJB/UXZR8VNVRW5GRmcmvoP7CgLAL0DY20xbpUUlHWlO9WlpuZUX5fsb4ilTQ0RB8u++H5x7R1cqVeHqsEHbEiEWiIR0UN186jkq0yj8+qgka+K3b8lRQX+zgkODjo7O2L57YsW9DMy8fIzIK2SgryKOtpYFv27JlUzJa/HzDFOPolDyjW12cJjLKSZjDKV2o/N49RGYd+WX9i9+8WtvYT5n+lb2xyYMuPNKplNQmjV6i/aArSvZUXU+y08Te35kZZG47qLNfmLWicS7MZdPXOxfPc1ssn/yq/r7N7MzWhkJLRzMqmlY9/83a+Bbk5NJ1Jg1BWOZYOTlxL7nbZ41NPLTjodGUfv+yOr41Umj04+Mv6wL/2Wto7+vUdPPvbn8xt7Ci787IzaURP3ybdhmZ+6bKwoGDO0J4f9PONDntQ8WO6NmlJl5L8PHpV9GVkYkYT0+Lnqt3KiHx4ny5plrZ1xy6Obu5J8U+Yosqu7Im+3gBqOqjXRkyft3jycGqc52Sm02j35jnFFMHAcdO4EWunAUN2/rDi9P6dWemp+Xk5aYkJTDHGUoyyqH1GDa8z+/9Y8dF4+neNjwynXhVNvLb08a/kUxubWbTo0IkmKzcv++zWhVOx4Y+0dHTLy7qKH58qsvSkxK0rv/Jo5zvig3mvegotLe2jO7fQrDHNchqamSXGxtDMjIWdg7VTA8rx3sPHHfptw8YlnwUHnaOJCCpmG3t6uzVvnZoQX8HL7jF8bNDxgzcDT62cPcnQ1ILeGwol+XO/20hTxqzSLO3tH966Qu8cGhoaITcuUZ+OJpdpRqJBEw+a4WU1ADUd1GtO7k0/W/db49Ztw+7evHH+lI2z6+QFy/qPncxt7T5kdI9hY6i3df/GZX1D47HzFtJKueyf02yPnvX5oAnT1TVEgX/tS46P7Tp4xJzvNgheOuR7hYmfLKGwo47hozs3vbv1ofkQWikUqr/28UdMn0uDvuS42LiIsAoe39DU7PN125u28Q6+dP74H1ujQ+9Tjnyy5heKOdr6zqQZQ6fO1jcyunr6KJWHvUaMm7Virdrrdtqg2YbPf9rWxLN92N1bl08ctnRwpFdV1V3hBk+cQd84PWng0f2tfLrMXvkzZVxWWkro7RusZiiaFAxAiZ1NjT+VEj/IypnxDuVUZnqqvUtDbnZyxYzxD25eCZj80cD33mfwOksf39rj1VNbWKmBKUavADXot+++4mZR/6vvuxP2bvqBRq9m1rYtvP0yUpMo5vSMjLm9QCopMzVl1/qVr9o6+fNl3GwDoKYDZcfjmo5mIfZtWBN86VxOepqugZFrsxZU0Fk78vA7rQmo6QBUg45Yd8ycBfTFoIYh6QCA/5B0AMB/SDoA4D8kHQDwH5IOAPgPSQcA/IekAwD+Q9IBAP8h6QCA/5B0AMB/SDpQdiKBUF9dxAD+PxexAav0MbJwfDpQdvY6eo9zMxnAc9KlhRnSQm01YSVvj6QDZeego2eiqSXFQXfgOUlFBe1NrCp/eyQdqIAx9o22PQllAGVy5LKDidFTnZpW/i44Ph2ohrC8rK/DbvS2dDIRaRqgbVdfpRRJaNx66Fn03ra9RIIqFGpIOlAZTyV5O+PD72SlCAVqadJCVh+VlpaUCtTq6VCsob5hnkzWwcRqgkPjqt4XSQeqR85KBfXyz/bJkyfz5s3bs2cPq5dKBYI33lkEe5mA6lFnAlaFM3Dxh6KWKykRCurlN/92kHQAwH9IOgDgPyQdAPAfkg4A+A9JBwD8h6QDAP5D0gEA/yHpAID/kHQAwH9IOgDgPyQdAPAfkg4A+A9JBwD8h6QDAP5D0gEA/yHpAID/kHQAwH9IOgDgPyQdAPAfkg4A+A9JBwD8h6QDAP5D0gGoDIFA0KBBAwZVh6QDUBmlpaWRkZEMqg5JBwD8h6QDAP5D0gEA/yHpAID/kHQAwH9IOgDgPyQdAPAfkg4A+A9JBwD8h6QDAP5D0gEA/yHpAID/kHQAwH9IOgDgPyQdAPCfoLS0lAGAEps2bVp6erpAICgsLHz27JmjoyMtFxUVHTx4kEHloKYDUHaNGzf+/fffy4uSqKgoBlWkxgBAuQUEBNjZ2T2/hlKvbdu2DCoNSQeg7CwtLTt37vz8GgMDg3HjxjGoNCQdgAoYOnSovb09t0wFnZubW5s2bRhUGpIOQAWYm5v7+/tzy1TQTZgwgUFVIOkAVMOwYcNo1pUWGjZsiIKuqjD3CrxSorjg545TpuZmHTv5ZR7OGjf+vRKefo+s7JcnZAJW3bA/HfDBg5z03U8jHuVmSEuKZSUlDFSWi9ggRy71NLKY5txMQ1Btg04kHai8i+mJO+LC/M3szDS1xUIMU1ReurQwXVq0++njnW26G2loseqApAPVdiI57nhy7EhbNwa8s+zxrT+8eugKNdhbw4wEqLC8YtnJ5CeIOb4aZd9wfdR9Vh2QdKDCwnOzpKXoyvGWlZY4KC2BVQckHaiwxMICJx09BjxFMxJN9Y2fSvLYW0P7FlSYpFhWUFzMgL/ozaxainYkHQDwH5IOAPgPSQcA/IekAwD+Q9IBAP8h6QCA/5B0AMB/SDoA4D8kHQDwH5IOAPgPSQcA/IdP+APUveT4J6O8G9FXfm4246mfFs+jb3D76mWsLiDpACrl4vHD9I8aGx7K6pnZAd1Wz5/OVBySDqBSrp89zuqf6NAHKQnxTPWhTwf1S15O9m8rv7x7JVBDJPLvP1TX0OiPtd94de45Y+ka2pqTlbHn59Wht65lpKXYODgPmTqzRXs/GlFO6d6Wu/uCse+4NG7+5S97KniKzNSUfZvXPrhxOScjXd/E1NOv69ApMzW1dWiTJD/3z59X3bpwJi8nx9LOods7I7u8M/z5++ZmZ/+8+OPQ29d19QxHfDjPu1sfbj3Vkvs2rY0Je1BYkO/WvNWYWQusHJxo/Q+fzrgZeGrUzE/p+zq1dyet6Tpo2KAJ07etWnr19DGRSDT8g3kd+7zDPcij2zfohcVHhqsJ1VybtRw+fa6No0sF3wiNNE/u2UYLwUFnqZ6dt2qzh7evtFBycOvP18/8nZ7yTFus27hV2yFTZnIvhqQlJezduCbk+uXy7Z3cAAAQAElEQVSC3BxDEzNPv24Bkz/UFtf9MQRR00H9QjF37czx0tLSpl4+Ny+cPrP/D1opVFe85cvl8hUzxgf+tdfYwrLvqAn0n7zq42mRD+9piDR7j3iPu7tPrwEdevar+ClorHfhyD67Bg27Bow0Nrc8+ee2zcsW0PqSkpKVc6ae2b+LUq9Dj3456albVy4+un3z8/f9dcUXGanJOrp6GalJPy+el5r4lFYmPY37+v3Rdy8HNvfy8esb8ODGlWUfjKPQpE0ampp0ef6vfZH37zZu5VWQm/3Xtk3fz30/My2lUcs2OVmZW5YtoG+EbvM0OuKbWZPC7wX79Ozv1KjJnUvnV817XyaTVvCNNG7d1rV5K1qwsLWnn4CZlQ393FZ/8sGRbZskkvz23fuZWFjfOH/yyykjuKfIycz4ctLIyyeOGBgad+jRv6S4hILy21mTi5XgGIKo6aAeoX9F+s+khUmfL2/XpackP3/2kG50VSBQnGCUSq24iDCxvsHHqzaJtLRtnRqs+2L2kW2bZ32zbuSM+Sf+/J2iqufwsY5ujSt4ioL8vOhH99VFmjOX/6iuoUHpefDX9SbmlrQp5NpFChoNTa1Fm3bpGxqH3uq7cvbkE3u29/w3Romts9uY2Z9TgTY7oDvFVsi1S1T0ndi9lUo5qqemLFzBFIksPXfwz6BjB3sMHcPdS1ZYOG/1ZjU1tTlDutNgMysjbfn2w/RqZwzwy05PoxLVt/egkOuXzKysXZu1GjNnQZGkYEqPtslP4+Ijwp0bN33V99K6Y5f4qPCIkNu2zq70E1B8C9cv3b9+WU0oXLRpt6WtPX13C8cH0A/txO7f353xyd+7f8tMS6b6bslv++ntgeJvTkD3iPt37l250Mq3M6tTqOmgHnkWF11SVl+09vWnS22x2LNj1/KtUQ/v0qW1g3NuThb9l1IhQ1cjHtxhVaEj1jUytZBLi+aP7LN9zTIqxPq+O7HzwGG06dGdm3Tp7N6UYo4WGnu22xoUsu5IkLr6/woObjCrq2/g1qwFLWSmp9Bl5IMQurRxbECvir4oDRUv7P7/XlhDj9ZCoZDy2s5Fscm9RRtapjU2Tq50lQbRdElF2crdf0/+fCnVcQI1NX1DE1pJlSOriqiHilfi4t7MsuyHQ6+ci7CYsIeKraGKrTRipZijBRNzK5cmHoqtjx+yuoaaDuqRvGzFPhwiLS3uX5HoGhiUby3IU5yvgBLkowH+5SspJuQyGVVnrNJmfvMjDVefRoXTuJW+qEs1etan1Cyj1hVtFevpV3BfA2NTbkFLR9HXKy3L5YI8xR2P79pKX+W3zEhNKV/W+fcxqfmouKqry10VlV0tLlYcnzw9OXHHmhU08pUUPH9ahqqdBDUzRZGM1NwsX6NnYKh4McmK9RllW/We26qrb1j21FXL05qApIN6hPpfdCktLJQWFYo0FadMzs3KKt/KZZCTe5NB4z9gb4GmLFbs+CspLvZxSDD18m9fPEfNsmZePkZm5qxsSoS7GfW8aGhJC3pGxuX3LRtGv0isr88SGGWlZ6du5StpNoBVxbqFc2kcShMsNACnRuHqee9TF49VkY6+4o2BKxI53LJuWd6JdRU/QGoR/G9rlmL5+eyrKxi9Qj1iaefIteRuXzzPynpqwUGny7e6cgPG1NRmXu1b+fg7NmxMVZimptY/BV3ZHanDVfFT0OzBwV/W07SGpb2jX9/Bs7/9ydzGjlpmedmZLo3LhnKh97mAo+Lxg36+c4Z2L5bLKn5M1yYtmWLeNo9eFX0ZmZjRBKhYtwoTmpSq0WVDyy7vjGjapr2ungEXc6+fKyj7riUF/3zXHt4dWdloNLls1xOqdqm5SQv0E6NLilGmmKg9w0100HQK96Tc1rqFmg7qEaqqWnToRNOOm5d9duvCqdjwR1o6uuVlXcsO/g6u7k8iHi2aOIxS7/61yymJ8f3GTGrSxrvsvhbpSYlbV37l0c53xAfzXvUUWlraR3dukUmlj+8GG5qZJcbG0BSBhZ2DtVMDmo2lhtrje8E0Wenequ2dy4q0pS4eV11WoMfwsUHHD94MPLVy9iRDU4sbZ08USvLnfrfR3rURqxzKdwsb+8Qn0Qd+WRceEnzl5FGaVKUS7/S+nQbGJo1atHnVHY3L6tCwOzc2fDXfr1+Ae8s2rTt2pSz7euqo5t6+MWEPEmKjqC9Jr5Bu1nP4uMC/9j17ErN44nAHN3eagSmWy5u382ni6c3qGmo6qF8mfrKEwo5aVzQ/4N2tj6efYkZCKFS85VPtNv+HX3x6DchMTTp/eG8pK6UJx6FTZ3N3HDF9rr6xSXJcLE01VvD4hqZmn6/b3rSNd/Cl88f/2Bodep8e8JM1v9D8AG2d9e1PnQcMLZQUXDl1lFpy4+YuGvDe++x1LGzsPv9pWxPP9mF3b10+cdjSwXHOdxs82ndkVTFl4TeODZvER0VQFUZ9w3FzvzCxsIoKvU+j7Aru5eXfk2pAoZow5GqQVCKhNdO/XNl39CQ1deGlvw9lpqXQd7d4yy5ujoVmeL7YuMO7e9+MlER6nSKR5oCxU2auWCd46Zi8dgmorGUAqmlvQuSj3Mzu5naVvwvlVGZ6qr1LQ65rtmLG+Ac3rwRM/mhgJRIHat/66PtLm3jba1etKflfGL1C/bJ30w80ejWztm3h7ZeRmkQxRxMC3F4glZSZmrJr/cpXbZ38+bIqTdTWuVP7dkY+uPvSTdQTbNe1N+MF1HSgwt6gpqNZiH0b1gRfOpeTnqZrYET9OCrorB2dGSgl1HQAb0JHrDtmzgL6YlCfIOkAgP+QdADAf0g6AOA/JB0A8B+SDgD4D0kHAPyHpAMA/kPSAQD/IekAgP+QdADAf0g6UGFaQqF22dGQgK+stcWsOuD4dKDCLDR14gpyGfBUKWN3s1Lf/uP9DDUdqDRnsYGmEH/DvJVcVNDexIpVB9R0oMJMRVqehuaHnsUw4KPdT8MnOjZh1QHHpwOVtzM+/GZWcndze2MNTQaqr7i0NKVIsutp+Iqm3s46Bqw6IOmAD86nJexPiIrJzzYSaZWUljCeKiktlUmlmpp8DnQrLXFobkYHE6vxDo2ttapnOoIh6YBPikqK06WFPP6DTkhIWLZs2fr16xl/CWi+tfoCrhy6ucAfmmrCmvgnUR4yoUiYlWvD6++xhiDpAID/kHQAwH9IOgDgPyQdAPAfkg4A+A9JBwD8h6QDAP5D0gEA/yHpAID/kHQAwH9IOgDgPyQdAPAfkg4A+A9JBwD8h6QDAP5D0gEA/yHpAID/kHQAwH9IOgDgPyQdAPAfkg4A+A9JBwD8h6QDUBkCgcDZ2ZlB1SHpAFRGaWlpdHQ0g6pD0gEA/yHpAID/kHQAwH9IOgDgPyQdAPAfkg4A+A9JBwD8h6QDAP5D0gEA/yHpAID/kHQAwH9IOgDgPyQdAPAfkg4A+A9JBwD8h6QDAP4TlJaWMgBQYkuWLDl48KCamhotl5SUCMrQf25wcDCDylFjAKDcRo0aZW9vzy1T3lHM0UKrVq0YVBqSDkDZOTk5eXl5PT/8MjAwGDNmDINKQ9IBqICRI0fa2dmVX6Xs8/X1ZVBpSDoAFeDo6Ni2bVtumQq60aNHM6gKJB2AaqCyztbWlhZcXFz8/PwYVAWSDkA1ODg4ULdOLBbTBAWDKsJeJgD/T3he1p6EiERJfkqRhCmZkpLiggKJrq4uUzKWWjp02czAdIpjE6aUkHQA/3MhLWHrk0dtjS1stHW1hdivvrKETJBaJMmQFR1KjNrZpoepSIspGSQdwD+OJcWeTokfbuvK4E2VMLY26t5PHn7GShZ26NMBKKRKC08h5t4aBcowW9c1UfeYkkHSASjcyUrRVhMyeGtWmjp3s1Lzi2VMmSDpABSSCgvsdPQYVIfmBibR+blMmaDnCqCQLZMWK7pMUA0yZVJZSTFTJkg6AOA/JB0A8B+SDgD4D0kHAPyHpAMA/kPSAQD/IekAgP+QdADAf0g6AOA/JB0A8B+SDgD4D0kHAPyHpAMA/kPSAQD/IekAgP+QdABvqCAv5/fvlwQHndUQifz7D9XU0dm7YY1X554zlq55cPPKihnjtcV6m8/c5G78xXuDY8IeTvjkK/8BQ+lqbHjovk1rY8IeFBbkuzVvNWbWAisHJ1r/w6czbgaeevejT6IehtwKOjvx0682fDmf1v/4V5CRmTktpCY+nTW4Ky2sOXjW1NLmVa+ttLR03+a15w79WSQpaOHt12XQ8OUz3tM3NPrp76u0VS6XH9u55cqpYykJ8fpGxt0Hj+wzaiJ3x6k92+VlZy3avDvo6IHrZ0/Q43R5Z/jQqbPU1FT7qL045jDAG6KYu3ziCGVBUy+fmxdOnzvwJ60Uqr++ekh6Gvf1+6PvXg5s7uXj1zfgwY0ryz4YJyk7SK+GpiZdBh07GHr7unsLTzsXN2f3ZrTmzuXz3H3vXb1Il+6tvCqIOXLu0J7DW3/Ozcxo4umdm535yzcLaaWauga3dceapRTK0kJJv9ETdXT1dq3/7viurdwmDQ3FC9j67eKczHRPv670qo5u30zfJlNxqOkA3kROVsa1M3/TwpQvVnj596DSafaQ7nRVIBC89r4ndm+lUs7D23fKwhVMUWFJzx38k9Ktx9Ax3A3SniV+9+ffBiamtOw/YEj0o/vBF892HjiMrt67FkSXPr0GVPwUZw78QZddB48YN3cRLXw3ZwqVbwKmeG1Zaan0dLTwwZJVLo2bd+ofMHNQlyPbNvYcNra8cDOzspn1zXpakMmkV08dvXc10Lf3AKbKUNMBvInE2KhiuZwWWnboRJea2jqtfTpX8r6RD0Lo0saxQXrKM/qydXajqxH375TfoJlXey7mSLuufbR0dEJvXpPk51PuhAZfE2lptfHvUcHjl5SUJMRE0kIr3y7cmvbd+5ZvpdykG1CoGRib0LNTTWpqYZ2blfUsLqb8Ni19/LkFZ/emdJmZlspUHGo6gDeRl51JlxQ6GiJNbo3YwKCS96UGH13SgLF8zEgyUlPKlw2MTcuXtcViCrvAv/bev3GJRppFEol39746Yt0KHz+3pFhxGgexnsG/r83w+a2sLA2plHv+XpmpyTaOLtyyrv4/dxSVnbaVbsxUHJIO4E3o6CqyQFpYKJMWcWGXl51dvpUbJ8qlReVrcrOzypfF+vosgXXs845np27lK7WfCy814f87HyMNYCnpbl88q29owioxdKWHokE0FWt5Of88aV5W5nPPrnjlGhqiD5f98Py9bJ34fK5bjF4B3oS1gzPX1bpzOZAuaWh5K+hM+VZ9Y0Uk0WDzadko8knEo7RnCeVbXZu0LLtLXisff/oyMjGjyQGx7ivPwUjdNLsGDe9cvnDnSqChqVnTNu0rfGlMKBRa2jvSAoUjt+bSicPlW2mKg5KUXhs14+jZm7fzLcjNoclaKh4Zf6GmA3gTlDjUzAoOOrvp68/uXDwfFRoi0tQq32rt6GJmmF76EwAAEABJREFUbZua+HT1/OktvP1o5tTKwenZk38aYT2Gjw06fvBm4KmVsycZmlrcOHuiUJI/97uN9q6NXvV0/v0Dtq1amp+T3XvEe0Lh68/A7T9g6B9rvzl7YHdaUmJhfn5GanL5JmrP0eTGmf1/rPhofOuOXeIjw6lF6NqsZXlvjpdQ0wG8ofHzv2rR3k8ul9+/edmrS892XXuXb6Iw+mj5WqqeMlKSH968MnbOQruyaQeZTHFmewsbu89/2tbEs33Y3VuXTxy2dHCc890Gj/YdK3iuFmXzHqwSQ1cOTeP2GDZGR1f/8d1gI3PLwRM/VLwqjX8qm9GzPh80Ybq6hijwr33J8bE0RUsvoDKzxqpLMZhnAPXej1EhxayknZEle1O7f/r+6PbN7Xv0m7Z4Jatuezf9cHjrz24erRdu2FmZ21M5SV96hkY07KWrh3/fsHfDmsae3p/9uJXVvO3xjyc4NG5laMaUBkavAErt8O8bqSoMDb5ONdeQKTPL15/atzPywd2X3oW6bzRcpdGrto5um849qJ94+aRi19+B46ay+gpJB6DUkp/GhYfcNrexe2fCB+4t25Sv7x7wLn1VcEdKxsAj+6+fPU5Tw86NmvQfN7Vx67asvsLoFUDh7UevUA6jVwCAOoC5V6jvSkpKfvzxx8uXLzPgLyQd1C9ZWVncrh6ffPJJ9+7di4uLKen09PQaNmzIgL+QdMBzUqk0ODg4M1PxcagpU6YEBARIJBJa7t+//65du4RCobq6+rhx40xNTRnwF/p0wEPx8fFXr1719PR0dnb+8MMPadpt6dKltH7JkiXm5ubcbdq3b8+g3kDSAU/cvXv3xIkTHTt2pAg7cOBAYWFh586Kwyht3Lix/DblMQf1DZIOVBK12wwNDS9duvTLL7/06NFj+PDhVMc1aNCgSZMmtPWjjz5iAM9Bnw5UQ3JyclhYGC2cO3fOz8/v6NGjtKyvrz9r1qxhwxQH4+3Xrx/14AwqfZA4qFdQ04GSksvlN27cyMvLoxnSwMDAb7/9dvz48Y0aNWrcuPGxY8d0dRVHc2vevDkDqAQkHSgRaq7t27cvJydn2rRpISEhNDfau7fiACHe3t7Hjx/nbmNpWSMfY9AWqktL5Qyqg6GGprIdGQVJB3WM0m3FihVpaWnr1q1LT0+nBW5WtFUZ7jaampqshhmLNEOycxnGvtUhKi/LSkuHKRMkHdSqqKgoBwcHdXX1MWPGxMTEXLx4sbi4uHXr1h4eHrTVxsZm5syZrC44ifXvZqcxeGuy0hJzLR0LTeVKOnzCH2pWSkrKvXv32rZtS7MHffr0EYvFO3bsEIlEDx8+5OZJlcdXYTdNRFqtlelz6aroz4SIvpZOXcxsmTJB0kH1oxbblStXevbs6ejo+OGHH1K6LViwgOYQioqKamEc+jYWhF4zFGm2N7ZUY3w+AG8NKSop3p8Q1cPSoY+FA1MySDp4WzRJSqPRCxcuHD16dMiQIV5eXuvXr6dEGz58ODdDqlo2xDw4lBjtoKMnfF1PPSMzw9jImCm9AkmBjnZNjSUTEhPpUiSVF+jr6BTJHZKz7XOK6L1twoQJTJkg6aDKKNoyMzPNzMwo2n799dfJkydT+Xby5EkNDY0OHTooedVWSbEFudmyogpuMGfOnHHjxjVr1ozVIu7tZNasWdbW1pW/1+PHj48dOzZ79mxW3eiRN23alJeXR8vFqRklNKXzb54EBwczZYKkg0qhv2mZTNa0adNDhw4tX7580aJFvXv3Dg0NpXdvmmFg9UZ+fj79KGhSuPZH4vTzHzVqVGRkJLU7v/rqqyrd98GDB1paWg0aNGDVbdu2bVu2bCkoKHh+JaWKsiUdPiMBLyeRSP7++29uL7aDBw9++eWXSUlJtOzr63v9+nVuN7fGjRvXq5h7+vRpr169uHqq9kvX/fv3x8fHCwQCChHKuyrdl96iaiLmCM2he3p6Pl8wKWHMMSQdPC8rK2vt2rXr1q2j5fv371++fNnIyIiWBw4c+Mcff3Tt2pWWTUxMWP1DGcfKCrqgoKAa2nW5YtQxoGpaKpXSMr3lbN++nVURfQsBAQGsBnz99dd2dnblV2mSfebMmdz7ovJA0tVflGt0mZ2dPWPGjKlTp3JrDAwMunXrRss0sUB/wd7e3qzs3CusHjtx4gS3l18dHq2Tyuq4uDhumX4dN2/ejI6OrsoDMFtbW2rwUcOOVTcdHR3qWhoaGrKygu78+fMUqdwHk9PSlGUXRfTp6hEakD58+JDGGoWFhdyH4Xfu3JmTk0PlW/PmzfX09Bj8fxQu9vb2NNnSo0cPVneooOM6dOVr6N+2X79+ixcvZkpj5cqVNL6mQQA1PcpX0vggJSVl4cKFNDvP6hSSjufCwsLu3r1Lw09qSNPwk6qS9evX038OvdnWyShMhVBJSzFHfShW1/bs2fPDDz/QHMjzK83Nzcs/C1x5JSUlNAm7Zs0aVgOGDh1KL/WFlVRFenh4UNODXj9X99UJJB0PXbhw4dKlS++99x71zunPmi5p8FXnb6oqhBvX0yhs0KBBTAmMGDEiNzeX/lVp+pW6DWZmZtzyqVOnWNVR+5XuSFNMrBZRzNEs1ocffkhvuqwuIOlUHk3wU6PkwIED9OZJHTd6/6RZf2Nj4759+4pEIgZVQdXu/Pnz6R/S0dGRKZ/Y2FjqiNEgkammwMDATp06Xbt2rV27dqx2YUZC9VDjI7Fsx3SagKO/m3v37tEyRRv9f3LHa5s4ceI777yDmHsDNL9J/S/ljLnqRXH5wk5wtYD+XOmShhfULK7lyVkknQqQSqX0Nnjnzh1apnpt7NixT548YWXnfDly5Ag3PUp/Qy1atKjnk6RvLDk5ed68ebRAEzXcfyPvNW3alN4RWV2gmLt161ZxcTEt7969m9UKJJ2SysjI2LFjBwUZKys0aJkGVqysZUNzW1y6ubi4YMK0WqxYsULZPqdZ02hu6scff6zDvUBsbGxY2QBl2rRprOahT6dEqJ7ftGkThdesWbOuXLly/fr1Xr16NWrUiEHNoIH/o0ePhg8fzlREtffp4uLiaA6X5uVZ3cnLy9PV1T169Kiamhr32ZuagJquznC73VO60WiU23GX+iY0n0BVGysbmVLeIeZqDo1Yf/jhB3ovYfWYgYFBzYVLJXEHvOncufPVq1dpXpjVDNR0tYemESIiIvz8/LKysmhilLoVa9asyczMTEhIoKYJg9py/vx5d3d3KmTqcPeuN1MTc6/0mM+ePeP6IXUuPz9fLBbPmDFj1KhRXl5erPqgpqtZNJOwcePGkpISmlWYMmVKUFAQK/v0zOnTp7m9N42MjBBztemvv/46duyYhYWFysVcDaGJZiWJOUIxR5ezZ8/mdoqmOoBVEyRddeKmk/bt20dvvNwv6fDhw4IyIpGIphe++OILWknL2traDGpXYGAgKzv+ynfffYdJ6hfQIEMikTDlQOHLfdAtJiaGGjvVMm2CpHsrVKlxhyGkmYSBAwfSL4aV7Q7er18/7hTLy5cvnzx5Mv6v6tz06dNpjEYLNXTwIlW3du3aLVu2MCXTqlUrmhO/ffs2+7ev/cbQp6uysLAwGn7a29t///33VL79+uuv1PSheVJra+vnj10DSuLx48cNGzYMDQ2lao6pOFX/jMTboPEQhdXXX3/N3ghqutejCQSaAr916xYr2/GKftY5OTm0PHLkSJotopij5bZt2yLmlA394vr3788V1DyIuVpAk9E0Jc2U0pIlS7iduuPi4t5gPIukezkqlameP3ToECs7PNnNmzf19fVpef78+Tt27ODmEKysrBgoMaqAfv75Zzc3NwaVM3z4cG6HJ+XEHQtWV1eXZmYvXLhQpfsi6RS4XltUVNTMmTNXrVrFyt43qNHm6enJyn79X375JfcPg46b8nv48KGPjw8ttGjRgtsRHyqJpqQPHjzIlJuxsTEVH3RJyzTYkslklblXPU06mmaidhstREdH0+wBjUlZ2dENAwICuPe09u3bjx071tZWuc7OCxXjDj4eHBx85swZBm+KejJKO4Ytx52Vjeo7X1/fyhyqoB7NSDx48ICGMzSbHh8fP2LECAo4GopmZmZS6lXpnHKgnGh2iN69FixYwPirdmYkKBPatGnDNaZVAv0Lp6en09vbuHHjXnWb+lLTUXN65cqVCQkJrKxEv3TpEsUcK9txFzHHA4WFhZGRkfyOOVbWPKmFiS96lnPnzlX1PBV1SFtbm4Zf1IOq4OSQ/K/pIiIiaG7hxx9/ZMBfJSUlamr8f9uuz3uZVIZcLn/VsbX5/8dB3zx3sGzgK/oVK8PZHvgkJSVFFQ9jFRgY+OjRo5du4n/Subq6oqDjNyroaN6cQfUpLi5W/kmJ/7p8+TKN4V66if9nUaFqFp/l5jcNDY2dO3cyqD7m5ua//PILUzVdunShLvxLN/G/pgsPD3///fcZ8Bd10J2dnRlUH6FQ+KrIUGY+Pj40hnvpJv4nHdXh3I7BwFfciZ8ZVB8V7dOdOXOm/vbp3Nzcfv75Zwb8hT5dtUOfTvVQHc4dvhn4Cn26aoc+nepBn4730KerdujTqR706XgPfbpqhz6d6kGfjvfQp6t26NOpHvTpeA99umqHPp3qQZ+O99Cnq3bo06ke9Ol4D326akd9uvfee4+pGvTp0KfjM/Tpqh3VB6mpqUzVoE+HPh2foU9X7ahP99tvvzFVgz4d+nR8hj5dtaP6wNTUlKma+tinmzp1asuWLT09PUeOHHn9+vVWrVq1LsOAd9Cnq3Yq2qc7depUaGjoSzfxOemoAueW1crQAmUfA95Bn67aqWif7urVq5GRkS/dxNuka9GixQsnMzYyMqL6jgHvoE9X7VS0T9etW7cmTZq8dBOf+3Rjx441MTEpv+ro6Ni5c2cGvIM+XbVT0T5d+/btXVxcXrqJz0nHlXXcKYEMDAxGjBjBgI+oT4dfbvVCn07FUFnHvTVRQUcz0Az4iPp0sbGxDKoP+nQqhsq6Zs2aaWpqokPHY9Sn2717N4Pqw78+3Wv2HJaVlvz5NCI8LytDKmGqqWBwF0OfpgdNhQfvBTIVZKkl1lRT9zAw7W5e46c0Vi0ffPABTbly5/eksk5QhoqR48ePM3g7qtune9WmipIuIi9rRkhQJ1MbZx39ZvrGTHXZN2AqS6im9kySfyc79VhSzOrmvmpMwKDM8OHDFy1a9MIgi/dnaq8d1KebP3/+1q1bmUqhPp2tre0LO11wXpl0D3My1seELGrkxaCuWWuK6TI0N3NmyMW1zTsyKOPj4+Pm5nbz5s3nV7Zt25bBW1PdPl3Lli1fmnQv79MVl5b+EHVvuI0bA6XRWM/IXd/4lyehDP5F7VeaVS+/Ssvjxo1j8Nbqy/50NFbSVFMTqfH/U7GqxUlb/0xKPIN/+fr6Pr//lLu7u5cXRiHVoL7sTxcvyXPU0WegZAw1RMYamjlyKYN/jRkzhivr9PT0aJlBdagv+yJwMTMAABAASURBVNPlyKQ068pA+aRKC4tKihn8i7p19DZOExEo6KoR//an4//x6UDZFJYUR+fnyEuLpcUlxiItZ7F+hqwoOi/7jZc7jBkRK8mlGiRdWhiTn2OiqeWko/82y6lSSWpRoZ22rp66BquXVLdP96rj0yHpoDZQHXosKZYm9B109KLys+mLZr2Kiot1NTTMRdr5cllykeTNl9Ullh+N/1OzKDf0amqhRFddw1xTO7dYVrVluZTSjXvMvGIZPayhhlZbY4sSVmqkodXFzFZHWI/+WerX/nQAby+mILe4tGR7XNjtrFTKu4vp/28rZUpSYUH1LBdV0/K/j0lh+jgvkxY01YSnU+LmNGipLVSnTGT1QD3anw7g7f0YFXIxPTFLVsRUGQV0WG7m5DvnrLV1PQxMZ7p4ML7j3/50SDqoEbly2bnU+KNJMbz5yAJ9IwmSvERJnqvYsLuFnYaAz/tgoU8H8Ho05/DpwyvheVmMdyjvfoi6G5yVMse1hVjI2/kK/vXpsG8wVLOnhXnjb5/lZcyVu5SeOD74bLLKHvbitZKTk0ePHs1UTf09Ph3UvhsZyWlFvI2AcpmyopsZyYynSkpKMjMzmarB/nRQSxY9un4tI4nVD+uiQzJlhaPtGjHeoW7X9u3bmapBnw5qw96EyNvZafXnqEklpaUHEqJNNbV7mTswflFTUzMyMmKqBn06qA1lOwPLWX2SXyyLzsthvKOifboTJ048ePDgpZuQdFA94iR5u56Gs/onKC1BWsK3D4mraJ/u+vXr0dHRL92EpIPq8eWj6xLlLuhywqNP+wzMfljNcUxTE1Pvnmf8oqJ9uh49ejRt2vSlm/icdOnJiaO8G/29+zcGNeyJ4iNfyt6gyw2Ppv6Trkv199Ty5LKYAl6NYVW0T9euXbtXnfmXz0l39czfDGqFtbZY+T/ylRsRrWNrJdTSZNVNIBDYaOsyHuFfn67a5l5LS0upejp36M+0ZwnGZpaenboNHD9NR/zPrz/wyL7Te3cmPIlWVxc6uLr3HzfVo50vrY+PCv90VH+xvsFHy9b+vPhje7eGw6fNfWHNvO83yeXyYzu3XDl1LCUhXt/IuPvgkX1GTaz4eT8bMzAuIoxusPOHFfT1a+BdkabWq158QV7O798vCQ46qyES+fcfqqmjs3fDGq/OPWcsXfPg5pUVM8Zri/U2n/nnfAVfvDc4JuzhhE++8h8wlK7mZGXs+Xl16K1rGWkpNg7OQ6bObNHej9af2rdj2/dfe/p1a+jRev+WH/uPmXxiz7acjPQPlqxq17U391AfDeqcnpT44dI1bTv3ZKrsZmZKQU0OXaWZ2REbt6deulEqL9ZzdXKdPs6gkeIsSFkPH9+cMr/Vmi+f/HGQhqWUYi6T3rXp25W7V/L5K7E79uc9eaptYdZw5qTcyFi9Bo6sBmRKC6msM9ao/gytK6rbp5NKpS8dwFZbTbd3w+o/1n6Tk5np3a2vhpbW8T9+Xf/FLG7T4d83bFm2ICE20rNjl4YtPB/fC/5u9uQ7lwNpk0ik+OOQ5OVu+36JqbWNtYPzf9fQ1R1rllL0SAsl/UZP1NHV27X+u+O7tlb8vL69BppYWNFC49Zte494T63CQ+5QzF0+cYRCs6mXz80Lp88d+JNWCtVf/zZAEUw5GPjXXmMLy76jJqSnPFv18bTIh/eY4iSkIrpMjI06sGWdc+PmRmbmvr0H0ZpbQWe5+ybERlHMaenotPBW+ZPg7EuIZDVGlpd/c9qnedFPWqz4rO0v32lbW97+aGFRuuL/MD/2KV0+2XXYddq4Tse3m/u3D1u1sbhQUV2m37gTsnClSduW7X5dRcn4+IfNeVFPKCVZzVgcep3xCP/6dNVT0+VlZ/296zdamLb4W6poJPm5M9/pGnrremx4qLm17aGtG2gTFUHcv/pv3315Zv+u/Zt/bNmhE3d3egNp6es/7P05tJwc/+SFNVlpqecOKqKHqiGXxs079Q+YOajLkW0bew4bW5Cb86rn7TVi3J0rF9KTn7X08e81fFwFL56Ksmtl49wpX6zw8u9RJCmYPaQ7KxuSsNe5deEMVY5UgX68apNIS9vWqcG6L2Yf2bZ51jfruBskPomet3ozV8AmxcUe27Hl3pUguUymrqFx72oQraSiT1Nbh6k49Zr8uHv0b3tkObltflouMlIcRb3R7MlJZ4JSLlyze6dXXkycQEO90exJOjaKdzVjT4/4fcekGVna1haRm3Yat27eYPIoWi+2t8l++Djm9701l3SZKn68lheobp/uVZuq5w806mGITCalaGjq1YGu0lhv48nrW4NCHN0ax0U+lhUVKl7Ev0M2r0496DIuMowKovJH6NCj/wuPWb4m+tF9Cj760RsYm1DRRJWXqYV1blbWs7iYCp6XVRqVXcVlr4RLXsqd1j6dK3nfqId36ZIKz9ycLHptFrb2dDXiwZ3yG+gbGnExRyztHRu1bENxHHZXMRC+d+UiXfr0GsBUXztjC1Yz6Nf97Pg5y66+XMwRoaZI08S4MDWNlvMiY4xbNuVijhSlptP/qMjEqDA5LScs0rqXf/njiIwM6VK3QU0l3Wj7hqzm0Z+6vb09q3lpaWkLFy5kqqbG+3T5udl0qaUtVv/PiC8jRfHZQC0dsYbony6GroHib66kuDg7PaX8ZgbGLx44oXxNQV4uK6vyqJR7/gaZqckVPG/l5WUrxkEiLa3yVyh+7sR6FSvIy6PLiPt3Phrwv38qasZR1cYt6/3/78u//5CwOzeDL5x1bdoi/N4taiw2bt2Oqb50aU1VNJLEZCronh46mXDkdPnKEqlMQ1+PFnIjn9gP6VO+nka4YjtrisK0sAi6qu/uWr6JQlDD0EDLtKZO0K5TK8c1odyPi4tjNU8mk92+fZupmgr6dNWTdEZmird0SUEeNy6j5dysTCqUdHR1xXqK1CgsyKcuG43vWNlokZW9O+noGuRkpHGPoCZ8sbosX0NjQ1bW9vpw2Q/P38DWyfVZWfftpc/LPVdl0MugS2lhoUxaxIVdXnZ2+VYBU4xh5c/9J+dm/+8oHWI9xRnUnNybDBr/wUsfXCgUPn+1jX/331ctvX3xXLO2Haga7dCrnxovTjUZJ8llNUOerzgCcLOv5uo62j2/XtPUuCgtQ5aVreviWL6S5hx0y+YcqKajS20r8/JNmSGhNTQdwTmWHOtjYsX4goauH3/8MVM11KczNzd/6abq+Tezc3GjmogW7l4JZIpcK5gztOcH/Xyjwx64NvPQ0VXEwbVzJ7kbc02xBs1aaovFlXlwZ/dmakIh5YKZlU0rH//m7XypPUfvbnT3Cp6X/RtSRZLXHFeDxp5c3HCTJJL8/FtBZ8q36hubMMVbnPRpjKLp/iTiEU3ylm91bdaCKarL1GZe7em1OTZsTK9NU1OLi93/ovlfnx79aJx7ZPtmphi6DmS84G1syWqGlpni568u1hE72HJfVNdomZvSGso12lSeX7ReMedQdlWtrMYvlhRym3IeR2U/eFxzTbpSxtx0DRmPaGlpdeyoehNlFexPVz01HQ1Iew8fd+i3DRuXfBYcdI4mBApysxt7ers1b00hMnjSB9tXL/v1m0Wht67kZGaEXLtE05pDp86q5INTe67zwGFn9v+x4qPxrTt2iY8Mp9Gia7OWNNVAPbVXPS/d0dhMke6n9mxLfZYw7P3Z+kYvH7kYmprRQwUHnd309Wd3Lp6PCg15fn8Ua0cXM2vb1MSnq+dPb+Htd+fyeSsHp2dPYritLTv4O7i6U/wtmjiMUu/+tcspifH9xkxq0sb7Vd+O/4Ahp/btoG/BqVETG0cXxgu9LBz2Po1IKMxn1Y3aczR/Grlxh1BLU9PYKP3WvfB1W2lSwrqnf15UrLquWNvyn/dwGucWF0j0yjpxhs0a0aghassum/7d6WZxe45QENZc0tlp675n7854JCsra9OmTSpX1lGfztbWtmb3Mnln0oyhUylNjK6ePkrTlzT1OWvFWq5W6jF0zMRPl1jZO14/cyIi5G4zrw6fr9/m3rJN5R989KzPB02Yrq4hCvxrX3J8bNfBI+Z8t4GbG63geXu/O56iJD8v9+Gtq6UVfjJx/PyvaOqWZkju37zs1aVn+eQJKxt+frR8LdWV1HB8ePPK2DkL7ZzdWFkjgy6pdpv/wy80q5CZmnT+8N5SVjpyxnx6PRU8l12DhtzuL/yYi+AUFsvNtWpqBrnpF7No8vTep8uvjv0o4ejpxp9Mp5hj3FjV+X/t+byyEo8bvVKoNZw5MeXS9RtTPk4+d9lpnGLPx+fHudXL09CcZx98lUgkQUFBTNVU8LlXQenLPsTze1zYs8L8TqY2rF7a/dP3R7dvbt+j37TFK1l1e3jz6vIZ79EUzZqD53T1Kzv1UW5V5N31LfzMREp3hqqF9enIdC/wMbFe2KgK79xvLDY2ds6cOfv372c1rLCw8MaNGyo3gL127Rr16V46gK0vx6f77buvuDnc/+r77gR719o4mCJNRJw7vOfRbcUupn1HT3qDmFNmU5yaphUVRua/8qDqTw+fzHrw+L/riyUSofbLg9tl/PDnZxXeUkrQ9ZSLL9+/V6Cm9qqqn8pDh6H92KvZaeu9a+fG+EV1+3Sv2lRfkm7c3LrfOYgmnR/euqatrd31nZH9x0xm/GKjJZ7j2vL9Vx/Vw3ZAD/pidce8Y1v6YtWKuiRLm7Sz1FT5fb9fwL8+HY45/BLDp82hL1bdOvULoC/GX2oCRv/z5WeJrg8a6RmL1ISMd7g+ncolXW187hXASUe/u6W9rjpvzw34Ah11DW8TKz59sL+c6u5PV7OfewXgjLJt2NbI8sN7F0qU/nB1b0lTTbiokVdLA9U7KWpl8K9Ph5oOqpmr2KCnBd/OIPNf4x3d+RpzrKxP9+233zJVg/NIQK2a6eLRxsiCr8NYHaG6r4nNICue7PX9Uvzbnw6jV6gRSxu3iy7IWfzoelIhryYonMX6Y+zd29fYp9+UhIr26Xr16vWqz70i6aCmOOvor/PotDD0ao5c9lSSx1ScsUjTQlO8qpmPsBIHLlR1Ktqn8/LyetUmJB3UIH11jTXNOz4pyBWra3wXcTtekpdWJOGmKrjL8sworeLyv2sodUqrf1mgOGCA4uUJmImGdjdzu4HWzvTim+ubsPpBRfenO378uJ2dXbNmzf67CUkHNc5BR3EsucXubW9kJhuoiww0RNvjHscW5DbQNbDREtNKqvjaGltWabmdsaW1lvhaZlKiJP/Nlq9kJCUV5nubWFlp6rywXMpK/c1s2xpZBGelWmjqdDCxVGMCIz7uTfIqKro/3c2bN+Vy+UuTDp97VTFK+7lXqAX43GvF6DVTn87R0fG/m15e06kLBOr1oBmhivQ0NEsZfjVQs/jXp3v5XibGIq0MKa/OAMIPVH7HF+SYi7QYQE1S0f3pqE93//79l256edI5iQ2KSooZKJk0aaEHf/dWBeWhovudvhonAAAQAElEQVTTUZ8uJibmpZtennSNdA111TXuZacxUCbHk2OH2rgygBpmZGT06aefMlXTq1ev5s2bv3TTKz8j8aV728d5WbezUxkohx3xj4fYNGhjVG3HawN4FerTdejQgaka6tO9dDqCVbyXyapmPivCg9dFhxhpaGkLVXV/lNLSErlMriESMdWkp6ERm5+jqy4aaO3c2dSWAdQ86tNt2LDhk08+YSrlzfen+8StNfWGYgty0osKmWp69uzZ0eMnJ02axFSTSE2NRqzOYgMNzIZDbaE+3aVLl5iqqWB/utdXaqYiLVNVnux7lJF/9nFsD4vaOPM5AD+obp8On3sFgMpS3T7dqzbhqE0A8CLq061YsYKpmirvTwcA9Znq9uletT8dRq8A8CL06QCA/9CnAwD+Q58OAPgPfToA4D/06QCA/9CnAwD+Q58OAPgPfToA4D8V7dP16dPH1PTlh6pF0gHAi1S0T+fp6fmqTRi9AsCLVLRPd/To0ZCQkJduQtIBwItUtE8XHBwcGxv70k0YvQLAi9CnAwD+Q58OAPgvMzNz6dKlTNWgTwcAVVBYWHj16lWmatCnA4AqoD7d559/zlQN+nQAUAXUp/P29maqBn06AKgC9OlUj0gkKikpiY+PZwAq7u7du2KxmNW87OzsqKgopmrCwsLi4uJeuklQWlrK+C4wMHDNmjU2NjZDhgzp1KkTA1ApEolkz549e/fudXFx+eKLL17ViqpeSUlJVCUYGxsz1XHu3Lm2bdu+9M2gXiQd59q1a/v27Xvw4MGQMvr6+gxAudGfKwXc2bNnhw4dSn+0VlZWrBZRiWRhYUGzE0z11aOk46Smpu4tQw1X+tNp2bIlA1A+hw4dojdmdXX1gICAvn37sjpCCbt8+XKqJZnS279/v6GhYZcuXV66td4lXbmTJ09S3uXm5lLe0R8TA1AC1FCmP0saq/bp04f+Mhs1asTq2sOHD93d3dXUlL2n361btz///PNVw+36m3ScyMhI+sOidwNuSOvs7MwA6gJ1k+lPMSEhgf4OqZLS0NBgykEqlYaGhrZo0YIpscLCQqpazMzMXnWD+p50HPohcENaaknQ3xm9OTCAWpGTk0MVHA1UmzZtSmOLdu3aMeVz+/btn3/+efPmzUxlIen+n+DgYMq7mzdvciWeiYkJA6gZd+7coT+2q1evcrMNtTOj+sbS0tLy8vIcHR2ZUvLz86N5G2prvuoGSLqXyMrK4ko8Dw8P+hOs4IRDAG+AKjj669LT06O/rh49ejAV8ezZM4oLa2trpmQuXbpEY/8FCxZUcBskXUXOnTtHf5HJyclciVfBOwbAa0VHR3MD1YAyDRo0YKpm0aJFbdq0qcO54DeGpHu9J0+eUN7RHyj9ginvGjZsyACq4vTp0/QnlJmZyQ1UmSqj2Ql7e3tdXV2mHCjBHj9+/NpJaiRdFRw8eJD+XjU1NemPtXfv3gygQtTb4gaqVAfR30zr1q0ZL4SFhVFBqiRDnEOHDt2/f/+LL76o+GZIuioLCQmhv90LFy5wQ1pLS0sG8P/duHGD/kjoT4XbW9PQ0JDxSFFRkb+//5UrV5gS2LBhQ9euXV/bCkDSvaH8/HxuSEs/YvprVsVDUUO1k8vl3FyWhYUF/VV07tyZ8VRBQUF4eLiS72T3PCTd27p48SL9ZcfExHAlnra2NoP6hwZ09LZ39OhRquDoz8DBwYHxXV5eXlZWlq2tLas79GOXSCSV+Uwnkq56JCYmcm/mXbp0oT/0pk2bMqgfjh8/Tr93qVRKv/eBAwey+mT37t1Pnz6dO3cuqyOjRo1asGBBZT4zh6SrZvSuTu/tNIqhv/sBAwYw4KmkpCTuvc3Pz49+182bN2f1UnR0NM3R2djYsFqXnZ1N7fL+/ftX5sZIuhrx6NEj+h/4+++/uSGtnZ0dA764fPky/XIjIyO5gWrtHBpTmSUkJBgYGCjPficvhaSrQTSi4d72cRBQHqB+EPfbdHJyGjp0qI+PD4N/DRs2bOnSpbW8L/S33347fvz4Sn6KDklXGypzEND169dPnz6dgfIpPxwm9+tTwo9DKYPAwEBfX1+hUMhqBf1SVq5c+fvvv1fy9ki62lPBQUCp10O/iBkzZuBIeUrl8OHD9Puq88NhqoTi4uL4+PhaOwTAs2fPNDQ0Kn9YBCRdHfjvQUBbt24tEAgMDQ0XL16MYVGd4w6HSXr16kW/I3d3dwaVcP/+/e+///63335jygdJV2eopb2vjLa2NvWAuJX0HrVp0yZ7e3sGdeH5w2ESkUjEoCqo1EpPT6/pvaxu37594MCBr7/+uvJ3QdLVMfr5U0H3/KGrzc3N//rrLxw3pTbl5ORwRZwyHw5TVWRnZ9MApUbPSPXVV1/Rf02fPn0qfxckXR0bMGAAVRDPr6HfCA2XduzYwaDmlR8OkyviKjg8N1QeNWE8PT2VqrOJpKtL8tLSTnOmC8yM1PT1uDWlrFRdqC4QMAMDAw8PlflQoYq6fec2/cRtbGwsLCy4NWJ1DT11DVc9o86mdbArLJ9cu3bNzc2tJk4XW1hYSN2eqp6bEUlXZ+7npC98dL0wMlanQCoSCmkiiRp2Ojo6tEBDVycnJwY1jMZZ9I7y/Bp1gVqqVJIvl6VJC9c099UQKPsJsZRZcnIy9Z2rfb+TuXPnUrVY1b1T0QyqG7ezU7c+eTTftRWjL6gr+i85T4g7UxQLsZLcD+9eWN+ik5AKbHgjFHPe3t43btxg1Ucmk1FN9wY74aOmqwM0aB16/e+P3ZBxSu1hbkZSYcHnDT0ZvKn8/Pzr168rw9GrUJzXgZPJTxrrV3//AqpXEz3jaxnPJMVyBm9KLBZ36NAhKyuLVRPKzfT0dFZ1SLo6EFeQa61V3z8WrhLcdI0j8qrtv7R+0tTUPHny5LfffsveWmpq6qJFi97s3KRIujpA3W51dH9UAU2F58plDN7OsGHDevToERkZyd5OfHz8a88X8SqYkQCAGufh4ZGbmyuVSt/mYyetWr15axs1HQDUBj09vbFjx4aHh7M3Qu25TZs2sTeFpAOAWrJr164HDx7I5W8yybNnz57nPzRZVRi9AkDtGTRoUH5+/hscoLhNmzZvc+AA1HQAUHsEAkFsbOy4ceNYFXl6emppabE3haQDgFpFpdnixYurdGLsX3755dSpU+wtIOkAoLY5Ojp6eXnJZJXdg2fHjh1veSgtJB0A1AF1dfXly5cfPnz4tbekGYzjx4+/5QHvkHQAUDcWLlwoFouTkpIqvllJSYmGhgZ7O0g6AKgzXbt2NTExqfg4Iz4+PoK3/kwRkg4A6pJQKKSe3au2Xr16deTIkW9/kDskHQDUJTU1tbNnz+7du/elW729vWfOnMneGpIOAOoYzTYEBARQP+6F9cXFxdevX2fVAUkHVTM7oNvq+dMZQLWiTtzBgweXLVv2/MpDhw5RuceqA5IOqiA69EFKQjwDqAGDBw/u3LnzvXv3ytdIJJIxY8aw6oCkUw05WRlbln8xe3C3cX4en48ZdPfKBW79jwtmjvJutOaTD7mr184cp6vTenlnZyiOyxobHvrd3KnT+/pM6Nzym5kTnj2JKX/AxNhoKs0mdW0zqYvnkvdHhd66xq3fu2E1PUJ51SbJz6er9JUc/2T76mULJwTQyuCgs7Tm3tWLFT9FBQ7++hPdZbx/i7WffUTfC/eaWdmeU9zT0cNyt/xj7Td09afF8yr+OcRHhdPNpvRoGxp8/cN+fivnTF49/wNa8+u3i8qfdMNX82nNkW2bGSirdu3aeXh4lF8dNWqUra0tqw5IOhVA//8rZowP/GuvsYVl31ET0lOerfp4WuRDxVvfuLmLDExMb104Tf/zBfl5O35YoVj58WIDY5Okp3Ffvz/67uXA5l4+fn0DHty4suyDcZL8XLpBZmrKkvdHUmDZN3Br6esf+eDuipkTwu8FV/wyGrdu69pccYAwC1v73iPeM7OyqeApKkDfyP7Na7PT05p4euflZG39ZjGtVFN//Q5TFfwcRCJNupTk5W77fomptY21g3PnAUNpze2L57k9GOjy/o3LtNCsXQcGym306NHh4eF3796liVdWTZB0KuDWhTNxEWFifYOPV20KmDRj3NyFJcXFXG2iZ2g0Yf5XtPD790t2rfs2Ky3Fu3tfL/8etObE7q2FBfke3r5TFq4YM/tz/4FDM9OSg44dVGz68/fcrCxn92YLft4xbfHKAeOmCtWEf+/+veKX0bpjF492vrRg6+w6csZ8a0fnCp6iAqf376LLboPfnbPy58/W/e7YqDFdFbDX7zBVwc+BQy1tCu5FG/94d8Ynzdr5mFhY0Q8k+tED2hT7+CFlq6mVjYOrOwPltn379osXL65YseLNDqT+Ukg6FRD18C5dUp2Sm5NFhQyVVHQ14sEdbmsr386+vQelJj49f2iPoanZ2Dn/HH468kEIXdo4NqC70Jets5viXvcV93p0W3FiuubevtwOme9M+GBrUMhHy9eyKqrgKV6Fwig+6jEtUCRxa9p26cUqp+KfA6dDj/7cgpqaWse+79DC7aAzdHnv2iW69OnRT4Dj2quCoUOHTp061c3NjVUTHJ9OBRTk5bGyBPlogH/5ypyMdLlMpl72KRn//gEXjysqKUo9XX2Df++VQ5fHd22lr/J7ZaSm0GV+2Sax7lt9kLDip3j1XXKpEFM8u94/r1Osb8Aq+3Sv/DmUXzUwNi1f9uv7zqFff7p18dyQqbNCrim6ij69BjJQBXp6em9wUtcKIOlUgFhPEUlO7k0Gjf/gv1upe7V9jWJuXqSlFfjXPv9+Q5zcFQcsFOvrswTWsc87np26ld9YW6w4AqKxmQXNMOTn/HPWK5m0KD8nR00o1DcyZmWHdZUWFXKb8nIqOjNWBU/xKrSVqi2q7PJzs7k1+dn/e4ryg8rKpFJuIfe5rRX/HP55BOH/himmljbN2/nQzEnMowfUi2zQxMPS3pFBvYTRqwpwbdaCKaYRUpt5tW/l4+/YsHFBbo6mphZX0B3dsSUm7GGL9n7j5i2mcmnj0s9kMkVMuDZpyRSTp3l0F/oyMjGTFkrEunq00qWJYnrr7tWL3L6aVJF90M933cLZTFETKTojNJXJHQL79sX/vzdT2dBPUlDwzwt79VO8ilAotLJ3ooU7F89zay6fOlK+lZJO18CQFmLDFHOv9GjcNEJlfg4v1an/ELrctnop/WRQ0NVnqOlUQMsO/tRHfxLxaNHEYfTffv/a5ZTE+H5jJjVp4/00OuLQr+vVRZqjZy+wsLG78Nfex/eCD/2ynsZrPYaPDTp+8GbgqZWzJxmaWtw4e6JQkj/3u432ro16j3zv3KE91KRfMvVdcxvb62dPUPdq4Nip9FzN23Wk5ay01G8+Gm/l4BQd+oBypHx4aGxmTpdhd25s+Gq+X7+ACp6igm+n04AhO39YcXr/zsy0lIL83OSncc9vpci+9PfhPT+vehYXEx5y29DEgeYCFQAAAopJREFUjGYVXvtzeOWPzqezvrEJDXjpu2jXtbINQeAf1HQqgP5L5//wi0+vAZmpSecP7y1lpTT1OXTq7GKq4L7+hGJowNgpFHNMsdPJQhqEHqEq79EDWvP5T9uaeLYPu3vr8onDlg6Oc77b4NG+I91M39D4i5+3U6Y8jYq4fTGQSrxPfvi1safiSIeWtvbvL/rWws4h8mFIUlzsB1+v1hYrTsLN1Yle/j2btmlPE7UhV4OkEkkFT1GB7kNG9xg2Rlus9/DmVX0jk2Hvz35+K02btu7YlYrHG+dPtuvWm5tVkJcNZl/1c6joR6eu3rytDy14ePtx1SLUT4KKj5cCNWFJ2E0LTe3mBqYMaFb06kUqCY1MLX48coFVt5zMjHnDe+XnZH+y9lfKaFZFexIiB1u7dDCxYqDiMHqF6ndq306aAXjpJuqvtevam9W81GcJ21cvpX4fxRxVnW8Qc8AnSDqoft0D3qUvVqdkRUWhwYrDYNBYePz8LxnUb0g6qGMe3r47roax6mbt6LzlbDADKIOkAwD+Q9IBAP8h6QCA/5B0AMB/SDoA4D8kHQDwH5IOAPgPSQcA/IekAwD+Q9IBAP8h6eqAsUgzv1jOQOnlyqUmIi0Gqg/Hp6sDrrpGGdJCBkovU1rkLK7saS5AmSHp6kB3c7uw3MxcuYyBEruUkdjF3Fakhv8RPsBvsW6sb9HpQGJUOio7ZXU1I6mwuPh9p2YMeAHHHK4zKUWSRY+uM1Zqr6PH8EtQDhpC9fSiguLSUgtNnTmuLRnwBZKujj3ISY/Jz82SFzFQAhoCNVORlpNY3wXtOX5B0gEA/2EvEwDgPyQdAPAfkg4A+A9JBwD8h6QDAP5D0gEA//0fAAAA//+iCWiqAAAABklEQVQDAFoxXWB13ElOAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 그래프 실행",
   "id": "9954ad9d455e26df"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:55:28.529155Z",
     "start_time": "2025-04-27T12:55:27.473315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import random_uuid, invoke_graph, stream_graph\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.errors import GraphRecursionError\n",
    "\n",
    "\n",
    "def run_graph(\n",
    "    message: str, recursive_limit: int = 30, node_names=[], stream: bool = False\n",
    "):\n",
    "    # config 설정(재귀 최대 횟수, thread_id)\n",
    "    config = RunnableConfig(\n",
    "        recursion_limit=recursive_limit, configurable={\"thread_id\": random_uuid()}\n",
    "    )\n",
    "\n",
    "    # 질문 입력\n",
    "    inputs = {\n",
    "        \"messages\": [HumanMessage(content=message)],\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        if stream:\n",
    "            # 그래프 실행\n",
    "            stream_graph(app, inputs, config, node_names=node_names)\n",
    "        else:\n",
    "            invoke_graph(app, inputs, config, node_names=node_names)\n",
    "        output = app.get_state(config).values\n",
    "        return output\n",
    "    except GraphRecursionError as recursion_error:\n",
    "        print(f\"GraphRecursionError: {recursion_error}\")\n",
    "        output = app.get_state(config).values\n",
    "        return output"
   ],
   "id": "cb6fd7f340fd1ea6",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:55:44.268133Z",
     "start_time": "2025-04-27T12:55:33.162225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output = run_graph(\n",
    "    \"Andrew Adam 직원의 인적정보를 모두 조회해줘\",\n",
    "    stream=False,\n",
    ")"
   ],
   "id": "ea2c8dedae6fb69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mfirst_tool_call\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_list_tables (initial_tool_call_abc123)\n",
      " Call ID: initial_tool_call_abc123\n",
      "  Args:\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mlist_tables_tool\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: sql_db_list_tables\n",
      "\n",
      "Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mmodel_get_schema\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_schema (call_ez5mBqoMtZYypeAOXqs60k7Q)\n",
      " Call ID: call_ez5mBqoMtZYypeAOXqs60k7Q\n",
      "  Args:\n",
      "    table_names: Employee\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mget_schema_tool\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: sql_db_schema\n",
      "\n",
      "\n",
      "CREATE TABLE \"Employee\" (\n",
      "\t\"EmployeeId\" INTEGER NOT NULL, \n",
      "\t\"LastName\" NVARCHAR(20) NOT NULL, \n",
      "\t\"FirstName\" NVARCHAR(20) NOT NULL, \n",
      "\t\"Title\" NVARCHAR(30), \n",
      "\t\"ReportsTo\" INTEGER, \n",
      "\t\"BirthDate\" DATETIME, \n",
      "\t\"HireDate\" DATETIME, \n",
      "\t\"Address\" NVARCHAR(70), \n",
      "\t\"City\" NVARCHAR(40), \n",
      "\t\"State\" NVARCHAR(40), \n",
      "\t\"Country\" NVARCHAR(40), \n",
      "\t\"PostalCode\" NVARCHAR(10), \n",
      "\t\"Phone\" NVARCHAR(24), \n",
      "\t\"Fax\" NVARCHAR(24), \n",
      "\t\"Email\" NVARCHAR(60), \n",
      "\tPRIMARY KEY (\"EmployeeId\"), \n",
      "\tFOREIGN KEY(\"ReportsTo\") REFERENCES \"Employee\" (\"EmployeeId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Employee table:\n",
      "EmployeeId\tLastName\tFirstName\tTitle\tReportsTo\tBirthDate\tHireDate\tAddress\tCity\tState\tCountry\tPostalCode\tPhone\tFax\tEmail\n",
      "1\tAdams\tAndrew\tGeneral Manager\tNone\t1962-02-18 00:00:00\t2002-08-14 00:00:00\t11120 Jasper Ave NW\tEdmonton\tAB\tCanada\tT5K 2N1\t+1 (780) 428-9482\t+1 (780) 428-3457\tandrew@chinookcorp.com\n",
      "2\tEdwards\tNancy\tSales Manager\t1\t1958-12-08 00:00:00\t2002-05-01 00:00:00\t825 8 Ave SW\tCalgary\tAB\tCanada\tT2P 2T3\t+1 (403) 262-3443\t+1 (403) 262-3322\tnancy@chinookcorp.com\n",
      "3\tPeacock\tJane\tSales Support Agent\t2\t1973-08-29 00:00:00\t2002-04-01 00:00:00\t1111 6 Ave SW\tCalgary\tAB\tCanada\tT2P 5M5\t+1 (403) 262-3443\t+1 (403) 262-6712\tjane@chinookcorp.com\n",
      "*/\n",
      "==================================================\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_TVFunEKrVdK4dJwrbDQ6HGQH)\n",
      " Call ID: call_TVFunEKrVdK4dJwrbDQ6HGQH\n",
      "  Args:\n",
      "    state: {'messages': [{'content': 'Andrew Adam 직원의 인적정보를 모두 조회해줘', 'type': 'human'}, {'content': 'Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track', 'type': 'function', 'name': 'sql_db_list_tables'}, {'content': '\\nCREATE TABLE \"Employee\" (\\n\\t\"EmployeeId\" INTEGER NOT NULL, \\n\\t\"LastName\" NVARCHAR(20) NOT NULL, \\n\\t\"FirstName\" NVARCHAR(20) NOT NULL, \\n\\t\"Title\" NVARCHAR(30), \\n\\t\"ReportsTo\" INTEGER, \\n\\t\"BirthDate\" DATETIME, \\n\\t\"HireDate\" DATETIME, \\n\\t\"Address\" NVARCHAR(70), \\n\\t\"City\" NVARCHAR(40), \\n\\t\"State\" NVARCHAR(40), \\n\\t\"Country\" NVARCHAR(40), \\n\\t\"PostalCode\" NVARCHAR(10), \\n\\t\"Phone\" NVARCHAR(24), \\n\\t\"Fax\" NVARCHAR(24), \\n\\t\"Email\" NVARCHAR(60), \\n\\tPRIMARY KEY (\"EmployeeId\"), \\n\\tFOREIGN KEY(\"ReportsTo\") REFERENCES \"Employee\" (\"EmployeeId\")\\n)\\n\\n/*\\n3 rows from Employee table:\\nEmployeeId\\tLastName\\tFirstName\\tTitle\\tReportsTo\\tBirthDate\\tHireDate\\tAddress\\tCity\\tState\\tCountry\\tPostalCode\\tPhone\\tFax\\tEmail\\n1\\tAdams\\tAndrew\\tGeneral Manager\\tNone\\t1962-02-18 00:00:00\\t2002-08-14 00:00:00\\t11120 Jasper Ave NW\\tEdmonton\\tAB\\tCanada\\tT5K 2N1\\t+1 (780) 428-9482\\t+1 (780) 428-3457\\tandrew@chinookcorp.com\\n2\\tEdwards\\tNancy\\tSales Manager\\t1\\t1958-12-08 00:00:00\\t2002-05-01 00:00:00\\t825 8 Ave SW\\tCalgary\\tAB\\tCanada\\tT2P 2T3\\t+1 (403) 262-3443\\t+1 (403) 262-3322\\tnancy@chinookcorp.com\\n3\\tPeacock\\tJane\\tSales Support Agent\\t2\\t1973-08-29 00:00:00\\t2002-04-01 00:00:00\\t1111 6 Ave SW\\tCalgary\\tAB\\tCanada\\tT2P 5M5\\t+1 (403) 262-3443\\t+1 (403) 262-6712\\tjane@chinookcorp.com\\n*/', 'type': 'function', 'name': 'sql_db_schema'}]}\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mquery_gen\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_TVFunEKrVdK4dJwrbDQ6HGQH)\n",
      " Call ID: call_TVFunEKrVdK4dJwrbDQ6HGQH\n",
      "  Args:\n",
      "    state: {'messages': [{'content': 'Andrew Adam 직원의 인적정보를 모두 조회해줘', 'type': 'human'}, {'content': 'Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track', 'type': 'function', 'name': 'sql_db_list_tables'}, {'content': '\\nCREATE TABLE \"Employee\" (\\n\\t\"EmployeeId\" INTEGER NOT NULL, \\n\\t\"LastName\" NVARCHAR(20) NOT NULL, \\n\\t\"FirstName\" NVARCHAR(20) NOT NULL, \\n\\t\"Title\" NVARCHAR(30), \\n\\t\"ReportsTo\" INTEGER, \\n\\t\"BirthDate\" DATETIME, \\n\\t\"HireDate\" DATETIME, \\n\\t\"Address\" NVARCHAR(70), \\n\\t\"City\" NVARCHAR(40), \\n\\t\"State\" NVARCHAR(40), \\n\\t\"Country\" NVARCHAR(40), \\n\\t\"PostalCode\" NVARCHAR(10), \\n\\t\"Phone\" NVARCHAR(24), \\n\\t\"Fax\" NVARCHAR(24), \\n\\t\"Email\" NVARCHAR(60), \\n\\tPRIMARY KEY (\"EmployeeId\"), \\n\\tFOREIGN KEY(\"ReportsTo\") REFERENCES \"Employee\" (\"EmployeeId\")\\n)\\n\\n/*\\n3 rows from Employee table:\\nEmployeeId\\tLastName\\tFirstName\\tTitle\\tReportsTo\\tBirthDate\\tHireDate\\tAddress\\tCity\\tState\\tCountry\\tPostalCode\\tPhone\\tFax\\tEmail\\n1\\tAdams\\tAndrew\\tGeneral Manager\\tNone\\t1962-02-18 00:00:00\\t2002-08-14 00:00:00\\t11120 Jasper Ave NW\\tEdmonton\\tAB\\tCanada\\tT5K 2N1\\t+1 (780) 428-9482\\t+1 (780) 428-3457\\tandrew@chinookcorp.com\\n2\\tEdwards\\tNancy\\tSales Manager\\t1\\t1958-12-08 00:00:00\\t2002-05-01 00:00:00\\t825 8 Ave SW\\tCalgary\\tAB\\tCanada\\tT2P 2T3\\t+1 (403) 262-3443\\t+1 (403) 262-3322\\tnancy@chinookcorp.com\\n3\\tPeacock\\tJane\\tSales Support Agent\\t2\\t1973-08-29 00:00:00\\t2002-04-01 00:00:00\\t1111 6 Ave SW\\tCalgary\\tAB\\tCanada\\tT2P 5M5\\t+1 (403) 262-3443\\t+1 (403) 262-6712\\tjane@chinookcorp.com\\n*/', 'type': 'function', 'name': 'sql_db_schema'}]}\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "\n",
      "Error: The wrong tool was called: model_check_query. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\n",
      "==================================================\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "SELECT * FROM Employee WHERE FirstName = 'Andrew' AND LastName = 'Adams';\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mquery_gen\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "SELECT * FROM Employee WHERE FirstName = 'Andrew' AND LastName = 'Adams';\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mcorrect_query\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  db_query_tool (call_60ilvvUTlNXTWJxX5viTET4s)\n",
      " Call ID: call_60ilvvUTlNXTWJxX5viTET4s\n",
      "  Args:\n",
      "    query: SELECT * FROM Employee WHERE FirstName = 'Andrew' AND LastName = 'Adams';\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mexecute_query\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: db_query_tool\n",
      "\n",
      "[(1, 'Adams', 'Andrew', 'General Manager', None, '1962-02-18 00:00:00', '2002-08-14 00:00:00', '11120 Jasper Ave NW', 'Edmonton', 'AB', 'Canada', 'T5K 2N1', '+1 (780) 428-9482', '+1 (780) 428-3457', 'andrew@chinookcorp.com')]\n",
      "==================================================\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Answer: Andrew Adams 직원의 인적 정보는 다음과 같습니다:\n",
      "\n",
      "- 이름: Andrew Adams\n",
      "- 직책: General Manager\n",
      "- 생년월일: 1962-02-18\n",
      "- 고용일: 2002-08-14\n",
      "- 주소: 11120 Jasper Ave NW, Edmonton, AB, Canada, T5K 2N1\n",
      "- 전화번호: +1 (780) 428-9482\n",
      "- 팩스: +1 (780) 428-3457\n",
      "- 이메일: andrew@chinookcorp.com\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mquery_gen\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Answer: Andrew Adams 직원의 인적 정보는 다음과 같습니다:\n",
      "\n",
      "- 이름: Andrew Adams\n",
      "- 직책: General Manager\n",
      "- 생년월일: 1962-02-18\n",
      "- 고용일: 2002-08-14\n",
      "- 주소: 11120 Jasper Ave NW, Edmonton, AB, Canada, T5K 2N1\n",
      "- 전화번호: +1 (780) 428-9482\n",
      "- 팩스: +1 (780) 428-3457\n",
      "- 이메일: andrew@chinookcorp.com\n",
      "==================================================\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:56:01.496535Z",
     "start_time": "2025-04-27T12:55:54.654940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output = run_graph(\n",
    "    \"2009년도에 어느 국가의 고객이 가장 많이 지출했을까요? 그리고 얼마를 지출했을까요? 한글로 답변하세요.\",\n",
    "    stream=False,\n",
    ")"
   ],
   "id": "9be2c7d8eaa33a77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mfirst_tool_call\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_list_tables (initial_tool_call_abc123)\n",
      " Call ID: initial_tool_call_abc123\n",
      "  Args:\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mlist_tables_tool\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: sql_db_list_tables\n",
      "\n",
      "Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mmodel_get_schema\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_schema (call_JS8B77E8oOCo2FhfsvAhhAks)\n",
      " Call ID: call_JS8B77E8oOCo2FhfsvAhhAks\n",
      "  Args:\n",
      "    table_names: Customer, Invoice\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mget_schema_tool\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: sql_db_schema\n",
      "\n",
      "\n",
      "CREATE TABLE \"Customer\" (\n",
      "\t\"CustomerId\" INTEGER NOT NULL, \n",
      "\t\"FirstName\" NVARCHAR(40) NOT NULL, \n",
      "\t\"LastName\" NVARCHAR(20) NOT NULL, \n",
      "\t\"Company\" NVARCHAR(80), \n",
      "\t\"Address\" NVARCHAR(70), \n",
      "\t\"City\" NVARCHAR(40), \n",
      "\t\"State\" NVARCHAR(40), \n",
      "\t\"Country\" NVARCHAR(40), \n",
      "\t\"PostalCode\" NVARCHAR(10), \n",
      "\t\"Phone\" NVARCHAR(24), \n",
      "\t\"Fax\" NVARCHAR(24), \n",
      "\t\"Email\" NVARCHAR(60) NOT NULL, \n",
      "\t\"SupportRepId\" INTEGER, \n",
      "\tPRIMARY KEY (\"CustomerId\"), \n",
      "\tFOREIGN KEY(\"SupportRepId\") REFERENCES \"Employee\" (\"EmployeeId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Customer table:\n",
      "CustomerId\tFirstName\tLastName\tCompany\tAddress\tCity\tState\tCountry\tPostalCode\tPhone\tFax\tEmail\tSupportRepId\n",
      "1\tLuís\tGonçalves\tEmbraer - Empresa Brasileira de Aeronáutica S.A.\tAv. Brigadeiro Faria Lima, 2170\tSão José dos Campos\tSP\tBrazil\t12227-000\t+55 (12) 3923-5555\t+55 (12) 3923-5566\tluisg@embraer.com.br\t3\n",
      "2\tLeonie\tKöhler\tNone\tTheodor-Heuss-Straße 34\tStuttgart\tNone\tGermany\t70174\t+49 0711 2842222\tNone\tleonekohler@surfeu.de\t5\n",
      "3\tFrançois\tTremblay\tNone\t1498 rue Bélanger\tMontréal\tQC\tCanada\tH2G 1A7\t+1 (514) 721-4711\tNone\tftremblay@gmail.com\t3\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE \"Invoice\" (\n",
      "\t\"InvoiceId\" INTEGER NOT NULL, \n",
      "\t\"CustomerId\" INTEGER NOT NULL, \n",
      "\t\"InvoiceDate\" DATETIME NOT NULL, \n",
      "\t\"BillingAddress\" NVARCHAR(70), \n",
      "\t\"BillingCity\" NVARCHAR(40), \n",
      "\t\"BillingState\" NVARCHAR(40), \n",
      "\t\"BillingCountry\" NVARCHAR(40), \n",
      "\t\"BillingPostalCode\" NVARCHAR(10), \n",
      "\t\"Total\" NUMERIC(10, 2) NOT NULL, \n",
      "\tPRIMARY KEY (\"InvoiceId\"), \n",
      "\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Invoice table:\n",
      "InvoiceId\tCustomerId\tInvoiceDate\tBillingAddress\tBillingCity\tBillingState\tBillingCountry\tBillingPostalCode\tTotal\n",
      "1\t2\t2009-01-01 00:00:00\tTheodor-Heuss-Straße 34\tStuttgart\tNone\tGermany\t70174\t1.98\n",
      "2\t4\t2009-01-02 00:00:00\tUllevålsveien 14\tOslo\tNone\tNorway\t0171\t3.96\n",
      "3\t8\t2009-01-03 00:00:00\tGrétrystraat 63\tBrussels\tNone\tBelgium\t1000\t5.94\n",
      "*/\n",
      "==================================================\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_JtajSsSqR5paZay3pe8F4jwb)\n",
      " Call ID: call_JtajSsSqR5paZay3pe8F4jwb\n",
      "  Args:\n",
      "    state: {'messages': [{'content': \"SELECT BillingCountry, SUM(Total) as TotalSpent FROM Invoice WHERE strftime('%Y', InvoiceDate) = '2009' GROUP BY BillingCountry ORDER BY TotalSpent DESC LIMIT 1;\", 'type': 'ai'}]}\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mquery_gen\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_JtajSsSqR5paZay3pe8F4jwb)\n",
      " Call ID: call_JtajSsSqR5paZay3pe8F4jwb\n",
      "  Args:\n",
      "    state: {'messages': [{'content': \"SELECT BillingCountry, SUM(Total) as TotalSpent FROM Invoice WHERE strftime('%Y', InvoiceDate) = '2009' GROUP BY BillingCountry ORDER BY TotalSpent DESC LIMIT 1;\", 'type': 'ai'}]}\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "\n",
      "Error: The wrong tool was called: model_check_query. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\n",
      "==================================================\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "```sql\n",
      "SELECT BillingCountry, SUM(Total) as TotalSpent FROM Invoice WHERE strftime('%Y', InvoiceDate) = '2009' GROUP BY BillingCountry ORDER BY TotalSpent DESC LIMIT 1;\n",
      "```\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mquery_gen\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "```sql\n",
      "SELECT BillingCountry, SUM(Total) as TotalSpent FROM Invoice WHERE strftime('%Y', InvoiceDate) = '2009' GROUP BY BillingCountry ORDER BY TotalSpent DESC LIMIT 1;\n",
      "```\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mcorrect_query\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  db_query_tool (call_j94pOEVxw1rkK6t3k1ZpFWOp)\n",
      " Call ID: call_j94pOEVxw1rkK6t3k1ZpFWOp\n",
      "  Args:\n",
      "    query: SELECT BillingCountry, SUM(Total) as TotalSpent FROM Invoice WHERE strftime('%Y', InvoiceDate) = '2009' GROUP BY BillingCountry ORDER BY TotalSpent DESC LIMIT 1;\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mexecute_query\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: db_query_tool\n",
      "\n",
      "[('USA', 103.95)]\n",
      "==================================================\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Answer: 2009년도에 미국(USA) 고객이 가장 많이 지출했으며, 총 지출 금액은 103.95입니다.\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mquery_gen\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Answer: 2009년도에 미국(USA) 고객이 가장 많이 지출했으며, 총 지출 금액은 103.95입니다.\n",
      "==================================================\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# LangSmith Evaluator 를 활용한 SQL Agent 평가\n",
   "id": "7ceecf0a1cdff092"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:56:25.133289Z",
     "start_time": "2025-04-27T12:56:22.616969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langsmith import Client\n",
    "\n",
    "# 클라이언트 초기화\n",
    "client = Client()\n",
    "\n",
    "# 데이터셋 생성 및 업로드\n",
    "examples = [\n",
    "    (\n",
    "        \"Which country's customers spent the most? And how much did they spend?\",\n",
    "        \"The country whose customers spent the most is the USA, with a total spending of 523.06.\",\n",
    "    ),\n",
    "    (\n",
    "        \"What was the most purchased track of 2013?\",\n",
    "        \"The most purchased track of 2013 was Hot Girl.\",\n",
    "    ),\n",
    "    (\n",
    "        \"How many albums does the artist Led Zeppelin have?\",\n",
    "        \"Led Zeppelin has 14 albums\",\n",
    "    ),\n",
    "    (\n",
    "        \"What is the total price for the album “Big Ones”?\",\n",
    "        \"The total price for the album 'Big Ones' is 14.85\",\n",
    "    ),\n",
    "    (\n",
    "        \"Which sales agent made the most in sales in 2009?\",\n",
    "        \"Steve Johnson made the most sales in 2009\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "dataset_name = \"SQL Agent Response\"\n",
    "\n",
    "if not client.has_dataset(dataset_name=dataset_name):\n",
    "    dataset = client.create_dataset(dataset_name=dataset_name)\n",
    "    inputs, outputs = zip(\n",
    "        *[({\"input\": text}, {\"output\": label}) for text, label in examples]\n",
    "    )\n",
    "    client.create_examples(inputs=inputs, outputs=outputs, dataset_id=dataset.id)\n"
   ],
   "id": "e52ea2537fb5b8e1",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:56:35.001105Z",
     "start_time": "2025-04-27T12:56:34.994946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 에이전트의 SQL 쿼리 응답을 예측하기 위한 함수 정의\n",
    "def predict_sql_agent_answer(example: dict):\n",
    "    \"\"\"Use this for answer evaluation\"\"\"\n",
    "    config = RunnableConfig(configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "    inputs = {\n",
    "        \"messages\": [HumanMessage(content=example[\"input\"])],\n",
    "    }\n",
    "    # 그래프를 실행하여 메시지 결과 조회\n",
    "    messages = app.invoke(inputs, config)\n",
    "    answer = messages[\"messages\"][-1].content\n",
    "    # 결과 반환\n",
    "    return {\"response\": answer}"
   ],
   "id": "6cf7755212610e8f",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:56:41.828609Z",
     "start_time": "2025-04-27T12:56:41.369963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Grade prompt\n",
    "grade_prompt_answer_accuracy = hub.pull(\"langchain-ai/rag-answer-vs-reference\")\n",
    "\n",
    "\n",
    "# 답변 평가자 LLM-as-judge 정의\n",
    "def answer_evaluator(run, example) -> dict:\n",
    "    # input: 질문\n",
    "    input_question = example.inputs[\"input\"]\n",
    "    # output: 참조 답변\n",
    "    reference = example.outputs[\"output\"]\n",
    "    # 예측 답변\n",
    "    prediction = run.outputs[\"response\"]\n",
    "\n",
    "    # LLM 평가자 초기화\n",
    "    llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "    answer_grader = grade_prompt_answer_accuracy | llm\n",
    "\n",
    "    # 평가자 실행\n",
    "    score = answer_grader.invoke(\n",
    "        {\n",
    "            \"question\": input_question,\n",
    "            \"correct_answer\": reference,\n",
    "            \"student_answer\": prediction,\n",
    "        }\n",
    "    )\n",
    "    score = score[\"Score\"]\n",
    "\n",
    "    # 점수 반환\n",
    "    return {\"key\": \"answer_v_reference_score\", \"score\": score}"
   ],
   "id": "807eec0250a1d9d",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T12:58:49.071991Z",
     "start_time": "2025-04-27T12:56:46.748071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "# 평가용 데이터셋 이름\n",
    "dataset_name = \"SQL Agent Response\"\n",
    "\n",
    "try:\n",
    "    # 평가 진행\n",
    "    experiment_results = evaluate(\n",
    "        predict_sql_agent_answer,  # 평가시 활용할 예측 함수\n",
    "        data=dataset_name,  # 평가용 데이터셋 이름\n",
    "        evaluators=[answer_evaluator],  # 평가자 목록\n",
    "        num_repetitions=3,  # 실험 반복 횟수 설정\n",
    "        experiment_prefix=\"sql-agent-eval\",\n",
    "        metadata={\"version\": \"chinook db, sql-agent-eval: gpt-4o\"},  # 실험 메타데이터\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ],
   "id": "855b9fdd0ab8ca15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'sql-agent-eval-6577c631' at:\n",
      "https://smith.langchain.com/o/9b141874-d093-4103-946d-7bc247255f98/datasets/879fc605-cd4f-490d-9e08-8b82765750f0/compare?selectedSessions=3a1ad9e3-724a-4c29-a624-edb6650e8fb3\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1847882000dc4c469b363c1d54608446"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_4VXRwmeSIdwE1WW72TkqgCnW)\n",
      " Call ID: call_4VXRwmeSIdwE1WW72TkqgCnW\n",
      "  Args:\n",
      "    state: {'messages': [{'content': 'SELECT c.Country, SUM(i.Total) as TotalSpent FROM Customer c JOIN Invoice i ON c.CustomerId = i.CustomerId GROUP BY c.Country ORDER BY TotalSpent DESC LIMIT 1;', 'type': 'ai'}]}\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "SELECT c.Country, SUM(i.Total) as TotalSpent FROM Customer c JOIN Invoice i ON c.CustomerId = i.CustomerId GROUP BY c.Country ORDER BY TotalSpent DESC LIMIT 1;\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Answer: The country whose customers spent the most is the USA, with a total spending of 523.06.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_tR81FZtG8kVh04fWBu0B4wwR)\n",
      " Call ID: call_tR81FZtG8kVh04fWBu0B4wwR\n",
      "  Args:\n",
      "    state: {'messages': [{'content': 'What is the total price for the album “Big Ones”?', 'type': 'human'}, {'content': 'Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track', 'type': 'function', 'name': 'sql_db_list_tables'}, {'content': 'CREATE TABLE \"Album\" (\\n\\t\"AlbumId\" INTEGER NOT NULL, \\n\\t\"Title\" NVARCHAR(160) NOT NULL, \\n\\t\"ArtistId\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"AlbumId\"), \\n\\tFOREIGN KEY(\"ArtistId\") REFERENCES \"Artist\" (\"ArtistId\")\\n)\\n\\n/*\\n3 rows from Album table:\\nAlbumId\\tTitle\\tArtistId\\n1\\tFor Those About To Rock We Salute You\\t1\\n2\\tBalls to the Wall\\t2\\n3\\tRestless and Wild\\t2\\n*/\\n\\n\\nCREATE TABLE \"Invoice\" (\\n\\t\"InvoiceId\" INTEGER NOT NULL, \\n\\t\"CustomerId\" INTEGER NOT NULL, \\n\\t\"InvoiceDate\" DATETIME NOT NULL, \\n\\t\"BillingAddress\" NVARCHAR(70), \\n\\t\"BillingCity\" NVARCHAR(40), \\n\\t\"BillingState\" NVARCHAR(40), \\n\\t\"BillingCountry\" NVARCHAR(40), \\n\\t\"BillingPostalCode\" NVARCHAR(10), \\n\\t\"Total\" NUMERIC(10, 2) NOT NULL, \\n\\tPRIMARY KEY (\"InvoiceId\"), \\n\\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\\n)\\n\\n/*\\n3 rows from Invoice table:\\nInvoiceId\\tCustomerId\\tInvoiceDate\\tBillingAddress\\tBillingCity\\tBillingState\\tBillingCountry\\tBillingPostalCode\\tTotal\\n1\\t2\\t2009-01-01 00:00:00\\tTheodor-Heuss-Straße 34\\tStuttgart\\tNone\\tGermany\\t70174\\t1.98\\n2\\t4\\t2009-01-02 00:00:00\\tUllevålsveien 14\\tOslo\\tNone\\tNorway\\t0171\\t3.96\\n3\\t8\\t2009-01-03 00:00:00\\tGrétrystraat 63\\tBrussels\\tNone\\tBelgium\\t1000\\t5.94\\n*/\\n\\n\\nCREATE TABLE \"InvoiceLine\" (\\n\\t\"InvoiceLineId\" INTEGER NOT NULL, \\n\\t\"InvoiceId\" INTEGER NOT NULL, \\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\t\"UnitPrice\" NUMERIC(10, 2) NOT NULL, \\n\\t\"Quantity\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"InvoiceLineId\"), \\n\\tFOREIGN KEY(\"TrackId\") REFERENCES \"Track\" (\"TrackId\"), \\n\\tFOREIGN KEY(\"InvoiceId\") REFERENCES \"Invoice\" (\"InvoiceId\")\\n)\\n\\n/*\\n3 rows from InvoiceLine table:\\nInvoiceLineId\\tInvoiceId\\tTrackId\\tUnitPrice\\tQuantity\\n1\\t1\\t2\\t0.99\\t1\\n2\\t1\\t4\\t0.99\\t1\\n3\\t2\\t6\\t0.99\\t1\\n*/', 'type': 'function', 'name': 'sql_db_schema'}]}\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "```sql\n",
      "SELECT SUM(Invoice.Total) AS TotalPrice\n",
      "FROM Album\n",
      "JOIN Track ON Album.AlbumId = Track.AlbumId\n",
      "JOIN InvoiceLine ON Track.TrackId = InvoiceLine.TrackId\n",
      "JOIN Invoice ON InvoiceLine.InvoiceId = Invoice.InvoiceId\n",
      "WHERE Album.Title = 'Big Ones';\n",
      "```\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Answer: The total price for the album “Big Ones” is 82.17.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_VBaeOQohLwg5x3iX5cA0ogDh)\n",
      " Call ID: call_VBaeOQohLwg5x3iX5cA0ogDh\n",
      "  Args:\n",
      "    state: {'messages': [{'content': 'What was the most purchased track of 2013?', 'type': 'human'}, {'content': 'CREATE TABLE \"Invoice\" (\\n\\t\"InvoiceId\" INTEGER NOT NULL, \\n\\t\"CustomerId\" INTEGER NOT NULL, \\n\\t\"InvoiceDate\" DATETIME NOT NULL, \\n\\t\"BillingAddress\" NVARCHAR(70), \\n\\t\"BillingCity\" NVARCHAR(40), \\n\\t\"BillingState\" NVARCHAR(40), \\n\\t\"BillingCountry\" NVARCHAR(40), \\n\\t\"BillingPostalCode\" NVARCHAR(10), \\n\\t\"Total\" NUMERIC(10, 2) NOT NULL, \\n\\tPRIMARY KEY (\"InvoiceId\"), \\n\\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\\n)\\n\\n/*\\n3 rows from Invoice table:\\nInvoiceId\\tCustomerId\\tInvoiceDate\\tBillingAddress\\tBillingCity\\tBillingState\\tBillingCountry\\tBillingPostalCode\\tTotal\\n1\\t2\\t2009-01-01 00:00:00\\tTheodor-Heuss-Straße 34\\tStuttgart\\tNone\\tGermany\\t70174\\t1.98\\n2\\t4\\t2009-01-02 00:00:00\\tUllevålsveien 14\\tOslo\\tNone\\tNorway\\t0171\\t3.96\\n3\\t8\\t2009-01-03 00:00:00\\tGrétrystraat 63\\tBrussels\\tNone\\tBelgium\\t1000\\t5.94\\n*/\\n\\n\\nCREATE TABLE \"InvoiceLine\" (\\n\\t\"InvoiceLineId\" INTEGER NOT NULL, \\n\\t\"InvoiceId\" INTEGER NOT NULL, \\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\t\"UnitPrice\" NUMERIC(10, 2) NOT NULL, \\n\\t\"Quantity\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"InvoiceLineId\"), \\n\\tFOREIGN KEY(\"TrackId\") REFERENCES \"Track\" (\"TrackId\"), \\n\\tFOREIGN KEY(\"InvoiceId\") REFERENCES \"Invoice\" (\"InvoiceId\")\\n)\\n\\n/*\\n3 rows from InvoiceLine table:\\nInvoiceLineId\\tInvoiceId\\tTrackId\\tUnitPrice\\tQuantity\\n1\\t1\\t2\\t0.99\\t1\\n2\\t1\\t4\\t0.99\\t1\\n3\\t2\\t6\\t0.99\\t1\\n*/\\n\\n\\nCREATE TABLE \"Track\" (\\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(200) NOT NULL, \\n\\t\"AlbumId\" INTEGER, \\n\\t\"MediaTypeId\" INTEGER NOT NULL, \\n\\t\"GenreId\" INTEGER, \\n\\t\"Composer\" NVARCHAR(220), \\n\\t\"Milliseconds\" INTEGER NOT NULL, \\n\\t\"Bytes\" INTEGER, \\n\\t\"UnitPrice\" NUMERIC(10, 2) NOT NULL, \\n\\tPRIMARY KEY (\"TrackId\"), \\n\\tFOREIGN KEY(\"MediaTypeId\") REFERENCES \"MediaType\" (\"MediaTypeId\"), \\n\\tFOREIGN KEY(\"GenreId\") REFERENCES \"Genre\" (\"GenreId\"), \\n\\tFOREIGN KEY(\"AlbumId\") REFERENCES \"Album\" (\"AlbumId\")\\n)\\n\\n/*\\n3 rows from Track table:\\nTrackId\\tName\\tAlbumId\\tMediaTypeId\\tGenreId\\tComposer\\tMilliseconds\\tBytes\\tUnitPrice\\n1\\tFor Those About To Rock (We Salute You)\\t1\\t1\\t1\\tAngus Young, Malcolm Young, Brian Johnson\\t343719\\t11170334\\t0.99\\n2\\tBalls to the Wall\\t2\\t2\\t1\\tNone\\t342562\\t5510424\\t0.99\\n3\\tFast As a Shark\\t3\\t2\\t1\\tF. Baltes, S. Kaufman, U. Dirkscneider & W. Hoffman\\t230619\\t3990994\\t0.99\\n*/', 'type': 'ai'}]}\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "```sql\n",
      "SELECT t.Name, SUM(il.Quantity) AS TotalQuantity\n",
      "FROM Track t\n",
      "JOIN InvoiceLine il ON t.TrackId = il.TrackId\n",
      "JOIN Invoice i ON il.InvoiceId = i.InvoiceId\n",
      "WHERE strftime('%Y', i.InvoiceDate) = '2013'\n",
      "GROUP BY t.TrackId\n",
      "ORDER BY TotalQuantity DESC\n",
      "LIMIT 1;\n",
      "```\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Answer: The most purchased track of 2013 was \"Hot Girl\".\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_pK7gPWe8mvcPh8SDHy5j6eUO)\n",
      " Call ID: call_pK7gPWe8mvcPh8SDHy5j6eUO\n",
      "  Args:\n",
      "    state: {'messages': [{'content': 'Which sales agent made the most in sales in 2009?', 'type': 'human'}, {'content': 'Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track', 'type': 'function', 'name': 'sql_db_list_tables'}, {'content': '{\"table_names\":\"Employee, Invoice, InvoiceLine\"}', 'type': 'function', 'name': 'sql_db_schema'}, {'content': 'CREATE TABLE \"Employee\" (\\n\\t\"EmployeeId\" INTEGER NOT NULL, \\n\\t\"LastName\" NVARCHAR(20) NOT NULL, \\n\\t\"FirstName\" NVARCHAR(20) NOT NULL, \\n\\t\"Title\" NVARCHAR(30), \\n\\t\"ReportsTo\" INTEGER, \\n\\t\"BirthDate\" DATETIME, \\n\\t\"HireDate\" DATETIME, \\n\\t\"Address\" NVARCHAR(70), \\n\\t\"City\" NVARCHAR(40), \\n\\t\"State\" NVARCHAR(40), \\n\\t\"Country\" NVARCHAR(40), \\n\\t\"PostalCode\" NVARCHAR(10), \\n\\t\"Phone\" NVARCHAR(24), \\n\\t\"Fax\" NVARCHAR(24), \\n\\t\"Email\" NVARCHAR(60), \\n\\tPRIMARY KEY (\"EmployeeId\"), \\n\\tFOREIGN KEY(\"ReportsTo\") REFERENCES \"Employee\" (\"EmployeeId\")\\n)\\n\\n/*\\n3 rows from Employee table:\\nEmployeeId\\tLastName\\tFirstName\\tTitle\\tReportsTo\\tBirthDate\\tHireDate\\tAddress\\tCity\\tState\\tCountry\\tPostalCode\\tPhone\\tFax\\tEmail\\n1\\tAdams\\tAndrew\\tGeneral Manager\\tNone\\t1962-02-18 00:00:00\\t2002-08-14 00:00:00\\t11120 Jasper Ave NW\\tEdmonton\\tAB\\tCanada\\tT5K 2N1\\t+1 (780) 428-9482\\t+1 (780) 428-3457\\tandrew@chinookcorp.com\\n2\\tEdwards\\tNancy\\tSales Manager\\t1\\t1958-12-08 00:00:00\\t2002-05-01 00:00:00\\t825 8 Ave SW\\tCalgary\\tAB\\tCanada\\tT2P 2T3\\t+1 (403) 262-3443\\t+1 (403) 262-3322\\tnancy@chinookcorp.com\\n3\\tPeacock\\tJane\\tSales Support Agent\\t2\\t1973-08-29 00:00:00\\t2002-04-01 00:00:00\\t1111 6 Ave SW\\tCalgary\\tAB\\tCanada\\tT2P 5M5\\t+1 (403) 262-3443\\t+1 (403) 262-6712\\tjane@chinookcorp.com\\n*/\\n\\n\\nCREATE TABLE \"Invoice\" (\\n\\t\"InvoiceId\" INTEGER NOT NULL, \\n\\t\"CustomerId\" INTEGER NOT NULL, \\n\\t\"InvoiceDate\" DATETIME NOT NULL, \\n\\t\"BillingAddress\" NVARCHAR(70), \\n\\t\"BillingCity\" NVARCHAR(40), \\n\\t\"BillingState\" NVARCHAR(40), \\n\\t\"BillingCountry\" NVARCHAR(40), \\n\\t\"BillingPostalCode\" NVARCHAR(10), \\n\\t\"Total\" NUMERIC(10, 2) NOT NULL, \\n\\tPRIMARY KEY (\"InvoiceId\"), \\n\\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\\n)\\n\\n/*\\n3 rows from Invoice table:\\nInvoiceId\\tCustomerId\\tInvoiceDate\\tBillingAddress\\tBillingCity\\tBillingState\\tBillingCountry\\tBillingPostalCode\\tTotal\\n1\\t2\\t2009-01-01 00:00:00\\tTheodor-Heuss-Straße 34\\tStuttgart\\tNone\\tGermany\\t70174\\t1.98\\n2\\t4\\t2009-01-02 00:00:00\\tUllevålsveien 14\\tOslo\\tNone\\tNorway\\t0171\\t3.96\\n3\\t8\\t2009-01-03 00:00:00\\tGrétrystraat 63\\tBrussels\\tNone\\tBelgium\\t1000\\t5.94\\n*/\\n\\n\\nCREATE TABLE \"InvoiceLine\" (\\n\\t\"InvoiceLineId\" INTEGER NOT NULL, \\n\\t\"InvoiceId\" INTEGER NOT NULL, \\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\t\"UnitPrice\" NUMERIC(10, 2) NOT NULL, \\n\\t\"Quantity\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"InvoiceLineId\"), \\n\\tFOREIGN KEY(\"TrackId\") REFERENCES \"Track\" (\"TrackId\"), \\n\\tFOREIGN KEY(\"InvoiceId\") REFERENCES \"Invoice\" (\"InvoiceId\")\\n)\\n\\n/*\\n3 rows from InvoiceLine table:\\nInvoiceLineId\\tInvoiceId\\tTrackId\\tUnitPrice\\tQuantity\\n1\\t1\\t2\\t0.99\\t1\\n2\\t1\\t4\\t0.99\\t1\\n3\\t2\\t6\\t0.99\\t1\\n*/', 'type': 'function', 'name': 'sql_db_schema'}]}\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "```sql\n",
      "SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\n",
      "FROM Employee e\n",
      "JOIN Customer c ON e.EmployeeId = c.SupportRepId\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "WHERE strftime('%Y', i.InvoiceDate) = '2009'\n",
      "GROUP BY e.EmployeeId\n",
      "ORDER BY TotalSales DESC\n",
      "LIMIT 1;\n",
      "```\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Answer: The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 2a98dba0-d34d-48b3-96a6-9abc3ff43034: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Nlrc03jLTonhenq0ChcwpgIu on tokens per min (TPM): Limit 30000, Used 30000, Requested 293. Please try again in 586ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\316870680.py\", line 22, in answer_evaluator\n",
      "    score = answer_grader.invoke(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3029, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5365, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 307, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 843, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 683, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 908, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 901, in _generate\n",
      "    response = self.root_client.beta.chat.completions.parse(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\resources\\beta\\chat\\completions.py\", line 158, in parse\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Nlrc03jLTonhenq0ChcwpgIu on tokens per min (TPM): Limit 30000, Used 30000, Requested 293. Please try again in 586ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Nlrc03jLTonhenq0ChcwpgIu on tokens per min (TPM): Limit 30000, Used 30000, Requested 43. Please try again in 86ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\2799409917.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2392, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2046, in stream\n",
      "    for _ in runner.tick(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py\", line 146, in tick\n",
      "    run_with_retry(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\2576808191.py\", line 65, in <lambda>\n",
      "    \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5365, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 307, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 843, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 683, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 908, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 925, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Nlrc03jLTonhenq0ChcwpgIu on tokens per min (TPM): Limit 30000, Used 30000, Requested 43. Please try again in 86ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'model_get_schema' and id '4cfb8fe3-81eb-b3ca-c1d3-a52d37f1bc80'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run ab51175a-88df-4ad1-989f-6bbf1da5b8d2: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\316870680.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Nlrc03jLTonhenq0ChcwpgIu on tokens per min (TPM): Limit 30000, Used 30000, Requested 48. Please try again in 96ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\2799409917.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2392, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2046, in stream\n",
      "    for _ in runner.tick(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py\", line 146, in tick\n",
      "    run_with_retry(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\2576808191.py\", line 65, in <lambda>\n",
      "    \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5365, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 307, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 843, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 683, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 908, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 925, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Nlrc03jLTonhenq0ChcwpgIu on tokens per min (TPM): Limit 30000, Used 30000, Requested 48. Please try again in 96ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'model_get_schema' and id 'e4658443-13e7-6086-99bb-259cccfef3d7'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run ec76a2cd-6e10-4bc5-b091-6d2f568ce5d6: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\316870680.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Nlrc03jLTonhenq0ChcwpgIu on tokens per min (TPM): Limit 30000, Used 30000, Requested 44. Please try again in 88ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\2799409917.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2392, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2046, in stream\n",
      "    for _ in runner.tick(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py\", line 146, in tick\n",
      "    run_with_retry(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\2576808191.py\", line 65, in <lambda>\n",
      "    \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5365, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 307, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 843, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 683, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 908, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 925, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Nlrc03jLTonhenq0ChcwpgIu on tokens per min (TPM): Limit 30000, Used 30000, Requested 44. Please try again in 88ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'model_get_schema' and id 'b6381021-6c9d-417f-3e81-5c8cce4c5bdc'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 53778838-ecad-484a-a134-cff3de1fe4c4: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\316870680.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_QEPl5zQmpXm23lIP4rgRPuhz)\n",
      " Call ID: call_QEPl5zQmpXm23lIP4rgRPuhz\n",
      "  Args:\n",
      "    state: {'messages': [{'content': 'What was the most purchased track of 2013?', 'type': 'human'}, {'content': 'SELECT * FROM Track;', 'type': 'ai'}, {'content': 'SELECT * FROM InvoiceLine;', 'type': 'ai'}, {'content': 'SELECT * FROM Invoice;', 'type': 'ai'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Nlrc03jLTonhenq0ChcwpgIu on tokens per min (TPM): Limit 30000, Used 29948, Requested 881. Please try again in 1.658s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\2799409917.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2392, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2046, in stream\n",
      "    for _ in runner.tick(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py\", line 146, in tick\n",
      "    run_with_retry(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\2576808191.py\", line 116, in query_gen_node\n",
      "    message = query_gen.invoke(state)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3029, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5365, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 307, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 843, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 683, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 908, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 925, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Nlrc03jLTonhenq0ChcwpgIu on tokens per min (TPM): Limit 30000, Used 29948, Requested 881. Please try again in 1.658s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'query_gen' and id '59d3fb3e-8b7e-6315-daff-f415173ee2be'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 54e0e1cc-8b0d-499b-98e3-b7efd725cfe3: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\316870680.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_WxzycW4LwAXyet7P60F324kJ)\n",
      " Call ID: call_WxzycW4LwAXyet7P60F324kJ\n",
      "  Args:\n",
      "    state: {'messages': [{'content': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales FROM Employee e JOIN Customer c ON e.EmployeeId = c.SupportRepId JOIN Invoice i ON c.CustomerId = i.CustomerId WHERE strftime('%Y', i.InvoiceDate) = '2009' GROUP BY e.EmployeeId ORDER BY TotalSales DESC LIMIT 1;\", 'type': 'ai'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Nlrc03jLTonhenq0ChcwpgIu on tokens per min (TPM): Limit 30000, Used 29976, Requested 967. Please try again in 1.886s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\2799409917.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2392, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2046, in stream\n",
      "    for _ in runner.tick(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py\", line 146, in tick\n",
      "    run_with_retry(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\2576808191.py\", line 116, in query_gen_node\n",
      "    message = query_gen.invoke(state)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3029, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5365, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 307, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 843, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 683, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 908, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 925, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Nlrc03jLTonhenq0ChcwpgIu on tokens per min (TPM): Limit 30000, Used 29976, Requested 967. Please try again in 1.886s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'query_gen' and id '5f9b3184-fc69-d991-4858-5c6587b5fccf'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 5317317d-f7d0-4494-8a2e-c8a29e28d2a4: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\316870680.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_uZxAdIDscoilr21K9AnIt5Q0)\n",
      " Call ID: call_uZxAdIDscoilr21K9AnIt5Q0\n",
      "  Args:\n",
      "    state: {'messages': [{'content': 'How many albums does the artist Led Zeppelin have?', 'type': 'human'}, {'content': 'Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track', 'type': 'function', 'name': 'sql_db_list_tables'}, {'content': '\\nCREATE TABLE \"Album\" (\\n\\t\"AlbumId\" INTEGER NOT NULL, \\n\\t\"Title\" NVARCHAR(160) NOT NULL, \\n\\t\"ArtistId\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"AlbumId\"), \\n\\tFOREIGN KEY(\"ArtistId\") REFERENCES \"Artist\" (\"ArtistId\")\\n)\\n\\n/*\\n3 rows from Album table:\\nAlbumId\\tTitle\\tArtistId\\n1\\tFor Those About To Rock We Salute You\\t1\\n2\\tBalls to the Wall\\t2\\n3\\tRestless and Wild\\t2\\n*/\\n\\n\\nCREATE TABLE \"Artist\" (\\n\\t\"ArtistId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(120), \\n\\tPRIMARY KEY (\"ArtistId\")\\n)\\n\\n/*\\n3 rows from Artist table:\\nArtistId\\tName\\n1\\tAC/DC\\n2\\tAccept\\n3\\tAerosmith\\n*/', 'type': 'function', 'name': 'sql_db_schema'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Nlrc03jLTonhenq0ChcwpgIu on tokens per min (TPM): Limit 30000, Used 30000, Requested 482. Please try again in 964ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\2799409917.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2392, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2046, in stream\n",
      "    for _ in runner.tick(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py\", line 146, in tick\n",
      "    run_with_retry(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\2576808191.py\", line 116, in query_gen_node\n",
      "    message = query_gen.invoke(state)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3029, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5365, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 307, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 843, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 683, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 908, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 925, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Nlrc03jLTonhenq0ChcwpgIu on tokens per min (TPM): Limit 30000, Used 30000, Requested 482. Please try again in 964ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'query_gen' and id 'f4afc832-65a6-3c99-740c-978e706a2615'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 50e76ae0-49ea-4180-913a-912738b9b713: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\316870680.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_WesBlmr55lHXWi7iAeswNQu7)\n",
      " Call ID: call_WesBlmr55lHXWi7iAeswNQu7\n",
      "  Args:\n",
      "    state: {'messages': [{'content': \"Which country's customers spent the most? And how much did they spend?\", 'type': 'human'}, {'content': 'Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track', 'type': 'function', 'name': 'sql_db_list_tables'}, {'content': '{\"table_names\":\"Customer, Invoice\"}', 'type': 'function', 'name': 'sql_db_schema'}, {'content': '\\nCREATE TABLE \"Customer\" (\\n\\t\"CustomerId\" INTEGER NOT NULL, \\n\\t\"FirstName\" NVARCHAR(40) NOT NULL, \\n\\t\"LastName\" NVARCHAR(20) NOT NULL, \\n\\t\"Company\" NVARCHAR(80), \\n\\t\"Address\" NVARCHAR(70), \\n\\t\"City\" NVARCHAR(40), \\n\\t\"State\" NVARCHAR(40), \\n\\t\"Country\" NVARCHAR(40), \\n\\t\"PostalCode\" NVARCHAR(10), \\n\\t\"Phone\" NVARCHAR(24), \\n\\t\"Fax\" NVARCHAR(24), \\n\\t\"Email\" NVARCHAR(60) NOT NULL, \\n\\t\"SupportRepId\" INTEGER, \\n\\tPRIMARY KEY (\"CustomerId\"), \\n\\tFOREIGN KEY(\"SupportRepId\") REFERENCES \"Employee\" (\"EmployeeId\")\\n)\\n\\n/*\\n3 rows from Customer table:\\nCustomerId\\tFirstName\\tLastName\\tCompany\\tAddress\\tCity\\tState\\tCountry\\tPostalCode\\tPhone\\tFax\\tEmail\\tSupportRepId\\n1\\tLuís\\tGonçalves\\tEmbraer - Empresa Brasileira de Aeronáutica S.A.\\tAv. Brigadeiro Faria Lima, 2170\\tSão José dos Campos\\tSP\\tBrazil\\t12227-000\\t+55 (12) 3923-5555\\t+55 (12) 3923-5566\\tluisg@embraer.com.br\\t3\\n2\\tLeonie\\tKöhler\\tNone\\tTheodor-Heuss-Straße 34\\tStuttgart\\tNone\\tGermany\\t70174\\t+49 0711 2842222\\tNone\\tleonekohler@surfeu.de\\t5\\n3\\tFrançois\\tTremblay\\tNone\\t1498 rue Bélanger\\tMontréal\\tQC\\tCanada\\tH2G 1A7\\t+1 (514) 721-4711\\tNone\\tftremblay@gmail.com\\t3\\n*/\\n\\n\\nCREATE TABLE \"Invoice\" (\\n\\t\"InvoiceId\" INTEGER NOT NULL, \\n\\t\"CustomerId\" INTEGER NOT NULL, \\n\\t\"InvoiceDate\" DATETIME NOT NULL, \\n\\t\"BillingAddress\" NVARCHAR(70), \\n\\t\"BillingCity\" NVARCHAR(40), \\n\\t\"BillingState\" NVARCHAR(40), \\n\\t\"BillingCountry\" NVARCHAR(40), \\n\\t\"BillingPostalCode\" NVARCHAR(10), \\n\\t\"Total\" NUMERIC(10, 2) NOT NULL, \\n\\tPRIMARY KEY (\"InvoiceId\"), \\n\\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\\n)\\n\\n/*\\n3 rows from Invoice table:\\nInvoiceId\\tCustomerId\\tInvoiceDate\\tBillingAddress\\tBillingCity\\tBillingState\\tBillingCountry\\tBillingPostalCode\\tTotal\\n1\\t2\\t2009-01-01 00:00:00\\tTheodor-Heuss-Straße 34\\tStuttgart\\tNone\\tGermany\\t70174\\t1.98\\n2\\t4\\t2009-01-02 00:00:00\\tUllevålsveien 14\\tOslo\\tNone\\tNorway\\t0171\\t3.96\\n3\\t8\\t2009-01-03 00:00:00\\tGrétrystraat 63\\tBrussels\\tNone\\tBelgium\\t1000\\t5.94\\n*/', 'type': 'function', 'name': 'sql_db_schema'}]}\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "```sql\n",
      "SELECT c.Country, SUM(i.Total) AS TotalSpent\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY TotalSpent DESC\n",
      "LIMIT 1;\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Nlrc03jLTonhenq0ChcwpgIu on tokens per min (TPM): Limit 30000, Used 30000, Requested 204. Please try again in 408ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\2799409917.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2392, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2046, in stream\n",
      "    for _ in runner.tick(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py\", line 146, in tick\n",
      "    run_with_retry(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\2576808191.py\", line 46, in model_check_query\n",
      "    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3029, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5365, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 307, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 843, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 683, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 908, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 925, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Nlrc03jLTonhenq0ChcwpgIu on tokens per min (TPM): Limit 30000, Used 30000, Requested 204. Please try again in 408ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'correct_query' and id '89c51888-0abe-3c84-fbe4-475d5b012c21'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 045c62c3-d8af-4e38-9917-758979997a4f: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\316870680.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Nlrc03jLTonhenq0ChcwpgIu on tokens per min (TPM): Limit 30000, Used 30000, Requested 44. Please try again in 88ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\2799409917.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2392, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2046, in stream\n",
      "    for _ in runner.tick(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py\", line 146, in tick\n",
      "    run_with_retry(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\2576808191.py\", line 65, in <lambda>\n",
      "    \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5365, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 307, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 843, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 683, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 908, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 925, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Nlrc03jLTonhenq0ChcwpgIu on tokens per min (TPM): Limit 30000, Used 30000, Requested 44. Please try again in 88ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'model_get_schema' and id 'a2c20a27-6058-5480-fe8d-6898560235f8'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run de7411c8-fbaa-486a-ab82-fb051f2655de: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\316870680.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Nlrc03jLTonhenq0ChcwpgIu on tokens per min (TPM): Limit 30000, Used 30000, Requested 41. Please try again in 82ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\2799409917.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2392, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2046, in stream\n",
      "    for _ in runner.tick(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py\", line 146, in tick\n",
      "    run_with_retry(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\2576808191.py\", line 65, in <lambda>\n",
      "    \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5365, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 307, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 843, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 683, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 908, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 925, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Nlrc03jLTonhenq0ChcwpgIu on tokens per min (TPM): Limit 30000, Used 30000, Requested 41. Please try again in 82ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'model_get_schema' and id '1ae57f5b-bf0a-dfee-462a-f5ffd44d7d48'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 0613c1b3-6c19-4059-a275-9f06b0f5e44e: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\316870680.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Nlrc03jLTonhenq0ChcwpgIu on tokens per min (TPM): Limit 30000, Used 30000, Requested 43. Please try again in 86ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\2799409917.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2392, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2046, in stream\n",
      "    for _ in runner.tick(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py\", line 146, in tick\n",
      "    run_with_retry(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\2576808191.py\", line 65, in <lambda>\n",
      "    \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5365, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 307, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 843, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 683, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 908, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 925, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Nlrc03jLTonhenq0ChcwpgIu on tokens per min (TPM): Limit 30000, Used 30000, Requested 43. Please try again in 86ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'model_get_schema' and id '126636bb-7cd3-c61a-6f90-270783604a07'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 29a8ff60-fc03-4ea5-93d4-8a80b9305786: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\316870680.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_yRfSTAZvKKShHqGj6EBrKMtJ)\n",
      " Call ID: call_yRfSTAZvKKShHqGj6EBrKMtJ\n",
      "  Args:\n",
      "    state: {'messages': [{'content': 'How many albums does the artist Led Zeppelin have?', 'type': 'human'}, {'content': 'Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track', 'type': 'function', 'name': 'sql_db_list_tables'}, {'content': '\\nCREATE TABLE \"Album\" (\\n\\t\"AlbumId\" INTEGER NOT NULL, \\n\\t\"Title\" NVARCHAR(160) NOT NULL, \\n\\t\"ArtistId\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"AlbumId\"), \\n\\tFOREIGN KEY(\"ArtistId\") REFERENCES \"Artist\" (\"ArtistId\")\\n)\\n\\n/*\\n3 rows from Album table:\\nAlbumId\\tTitle\\tArtistId\\n1\\tFor Those About To Rock We Salute You\\t1\\n2\\tBalls to the Wall\\t2\\n3\\tRestless and Wild\\t2\\n*/\\n\\n\\nCREATE TABLE \"Artist\" (\\n\\t\"ArtistId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(120), \\n\\tPRIMARY KEY (\"ArtistId\")\\n)\\n\\n/*\\n3 rows from Artist table:\\nArtistId\\tName\\n1\\tAC/DC\\n2\\tAccept\\n3\\tAerosmith\\n*/', 'type': 'function', 'name': 'sql_db_schema'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Nlrc03jLTonhenq0ChcwpgIu on tokens per min (TPM): Limit 30000, Used 29941, Requested 482. Please try again in 846ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\2799409917.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2392, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2046, in stream\n",
      "    for _ in runner.tick(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py\", line 146, in tick\n",
      "    run_with_retry(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\2576808191.py\", line 116, in query_gen_node\n",
      "    message = query_gen.invoke(state)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3029, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5365, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 307, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 843, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 683, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 908, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 925, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Nlrc03jLTonhenq0ChcwpgIu on tokens per min (TPM): Limit 30000, Used 29941, Requested 482. Please try again in 846ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'query_gen' and id 'a080b089-8283-8341-b786-77d63a89131e'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 93754742-247e-47fc-95f2-4753c69cb863: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"C:\\Users\\kakao\\AI_study\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kakao\\AppData\\Local\\Temp\\ipykernel_14980\\316870680.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n"
     ]
    }
   ],
   "execution_count": 38
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
