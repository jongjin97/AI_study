{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-23T05:33:21.768296Z",
     "start_time": "2025-04-23T05:33:21.752095Z"
    }
   },
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH17-LangGraph\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH17-LangGraph\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 도구(Tool) 사용하기",
   "id": "f1c843bfe11d6f4e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T05:33:48.389480Z",
     "start_time": "2025-04-23T05:33:43.070037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "\n",
    "# 검색 도구 생성\n",
    "tool = TavilySearch(max_results=3)\n",
    "\n",
    "# 도구 목록에 추가\n",
    "tools = [tool]\n",
    "\n",
    "# 도구 실행\n",
    "tool.invoke(\"테디노트 랭체인 튜토리얼\")"
   ],
   "id": "a377f7f7406a99fc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'linktr.ee/teddynote | Linktree',\n",
       "  'url': 'https://linktr.ee/teddynote',\n",
       "  'content': '03/04 LangGraph Hands On 튜토리얼 (2시간 분량) [FastCampus] 테디노트의 RAG 비법노트🙌. 🔥[100% 무료] 테디노트 YouTube 콘텐츠 학습 순서🔥. 📘 랭체인 한국어 튜토리얼🇰🇷 ... Github. 9/21 테디노트-Gencon2024-ModularRAG-20240921.pdf.',\n",
       "  'score': 0.71948266,\n",
       "  'raw_content': None},\n",
       " {'title': ' - LangChain 한국어 튜토리얼 - WikiDocs',\n",
       "  'url': 'https://wikidocs.net/book/14314',\n",
       "  'content': \"대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL) 01. 구조화된 출력 체인(with_structered_output) CH15 평가(Evaluations) 01. 온라인 평가를 활용한 평가 자동화 CH16 에이전트(Agent) 01. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH17 LangGraph 01. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 - shcheon99@naver.com, Jan. 9, 2025, 12:28 p.m. 출력된 결과를 비교했을 때, kiwi tokenizer을 사용한 결과와 kkma, okt 를 사용한 결과가 큰 차이가 없다고 봐도 되는 건가요? CH01 LangChain 시작하기 - NamHyeon, Dec. 8, 2024, 1:17 p.m. 좋은 자료를 무료로 공유해 주셔서, 감사한 마음에 '테디노트의 RAG 비법노트' 강의 등록했습니다 ! 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) - Jan. 16, 2025, 12:23 a.m. 멀티 에이전트 감독자(Multi-Agent Supervisor) - Dec. 23, 2024, 3:04 a.m. 계층적 멀티 에이전트 팀(Hierarchical Multi-Agent Teams) - Dec. 23, 2024, 3:04 a.m.\",\n",
       "  'score': 0.70531887,\n",
       "  'raw_content': '<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 - WikiDocs\\n<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기 01. 설치 영상보고 따라하기 02. OpenAI API 키 발급 및 테스트 03. LangSmith 추적 설정 04. OpenAI API 사용(GPT-4o 멀티모달) 05. LangChain Expression Language(LCEL) 06. LCEL 인터페이스 07. Runnable CH02 프롬프트(Prompt) 01. 프롬프트(Prompt) 02. 퓨샷 프롬프트(FewShotPromptTemplate) 03. LangChain Hub 04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers) 01. Pydantic 출력 파서(PydanticOutputParser) 02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser) 03. 구조화된 출력 파서(StructuredOuputParser) 04. JSON 출력 파서(JsonOutputParser) 05. 데이터프레임 출력 파서(PandasDataFrameOutputParser) 06. 날짜 형식 출력 파서(DatetimeOutputParser) 07. 열거형 출력 파서(EnumOutputParser) 08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model) 01. 다양한 LLM 모델 활용 02. 캐싱(Cache) 03. 모델 직렬화(Serialization) - 저장 및 불러오기 04. 토큰 사용량 확인 05. 구글 생성 AI(Google Generative AI) 06. 허깅페이스 엔드포인트(HuggingFace Endpoints) 07. 허깅페이스 로컬(HuggingFace Local) 08. 허깅페이스 파이프라인(HuggingFace Pipeline) 09. 올라마(Ollama) 10. GPT4ALL 11. 비디오(Video) 질의 응답 LLM (Gemini) CH05 메모리(Memory) 01. 대화 버퍼 메모리(ConversationBufferMemory) 02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory) 03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) 04. 대화 엔티티 메모리(ConversationEntityMemory) 05. 대화 지식그래프 메모리(ConversationKGMemory) 06. 대화 요약 메모리(ConversationSummaryMemory) 07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory) 08. LCEL Chain 에 메모리 추가 09. SQLite 에 대화내용 저장 10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader) 01. 도큐먼트(Document) 의 구조 02. PDF 03. 한글(HWP) 04. CSV 05. Excel 06. Word 07. PowerPoint 08. 웹 문서(WebBaseLoader) 09. 텍스트(TextLoader) 10. JSON 11. Arxiv 12. UpstageLayoutAnalysisLoader 13. LlamaParser CH07 텍스트 분할(Text Splitter) 01. 문자 텍스트 분할(CharacterTextSplitter) 02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter) 03. 토큰 텍스트 분할(TokenTextSplitter) 04. 시멘틱 청커(SemanticChunker) 05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등) 06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter) 07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter) 08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding) 01. OpenAIEmbeddings 02. 캐시 임베딩(CacheBackedEmbeddings) 03. 허깅페이스 임베딩(HuggingFace Embeddings) 04. UpstageEmbeddings 05. OllamaEmbeddings 06. GPT4ALL 임베딩 07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore) 01. Chroma 02. FAISS 03. Pinecone CH10 검색기(Retriever) 01. 벡터스토어 기반 검색기(VectorStore-backed Retriever) 02. 문맥 압축 검색기(ContextualCompressionRetriever) 03. 앙상블 검색기(EnsembleRetriever) 04. 긴 문맥 재정렬(LongContextReorder) 05. 상위 문서 검색기(ParentDocumentRetriever) 06. 다중 쿼리 검색기(MultiQueryRetriever) 07. 다중 벡터저장소 검색기(MultiVectorRetriever) 08. 셀프 쿼리 검색기(SelfQueryRetriever) 09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever) 10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 11. Convex Combination(CC) 적용된 앙상블 검색기(EnsembleRetriever) CH11 리랭커(Reranker) 01. Cross Encoder Reranker 02. Cohere Reranker 03. Jina Reranker 04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG) 01. PDF 문서 기반 QA(Question-Answer) 02. 네이버 뉴스기사 QA(Question-Answer) 03. RAG 의 기능별 다양한 모듈 활용기 04. RAPTOR: 긴 문맥 요약(Long Context Summary) 05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL) 01. RunnablePassthrough 02. Runnable 구조(그래프) 검토 03. RunnableLambda 04. LLM 체인 라우팅(RunnableLambda, RunnableBranch) 05. RunnableParallel 06. 동적 속성 지정(configurable_fields, configurable_alternatives) 07. @chain 데코레이터로 Runnable 구성 08. RunnableWithMessageHistory 09. 사용자 정의 제네레이터(generator) 10. Runtime Arguments 바인딩 11. 폴백(fallback) 모델 지정 CH14 체인(Chains) 01. 문서 요약 02. SQL 03. 구조화된 출력 체인(with_structered_output) CH15 평가(Evaluations) 01. 합성 테스트 데이터셋 생성(RAGAS) 02. RAGAS 를 활용한 평가 03. 생성한 평가용 데이터셋 업로드(HuggingFace Dataset) 04. LangSmith 데이터셋 생성 05. LLM-as-Judge 06. 임베딩 기반 평가(embedding_distance) 07. 사용자 정의(Custom) LLM 평가 08. Rouge, BLEU, METEOR, SemScore 기반 휴리스틱 평가 09. 실험(Experiment) 평가 비교 10. 요약(Summary) 방식의 평가 11. Groundedness(할루시네이션) 평가 12. 실험 비교(Pairwise Evaluation) 13. 반복 평가 14. 온라인 평가를 활용한 평가 자동화 CH16 에이전트(Agent) 01. 도구(Tools) 02. 도구 바인딩(Binding Tools) 03. 에이전트(Agent) 04. Claude, Gemini, Ollama, Together.ai 를 활용한 Agent 05. Iteration 기능과 사람 개입(Human-in-the-loop) 06. Agentic RAG 07. CSVExcel 데이터 분석 Agent 08. Toolkits 활용 Agent 09. RAG + Image Generator Agent(보고서 작성) 10. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH17 LangGraph 01. 핵심 기능 01. LangGraph 에 자주 등장하는 Python 문법이해 02. LangGraph를 활용한 챗봇 구축 03. LangGraph를 활용한 Agent 구축 04. Agent 에 메모리(memory) 추가 05. 노드의 단계별 스트리밍 출력 06. Human-in-the-loop(사람의 개입) 07. 중간단계 개입 되돌림을 통한 상태 수정과 Replay 08. 사람(Human)에게 물어보는 노드 추가 09. 메시지 삭제(RemoveMessage) 10. ToolNode 를 사용하여 도구를 호출하는 방법 11. 병렬 노드 실행을 위한 분기 생성 방법 12. 대화 기록 요약을 추가하는 방법 13. 서브그래프 추가 및 사용 방법 14. 서브그래프의 입력과 출력을 변환하는 방법 15. LangGraph 스트리밍 모드의 모든 것 02. 구조 설계 01. 기본 그래프 생성 02. Naive RAG 03. 관련성 체커(Relevance Checker) 모듈 추가 04. 웹 검색 모듈 추가 05. 쿼리 재작성 모듈 추가 06. Agentic RAG 07. Adaptive RAG 03. Use Cases 01. 에이전트 대화 시뮬레이션 (고객 응대 시나리오) 02. 사용자 요구사항 기반 메타 프롬프트 생성 에이전트 03. CRAG(Corrective RAG) 04. Self-RAG 05. 계획 후 실행(Plan-and-Execute) 06. 멀티 에이전트 협업 네트워크(Multi-Agent Collaboration Network) 07. 멀티 에이전트 감독자(Multi-Agent Supervisor) 08. 계층적 멀티 에이전트 팀(Hierarchical Multi-Agent Teams) 09. SQL 데이터베이스와 상호작용하는 에이전트 10. STORM 개념을 도입한 연구를 위한 멀티 에이전트 CH18 기타 정보 01. StreamEvent 타입별 정리\\nPublished with WikiDocs\\n\\n\\n<랭체인LangChain 노트> - Lang…\\n\\n\\n도서 증정 이벤트 !!\\n\\nWikiDocs\\n\\n<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷\\n\\nAuthor: 테디노트\\nLast edited by : Jan. 16, 2025, 12:23 a.m.\\nCopyright : \\n2,553 Like; \"추천\")\\n추천은 공유할 수 있는 무료 전자책을 집필하는데 정말 큰 힘이 됩니다. \"추천\" 한 번씩만 부탁 드리겠습니다🙏🙏\\n✅ 랭체인 한국어 튜토리얼 강의\\n패스트캠퍼스 - RAG 비법노트\\n✅ 랭체인 한국어 튜토리얼 코드저장소(GitHub) 📘🖥️\\nhttps://github.com/teddylee777/langchain-kr\\n✅ 유튜브 \"테디노트\" 🎥📚\\nhttps://www.youtube.com/c/@teddynote\\n✅ 데이터 분석 블로그 https://teddylee777.github.io\\n✅ 문의 teddylee777@gmail.com\\nLICENSE\\n인용 및 출처 표기\\n\\n본 저작물을 블로그, 유튜브 등 온라인 매체에 인용하여 게재할 경우, Creative Commons Attribution-NonCommercial-NoDerivs 2.0 Korea 라이선스에 따라 반드시 출처를 명시해야 합니다.\\n\\n상업적 사용에 대한 사전 협의\\n\\n본 저작물(Wikidocs 및 관련 실습 코드 포함)을 강의, 강연 등 상업적 목적으로 활용하고자 하는 경우, 저작권자와의 사전 서면 협의가 필수적으로 요구됩니다. 해당 협의는 teddylee777@gmail.com으로 문의하여 진행하실 수 있습니다.\\n\\n본 저작물은 2024년 테디노트에 의해 작성되었습니다. \\n모든 권리는 저작권자에게 있으며, 본 저작물은 Creative Commons Attribution-NonCommercial-NoDerivs 2.0 Korea 라이선스에 따라 배포됩니다.\\n본 저작물의 무단 전재 및 재배포를 금지하며, 전체 혹은 일부를 인용할 경우 출처를 명확히 밝혀주시기 바랍니다.\\n본 문서는 다른 문서의 내용을 참고하여 작성되었을 수 있습니다. 참고 자료는 본 문서 하단의 출처 목록에서 확인하실 수 있습니다.\\nCopyright (c) 테디노트.\\nReference\\n\\nLangChain Github\\nLangGraph Github\\nLangChain Document\\n\\nRecent Comments (8) Recent Modifications (10) RSS\\n02. 네이버 뉴스기사 QA(Question-Answer) - 김민겸, Feb. 2, 2025, 12:17 p.m.\\n\"bullet points 형식으로 정리\"에서 \"주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다.\" 라고 나오는데 이유를 알려주실 수 있나요? kmk582@naver.com\\n10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 - shcheon99@naver.com, Jan. 9, 2025, 12:28 p.m.\\n출력된 결과를 비교했을 때, kiwi tokenizer을 사용한 결과와 kkma, okt 를 사용한 결과가 큰 차이가 없다고 봐도 되는 건가요?\\nCH01 LangChain 시작하기 - NamHyeon, Dec. 8, 2024, 1:17 p.m.\\n좋은 자료를 무료로 공유해 주셔서, 감사한 마음에 \\'테디노트의 RAG 비법노트\\' 강의 등록했습니다 ! 물론 제 현업에 필요한 기술이라서, 강의 또한 기쁜 마음에 신청했구요 ~ 정주행 해서, 창공을 날아가 보겠습니다 ^^\\n06. Word - Paul, Oct. 27, 2024, 5:38 p.m.\\npython-docx도 설치해야 할까요?\\n10. JSON - Paul, Oct. 27, 2024, 5:37 p.m.\\n!pip install jq 부분이 들어가야 할 것 같습니다.\\n02. PDF - Paul, Oct. 27, 2024, 3:29 p.m.\\n<html><head> <meta http-equiv=\"Content-Type\" content=\"text/html\"> </head><body> <span style=\"position:absolute; border: gray 1px solid; left:0px; top:50px; width:612px; height:858px;\"></span> <div style=\"position:absolute; top:50px;\"><a name=\"1\">Page 1</a></div> <div style=\"position:absolute; border 이 부분이 출력 결과가 아니라 코드인 것처럼 표시되어 있네요~\\n12. UpstageLayoutAnalysisLoader - Paul, Oct. 27, 2024, 10:59 a.m.\\n감사히 잘 참고하고 있습니다. 아주 사소한 오기이지만... 11번 Arxiv 다음에 12번이 와야 할 텐데, 원래 넣으시려던 다른 목차가 빠진 것인지 바로 13번이 나왔네요^^\\n03. 모델 직렬화(Serialization) - 저장 및 불러오기 - 동구, Sept. 20, 2024, 12:58 p.m.\\nloads는 뭐에요?\\n10. JSON - Jan. 16, 2025, 12:23 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) - Jan. 16, 2025, 12:23 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등) - Jan. 16, 2025, 12:19 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n04. Self-RAG - Dec. 23, 2024, 3:48 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n10. STORM 개념을 도입한 연구를 위한 멀티 에이전트 - Dec. 23, 2024, 3:16 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n03. CRAG(Corrective RAG) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n05. 계획 후 실행(Plan-and-Execute) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n07. 멀티 에이전트 감독자(Multi-Agent Supervisor) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n08. 계층적 멀티 에이전트 팀(Hierarchical Multi-Agent Teams) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n09. SQL 데이터베이스와 상호작용하는 에이전트 - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n\\nNext : CH01 LangChain 시작하기\\n\\n\\n×\\n책갈피\\n추가 닫기\\n\\n×\\nLeave feedback on this page\\nEmail address to reply to\\nWhat you want to say\\n※ Feedback is delivered to the author by email.\\nClose Send'},\n",
       " {'title': 'GitHub - teddylee777/langchain-kr: LangChain 공식 Document, Cookbook, 그 ...',\n",
       "  'url': 'https://github.com/teddylee777/langchain-kr',\n",
       "  'content': 'GitHub - teddylee777/langchain-kr: LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. GitHub Copilot Write better code with AI GitHub Copilot Enterprise-grade AI features Search code, repositories, users, issues, pull requests... LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 🌟 LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 🔥성능이 놀라워요🔥 무료로 한국어🇰🇷 파인튜닝 모델 받아서 나만의 로컬 LLM 호스팅 하기(#LangServe) + #RAG 까지!! 무료로 한국어🇰🇷 파인튜닝 모델 받아서 나만의 로컬 LLM 호스팅 하기(LangServe) + RAG 까지!! 참고 자료는 본 문서 하단의 출처 목록에서 확인하실 수 있습니다. langchain-ai 📖 LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. tutorial cookbook openai huggingface gpt-3 openai-api gpt-4 generative-ai chatgpt langchain chatgpt-api langchain-python',\n",
       "  'score': 0.49494705,\n",
       "  'raw_content': 'GitHub - teddylee777/langchain-kr: LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 본 튜토리얼을 통해 LangChain을 더 쉽고 효과적으로 사용하는 방법을 배울 수 있습니다.\\nSkip to content \\nNavigation Menu\\nToggle navigation\\n\\nSign in\\n\\n\\nProduct\\n\\nGitHub Copilot Write better code with AI\\nSecurity Find and fix vulnerabilities\\nActions Automate any workflow\\nCodespaces Instant dev environments\\nIssues Plan and track work\\nCode Review Manage code changes\\nDiscussions Collaborate outside of code\\nCode Search Find more, search less\\n\\nExplore\\n\\nAll features\\nDocumentation\\nGitHub Skills\\nBlog\\n\\n\\n\\nSolutions\\nBy company size\\n\\nEnterprises\\nSmall and medium teams\\nStartups\\nNonprofits\\n\\nBy use case\\n\\nDevSecOps\\nDevOps\\nCI/CD\\nView all use cases\\n\\nBy industry\\n\\nHealthcare\\nFinancial services\\nManufacturing\\nGovernment\\nView all industries\\n\\nView all solutions\\n\\n\\nResources\\nTopics\\n\\nAI\\nDevOps\\nSecurity\\nSoftware Development\\nView all\\n\\nExplore\\n\\nLearning Pathways\\nWhite papers, Ebooks, Webinars\\nCustomer Stories\\nPartners\\nExecutive Insights\\n\\n\\n\\nOpen Source\\n\\n\\nGitHub Sponsors Fund open source developers\\n\\n\\nThe ReadME Project GitHub community articles\\n\\n\\nRepositories\\n\\nTopics\\nTrending\\nCollections\\n\\n\\n\\nEnterprise\\n\\nEnterprise platform AI-powered developer platform\\n\\nAvailable add-ons\\n\\nAdvanced Security Enterprise-grade security features\\nGitHub Copilot Enterprise-grade AI features\\nPremium Support Enterprise-grade 24/7 support\\n\\n\\n\\nPricing\\n\\n\\nSearch or jump to...\\nSearch code, repositories, users, issues, pull requests...\\nSearch\\nClear\\nSearch syntax tips\\nProvide feedback\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\nCancel Submit feedback\\nSaved searches\\nUse saved searches to filter your results more quickly\\nName  \\nQuery \\nTo see all available qualifiers, see our documentation.\\nCancel Create saved search\\nSign in\\nSign up Reseting focus\\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\\n{{ message }}\\nteddylee777 / langchain-kr Public\\n\\nNotifications You must be signed in to change notification settings\\nFork 407\\nStar 1.4k\\n\\nLangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 본 튜토리얼을 통해 LangChain을 더 쉽고 효과적으로 사용하는 방법을 배울 수 있습니다.\\nwikidocs.net/book/14314\\nLicense\\nApache-2.0 license\\n1.4k stars 407 forks Branches Tags Activity\\nStar\\nNotifications You must be signed in to change notification settings\\n\\nCode\\nIssues 2\\nPull requests 0\\nActions\\nProjects 0\\nSecurity\\nInsights\\n\\nAdditional navigation options\\n\\nCode\\nIssues\\nPull requests\\nActions\\nProjects\\nSecurity\\nInsights\\n\\nteddylee777/langchain-kr\\nmain\\nBranchesTags\\n\\nGo to file\\nCode\\nFolders and files\\n| Name | Name | \\nLast commit message\\n| \\nLast commit date\\n|\\n| --- | --- | --- | --- |\\n| \\nLatest commit\\nHistory\\n391 Commits\\n\\n|\\n| \\n01-Basic\\n| \\n01-Basic\\n| \\n| \\n|\\n| \\n02-Prompt\\n| \\n02-Prompt\\n| \\n| \\n|\\n| \\n03-OutputParser\\n| \\n03-OutputParser\\n| \\n| \\n|\\n| \\n04-Model\\n| \\n04-Model\\n| \\n| \\n|\\n| \\n05-Memory\\n| \\n05-Memory\\n| \\n| \\n|\\n| \\n06-DocumentLoader\\n| \\n06-DocumentLoader\\n| \\n| \\n|\\n| \\n07-TextSplitter\\n| \\n07-TextSplitter\\n| \\n| \\n|\\n| \\n08-Embeddings\\n| \\n08-Embeddings\\n| \\n| \\n|\\n| \\n09-VectorStore\\n| \\n09-VectorStore\\n| \\n| \\n|\\n| \\n10-Retriever\\n| \\n10-Retriever\\n| \\n| \\n|\\n| \\n11-Reranker\\n| \\n11-Reranker\\n| \\n| \\n|\\n| \\n12-RAG\\n| \\n12-RAG\\n| \\n| \\n|\\n| \\n13-LangChain-Expression-Language\\n| \\n13-LangChain-Expression-Language\\n| \\n| \\n|\\n| \\n14-Chains\\n| \\n14-Chains\\n| \\n| \\n|\\n| \\n15-Agent\\n| \\n15-Agent\\n| \\n| \\n|\\n| \\n16-Evaluations\\n| \\n16-Evaluations\\n| \\n| \\n|\\n| \\n17-LangGraph\\n| \\n17-LangGraph\\n| \\n| \\n|\\n| \\n18-FineTuning\\n| \\n18-FineTuning\\n| \\n| \\n|\\n| \\n19-Streamlit\\n| \\n19-Streamlit\\n| \\n| \\n|\\n| \\n20-Projects/01-ParsingOutput\\n| \\n20-Projects/01-ParsingOutput\\n| \\n| \\n|\\n| \\n22-OpenAI\\n| \\n22-OpenAI\\n| \\n| \\n|\\n| \\n99-Projects\\n| \\n99-Projects\\n| \\n| \\n|\\n| \\nimages\\n| \\nimages\\n| \\n| \\n|\\n| \\n.env_sample\\n| \\n.env_sample\\n| \\n| \\n|\\n| \\n.gitignore\\n| \\n.gitignore\\n| \\n| \\n|\\n| \\nLICENSE\\n| \\nLICENSE\\n| \\n| \\n|\\n| \\nREADME.md\\n| \\nREADME.md\\n| \\n| \\n|\\n| \\npoetry.lock\\n| \\npoetry.lock\\n| \\n| \\n|\\n| \\npyproject.toml\\n| \\npyproject.toml\\n| \\n| \\n|\\n| \\nrequirements-mini.txt\\n| \\nrequirements-mini.txt\\n| \\n| \\n|\\n| \\nrequirements-onnx.txt\\n| \\nrequirements-onnx.txt\\n| \\n| \\n|\\n| \\nrequirements.txt\\n| \\nrequirements.txt\\n| \\n| \\n|\\n| \\nView all files\\n|\\nRepository files navigation\\n\\nREADME\\nApache-2.0 license\\n\\n📘 LangChain 한국어 튜토리얼\\n\\n\\n🌟 LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다.\\n본 튜토리얼을 통해 LangChain을 더 쉽고 효과적으로 사용하는 방법을 배울 수 있습니다.\\n📔 위키독스 전자책(무료)\\n\\n\\n위키독스에 무료 전자책을 등록하였습니다✌️\\n위키독스 페이지에서 책 \"추천\" 버튼 한 번씩만 눌러 주시면 제작에 큰 힘이 됩니다. 미리 감사 드립니다🫶\\n틈나는대로 열심히 업데이트 하고 있습니다. 앞으로도 신규 기능이 추가 될 때마다 빠르게 x100 업데이트 예정입니다.\\n\\n랭체인LangChain 노트 by 테디노트 구경하러 가기\\n\\n🍿 유튜브\\n\\n\\n🤗 huggingface 에 공개된 오픈모델을 💻 로컬PC 에서 빠르게 실행🔥 해보고 테스트 하는 방법 + 모델 서빙🚀 + 업무자동화🤖 에 적용하는 방법까지!\\n👀 코드 기반 답변하는 💻 GitHub 소스코드 기반 Q&A 챗봇🤖 제작기\\nllama3 출시🔥 로컬에서 Llama3-8B 모델 돌려보기👀\\n🔥성능이 놀라워요🔥 무료로 한국어🇰🇷 파인튜닝 모델 받아서 나만의 로컬 LLM 호스팅 하기(#LangServe) + #RAG 까지!!\\n무료로 한국어🇰🇷 파인튜닝 모델 받아서 나만의 로컬 LLM 호스팅 하기(LangServe) + RAG 까지!!\\nStreamlit 으로 ChatGPT 클론 서비스 제작하는 방법\\n대화내용을 기록하는 LLM Chain 생성 방법 + 도큐먼트 참조하는 tip!\\n(Self Learning GPT) LangSmith 피드백으로 원하는 형식의 답변을 학습하는 GPT\\n(LangServe 리뷰) 초간편 LLM 웹앱 제작 & 배포기능까지! 과연, Streamlit 대체할 수 있을까?\\nAI vs AI 의대 증원에 대한 모의 찬반토론 (AI 더빙본)\\n토론 AI 에이전트 - 의대 입학정원 증원에 대한 찬반토론을 AI 끼리 한다면?\\n긴 문서(long context) 에 대한 참신한 RAG 방법론: RAPTOR! 논문 리뷰와 코드를 준비했습니다\\nLangChain 밋업 발표 / R.A.G. 우리가 절대 쉽게결과물을 얻을 수 없는 이유\\n노코딩으로 쇼핑몰 리뷰 분석 (크롤링 + Q&A 챗봇)\\nChatGPT 의 GPTS 에 API 호출기능을 붙이면 어떻게 될까?\\nLangChain Agent 를 활용하여 ChatGPT를 업무자동화 에 적용하는 방법🔥🔥\\nPrivate GPT! 나만의 ChatGPT 만들기 (HuggingFace Open LLM 활용)\\nLangGraph 의 멀티 에이전트 콜라보레이션 찍먹하기\\n마법같은 문법 LangChain Expression Language(LCEL)\\n이미지를 matplotlib 파이썬 코드로, 원하는 문장을 입력하면 파이썬 코드로 변환하는 방법\\nRAG 파이프라인 이해해보기 - 네이버 뉴스기사 기반 Q&A 챗봇 제작\\nOpenAI 의 새로운 기능 Assistant API 완벽히 이해해보기\\nOpenAI 의 새로운 기능 Assistant API 3가지 도구 활용법\\n\\n✏️ 블로그 글 목록\\n\\nGeneral\\n\\n\\nOpenAI API 모델 리스트 / 요금표\\n\\nOpenAI Python API\\n\\n\\nOpenAI Python API 키 발급방법, 요금체계\\n채팅(chat) 함수 사용하기(1)\\nDALL·E를 사용하여 이미지 생성, 수정, 다양화하기(2)\\nWhisper API를 사용하여 TTS, STT 구현하기(3)\\n\\nLangChain\\n\\n\\nOpenAI GPT 모델(ChatOpenAI) 사용법\\n허깅페이스(HuggingFace) 모델 사용법\\n챗(chat) - ConversationChain, 템플릿 사용법\\n정형데이터(CSV, Excel) - ChatGPT 기반 데이터분석\\n웹사이트 크롤링 - 웹사이트 문서 요약\\n웹사이트 정보 추출 - 스키마 활용법\\nPDF 문서요약, Map-Reduce\\nPDF 기반 질의응답(Question-Answering)\\n문장을 파이썬 코드로, 이미지를 파이썬 코드로 변경하는 방법\\nLangChain Expression Language(LCEL) 원리 이해와 파이프라인 구축 가이드\\nLLMs를 활용한 문서 요약 가이드: Stuff, Map-Reduce, Refine 방법 총정리\\n자동화된 메타데이터 태깅으로 문서의 메타데이터(metadata) 생성 및 자동 라벨링\\n네이버 뉴스 기반 Q&A 애플리케이션 구축하기 - 기본편\\nRAG 파헤치기: 문서 기반 QA 시스템 설계 방법 - 심화편\\n에이전트(Agent)와 도구(tools)를 활용한 지능형 검색 시스템 구축 가이드\\n\\nLangGraph\\n\\n\\nMulti-Agent Collaboration(다중 협업 에이전트) 로 복잡한 테스크를 수행하는 LLM 어플리케이션 제작\\nLangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\\n\\n👥 LangChain 밋업 2024 Q1 발표자료\\n\\n\\nRAG - 우리가 절대 쉽게 원하는 결과물을 얻을 수 없는 이유 - 테디노트\\n프름프트 흐름과 LLM 모델 평가 - 이재석님\\n인공지능을 통한 게임 제작 파이프라인의 변화 - 김한얼님\\nOpenAI SORA 살짝 맛보기 - 박정현님\\nSemantic Kernel로 만드는 AI Copilot - 이종인님\\nStreamlit 과 langchain으로 나만의 웹서비스 개발하기 - 최재혁님\\nLlama2-koen을 만들기까지 - 최태균님\\n올바른 한국어 언어 모델 평가를 위해: HAE-RAE Bench, KMMLU - 손규진님\\n랭체인 네이버 기사 크롤링 - 우성우님\\nGemma와 LangChain을 이용한 SQL 체인만들기 - 김태영님\\n\\n📜 라이선스\\n\\n본 프로젝트는 Apache License 2.0에 따라 라이선스가 부여됩니다.\\n🚫 라이선스 고지\\n\\n🔒 본 내용의 저작권은 2024년 테디노트에 있습니다. 모든 권리는 저작권자에게 있으며, teddylee777@gmail.com 으로 문의할 수 있습니다.\\n```\\nCopyright 2024 테디노트(teddylee777@gmail.com)\\nLicensed under the Apache License, Version 2.0 (the \"License\");\\nyou may not use this file except in compliance with the License.\\nYou may obtain a copy of the License at\\nhttp://www.apache.org/licenses/LICENSE-2.0\\n\\nUnless required by applicable law or agreed to in writing, software\\ndistributed under the License is distributed on an \"AS IS\" BASIS,\\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\nSee the License for the specific language governing permissions and\\nlimitations under the License.\\n```\\n인용 및 출처 표기\\n\\n본 저작물의 내용을 블로그, 유튜브 등 온라인 매체에 인용하여 게재하는 경우, 저작권법에 따라 반드시 출처를 명시 해야 합니다.\\n\\n상업적 사용에 대한 사전 협의\\n\\n본 저작물(Wikidocs 및 관련 실습 코드 포함)을 강의, 강연 등 상업적 목적으로 활용하고자 하는 경우, 저작권자와의 사전 서면 협의가 필수적으로 요구됩니다.\\n\\n본 내용의 무단 전재 및 재배포를 금지합니다. 본 내용의 전체 혹은 일부를 인용할 경우, 출처를 명확히 밝혀주시기 바랍니다. 본 문서는 다른 문서의 내용을 참고하여 작성되었을 수 있습니다. 참고 자료는 본 문서 하단의 출처 목록에서 확인하실 수 있습니다.\\n📚 출처\\n\\n\\nlangchain-ai 📖\\nOpenAI API Reference 🤖\\n\\n🌐 추가 자료\\n\\n\\n유튜브 채널: LangChain 한국어 튜토리얼 🎥\\n블로그: 테디노트 📝\\nPlayground: LangChain LLM Playground 🎮\\n\\n🚀 시작하기\\n\\n본 튜토리얼을 시작하기 전에, LangChain과 관련된 기본적인 지식을 갖추는 것이 좋습니다. 위의 출처 링크를 통해 기본적인 정보를 얻을 수 있습니다.\\nStart History\\n\\n\\n💡 컨트리뷰션\\n\\n본 튜토리얼에 기여하고자 하는 분들은 언제든지 풀 리퀘스트를 보내주시거나, 이슈를 등록하여 의견을 공유해 주시기 바랍니다. 모든 기여는 본 프로젝트의 발전에 큰 도움이 됩니다. 💖\\n\\nAbout\\nLangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 본 튜토리얼을 통해 LangChain을 더 쉽고 효과적으로 사용하는 방법을 배울 수 있습니다.\\nwikidocs.net/book/14314\\nTopics\\ntutorial cookbook openai huggingface gpt-3 openai-api gpt-4 generative-ai chatgpt langchain chatgpt-api langchain-python\\nResources\\nReadme\\nLicense\\nApache-2.0 license\\nActivity\\nStars\\n1.4k stars\\nWatchers\\n37 watching\\nForks\\n407 forks\\nReport repository\\nReleases\\nNo releases published\\nPackages 0\\nNo packages published  \\nContributors 5\\nLanguages\\n\\nJupyter Notebook 97.8%\\nPython 2.0%\\nHTML 0.2%\\n\\nFooter\\n© 2025 GitHub,\\xa0Inc.\\nFooter navigation\\n\\nTerms\\nPrivacy\\nSecurity\\nStatus\\nDocs\\nContact\\nManage cookies\\nDo not share my personal information\\n\\nYou can’t perform that action at this time.'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T05:34:09.975215Z",
     "start_time": "2025-04-23T05:34:09.900988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# State 정의\n",
    "class State(TypedDict):\n",
    "    # list 타입에 add_messages 적용(list 에 message 추가)\n",
    "    messages: Annotated[list, add_messages]"
   ],
   "id": "d40fd799627f95d4",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T05:34:23.550720Z",
     "start_time": "2025-04-23T05:34:21.708769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# LLM 에 도구 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ],
   "id": "46c3f0ee5b8b5a1b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T05:35:13.628433Z",
     "start_time": "2025-04-23T05:35:13.624977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 노드 함수 정의\n",
    "def chatbot(state: State):\n",
    "    answer = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # 메시지 목록 반환\n",
    "    return {\"messages\": [answer]}  # 자동으로 add_messages 적용"
   ],
   "id": "8301f15220e5afe0",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T05:35:55.803732Z",
     "start_time": "2025-04-23T05:35:55.796330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "# 상태 그래프 초기화\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 노드 추가\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ],
   "id": "f1d6e3da287aa394",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2a47f6d1a50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 도구 노드(Tool Node)",
   "id": "ff3cf94fe6fe055a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T05:41:21.965483Z",
     "start_time": "2025-04-23T05:41:21.956418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "class BasicToolNode:\n",
    "    \"\"\"Run tools requestd in the last AImessage Noede\"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        # 도구 리스트\n",
    "        self.tools_list = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        # 메시지가 존재할 경우 가장 최근 메시지 1개 추출\n",
    "        if message := inputs.get(\"messages\", []):\n",
    "            message = message[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "\n",
    "        # 도구 호출 결과\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            # 도구 호출 결과 저장\n",
    "            tool_result = self.tools_list[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(\n",
    "                        tool_result, ensure_ascii=False\n",
    "                    ), # 도구 호출 결과를 문자열로 변환\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "        return {\"messages\": outputs}\n",
    "\n",
    "# 도구 노드 생성\n",
    "tool_node = BasicToolNode(tools=[tool])\n",
    "\n",
    "# 그래프에 도구 노드 추가\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ],
   "id": "b2122906990a5cac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2a47f6d1a50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 조건부 엣지(Conditional Edge)",
   "id": "c792589f744c44e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T05:53:20.625921Z",
     "start_time": "2025-04-23T05:53:20.618069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import START, END\n",
    "\n",
    "def route_tools(state: State):\n",
    "    if messages := state.get(\"messages\", []):\n",
    "        # 가장 최근 AI 메시지를 추출\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        # 입력 상태에 메시지가 없는 경우 예외 발생\n",
    "        raise ValueError(f\"No message found in input state to tool_edge: {state}\")\n",
    "\n",
    "    # AI 메시지에 도구 호출이 있는 경우 \"tools\" 반환\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        # 도구 호출이 있는 경우 \"tools\" 반환\n",
    "        return \"tools\"\n",
    "    # 도구 호출이 없는 경우 \"END\" 반환\n",
    "    return END\n",
    "\n",
    "# 'tools_condition' 함수는 챗봇이 도구 사용을 요청하면 \"tools\"를 반환하고, 직접 응답이 가능항 경우 \"END\"를 반환\n",
    "graph_builder.add_conditional_edges(\n",
    "    source=\"chatbot\",\n",
    "    path=route_tools,\n",
    "    # route_tools의 반환값이 \"tools\"인 경우 \"tools\" 노드로, 그렇지 않으면 END 노드로 라우팅\n",
    "    path_map={\"tools\": \"tools\", END: END},\n",
    ")\n",
    "\n",
    "# tools > chatbot\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# START > chatbot\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = graph_builder.compile()"
   ],
   "id": "f0f6e968019e77a9",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T05:55:53.273954Z",
     "start_time": "2025-04-23T05:55:53.133912Z"
    }
   },
   "cell_type": "code",
   "source": "graph.get_graph().print_ascii()",
   "id": "dfb80153d2661101",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        +-----------+         \r\n",
      "        | __start__ |         \r\n",
      "        +-----------+         \r\n",
      "              *               \r\n",
      "              *               \r\n",
      "              *               \r\n",
      "        +---------+           \r\n",
      "        | chatbot |           \r\n",
      "        +---------+           \r\n",
      "         .         .          \r\n",
      "       ..           ..        \r\n",
      "      .               .       \r\n",
      "+-------+         +---------+ \r\n",
      "| tools |         | __end__ | \r\n",
      "+-------+         +---------+ \n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T05:56:19.862096Z",
     "start_time": "2025-04-23T05:56:09.365350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_teddynote.messages import display_message_tree\n",
    "\n",
    "question = \"테디노트 YouTube\"\n",
    "\n",
    "for event in graph.stream({\"messages\": [(\"user\", question)]}):\n",
    "    for key, value in event.items():\n",
    "        print(f\"\\n==============\\nSTEP: {key}\\n==============\\n\")\n",
    "        display_message_tree(value[\"messages\"][-1])"
   ],
   "id": "a4b4e60d67e77a1a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============\n",
      "STEP: chatbot\n",
      "==============\n",
      "\n",
      "    \u001B[93mcontent\u001B[0m: \"\"\n",
      "    \u001B[93madditional_kwargs\u001B[0m:\n",
      "        \u001B[94mtool_calls\u001B[0m:\n",
      "            \u001B[94mindex [0]\u001B[0m\n",
      "                \u001B[92mid\u001B[0m: \"call_594kyYHfqOukQuHniHCoQW02\"\n",
      "                \u001B[92mfunction\u001B[0m: {\"arguments\": \"{\"query\":\"테디노트 YouTube\"}\", \"name\": \"tavily_web_search\"}\n",
      "                \u001B[92mtype\u001B[0m: \"function\"\n",
      "        \u001B[94mrefusal\u001B[0m: None\n",
      "    \u001B[93mresponse_metadata\u001B[0m:\n",
      "        \u001B[94mtoken_usage\u001B[0m:\n",
      "            \u001B[95mcompletion_tokens\u001B[0m: 23\n",
      "            \u001B[95mprompt_tokens\u001B[0m: 97\n",
      "            \u001B[95mtotal_tokens\u001B[0m: 120\n",
      "            \u001B[95mcompletion_tokens_details\u001B[0m: {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}\n",
      "            \u001B[95mprompt_tokens_details\u001B[0m: {\"audio_tokens\": 0, \"cached_tokens\": 0}\n",
      "        \u001B[94mmodel_name\u001B[0m: \"gpt-4o-mini-2024-07-18\"\n",
      "        \u001B[94msystem_fingerprint\u001B[0m: \"fp_dbaca60df0\"\n",
      "        \u001B[94mid\u001B[0m: \"chatcmpl-BPNNa2fdHwdxLpOW73Q5JinwZuiUK\"\n",
      "        \u001B[94mfinish_reason\u001B[0m: \"tool_calls\"\n",
      "        \u001B[94mlogprobs\u001B[0m: None\n",
      "    \u001B[93mtype\u001B[0m: \"ai\"\n",
      "    \u001B[93mname\u001B[0m: None\n",
      "    \u001B[93mid\u001B[0m: \"run-fff1cac2-2fa4-48bf-a81a-8487b231d3da-0\"\n",
      "    \u001B[93mexample\u001B[0m: False\n",
      "    \u001B[93mtool_calls\u001B[0m:\n",
      "        \u001B[93mindex [0]\u001B[0m\n",
      "            \u001B[95mname\u001B[0m: \"tavily_web_search\"\n",
      "            \u001B[95margs\u001B[0m: {\"query\": \"테디노트 YouTube\"}\n",
      "            \u001B[95mid\u001B[0m: \"call_594kyYHfqOukQuHniHCoQW02\"\n",
      "            \u001B[95mtype\u001B[0m: \"tool_call\"\n",
      "    \u001B[93minvalid_tool_calls\u001B[0m:\n",
      "    \u001B[93musage_metadata\u001B[0m:\n",
      "        \u001B[94minput_tokens\u001B[0m: 97\n",
      "        \u001B[94moutput_tokens\u001B[0m: 23\n",
      "        \u001B[94mtotal_tokens\u001B[0m: 120\n",
      "        \u001B[94minput_token_details\u001B[0m: {\"audio\": 0, \"cache_read\": 0}\n",
      "        \u001B[94moutput_token_details\u001B[0m: {\"audio\": 0, \"reasoning\": 0}\n",
      "\n",
      "==============\n",
      "STEP: tools\n",
      "==============\n",
      "\n",
      "    \u001B[93mcontent\u001B[0m: \"[{\"title\": \"테디노트 TeddyNote - YouTube\", \"url\": \"https://www.youtube.com/channel/UCt2wAAXgm87ACiQnDHQEW6Q\", \"content\": \"An error occurred while retrieving sharing information. - Naive RAG - Advanced RAG - Agent - LangGraph - 수강하신 분들께만 드리는 소스코드 📘 랭체인 튜토리얼 무료 전자책(wikidocs) https://wikidocs.net/book/14314 ✅ 랭체인 한국어 튜토리얼 코드저장소(GitHub) https://github.com/teddylee777/langch... #rag #chatgpt --- 테디노트(깃헙 블로그) : https://teddylee777.github.io 머신러닝 혼자서 스터디 : https://github.com/teddylee777/machin... RAG 비법노트 강의 커리큘럼 소개 / #LangGraph 튜토리얼 하이라이트 EP.01 [캐글뽀개기] 영화리뷰 감정예측대회를 통한 자연어 처리 (머신러닝 & 딥러닝) 텐서플로우 튜토리얼 (전문가용, Expert) TensorFlow Datasets 활용하여 데이터셋 로드하기 - 텐서플로우 튜토리얼 Functional API - 텐서플로우 튜토리얼 train_on_batch 배치별 학습 - 텐서플로우 튜토리얼 GradientTape - 텐서플로우 튜토리얼 텐서플로우 튜토리얼 [텐서플로우 RNN 튜토리얼] 셰익스피어가 되어 보자 00 - #텐서플로우 2.0 튜토리얼 뽀개기를 시작합니다 구글 코랩 (Google Colab) 튜토리얼 강의와 꿀팁 An error occurred while retrieving sharing information.\", \"score\": 0.71113056, \"raw_content\": \"Warning: Target URL returned error 403: Forbidden\\n테디노트 TeddyNote - YouTube\\n•\\nNaN / NaN\\nBack \\nSkip navigation\\nSearch\\nSearch with your voice\\nSign in\\n\\nHome HomeShorts\\nShorts\\nSubscriptions SubscriptionsYou YouHistory History\\n\\n\\n테디노트 TeddyNote\\n@teddynote\\n•\\n35K subscribers•234 videos\\n데이터 분석, 머신러닝, 딥러닝, LLM 에 대한 내용을 다룹니다. 연구보다는 개발에 관심이 많습니다 🙇‍♂️ ...more...morefastcampus.co.kr/data_online_teddyand 2 more links\\nSubscribe\\nJoin\\nHome\\nVideos\\nShorts\\nLive\\nPlaylists\\nPosts\\nSearch \\n\\nSearch\\nInfo\\nShopping\\nTap to unmute\\n2x\\n\\nIf playback doesn't begin shortly, try restarting your device.\\n\\n•\\nSign in to confirm you’re not a bot\\nShare\\nInclude playlist\\nAn error occurred while retrieving sharing information. Please try again later.\\nWatch later\\nShare\\nCopy link\\n\\n0:00\\n0:00 / 0:00•Watch full videoLive\\n•\\n•\\n[#langchain 밋업 발표] R.A.G. 우리가 절대 쉽게결과물을 얻을 수 없는 이유\\n•\\n•\\n51,636 views 11 months ago\\n📍 발표자료: https://aifactory.space/task/2719/dis... ⭐️패스트캠퍼스 RAG 비법노트⭐️ 링크: https://fastcampus.co.kr/data_online_... - Naive RAG - Advanced RAG - Agent - LangGraph - 수강하신 분들께만 드리는 소스코드 📘 랭체인 튜토리얼 무료 전자책(wikidocs) https://wikidocs.net/book/14314 ✅ 랭체인 한국어 튜토리얼 코드저장소(GitHub) https://github.com/teddylee777/langch... #rag #chatgpt --- 테디노트(깃헙 블로그) : https://teddylee777.github.io 머신러닝 혼자서 스터디 : https://github.com/teddylee777/machin... LLM 프로젝트: http://llm.teddynote.com\\nRead more\\nOur members Thank you, channel members!\\n       \\nJoin\\n\\nVideos\\n\\n 19:56 19:56 Now playing\\n\\n#LangSmith Playground 로 프롬프트 실험하는 방법(스키마, Tool, Canvas)\\n1.4K views6 days ago\\n 8:13 8:13 Now playing\\n\\n#GTC 이벤트 참여하고 RTX 4080 의 주인공이 되세요!\\n897 views6 days ago\\n 8:41 8:41 Now playing\\n\\n❤️[책 소개+출간 이벤트] 일잘러의 비밀, 챗GPT와 GPTs로 나만의 AI 챗봇 만들기❤️\\n1.4K views11 days ago\\n 14:30 14:30 Now playing\\n\\n#옵시디언 에 #dify 연결해서 RAG / Agent / Workflow 를 옵시디언 노트에 적용해 보았습니다.\\n4.2K views1 month ago\\n 6:55 6:55 Now playing\\n\\n#Obsidian 노트에 제목, 메타데이터, 요약 작업 자동화 해봤습니다. (템플릿 무료 공유)\\n3.7K views1 month ago\\n 21:06 21:06 Now playing\\n\\n코딩 과외 선생님을 만들어 봤습니다.\\n2.9K views1 month ago\\n\\nLangChain 튜토리얼\\nPlay all\\n\\nlangchain #튜토리얼 모음입니다.\\n 19:56 19:56 Now playing\\n\\n#LangSmith Playground 로 프롬프트 실험하는 방법(스키마, Tool, Canvas)\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n1.4K views6 days ago\\n 21:06 21:06 Now playing\\n\\n코딩 과외 선생님을 만들어 봤습니다.\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n2.9K views1 month ago\\n 18:54 18:54 Now playing\\n\\nRAG 비법노트 강의 커리큘럼 소개 / #LangGraph 튜토리얼 하이라이트\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n3.6K views2 months ago\\n 1:00 1:00 Now playing\\n\\n[11월 주주총회] #LangGraph 로 #멀티턴 대화 구현이 정말 쉬운 이유!!!\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n2.4K views2 months ago\\n 14:03 14:03 Now playing\\n\\nEP04. Lazy #프롬프트 를 개선하는 메이커 구현해보기!\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n3.9K views3 months ago\\n 23:33 23:33 Now playing\\n\\nEP03. #PDF 문서 기반 QA #RAG 구축하기\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n6.5K views3 months ago\\n\\n깃헙(Github) 블로그 만들기 - 시즌2\\nPlay all\\n\\n 2:32 2:32 Now playing\\n\\nEP14. 깃헙(Github) 블로그 만들기 시즌2를 시작합니다!\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n7.7K views2 years ago\\n 6:45 6:45 Now playing\\n\\nEP15. 최신 업데이트 내역 블로그에 적용하기(최신 기능 적용)\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n3.1K views2 years ago\\n 3:56 3:56 Now playing\\n\\nEP16. 메인 페이지에 사진 추가, 유튜브 아이콘/링크 추가하기\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n1.9K views2 years ago\\n 11:52 11:52 Now playing\\n\\nEP17. 포스트 왼쪽 영역 확장, TOC 스타일 수정하기(CSS 스타일 수정하는 법)\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n1.9K views2 years ago\\n 8:14 8:14 Now playing\\n\\nEP18. 이미지 추가시 오류 해결 (A/S 영상)\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n1.5K views2 years ago\\n 5:26 5:26 Now playing\\n\\nEP19. 사이트 주소가 바뀌었을 때. redirect_from 플러그인으로 해결하기\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n667 views2 years ago\\n\\n깃헙(Github) 블로그 만들기 - 시즌1\\nPlay all\\n\\n 5:34 5:34 Now playing\\n\\nEP01. 개발환경 설치하기\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n44K views3 years ago\\n 4:45 4:45 Now playing\\n\\nEP02. 이미지 매우 간단하게 추가하기\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n17K views3 years ago\\n 7:49 7:49 Now playing\\n\\n번외편. Typora를 활용하여 블로그에 이미지 쉽게 추가하기 (초간단 셋팅법)\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n4.7K views1 year ago\\n 8:03 8:03 Now playing\\n\\nEP03. 업데이트 내역을 실시간 확인하기!! (로컬 개발환경 설정방법)\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n12K views3 years ago\\n 10:45 10:45 Now playing\\n\\nEP04. 블로그 설정 매우 쉽게 변경하기 - NO코딩! (config.yml 활용)\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n9.7K views3 years ago\\n 12:33 12:33 Now playing\\n\\nEP05. 댓글 & 구글 애널리틱스 추가하기\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n6.4K views3 years ago\\n\\nPopular videos\\n\\n 17:11 17:11 Now playing\\n\\n깃헙(GitHub) 블로그 10분안에 완성하기\\n110K views4 years ago\\n 28:51 28:51 Now playing\\n\\n🔥성능이 놀라워요🔥 무료로 한국어🇰🇷 파인튜닝 모델 받아서 나만의 로컬 LLM 호스팅 하기(#LangServe) + #RAG 까지!!\\n55K views10 months ago\\n 45:21 45:21 Now playing\\n\\n[#langchain 밋업 발표] R.A.G. 우리가 절대 쉽게결과물을 얻을 수 없는 이유\\n51K views11 months ago\\n 5:34 5:34 Now playing\\n\\nEP01. 개발환경 설치하기\\n44K views3 years ago\\n 12:05 12:05 Now playing\\n\\n오차역전파 (Backprogation)의 개념을 쉽게 이해해 봅시다\\n41K views4 years ago\\n 16:05 16:05 Now playing\\n\\n저는 도커를 이렇게 사용합니다\\n40K views3 years ago\\n\\n머신러닝 딥러닝을 위한 기초수학\\nPlay all\\n\\n머신러닝 딥러닝을 위한 기초 수학과 통계입니다.\\n 13:46 13:46 Now playing\\n\\n#머신러닝 #딥러닝 입문자를 위한 초스피드 기초 #수학\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n31K views4 years ago\\n 17:42 17:42 Now playing\\n\\n경사하강법 (Gradient Descent)의 기본 개념을 쉽게 알려드립니다\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n32K views4 years ago\\n 11:31 11:31 Now playing\\n\\n경사하강법을 파이썬(python) 코드 구현\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n15K views4 years ago\\n 20:21 20:21 Now playing\\n\\n#선형회귀 의 기초인 #최소제곱법 ? 공식 유도를 해보자~!\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n16K views4 years ago\\n 12:05 12:05 Now playing\\n\\n오차역전파 (Backprogation)의 개념을 쉽게 이해해 봅시다\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n41K views4 years ago\\n\\n캐글 - 영화 리뷰 감정 분석\\nPlay all\\n\\n 2:45 2:45 Now playing\\n\\nEP.01 [캐글뽀개기] 영화리뷰 감정예측대회를 통한 자연어 처리 (머신러닝 & 딥러닝)\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n2.1K views4 years ago\\n 3:02 3:02 Now playing\\n\\nEP.02 [캐글뽀개기] 영화 리뷰 감정분석 - 데이터 불러오기\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n1.4K views4 years ago\\n 7:58 7:58 Now playing\\n\\nEP.03 [캐글뽀개기] 문장 전처리, 불용어 제거 (BeautifulSoup, NLTK 패키지 활용)\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n1.6K views4 years ago\\n 4:36 4:36 Now playing\\n\\nEP.04 [캐글뽀개기] CountVectorizer를 활용한 문장 전처리\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n770 views4 years ago\\n 4:01 4:01 Now playing\\n\\nEP.05 [캐글뽀개기] 베이스라인 예측 - RandomForestClassifier\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n536 views4 years ago\\n 3:21 3:21 Now playing\\n\\nEP.06 [캐글뽀개기] 베이스라인 점수를 잡기 위한 첫 제출 (Submission)\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n435 views4 years ago\\n\\n텐서플로우 튜토리얼 (전문가용, Expert)\\nPlay all\\n\\n 7:17 7:17 Now playing\\n\\nEP01. TensorFlow Datasets 활용하여 데이터셋 로드하기 - 텐서플로우 튜토리얼\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n4.6K views4 years ago\\n 6:46 6:46 Now playing\\n\\nEP02. Sequential 을 사용한 모델링, compile 그리고 fit (학습) - 텐서플로우 튜토리얼\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n1.2K views4 years ago\\n 6:01 6:01 Now playing\\n\\nEP03. Functional API - 텐서플로우 튜토리얼\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n927 views4 years ago\\n 4:52 4:52 Now playing\\n\\nEP04. train_on_batch 배치별 학습 - 텐서플로우 튜토리얼\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n1.2K views4 years ago\\n 11:29 11:29 Now playing\\n\\nEP05. GradientTape - 텐서플로우 튜토리얼\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n1.2K views4 years ago\\n 6:55 6:55 Now playing\\n\\nEP01. TF 튜토리얼 - Sequential API로 모델링하기 (MNIST 데이터셋)\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n840 views4 years ago\\n\\n텐서플로우 튜토리얼\\nPlay all\\n\\n 21:18 21:18 Now playing\\n\\n[텐서플로우 RNN 튜토리얼] 셰익스피어가 되어 보자\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n3.4K views4 years ago\\n 24:30 24:30 Now playing\\n\\n텐서플로우 데이터세트(tensorflow-datasets) 활용법입니다.\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n3.6K views4 years ago\\n 3:46 3:46 Now playing\\n\\nEP. 00 - #텐서플로우 2.0 튜토리얼 뽀개기를 시작합니다\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n2.8K views4 years ago\\n 10:51 10:51 Now playing\\n\\n코랩(colab)에서 텐서보드 로드하기\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n4K views4 years ago\\n 2:35 2:35 Now playing\\n\\n구글 코랩 (Google Colab) 설치와 GPU 사용\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n11K views4 years ago\\n 11:48 11:48 Now playing\\n\\n구글 코랩 (Google Colab) 튜토리얼 강의와 꿀팁\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n25K views4 years ago\\n\\n텐서플로우 자격증\\nPlay all\\n\\n 18:54 18:54 Now playing\\n\\n#텐서플로우 개발자 #자격증 정보 & 시험을 위한 환경 설치\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n9.1K views4 years ago\\n 24:30 24:30 Now playing\\n\\n텐서플로우 데이터세트(tensorflow-datasets) 활용법입니다.\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n3.6K views4 years ago\\n 12:22 12:22 Now playing\\n\\n[텐서플로우 자격증 단기 취득 과정] 스터디 전 준비사항\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n3.2K views4 years ago\\n 2:02 2:02 Now playing\\n\\n딥러닝 기초 용어 정리 (Epoch, Loss, Accuracy)\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n2.7K views4 years ago\\n 10:04 10:04 Now playing\\n\\n[2023년 업데이트] 구글 텐서플로 자격 인증 시험을 위한 파이참, 가상환경, 플러그인 설정 방법\\n테디노트 TeddyNote\\n테디노트 TeddyNote\\n1.8K views2 years ago\\nShorts\\n\\nEP02. #카톡봇 과 todoist 할일 관리 연동 완료😍\\n984 views\\n\\n내년초 개인화된 카톡봇 구축을 위한 테스트를 진행하고 있어요. 카톡+langgraph 기반 에이전트!\\n1.1K views\\n\\n[11월 주주총회] #LangGraph 로 #멀티턴 대화 구현이 정말 쉬운 이유!!!\\n2.4K views\\n\\n결국 Modular...RAG?!!\\n2.6K views\\n\\n🔥 #RAG 에서 가장 어려운 #PDF 파서🔥\\n4.5K views\\n\\n#파이썬 코드를 #블로그 글로 변환하는 방법 feat. #chatgpt\\n3.6K views\\nSearch\\nInfo\\nShopping\\nTap to unmute\\n2x\\n\\nIf playback doesn't begin shortly, try restarting your device.\\n\\n•\\nYou're signed out\\nVideos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.\\nCancelConfirm\\nShare\\nInclude playlist\\nAn error occurred while retrieving sharing information. Please try again later.\\nWatch later\\nShare\\nCopy link\\n\\n0:00\\n/ •Watch full videoLive\\n•\\n•\\nScroll for details\\n\\n…\\nNaN / NaN\"}, {\"title\": \"EP01. #RAG 의 동작 과정 쉽게 이해하기! - YouTube\", \"url\": \"https://www.youtube.com/watch?v=zybyszetEcE\", \"content\": \"EP01. #RAG 의 동작 과정 쉽게 이해하기!\\n테디노트 TeddyNote\\n34900 subscribers\\n380 likes\\n15253 views\\n24 Oct 2024\\n*본 영상은 [패스트캠퍼스] 에서 오픈한 \\\"RAG 비법노트\\\" 강의의 일부를 편집한 내용입니다.\\n보다 자세한 강의 커리큘럼은 아래의 강의 링크에서 확인하실 수 있습니다.\\n\\n⭐️ 패스트캠퍼스 RAG 비법노트 [20% 할인 이벤트] ⭐️\\n🔆 할인코드: 테디노트\\n- 강의링크: https://bit.ly/3WJQjtf\\n- 분량: 약 70시간\\n- 쿠폰코드 사용방법: 강의 수강신청 → 쿠폰 선택 창에 쿠폰코드 입력 → 쿠폰 등록\\n\\n🔥 링크 모음 🔥\\nhttps://linktr.ee/teddynote\\n\\n📘 랭체인 튜토리얼 무료 전자책(wikidocs)\\nhttps://wikidocs.net/book/14314\\n\\n✅ 랭체인 한국어 튜토리얼 코드저장소(GitHub)\\nhttps://github.com/teddylee777/langchain-kr\\n\\n---\\n📍 \\\"테디노트의 RAG 비법노트\\\" 랭체인 강의: https://fastcampus.co.kr/data_online_teddy\\n📘 랭체인 한국어 튜토리얼(무료 전자책): https://wikidocs.net/book/14314\\n📝 테디노트(깃헙 블로그) : https://teddylee777.github.io\\n💻 GitHub 소스코드 저장소: https://github.com/teddylee777\\n55 comments\\n\", \"score\": 0.6922474, \"raw_content\": \"EP01. #RAG 의 동작 과정 쉽게 이해하기!\\n테디노트 TeddyNote\\n34900 subscribers\\n380 likes\\n15253 views\\n24 Oct 2024\\n*본 영상은 [패스트캠퍼스] 에서 오픈한 \\\"RAG 비법노트\\\" 강의의 일부를 편집한 내용입니다.\\n보다 자세한 강의 커리큘럼은 아래의 강의 링크에서 확인하실 수 있습니다.\\n\\n⭐️ 패스트캠퍼스 RAG 비법노트 [20% 할인 이벤트] ⭐️\\n🔆 할인코드: 테디노트\\n- 강의링크: https://bit.ly/3WJQjtf\\n- 분량: 약 70시간\\n- 쿠폰코드 사용방법: 강의 수강신청 → 쿠폰 선택 창에 쿠폰코드 입력 → 쿠폰 등록\\n\\n🔥 링크 모음 🔥\\nhttps://linktr.ee/teddynote\\n\\n📘 랭체인 튜토리얼 무료 전자책(wikidocs)\\nhttps://wikidocs.net/book/14314\\n\\n✅ 랭체인 한국어 튜토리얼 코드저장소(GitHub)\\nhttps://github.com/teddylee777/langchain-kr\\n\\n---\\n📍 \\\"테디노트의 RAG 비법노트\\\" 랭체인 강의: https://fastcampus.co.kr/data_online_teddy\\n📘 랭체인 한국어 튜토리얼(무료 전자책): https://wikidocs.net/book/14314\\n📝 테디노트(깃헙 블로그) : https://teddylee777.github.io\\n💻 GitHub 소스코드 저장소: https://github.com/teddylee777\\n55 comments\\n\\n예 여러분 안녕하세요 드디어 레그 레그의 비법 노트에 레그 파트까지 오시느라 정말 고생 많으셨습니다 레그의 전반적인 내용을 먼저 한번 들어 보시고요 그리고 잘 이해가 안 되면 또 반복해서 들어 보실 수 있으니까 반복해서 들어 보시고 그리고 더 중요한 거는이 실스 파일들을 여러분들이 반복해서 보시면서 계속 레그에 대한 프로세스 이해가 있어야 그다음에 다시 역으로 돌아가서 우리가 런 것들을 살펴볼 거예요 아프 파스랑 뭐 모델 메모리 체인드 이런 것들 쭉 살펴볼 때 어 역으로 더 이해가 잘 되실 거라는 생각이 들더라고요 그래서 우리가 여기 처음부터 다 하고 가려면은 너무 시간이 오래 걸리니까 이번 시간에는 레그를 좀 깊게 다뤄본 기보다는 일단은 레그가 뭔지 그리고 어떤 식으로 구현하는지 대충 감을 잡는다 그런 생각으로 오시면 됩니다 그래서 저희가 먼저 여기 레그의 베이식요 정도 수준에서 먼저 볼 건데요 먼저 그러려면은 우리가 레그에 대한 이해가 필요할 것 같아요 그래서 제가 좀 그림으로 그려왔어요 제가 그림으로 그리는 걸 되게 좋아하는데이 레그라 걸 도대체 왜 쓰느냐 우리가 그 강의 초반에도 말씀 드렸지만 레그를 쓰는 목적에 대해서 다시 한번만 짓고 넘어가 볼게요 자 우리가 레그를 안 쓰고 채치 PT 같은 걸 통해서 질문을 합니다 우리가 일반적으로 채치 피티에서 쓰는 거는 이런 방식이거든요 여기에 여러분들이 이러한 퀘들은 넣어 줘요 자 넣어주면 이게 프롬프트로 들어가죠 그래서 뭐 당신은 친절한 답변하는 AI 어시스턴트입니다 런 것들이 들어가고요 그다음에 좀 더 확대해서 보여 드리면 자 이렇게 들어가죠 그래서 당신은 친절한 답변을 하는 어시스턴 입니다 그다음에 사용자의 질문이 여기 들어와요 그러면 우리가 스트림 리스로 구현한 것처럼 요거에 대해서 프롬프트 완성을 해서 결국에는이 l&m 아테 전달이 된다는 거예요 LM 우리가 그걸 GPT 쓸 수도 있고 아니면 뭐 클로드는 모델을 쓸 수도 있고 라마 3라는 오픈 모델을 쓸 수도 있고요 어쨌든 이걸 넣어서 우리가 얻는 답변은 뭐냐면 뭐 삼성전자가 자체 개발한 AI 이름은 요거는 제가 피한 물어본 거거든요 답변을 이제 이런 식으로 준다라는 거예요 근데 얘 답변을 보시면은 바로 이제 할루시네이션이 나오는 거를 볼 수가 있어요 그래서 제대로 된 답변이 안 나오는 거예요 그래서 이게 뭐 때로는 빅스비라고 얘기하는 것도 있고 한데 사실 최근에 삼성전자에서 개발한이 AI 이름은 가우스라이플 좀 더 복잡해집니다 자 복잡해지는데 일단이 과정을 생략하고 보자고요이 생략하고 보면 결국에는 프로세스를요 좌측과 우측을 비교해서 한번 보세요 똑같은 질문이 들어왔을 때 얘는 지금 어딘가를 참조하자이 참조하는 부분이 어디예요 정보예요 정보 이게 최신 신문 기사가 될 수도 있고 문서가 될 수도 있고 우리가 저장한 비가 될 수도 있어요 어쨌든 그 정보를 참고해서 넣어 주는 거예요 그러니까 기존의 체치 PT 같은 일반 질문을 했을 때 는 아무런 참고할 만한 정보를 안 줘요 그냥 물어보는 거죠 그러면 GPT 사전 학습된 내용에서 답변을 할 수밖에 없어요 그래서이 사전 학습된 정보가 이미 아웃데이트 됐다 그러니까 오래 되었으면 제대로 된 답변이 이렇게 안 나오는 거예요 어쩔 수가 없는 거죠 그런데 우리가 최신 정보를 어 뭐 검색해서 가져오던 db's 가져오던 문서에서 가져오던 해서 프롬프트 입력에 실제적으로 어떻게 들어가냐는 이제 좌측과 우측을 비교해서 보시면 더 좋은데 좌측이 외그 그래요 그래서 어 프롬프트 자체도 좀 바뀌죠 당신은 주어진 정보를 참고해서 답변하는 AI 있니다 그러니까네 생각대로 말하지 말고 내가 정보를 줄 거야 그 정보를 바탕으로 질문에 답변하세요 이런 식으로 프롬프트가 바뀌게 돼요 그러면 얘가 사전에 알고 있던 정보 기반으로 답변하는게 아니라 내가 쥐어 주는이 참고 정보 우리가 이거를 문맥이 아는 표현을 써요 보통은 영어로 컨텍스트는 표현을 쓰거든요이 컨텍스트를 참고해서 이 안의 내용을 검색해 가지고 답변하게 돼요 그러면 우리가 PDF 문서를 줬을 때요 질문이 들어와서 참고할 만한 정보를 이렇게 넣어 주죠 뭐 예를 들어서 삼성전자 자체 개발 AI 삼성 가우스 공개해서요 관련된 내용들이 쭉 많이 들어갈 거예요 그러면 얘가 지금 답변해야 되는 건 참고 정보를 보고 답변하는 거잖아요 그래서이 컨텍스트에 있는 내용을 보고이 질문에 답변하는 거예요 그러면 삼성전자가 신규 개발한 AI 뭐야라는 질문이 들어왔을 때이 참고 정보 나에게 주어진 정보를 봤더니 아 여기 힌트가 있구나 이걸 보고서 얘는 이렇게 답변을 하는 거죠 요게 이제 실제 답변인데 삼성전자에서 자체 개발한 AI 이름은 삼성 가스입니다 이게 가능한 이유는 한마디로 우리가이 참고할 만한 정보를 여기서 주었기 때문이라고 보시면 돼요 그래서 레그의 큰 그림은 뭐냐면 이제 왼쪽이 레그 오른쪽이 GPT 레그는이 부분이 핵심인 거죠 참고할 정보를 주는 거 이게 바로 핵심이라고 보시면 돼요 자 그런데 여러분 우리 조금만 더 깊게 들어가 보자고요 자 여기 보시면요 이 참고할만한 정보를 그럼 얘가 어떻게 가져올까요 우리가 만약에 어 PDF 문서를 넣어줬다고 가정을 해볼게요이 문서도 우리가 이제 돌려볼 예시 중에 하나인데요 지금 여기에는 없죠 제가 다운로드를 여기서 받아볼 건데 여러분들도 나중에 다운로드 받으셔야 되거든요 자 요거를 우리 데에 있는 체인 KR 레그에 데이터에 넣어줄게요 이렇게 고요 그다음에 여기로 가셔서 PDF 문서를 열면은 이렇게 나옵니다 참고로 여러분들이이 PDF 문서가 여기서 안 열리시는 텐션에 가셔서 여기에 PDF고 검색을 해 보시면요 PDF vs 코드 PDF고 떠요 요거를 인스톨 하시면 이제 PDF 뜰 겁니다 자 그래서 이제 PDF 열어 주시면 되는데요 PDF 인공지능 산업의 최신 동향이라는 페 PDF 이고요 어 요거는 소프트웨어 정책 연구소에서 공개한 PDF 자료예요 그래서 저희가 요걸 가지고 레그를 해 볼 건데 이 페이지가 23 페이지짜리 말이에요이 안에 이제 다양한 정보들이 들어가 있어요 자 그런데 한번 생각해 보십시오 여러분들이 이제 GPT이 모든 정보를 다 때려놓고이 안에서 GPT 보로 참고해서 답변해 달라라고 하시는 거라고 생각을 하시는데요 근데 사실 그러면 무슨 문제가 발생할까요 여기에 있는이 글자수가 이렇게나 많은 우리가 질문을 할 때마다 23 페이지나 되는 내용들이 프롬프트 입력으로 들어가게 되는 거예요 그러면 어떻다 우리 력은 전부 다 비용이랑 관련이 있잖아요 그래서 굉장히 많은 비용이 잡히게 되는 거예요음 그러다 보면은 질문 한 개당 비용이 굉장히 비싸기도 하고 또 두 번째 문제는 뭐냐면 GPT 이렇게나 많은 정보를 주여 주면 내가 어디서이 정보를 찾아야 될지를 몰라요 그걸 로스트인더 미이라고온님 라고 보시면 되겠죠 그니까 가령 우리가 삼성전자가 신규 개발한 AI 뭐야라고 질문을 했을 때 이렇게 넘겨 보면 요런 페이지가 나오잖아요 13페이지 13 페이지만 쥐어주면 어떨까요 요거 한 페이지만 쥐어주면 우리는 대번에 요거를 찾을 수가 있다라는 거예요 자 그러면 우리가이 참고할 정보를 책한권을 다 때려 놓는게 아니죠이 질문에 답변하기 위한 정보만 골라 빼내서 넣어 주는게 가장 효율적이다 거예요 그 과정이 바로 왼쪽에 있는요 과정이에요이 검색기를 비롯해서이 과정들이 있죠 그래서 여기서 살펴보면요 이렇게 되는 거예요 자 보세요 우리가 만약에 방금 제가 보여 드린이 PDF 23장 짜리를 어 참고하도록 넣어 주고 싶으면 어떤 식으로 구현을 하셔야 되냐면 먼저 PDF 그요 일단은 불러 와야겠죠 PDF 될 수도 있고 워드가 될 수도 있고 엑셀이 될 수도 있고 뭐 논문이 될 수도 있고 어떤 형태든 상관없어요 랭 체인에서는 다 지원을 해 주거든요 자 그러면 이거를 일단 문서를 로드를 해요 여기서로드 한다는 거는 우리가 그 안에 있는 텍스트만 긁어 오겠다는 거예요 그럼 여기서 많이 나오는 질문 중에 하나가 뭐냐면 어이 PDF 안에 표도 있고 이미지도 있는데 이거는 활용 못 하나요 이것도 사실은 활용을 하시는 방법이 있어요 근데 저희가 일단은 베이직한 단계에서는 텍스트만 긁고 온다라고 우선은 생각을 할게요 그래서 성능 좋은 PDF 그 로더를 사용해서 가져오면 뭐 단이 분리되 이런 것들도 잘 처리 하거든요 그래서 어쨌든 그 PDF 안에 작성되어 있는 줄들을 다 긁어 오는 거죠 긁어와서 그다음 단계가 뭐냐면요 텍스트 스플릿이 자 그러면 우리가 텍스트 스플릿은 왜 하는지 한번 볼게요 자 여러분 다시 PDF Pro가 보자고요 자 이거를 끄고 한번 보면은 우리가 삼성에서 자체 개발한 생성형 AI 뭔가요라는 질문을 주잖아요이 질문에 답변하기 위해서 과연이 모든 내용이 다 필요할까요 여기 있는 내용들은 사실 필요 없을 수 있어요 그래서 우리가 가장 효율적인 부분은 뭐냐면요 우리가 어떤 특정 단락요 작은 단위만 가져오는게 좋겠죠 요것만 가져와도 얘는 답변을 할 수 있으니깐요 그러니까 쉽게 얘기해서 다시 말해서이 페이지가 전체가 다 필요하지는 않다라는 얘기예요 그래서 우리는 어떤 특정 단락만 필요한데이 특정 단락을 우리가 보통 무슨 기준으로 분할을 하냐면 청크 청크 얘기를 하는데요 청크 사이즈를 줘요 청크 사이즈는 이제 토큰 수 기반으로 잘라지고 돼요 예를 들어서 이게 뭐 1,000개의 토큰이다 이러면 1,000개의 토큰이 이렇게 잘라내 주는 거예요 얘도 자르고 여기도 보시면 얘를 요렇게 1,000개 토큰이 자르고 그리고 이게 1,000 개라면 그다음 1,000개를 또 자라요 이렇게 그다음 천개를 또 자르고 이렇게 잘라 놔요 그러니까 페이지는 23페이지이지만 한 페이지에 보통 천 토크씩 세 개가 들어간다고 해 볼게요 사실 천 토크는 굉장히 커서 넘어갈 거예요 근데 어쨌든 대 대충 요게 1000 토큰이 보면은 한 페이지에 3,000 토큰이 가정해 볼게요 그러면이 단락이 세 개 나오겠죠 그러면 총 23 페이지에 곱하기 세 개에서 총 단락이 몇 개 나와요 66개 요렇게 66개의 단락으로 분할해서 저장을 하는 거예요 그러면 나중에 우리가 어떤 유사도 검색이란 걸 할 거거든요이 질문이 들어오게 되면은이 지문 그니까 삼성전자가 자체 개발한 생성용 AI 뭐야라는 질문이 들어오게 되면요 아까 만든 66개의 단락이 있잖아 요 그 단락에 대해서 유사도 계산을 다 해요요 질문과요 단락의 유사도요 질문과요 단락의 유사도요 질문과 또 다른 단락의 유사도를 다 계산해요 그래서 관련성 있는 단락을 뽑아내는 작업을 합니다 그러면 어떻게 되냐면요 지금 얘가 단락 구분 해 놓고 얘가 단락 구분 해 놓고 저기 아래 있는요 단락요 단락 만약에 요렇게 만들었어요 근데 여기에는 삼성전자가 자체 개발한 AI 키워드가 전혀 없죠 그럼 얘는 유사도 몇 유사도가 낮게 잡혀요 유사하지 않다라는 거죠 예를 들면은 0.1 요렇게 낮게 잡히는 거예요 0에서 1 사이에 범위에 있다라고 봤을 때 그런데 첫 번째 달락 같은 경우에는 얘가 쪼개 놓은 거는 삼성전자가 자체 개발한 AI 아는 키워드도 들어가 있고요 쿼리문을 답변하기에 굉장히 좋은 단락이 이런 것들은 유사도가 높게 잡힌다고 얘는 0.9가 잡히는 거예요 그럼 얘가 나중에 검색을 할 때 최상이 유사도 뭐 세 개 다섯 개 일곱 개 이렇게 뽑아 내거든요 단락을 뽑 에서 그 단락을 모아 모아서 전달을 해 주는 거예요 다시 돌아가면 얘가요 참고 정보가 한 개의 단락이란 뜻은 아니에요 얘가 세 개가 될 수도 있고 다섯 개가 될 수도 있고 더 많을 수도 있어요 그건 여러분들이 지정하시는 건데 여기서 중요한 거는 사실 가장 베스트는이 질문에 답변하기 위한 단락이 포함되어 있으면 좋다는 거죠 그니까 숫자가 작으면 작을수록 좋은데 너무 숫자가 작아 버리면 어때요 우리가 정보들이 여기에 조금 있고 여기에 조금 있고 여기에 조금 있어요 그러면 여러 단락에서 결국엔 가져가야 되거든요 이럴 때는 단락의 개수가 너무 적어 버리면은 답변을 위한 충분한 정보 수집이 안 되게 되겠죠 그래서 여러분들이이 단락을 몇 개 우리가 K 아는 표현을 쓰는데 K 개를 잘 먼저 지정해 주시는게 중요해요 그래서 그거는 나중에 저희가 한번 고민을 해 볼 건데요 일단은 저희가 단락을 가져온다 근데 아까도 말씀드렸다시피 제가 계속 유사도는 말을 쓰잖아요 유사도는 개념은 뭐냐면 우리가 지금 이런 질문이 들어왔어요 자가 신규 개발한 AI 뭐야라고 걸 계산을 한다라고 말씀드렸는데 계산은 어떻게 할까요 계산은 수학적인 걸로 계산을 하거든요 근데 얘 같은 경우에는 문자아이 연산을 할 수가 없죠 그래서이 단락을 수학적인 표현으로 바꾸는 거예요 좌표계 쉽게 얘기해서 좌표계로 바꾼다고 생각하시면 좋아요 그다음 에 나오는게 바로 여기에 보시면 이제 임베딩이란 걸 표현을 씁니다 우리 다시 돌아가서 보면은 문서를 로드를 하고이 단락을 쪼개 놓는다고 했죠 그래서 잘게 쪼개 놓는 거예요 이거를 텍스트 스플릿이 표현을 쓰고요 그다음에 유사도는 걸 계산하기 위해서 각각의요 하나하나의 단락을 요러한 수학적인 표현으로 바꾸는 거예요 요거를 우리가 임베딩 한다라는 표현을 씁니다 근데 다들 여기까지는 쉽게 이해를 하세요 아 문서는 당연히 로드를 해야지 그다음에 쪼개는 거 오케이 알았어 좀 더 효율적이게 가져오기 위해서 쪼개는 거구나 또는이 GPT 뭐 뭐 페이지 단위로 들어가게 되면 쓸데 없는 정보가 많이 들어가니까 쪼개는구나 이런 것까지는 잘 이해를 하시는 편인데이 베딩에 대해서는 되게 어려워 하세요 왜냐면 이게 약간 처음 보는 개념이 그래서 임베딩의 필요성에 대해서는 잠깐 짓고 넘어가야 될 것 같아요 어 임베딩이란 거는 우리가 의미 이해를 하거나 정보 검색을 향상하고 이러한 목적으로 써요 그래서 밑에 예시를 제가 적어 놨는데요 자 보세요 어 지금 우리가 매운 맛이라는 좌표가 여기예요 수학적으로 따져 볼까요 0.1이라도 한번 해 볼게요 그다음에 새콤한 맛이라는 애는요 0.7의 수학으로 변환돼 있어요 그니까 이거는 우리가 한마디로 그냥 매핑 테이블이라고 보시면 되는데 매운 맛이 숫자로 뭐야라고 물어보면 우리가 0.1의 맵핑이 되 거죠 이거 자체가 지금 임베딩이 되어 있는 거예요 임베딩은이 문자 혹은 문자열 문장들을 수학적인 표현으로 바꾸 거 얘가 0.1로 바뀌어져 있고 세콤한 맛을 임베딩을 했더니 0.7로 바뀌어져 있고요 단맛을 임베딩을 했더니 0. 뭐 9로 임베딩이 되어 있어 가령 근데 만약에 사용자가 쿼리를 날렸을 때요 매콤 새콤한 맛이라는 퀄리 던집니다 그러면 우리가 현재 가지고 있는이 정보에는 없죠 하지만 우리가 얘의 임베딩 값을 유치해 볼 수가 있어요 어떻게요 얘는 매운 맛과 세콤한 맛 어떤 중간 지점쯤 되겠구나 그러면은음 봤을 때 대충 0.4 정도 될까 요렇게 유치해 볼 수 있는 거죠 그리고이 새콤 달달한 맛이라고 했으면은요 중간 어디쯤입니까 뭐 0.8 정도 되겠구나 이렇게 어 유치해 볼 수가 있는 거예요 그런데 이렇게 수치 표현으로 변경을 하면요 보세요 우리가 질문이이 단락에서 계산을 하는데 질문과 단락이 정확히 일치할 수가 있어요 없잖아요 다시 돌아가면 이 PDF 문서에 보시면요 우리 질문이 과연이 단락이란 정확히 똑같이 쓸까요 그렇지 않는다라는 거죠 그러면이 단락이 예를 들어서 임베딩이 되어 있다라고 했잖아요 자 얘가 만약에 아까 표현으로 0.6으로 임베딩이 되어 있어요 숫자 표현으로 0.6이고 우리 쿼리 질문을 했어요 질문도 임베딩이 들어가야 되거든요 얘도 문자가 뭐 어쩌고저쩌고 질문을 했어요 근데 얘를 수학적 표현으로 바꾸니까 뭐가 됐어요 0.7이 그래요 자 그러면 우리 질문은 수학적 표현으로 0.7이요 단락은 0.6이고요 단락은 예를 들어서 뭐 1.9에 그러면 얘와 얘의 거리가 가까워요 얘 얘와 얘의 거리가 거예요 얘까지 거리가 가깝잖아요 그러면은 얘가 제일 유사하다고 판단이 돼서요 단락이 비로소 선택이 되는 거예요 그러면 여기서 임베딩의 역할은 뭐예요이 단락을 수학적 표현으로 바꾸는 거 근데 아까 제가 단일 수학적 표현으로 바꿨지만 단일 숫자 값으로이 풍부한 표현을 다 표현할 수가 있을까요 표현할 수 없죠 그래서 우리는 벡 벡터 표현으로 바꾸는데 벡터는 뭐냐면 숫자들의 집합이라고 보시면 돼요 그러니까 단일 숫자값 하나로 바꾸는게 아니라 0.1 0.35 뭐 0.78 이런 식으로 쭉 수학의 좌표계를 늘려서 좀 더 정교하게 표현을 해 주는 거예요 그래서 우리가 오픈 AI 사의 임베딩을 쓸 건데 1536 차원을 써요 근데 이거는 의미가 뭐냐면 여기에 들어가는 숫자의 개수가 1536 개라는 거거든요 그러면이 단락 하나하나가 변경이 됐을 때요 1536 의 숫자로 표현이 된다 이렇게 보시면 돼요 자 그러면 결국에는이 숫자로 변환하는 작업이 뭐가 된다고요 바로 임베딩이 되는 거죠 우리가 이거는 단일 단어가 들어왔지만 우리가 어떤 단락이 들어올 수도 있고요 그다음에 때로 문장이 들어올 수도 있죠 어쨌든 그 모든 문자들이 들어왔을 때 뭐 한 단어가 되든 여러 단어가 되든 상관이 없어요 그 모든 것들을 어떤 숫자 표현으로 숫자 벡터로 바꿔 준다 이게 숫자 값들이 몇 개다 136개 전부 다 136개 다 변환을 하는 거예요 그러면 개수가 똑같잖아요 이제 유사도 계산을 할 수가 있는 거예요 자 그래서이 단락 활용 예시를 보죠 우리가 요렇게 들어왔을 때요 먼저 이전에 우리 텍스트 스플리터로 보고 올까요 텍스트 스플리터로 제가 자료를 열심히 만들어 놨는데 여러분들께 이거 다 드리니까 한번 다시 꺼내 보세요요 스플릿 하는 단계에서는 요렇게 어떤 특정 키워드들이 이제 여러 군데 포진해 있는데요 분할의 필요성은 우리 정확한 정보를 효율적으로 갖기 위해서다 우리가 여기에서 필요한 한 정보가 만약에요 정보인데 다른 정보들은 다 필요하진 않잖아요 어떤 특정 부분만 필요하니까 그걸 내가 딱 특정 부분만 끊어서 보관하기 어려우니까 어떤 큰 단위를 가지고 이렇게 분할해서 가지고 있는 거예요 그리고 아까 제가 문서 분할할 때도 우리가 청크 사이즈라는 걸 둬 가지고 분할을 하게 되는데 청크 사이즈를 가지고 이렇게 일정한 네모 박스 크기별로 변환을 하잖아요 그런데 여기에서 지금 보면은 중간 부분에 겹쳐져 있죠 이거 왜 겹쳐져 있어요 왜냐면 내가 이렇게 잘랐어요 근데 여기 첫 번째 자른데 보면은 를에서 지금 잘렸아요 잘렸고 그다음에 시작하는게 여기서부터 시작을 하시게 되면요 포함하는부터 다시이어서 시작을 하잖아요 근데 얘는 문장이 시작이 아니고 중간에 잘려진 거예요 그래서 우리는 항상 청크 오버랩이란 걸 둬요 요게 조금은 겹쳐서 가져오겠다는 거예요 중간에 끊어지는 부분 없이 그래서 청크를 자를 때요 요거 한 청크 그다음에 두 번째 청크는요 청크 세 번째 청크는요 청크 이렇게 분할해서 가져온다 는 거죠 이렇게 분할해서 가져와서 중간에 잘리는 텍스트 없이 가져오겠다는 거예요 그래서 이런 식으로 자른 다음에이 자른 단락을 뭘 한다 바로 임베딩이란 걸 한다 자 이렇게 임베딩 하는 거죠 그러면 여기에는 물론 오버랩 적용이 안 돼 있지만 이렇게 그냥 적용이 됐다라고 가성을 해 볼게요 그런데이 첫 번째 단락이 있고 두 번째 단락이 있고 세 번째 단락이 있어요 잘라 놓은 상태인데 얘 1번 단락을 이런 식으로 숫자 표현으로 바꿔 주는 거예요 자 1번 단락은 요렇게 바꿔 2번 단락은 요렇게 바꿔 3번 단락은 요렇게 바꾸죠 그러면 임베딩이는 과정은 더도 말고 덜도 말고 이런 단락이나 문장들을 요렇게 숫자 표현으로 바꾸는 과정까지가 임베딩이 그 이상도 아니에요 요거 숫자 표현으로 바꾸는 거예요 자 근데이 임베딩은 어떤 알고리즘을 쓰냐에 따라서이 숫자 표현의 개수가 달라지죠 개수가 우리 오픈의 임베딩을 쓰면은요 숫자의 개수가 몇 개 136개 있데요 어떤 알고리즘 쓰면은 뭐 200개가 될 수도 있고 어떤 알구 쓰면은 뭐 3,000개가 될 수도 있어요 근데 일반적으로 표현이 풍부하면 풍부할수록 정교하다고 얘기는 하지만 그마만큼 리소스는 더 많이 쓰는 거예요 그래서 그런 차이점이 있고요 어쨌든 다시 돌아와서 자 보세요 우리가 첫 번째 단락을 임베딩을 해서 이렇게 저장을 해요 두 번째 단락은 이렇게 저장을 하고 세 번째 단락은 이렇게 변환을 했어요 그런데 새로운 질문이 이렇게 돌아왔어요 시장 조사 기관 IDC 예측한 AI 소프트웨어 시장의 연평균 성장률 어떻게 되나 얘도 마찬가지로 벡터 표현으로 바꾼 거예요 자 여기 몇 개 136개 얘도 136개 136개 그럼 숫자 간의 거리를 쫙 다 계산할 수가 있어요 뭐 코사인 유사로 하든 유클리디언 디스턴스 하든 여러 가지 아무튼 알고리즘을 써서 거리 계산하 거예요 어디가 제일 가깝나 그러면 얘대 얘 얘대 예 얘대 얘 다 계산해요 그랬더니 첫 번째 유사도 거리가 그니까 유사도가 높다라는 건 뭐예요 거리가 가깝다라는 뜻이에요 그러면 1번 단락이 거리가 가깝네요 그럼 얘가 선택을 받는 거죠 나머지는 어때요 거리가 뭐니까 선택을 안 받는 거예요 그러면 우리가 이런 질문이 들어왔을 때요 결국에는이 수많은 문서 중에서이 질문에 답변하기 위한요 단락만 이제 선택 받았으니까 요거를 문맥의 입력으로 넣어 주는 거죠 그래서 문맥의 입력이란 어디냐면 여기 보시면요 부분 있잖아요요 부분에 방금 선택된 단락을 넣어 주는 거예요 근데 하나만 넣어 주는게 아니라 요거에 개수는 우리가 정할 수가 있다는 거죠 자 그러면 계속이어서가 볼게요 베딩까지 이해가 되셨으면 그다음 단계가 뭐냐면 임베딩 다음에는요 요거를 저장을 해둬야 돼요 자 한번 생각해 보세요 임베딩 하는데도 사실 여러분들 돈이 들어요 요것도 오픈 AI LM 쓰듯이 오픈 AI LM 쓰듯이 오픈 AI 임베딩을 쓸 때도 여러분들이 변환하는 개수만큼 돈을 내셔야 돼요 물론 임베딩은 답변을 받는 거만큼 비싸진 않아요 상대적으로 부담은 덜하지만 그래도 우리가 다량의 문서를 임베딩 할 때는 그마만큼 돈이 많이 들 수도 있어요 근데이 임베딩을 우리가 한번 프로그램이 실행했을 때마다 매번 임베딩을 해야 되면 어때요 돈이 계속 발생하는 거예요 같은 문서인데 명이 조회를 했어 그러면 열배의 요금이 나오게 되는 거죠 그래서 우리는 보통 어떻게 하냐면이 문서를 로드를 하고 이거를 어떤 특정 기준으로 청크 기준으로 쪼개고이 쪼개진 문서들을 숫자 표현으로 변환을 하고이 숫자 표현된 거를 저장을 해 두는 거죠 스토어 한다 저장한다 한다 얘를 뭐라고 하냐면 우리 얘가 임베딩 벡터라는 표현을 썼잖아요 벡터 벡터는 숫자들의 집합 요거 숫자들의 집합 그래서 벡터들을 저장하는 공간이다 해서 우리는 뭐 어떤 표현을 쓰냐면 벡터 스토어라는 표현을 쓰는 거예요 벡터를 저장하는 공간 그러면 이렇게 임베딩된 애들을 디스크 공간에다가 저장을 해 두는 거예요 왜 임베딩 할 때마다 돈이 든다면서 문단들을 요걸로 바꾸는데 돈이 드니까요 변환된 값을 저장해 놨다가 나중에 어떻게 해요 한번 저장을 해 놨으면 이제이 DB 다가 우리가 어 쿼리 요청을 하게 되면은이 단락은 얘가 즉각즉각 가져와요 그러니까요 단계는 언제만나 돼요 처음 한 번만 해 주면 되는 거죠 한 번만 해서이 데이터베이스 스토어 공간 안에다가 저장을 해두면 나중에 여기에다가 검색어를 날려서 관련성 있는 문서들을 가져올 수가 있게 되는 거예요 여기까지가 뭐냐면 우리 전처리 단계예요 우리 다시 한번 돌아가 볼게요 여기 리벌 어그멘티드 제너레이션의 여기에 보시면요 지금 레그 8단계 프로세스의 사전 준비 단계 있죠 우리가 PDF 문서 하나에 대해서 요렇게 처리하는 거 문서를 분할하고 분할된 각각의 문단들을 임베딩 벡터로 변환을 하고 변환은 왜 한다 요거는 나중에 유사도 계산을 위해서 하는 거예요 그래서 얘를 저장하는 단계까지가 우리가 사전 단계 즉 l&m 채팅에 채팅에 입력하기 전에 일어나는 단계라고 보시면 돼요 자 그래서 이번 영상은요요 사전 단계까지 살펴봤고요 다음 영상에이어서요 후반부에 대해서 한번 다뤄보도록 하겠습니다 y\"}, {\"title\": \"[벨루가 X 테디노트] 벨루가 멀티 RAG 아키텍처: LangGraph 활용 파이프라인 - YouTube\", \"url\": \"https://www.youtube.com/watch?v=eKsrya-v-04\", \"content\": \"벨루가 서비스를 만들고 계신 이상연 대표님과 박진훈 개발 리드님을 모시고 rag 아키텍쳐에 대해 공유해 주시기로 하였습니다.벨루가는 어떻게 rag\", \"score\": 0.40288594, \"raw_content\": null}]\"\n",
      "    \u001B[93madditional_kwargs\u001B[0m: {}\n",
      "    \u001B[93mresponse_metadata\u001B[0m: {}\n",
      "    \u001B[93mtype\u001B[0m: \"tool\"\n",
      "    \u001B[93mname\u001B[0m: \"tavily_web_search\"\n",
      "    \u001B[93mid\u001B[0m: \"b14f8a9c-2b6b-401c-838f-943aea5b1535\"\n",
      "    \u001B[93mtool_call_id\u001B[0m: \"call_594kyYHfqOukQuHniHCoQW02\"\n",
      "    \u001B[93martifact\u001B[0m: None\n",
      "    \u001B[93mstatus\u001B[0m: \"success\"\n",
      "\n",
      "==============\n",
      "STEP: chatbot\n",
      "==============\n",
      "\n",
      "    \u001B[93mcontent\u001B[0m: \"\"테디노트\"라는 유튜브 채널에서는 데이터 분석, 머신러닝, 딥러닝 등 다양한 주제에 대한 내용을 다루고 있습니다. 채널의 정보는 다음과 같습니다:\n",
      "\n",
      "- **채널 이름**: [테디노트 TeddyNote](https://www.youtube.com/channel/UCt2wAAXgm87ACiQnDHQEW6Q)\n",
      "- **구독자 수**: 35K\n",
      "- **동영상 수**: 234\n",
      "\n",
      "주요 동영상 내용 중 일부는 다음과 같습니다:\n",
      "1. [EP01. #RAG 의 동작 과정 쉽게 이해하기!](https://www.youtube.com/watch?v=zybyszetEcE)\n",
      "2. [벨루가 X 테디노트 - 멀티 RAG 아키텍처: LangGraph 활용 파이프라인](https://www.youtube.com/watch?v=eKsrya-v-04)\n",
      "\n",
      "이 채널에서는 머신러닝, 딥러닝 관련 강의와 튜토리얼, 연구 및 개발과 관련된 여러 주제를 다루고 있으며, 관련된 프로젝트와 자료들도 제공하고 있습니다.\"\n",
      "    \u001B[93madditional_kwargs\u001B[0m: {\"refusal\": None}\n",
      "    \u001B[93mresponse_metadata\u001B[0m:\n",
      "        \u001B[94mtoken_usage\u001B[0m:\n",
      "            \u001B[95mcompletion_tokens\u001B[0m: 244\n",
      "            \u001B[95mprompt_tokens\u001B[0m: 12343\n",
      "            \u001B[95mtotal_tokens\u001B[0m: 12587\n",
      "            \u001B[95mcompletion_tokens_details\u001B[0m: {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}\n",
      "            \u001B[95mprompt_tokens_details\u001B[0m: {\"audio_tokens\": 0, \"cached_tokens\": 0}\n",
      "        \u001B[94mmodel_name\u001B[0m: \"gpt-4o-mini-2024-07-18\"\n",
      "        \u001B[94msystem_fingerprint\u001B[0m: \"fp_dbaca60df0\"\n",
      "        \u001B[94mid\u001B[0m: \"chatcmpl-BPNNfsv2tgp5gkeaGeTiaYFCenAtE\"\n",
      "        \u001B[94mfinish_reason\u001B[0m: \"stop\"\n",
      "        \u001B[94mlogprobs\u001B[0m: None\n",
      "    \u001B[93mtype\u001B[0m: \"ai\"\n",
      "    \u001B[93mname\u001B[0m: None\n",
      "    \u001B[93mid\u001B[0m: \"run-232cfa3f-251a-4717-9930-448c51e730b6-0\"\n",
      "    \u001B[93mexample\u001B[0m: False\n",
      "    \u001B[93mtool_calls\u001B[0m:\n",
      "    \u001B[93minvalid_tool_calls\u001B[0m:\n",
      "    \u001B[93musage_metadata\u001B[0m:\n",
      "        \u001B[94minput_tokens\u001B[0m: 12343\n",
      "        \u001B[94moutput_tokens\u001B[0m: 244\n",
      "        \u001B[94mtotal_tokens\u001B[0m: 12587\n",
      "        \u001B[94minput_token_details\u001B[0m: {\"audio\": 0, \"cache_read\": 0}\n",
      "        \u001B[94moutput_token_details\u001B[0m: {\"audio\": 0, \"reasoning\": 0}\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
