{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-23T07:36:52.883902Z",
     "start_time": "2025-04-23T07:36:52.853965Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH17-LangGraph-Modules\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH17-LangGraph-Modules\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T07:44:51.157140Z",
     "start_time": "2025-04-23T07:44:46.208663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "# 1. 상태 정의\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# 2. 도구 정의 및 바인딩\n",
    "tool = TavilySearch(max_results=3)\n",
    "\n",
    "tools = [tool]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# 3. 노드 추가\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# 상태 그래프 생성\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 챗봇 노드 추가\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# 도구 노드 생성 및 추가\n",
    "tool_node = ToolNode(tools=tools)\n",
    "\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# 조건부 엣지\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "# 4. 엣지 추가\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# 5. 그래프 컴파일\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ],
   "id": "91dba81de18a5d67",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T07:45:51.382575Z",
     "start_time": "2025-04-23T07:45:51.378866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "question = \"LangGraph가 무엇인지 조사하여 알려주세요.\"\n",
    "\n",
    "input = State(messages=[(\"user\", question)])\n",
    "\n",
    "config = RunnableConfig(\n",
    "    configurable={\"thread_id\": \"1\"}\n",
    ")"
   ],
   "id": "32a50796651fb07",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T07:45:58.595777Z",
     "start_time": "2025-04-23T07:45:58.586752Z"
    }
   },
   "cell_type": "code",
   "source": "list(graph.channels)",
   "id": "8ca07a833d57fe4c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['messages',\n",
       " '__start__',\n",
       " 'chatbot',\n",
       " 'branch:to:chatbot',\n",
       " 'tools',\n",
       " 'branch:to:tools',\n",
       " 'start:chatbot']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T07:47:30.565705Z",
     "start_time": "2025-04-23T07:47:29.176023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 그래프 스트림 호출\n",
    "events = graph.stream(\n",
    "    input=input,\n",
    "    config=config,\n",
    "    interrupt_before=[\"tools\"],\n",
    "    stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "# 이벤트 반복 처리\n",
    "for event in events:\n",
    "    # 메시지가 이벤트에 포함된 경우\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ],
   "id": "9ea1ce44299b0e76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "LangGraph가 무엇인지 조사하여 알려주세요.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_vcpChqgKIV79kmIHhYcsdPlH)\n",
      " Call ID: call_vcpChqgKIV79kmIHhYcsdPlH\n",
      "  Args:\n",
      "    query: LangGraph\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T07:48:00.757703Z",
     "start_time": "2025-04-23T07:48:00.752196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 그래프 상태 스냅샷 생성\n",
    "snapshot = graph.get_state(config)\n",
    "\n",
    "# 가장 최근 메시지 추출\n",
    "last_message = snapshot.values[\"messages\"][-1]\n",
    "\n",
    "# 메시지 출력\n",
    "last_message.pretty_print()"
   ],
   "id": "b66d6a004f8c02dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_vcpChqgKIV79kmIHhYcsdPlH)\n",
      " Call ID: call_vcpChqgKIV79kmIHhYcsdPlH\n",
      "  Args:\n",
      "    query: LangGraph\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 사람의 개입 (Human-in-the-loop)",
   "id": "bb2fc284051bc9ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T07:48:50.283377Z",
     "start_time": "2025-04-23T07:48:50.279256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "modified_search_result = \"\"\"[수정된 웹 검색 결과]\n",
    "LangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\n",
    "LangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\n",
    "\n",
    "자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\n",
    "테디노트의 [랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.\"\"\"\n",
    "\n",
    "print(modified_search_result)"
   ],
   "id": "def1aebfd1094de6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[수정된 웹 검색 결과]\n",
      "LangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\n",
      "LangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\n",
      "\n",
      "자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\n",
      "테디노트의 [랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T07:49:52.015546Z",
     "start_time": "2025-04-23T07:49:52.010070Z"
    }
   },
   "cell_type": "code",
   "source": "last_message",
   "id": "c8b3b5a3227080e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_vcpChqgKIV79kmIHhYcsdPlH', 'function': {'arguments': '{\"query\":\"LangGraph\"}', 'name': 'tavily_web_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 101, 'total_tokens': 120, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BPP7JBOMKYnXWEKmes4HI2w4pYB9M', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-af11414d-08c5-482f-8d61-5b22e861c268-0', tool_calls=[{'name': 'tavily_web_search', 'args': {'query': 'LangGraph'}, 'id': 'call_vcpChqgKIV79kmIHhYcsdPlH', 'type': 'tool_call'}], usage_metadata={'input_tokens': 101, 'output_tokens': 19, 'total_tokens': 120, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T07:50:16.775326Z",
     "start_time": "2025-04-23T07:50:16.770106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 수정하고자 하는 'ToolMessage'의 'tool_call_id' 추출\n",
    "tool_call_id = last_message.tool_calls[0][\"id\"]\n",
    "print(tool_call_id)"
   ],
   "id": "a6d8771df54c5657",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call_vcpChqgKIV79kmIHhYcsdPlH\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T07:51:13.478098Z",
     "start_time": "2025-04-23T07:51:13.473418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "new_messages = [\n",
    "    # LLM API의 도구 호출과 일치하는 ToolMessage 필요\n",
    "    ToolMessage(\n",
    "        content=modified_search_result,\n",
    "        tool_call_id=tool_call_id,\n",
    "    )\n",
    "]\n",
    "\n",
    "new_messages[-1].pretty_print()"
   ],
   "id": "bafce293437eef76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "\n",
      "[수정된 웹 검색 결과]\n",
      "LangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\n",
      "LangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\n",
      "\n",
      "자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\n",
      "테디노트의 [랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T07:56:59.334237Z",
     "start_time": "2025-04-23T07:56:59.311823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "graph.update_state(\n",
    "    # 업데이트할 상태 지정\n",
    "    config,\n",
    "    # 제공할 업데이트된 값. `State`의 메시지는 \"추가 전용\"으로 기존 상태에 추가됨\n",
    "    {\"messages\": new_messages},\n",
    "    as_node=\"tools\",\n",
    ")\n",
    "\n",
    "print(\"(최근 1개의 메시지 출력)\\n\")\n",
    "print(graph.get_state(config).values[\"messages\"][-1])"
   ],
   "id": "4828b2f7faf194cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(최근 1개의 메시지 출력)\n",
      "\n",
      "content='[수정된 웹 검색 결과]\\nLangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\\nLangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\\n\\n자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\\n테디노트의 [랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.' id='032cb8fb-c95b-43d7-845e-53aceb5985a8' tool_call_id='call_vcpChqgKIV79kmIHhYcsdPlH'\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T07:57:36.517698Z",
     "start_time": "2025-04-23T07:57:36.510887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot.next"
   ],
   "id": "891941e1262dae18",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('chatbot',)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T07:57:49.029477Z",
     "start_time": "2025-04-23T07:57:45.732911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# `None`는 현재 상태에 아무것도 추가하지 않음\n",
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "\n",
    "# 이벤트 반복 처리\n",
    "for event in events:\n",
    "    # 메시지가 이벤트에 포함된 경우\n",
    "    if \"messages\" in event:\n",
    "        # 마지막 메시지의 예쁜 출력\n",
    "        event[\"messages\"][-1].pretty_print()"
   ],
   "id": "c7c5bc9231a53681",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "\n",
      "[수정된 웹 검색 결과]\n",
      "LangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\n",
      "LangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\n",
      "\n",
      "자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\n",
      "테디노트의 [랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "LangGraph는 상태 기반의 다중 액터 애플리케이션을 대형 언어 모델(LLM)을 활용하여 구축할 수 있도록 지원하는 오픈 소스 라이브러리입니다. 이 라이브러리는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능 등을 제공하여 개발자들이 더욱 효율적으로 애플리케이션을 설계하고 배포할 수 있게 해줍니다.\n",
      "\n",
      "자세한 튜토리얼은 다음 링크에서 확인할 수 있습니다:\n",
      "- [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/)\n",
      "- [랭체인 한국어 튜토리얼](https://wikidocs.net/233785)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T07:58:16.534514Z",
     "start_time": "2025-04-23T07:58:16.529615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 그래프 상태 스냅샷 생성\n",
    "snapshot = graph.get_state(config)\n",
    "\n",
    "# 최근 세 개의 메시지 출력\n",
    "for message in snapshot.values[\"messages\"]:\n",
    "    message.pretty_print()"
   ],
   "id": "1555d05d4a0c7059",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "LangGraph가 무엇인지 조사하여 알려주세요.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_vcpChqgKIV79kmIHhYcsdPlH)\n",
      " Call ID: call_vcpChqgKIV79kmIHhYcsdPlH\n",
      "  Args:\n",
      "    query: LangGraph\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "\n",
      "[수정된 웹 검색 결과]\n",
      "LangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\n",
      "LangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\n",
      "\n",
      "자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\n",
      "테디노트의 [랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "LangGraph는 상태 기반의 다중 액터 애플리케이션을 대형 언어 모델(LLM)을 활용하여 구축할 수 있도록 지원하는 오픈 소스 라이브러리입니다. 이 라이브러리는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능 등을 제공하여 개발자들이 더욱 효율적으로 애플리케이션을 설계하고 배포할 수 있게 해줍니다.\n",
      "\n",
      "자세한 튜토리얼은 다음 링크에서 확인할 수 있습니다:\n",
      "- [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/)\n",
      "- [랭체인 한국어 튜토리얼](https://wikidocs.net/233785)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T07:58:33.676250Z",
     "start_time": "2025-04-23T07:58:33.672287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 다음 상태 출력\n",
    "print(snapshot.next)"
   ],
   "id": "5f3f0ac29a2a5a21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Interrupt 후 메시지 상태 업데이트 - 이어서 진행",
   "id": "164b8ad2d444f103"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T07:59:21.092831Z",
     "start_time": "2025-04-23T07:59:20.219763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_teddynote.graphs import generate_random_hash\n",
    "\n",
    "thread_id = generate_random_hash()\n",
    "print(f\"thread_id: {thread_id}\")\n",
    "\n",
    "question = \"LangGraph 에 대해서 배워보고 싶습니다. 유용한 자료를 추천해 주세요!\"\n",
    "\n",
    "# 초기 입력 상태를 정의\n",
    "input = State(messages=[(\"user\", question)])\n",
    "\n",
    "# 새로운 config 생성\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "events = graph.stream(\n",
    "    input=input,\n",
    "    config=config,\n",
    "    interrupt_before=[\"tools\"],\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ],
   "id": "22b593ece3518759",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread_id: da7be0\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "LangGraph 에 대해서 배워보고 싶습니다. 유용한 자료를 추천해 주세요!\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_x97g4sjFCID0y9R8W42AUelP)\n",
      " Call ID: call_x97g4sjFCID0y9R8W42AUelP\n",
      "  Args:\n",
      "    query: LangGraph 소개\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T07:59:44.317244Z",
     "start_time": "2025-04-23T07:59:44.314073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# config 를 복사\n",
    "config_copy = config.copy()"
   ],
   "id": "4187b199631165e7",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:00:06.162547Z",
     "start_time": "2025-04-23T08:00:06.157827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "# 스냅샷 상태 가져오기\n",
    "snapshot = graph.get_state(config)\n",
    "\n",
    "# messages 의 마지막 메시지 가져오기\n",
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "\n",
    "# 메시지 ID 출력\n",
    "print(\"Message ID\", existing_message.id)"
   ],
   "id": "29449037f16ea79a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message ID run-d4934350-ee04-4cb8-a32f-b3c7ea24d77e-0\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:00:27.493301Z",
     "start_time": "2025-04-23T08:00:27.489439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 첫 번째 도구 호출 출력\n",
    "print(existing_message.tool_calls[0])"
   ],
   "id": "af3a863d7c2c8436",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'tavily_web_search', 'args': {'query': 'LangGraph 소개'}, 'id': 'call_x97g4sjFCID0y9R8W42AUelP', 'type': 'tool_call'}\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:00:45.490334Z",
     "start_time": "2025-04-23T08:00:45.484232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tool_calls 를 복사하여 새로운 도구 호출 생성\n",
    "new_tool_call = existing_message.tool_calls[0].copy()\n",
    "\n",
    "# 쿼리 매개변수 업데이트(갱신)\n",
    "new_tool_call[\"args\"] = {\"query\": \"LangGraph site:teddylee777.github.io\"}\n",
    "new_tool_call"
   ],
   "id": "8452e178d3542be5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'tavily_web_search',\n",
       " 'args': {'query': 'LangGraph site:teddylee777.github.io'},\n",
       " 'id': 'call_x97g4sjFCID0y9R8W42AUelP',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:01:32.180839Z",
     "start_time": "2025-04-23T08:01:32.176270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# AIMessage 생성\n",
    "new_message = AIMessage(\n",
    "    content=existing_message.content,\n",
    "    tool_calls=[new_tool_call],\n",
    "    # 중요! ID는 메시지를 상태에 추가하는 대신 교체하는 방법\n",
    "    id=existing_message.id,\n",
    ")\n",
    "\n",
    "print(new_message.id)\n",
    "\n",
    "# 수정한 메시지 출력\n",
    "new_message.pretty_print()"
   ],
   "id": "aba54efef075f7fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run-d4934350-ee04-4cb8-a32f-b3c7ea24d77e-0\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_x97g4sjFCID0y9R8W42AUelP)\n",
      " Call ID: call_x97g4sjFCID0y9R8W42AUelP\n",
      "  Args:\n",
      "    query: LangGraph site:teddylee777.github.io\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:02:18.180669Z",
     "start_time": "2025-04-23T08:02:18.168254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 업데이트된 도구 호출 출력\n",
    "print(new_message.tool_calls[0])\n",
    "\n",
    "# 메시지 ID 출력\n",
    "print(\"\\nMessage ID\", new_message.id)\n",
    "\n",
    "# 상태 업데이트\n",
    "graph.update_state(config, {\"messages\": [new_message]})"
   ],
   "id": "1c5abe9a5a7c210e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'tavily_web_search', 'args': {'query': 'LangGraph site:teddylee777.github.io'}, 'id': 'call_x97g4sjFCID0y9R8W42AUelP', 'type': 'tool_call'}\n",
      "\n",
      "Message ID run-d4934350-ee04-4cb8-a32f-b3c7ea24d77e-0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': 'da7be0',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f020194-6c05-6f66-8002-e60315b91858'}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:02:35.590852Z",
     "start_time": "2025-04-23T08:02:35.584478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 마지막 메시지의 도구 호출 가져오기\n",
    "graph.get_state(config).values[\"messages\"][-1].tool_calls"
   ],
   "id": "d8897becea54345d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_web_search',\n",
       "  'args': {'query': 'LangGraph site:teddylee777.github.io'},\n",
       "  'id': 'call_x97g4sjFCID0y9R8W42AUelP',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:02:57.402800Z",
     "start_time": "2025-04-23T08:02:45.121059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 그래프 스트림에서 이벤트 수신\n",
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "\n",
    "# 각 이벤트에 대한 처리\n",
    "for event in events:\n",
    "    # 메시지가 있는 경우 마지막 메시지 출력\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ],
   "id": "70a6a1edf2f133e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_x97g4sjFCID0y9R8W42AUelP)\n",
      " Call ID: call_x97g4sjFCID0y9R8W42AUelP\n",
      "  Args:\n",
      "    query: LangGraph site:teddylee777.github.io\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: tavily_web_search\n",
      "\n",
      "[{\"url\": \"https://teddylee777.github.io/langgraph/langgraph-multi-agent-collaboration/\", \"title\": \"LangGraph - Multi-Agent Collaboration(다중 협업 에이전트 ...\", \"content\": \"failed\", \"score\": 0.2976286, \"raw_content\": \"LangGraph - Multi-Agent Collaboration(다중 협업 에이전트) 로 복잡한 테스크를 수행하는 LLM 어플리케이션 제작 - 테디노트\\n\\nSkip to primary navigation\\nSkip to content\\nSkip to footer\\n\\n테디노트 데이터와 인공지능을 좋아하는 개발자 노트\\n\\n검색\\n카테고리\\n태그\\n연도\\n강의\\n어바웃미\\n\\n토글 메뉴\\n\\nHome \\n/3.  Langgraph \\n/5.  LangGraph - Multi-Agent Collaboration(다중 협업 에이전트) 로 복잡한 테스크를 수행하는 LLM 어플리케이션 제작\\n\\n🔥알림🔥\\n① 테디노트 유튜브 - 구경하러 가기!\\n② LangChain 한국어 튜토리얼 바로가기 👀\\n③ 랭체인 노트 무료 전자책(wikidocs) 바로가기 🙌\\n④ RAG 비법노트 LangChain 강의오픈 바로가기 🙌\\n⑤ 서울대 PyTorch 딥러닝 강의 바로가기 🙌\\nLangGraph - Multi-Agent Collaboration(다중 협업 에이전트) 로 복잡한 테스크를 수행하는 LLM 어플리케이션 제작\\n2024년 01월 29일 26 분 소요\\n목차\\n\\nReference\\n실습파일\\n요약\\n튜토리얼 영상\\n\\n\\n기본 다중 에이전트 협업\\n에이전트 생성\\nTool(도구) 정의\\n그래프 생성\\n상태 정의\\n에이전트 노드 정의하기\\nTool Node (도구 노드) 정의\\n에지 로직 정의\\n그래프 정의하기\\n\\n\\n호출\\n라이선스\\n\\nLangChain 에서 야심차게 LangGraph 를 새롭게 출시하였습니다. LangGraph 라이브러리가 출시하게 된 가장 큰 이유는 “복잡한 문제들은 단일 AI 에이전트만으로 해결하기 어렵다” 라는 문장에서 시작합니다.\\n이 글에서는 LangGraph의 다중 에이전트 협업을 통해 이러한 문제들을 효과적으로 해결하는 방법을 소개합니다. 특히, LangGraph를 활용한 새로운 접근법을 중점적으로 다룹니다.\\nReference\\n본 튜토리얼은 LangGraph 튜토리얼 노트북 파일을 참조하여 작성하였습니다.\\n\\n본 문서의 원 저작권자는 langchain-ai 이며, 코드는 MIT License 에 따라 사용이 허가된 파일입니다. 라이센스는 하단에 고지하였습니다.\\n원문 바로가기\\n\\n실습파일\\n\\n요약\\n주요내용\\n\\n🤖 다중 에이전트 협업: 각기 다른 도메인의 전문 에이전트들이 협력하여 복잡한 문제를 해결합니다.\\n🔧 도구 정의와 활용: 특정 작업에 적합한 도구들을 정의하고, 이를 에이전트가 활용하는 방법을 설명합니다.\\n📊 그래프 기반 시스템 구축: LangGraph를 사용하여 에이전트들이 서로 통신하고 협력하는 그래프를 생성합니다.\\n\\n튜토리얼 영상\\n기본 다중 에이전트 협업\\n단일 에이전트는 일반적으로 단일 도메인 내에서 소수의 도구를 사용하여 효과적으로 작동할 수 있지만, gpt-4와 같은 강력한 모델을 사용하더라도 많은 도구를 사용하는 데에는 덜 효과적일 수 있습니다.\\n복잡한 작업에 접근하는 한 가지 방법은 ‘나누고 정복하기(divide-and-conquer)’ 접근법입니다. 각 작업이나 도메인에 대해 전문화된 에이전트를 만들고 작업을 올바른 ‘전문가’에게 라우팅합니다.\\n이 노트북은 Wu 등이 작성한 논문 AutoGen: 다중 에이전트 대화를 통한 차세대 LLM 애플리케이션 가능하게 하기에서 영감을 받아 LangGraph를 사용하여 이를 수행하는 한 가지 방법을 보여줍니다.\\n결과적으로 생성된 그래프는 다음 다이어그램과 같은 모습일 것입니다.\\n\\n필요한 패키지를 설치합니다.\\n```\\nlangchain, langchain_openai, langsmith, pandas, langchain_experimental, matplotlib 패키지를 설치합니다.\\n이 코드는 패키지 설치를 위한 pip 명령어를 포함하고 있습니다.\\n```\\npython-dotenv 라이브러리를 사용하여 환경 변수에서 토큰 정보를 로드합니다.\\n이 라이브러리는 .env 파일에 저장된 환경 변수를 읽어와서 Python 프로그램에서 사용할 수 있게 해줍니다. load_dotenv 함수를 호출하여 .env 파일의 내용을 로드합니다.\\n```\\n토큰 정보를 로드하기 위한 라이브러리\\n설치 명령어: pip install python-dotenv\\nfrom dotenv import load_dotenv\\n토큰 정보 로드\\nload_dotenv()\\n```\\nTrue\\n_set_if_undefined는 환경 변수가 설정되어 있지 않을 경우 사용자로부터 해당 환경 변수의 값을 입력받아 설정하는 역할을 합니다. 이 함수는 OPENAI_API_KEY, LANGCHAIN_API_KEY, TAVILY_API_KEY 세 개의 API 키에 대해 환경 변수가 설정되어 있는지 확인하고, 없을 경우 사용자에게 입력을 요청합니다.\\n또한, LangSmith 추적 기능을 활성화하고 프로젝트 이름을 ‘Multi-agent Collaboration’으로 설정합니다.\\n```\\nimport getpass\\nimport os\\ndef _set_if_undefined(var: str):\\n    # 주어진 환경 변수가 설정되어 있지 않다면 사용자에게 입력을 요청하여 설정합니다.\\n    if not os.environ.get(var):\\n        os.environ[var] = getpass.getpass(f\\\"Please provide your {var}\\\")\\nOPENAI_API_KEY 환경 변수가 설정되어 있지 않으면 사용자에게 입력을 요청합니다.\\n_set_if_undefined(\\\"OPENAI_API_KEY\\\")\\nLANGCHAIN_API_KEY 환경 변수가 설정되어 있지 않으면 사용자에게 입력을 요청합니다.\\n_set_if_undefined(\\\"LANGCHAIN_API_KEY\\\")\\nTAVILY_API_KEY 환경 변수가 설정되어 있지 않으면 사용자에게 입력을 요청합니다.\\n_set_if_undefined(\\\"TAVILY_API_KEY\\\")\\nLangSmith 추적 기능을 활성화합니다. (선택적)\\nos.environ[\\\"LANGCHAIN_TRACING_V2\\\"] = \\\"true\\\"\\nos.environ[\\\"LANGCHAIN_PROJECT\\\"] = \\\"Multi-agent Collaboration\\\"\\n```\\n에이전트 생성\\ncreate_agent는 AI 에이전트를 생성하는 데 사용됩니다. 이 에이전트는 다른 AI 보조자들과 협력하여 제공된 도구들을 사용해 질문에 대한 답변을 진행합니다. 에이전트는 최종 답변을 할 수 있는 경우 응답 앞에 ‘FINAL ANSWER’라고 표시하여 팀이 작업을 멈출 수 있도록 합니다.\\ncreate_agent 함수는 llm, tools, system_message 세 개의 매개변수를 받으며, 각 도구의 이름을 포함한 프롬프트를 생성하여 에이전트에게 전달합니다.\\nformat_tool_to_openai_function 함수는 도구를 OpenAI 함수 형식으로 변환하는 데 사용되며, ChatPromptTemplate.from_messages는 에이전트에게 전달될 메시지 템플릿을 생성합니다. 마지막으로, 생성된 프롬프트는 llm.bind_functions을 통해 에이전트의 기능과 결합됩니다.\\n```\\nimport json\\nfrom langchain_core.messages import (\\n    BaseMessage,\\n    FunctionMessage,\\n    HumanMessage,\\n)\\nfrom langchain.tools.render import format_tool_to_openai_function\\nfrom langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\\nfrom langgraph.graph import END, StateGraph\\nfrom langgraph.prebuilt.tool_executor import ToolExecutor, ToolInvocation\\ndef create_agent(llm, tools, system_message: str):\\n    # 에이전트를 생성합니다.\\n    functions = [format_tool_to_openai_function(t) for t in tools]\\nprompt = ChatPromptTemplate.from_messages(\\n    [\\n        (\\n            \\\"system\\\",\\n            \\\"You are a helpful AI assistant, collaborating with other assistants.\\\"\\n            \\\" Use the provided tools to progress towards answering the question.\\\"\\n            \\\" If you are unable to fully answer, that's OK, another assistant with different tools \\\"\\n            \\\" will help where you left off. Execute what you can to make progress.\\\"\\n            \\\" If you or any of the other assistants have the final answer or deliverable,\\\"\\n            \\\" prefix your response with FINAL ANSWER so the team knows to stop.\\\"\\n            \\\" You have access to the following tools: {tool_names}.\\\\n{system_message}\\\",\\n        ),\\n        MessagesPlaceholder(variable_name=\\\"messages\\\"),\\n    ]\\n)\\nprompt = prompt.partial(system_message=system_message)\\nprompt = prompt.partial(tool_names=\\\", \\\".join(\\n    [tool.name for tool in tools]))\\nreturn prompt | llm.bind_functions(functions)\\n\\n```\\nTool(도구) 정의\\n우리의 에이전트들이 미래에 사용할 몇 가지 도구들을 정의할 것입니다\\n함수 python_repl은 주어진 파이썬 코드를 실행하고 그 결과를 반환합니다. 이 함수는 tool 데코레이터로 장식되어 있으며, 사용자가 제공한 코드를 PythonREPL 인스턴스를 통해 실행합니다.\\n실행 결과는 표준 출력으로 반환되며, 실행 중 발생한 예외는 오류 메시지와 함께 반환됩니다. 사용자는 print(...) 함수를 사용하여 값을 출력할 수 있습니다.\\n이 함수는 차트 생성과 같은 작업에 사용될 수 있습니다.\\n```\\nfrom langchain_core.tools import tool\\nfrom typing import Annotated\\nfrom langchain_experimental.utilities import PythonREPL\\nfrom langchain_community.tools.tavily_search import TavilySearchResults\\ntavily_tool = TavilySearchResults(max_results=5)\\nrepl = PythonREPL()\\n@tool\\ndef python_repl(\\n    code: Annotated[str, \\\"The python code to execute to generate your chart.\\\"]\\n):\\n    \\\"\\\"\\\"Use this to execute python code. If you want to see the output of a value,\\n    you should print it out with print(...). This is visible to the user.\\\"\\\"\\\"\\n    try:\\n        result = repl.run(code)\\n    except BaseException as e:\\n        return f\\\"Failed to execute. Error: {repr(e)}\\\"\\n    return f\\\"Succesfully executed:\\\\npython\\\\n{code}\\\\n\\\\nStdout: {result}\\\"\\n```\\n그래프 생성\\n이제 우리는 도구를 정의하고 몇 가지 헬퍼 함수를 만들었으므로, 아래에서 개별 에이전트를 생성하고 LangGraph를 사용하여 서로 통신하는 방법을 알려줄 것입니다.\\n상태 정의\\n우리는 먼저 그래프의 상태를 정의합니다. 이것은 가장 최근의 발신자를 추적하는 키와 함께 메시지의 리스트일 것입니다.\\n이 코드는 langchain 라이브러리를 사용하여 AI 에이전트와 상호작용하는 그래프 기반의 시스템을 구축하기 위한 준비 작업을 포함하고 있습니다.\\nAgentState 클래스는 에이전트의 상태를 나타내며, messages는 BaseMessage 객체의 시퀀스로 구성되며, sender는 메시지를 보낸 사람의 식별자를 나타냅니다.\\nAnnotated와 operator.add를 사용하여 messages 필드에 메시지를 추가할 수 있는 기능을 제공합니다.\\n```\\nimport operator\\nfrom typing import Annotated, Sequence, Tuple, TypedDict, Union\\nfrom langchain_openai import ChatOpenAI\\nfrom typing_extensions import TypedDict\\n각 에이전트와 도구에 대한 다른 노드를 생성할 것입니다. 이 클래스는 그래프의 각 노드 사이에서 전달되는 객체를 정의합니다.\\nclass AgentState(TypedDict):\\n    messages: Annotated[Sequence[BaseMessage], operator.add]\\n    sender: str\\n```\\n에이전트 노드 정의하기\\n이제 노드를 정의할 필요가 있습니다. 먼저, 에이전트들을 위한 노드를 정의합시다.\\n함수 agent_node는 주어진 에이전트의 상태를 처리하고, 결과 메시지와 발신자 정보를 포함하는 딕셔너리를 반환합니다. FunctionMessage 인스턴스인 경우에는 특별한 처리를 하지 않고, 그렇지 않은 경우에는 HumanMessage 인스턴스로 변환합니다.\\nChatOpenAI 클래스의 인스턴스 llm은 모델 gpt-4-1106-preview를 사용하여 생성됩니다.\\nresearch_agent와 chart_agent는 각각 연구자와 차트 생성기를 위한 에이전트를 생성하며, 이들은 llm을 사용하고 특정 도구(tavily_tool, python_repl)와 시스템 메시지를 설정합니다. research_node와 chart_node는 functools.partial을 사용하여 agent_node 함수에 필요한 인자를 미리 설정한 콜백 함수를 생성합니다.\\n```\\nimport functools\\ndef agent_node(state, agent, name):\\n    result = agent.invoke(state)\\n    if isinstance(result, FunctionMessage):\\n        pass\\n    else:\\n        result = HumanMessage(**result.dict(exclude={\\\"type\\\", \\\"name\\\"}), name=name)\\n    return {\\n        \\\"messages\\\": [result],\\n        \\\"sender\\\": name,\\n    }\\nllm = ChatOpenAI(model=\\\"gpt-4-1106-preview\\\")\\nResearch agent and node\\nresearch_agent = create_agent(\\n    llm,\\n    [tavily_tool],\\n    system_message=\\\"You should provide accurate data for the chart generator to use.\\\",\\n)\\nresearch_node = functools.partial(agent_node, agent=research_agent, name=\\\"Researcher\\\")\\nChart Generator\\nchart_agent = create_agent(\\n    llm,\\n    [python_repl],\\n    system_message=\\\"Any charts you display will be visible by the user.\\\",\\n)\\nchart_node = functools.partial(agent_node, agent=chart_agent, name=\\\"Chart Generator\\\")\\n```\\nTool Node (도구 노드) 정의\\n우리는 이제 도구를 실행하는 노드를 정의합니다\\ntool_node는 상태 객체를 받아 마지막 메시지에서 도구 호출을 추출하고, 해당 도구를 실행한 후 결과를 FunctionMessage 형태로 반환합니다.\\n이 함수는 ToolExecutor 인스턴스를 사용하여 도구를 실행하며, 실행 결과는 새로운 메시지 리스트에 추가되어 반환됩니다.\\n단일 인자 입력은 값으로 직접 전달되며, 복수 인자의 경우 ToolInvocation 객체를 통해 전달됩니다.\\n```\\ntools = [tavily_tool, python_repl]\\ntool_executor = ToolExecutor(tools)\\ndef tool_node(state):\\n    # 그래프에서 도구를 실행하는 함수입니다.\\n    # 에이전트 액션을 입력받아 해당 도구를 호출하고 결과를 반환합니다.\\n    messages = state[\\\"messages\\\"]\\n    # 계속 조건에 따라 마지막 메시지가 함수 호출을 포함하고 있음을 알 수 있습니다.\\n    last_message = messages[-1]\\n    # ToolInvocation을 함수 호출로부터 구성합니다.\\n    tool_input = json.loads(\\n        last_message.additional_kwargs[\\\"function_call\\\"][\\\"arguments\\\"]\\n    )\\n    # 단일 인자 입력은 값으로 직접 전달할 수 있습니다.\\n    if len(tool_input) == 1 and \\\"__arg1\\\" in tool_input:\\n        tool_input = next(iter(tool_input.values()))\\n    tool_name = last_message.additional_kwargs[\\\"function_call\\\"][\\\"name\\\"]\\n    action = ToolInvocation(\\n        tool=tool_name,\\n        tool_input=tool_input,\\n    )\\n    # 도구 실행자를 호출하고 응답을 받습니다.\\n    response = tool_executor.invoke(action)\\n    # 응답을 사용하여 FunctionMessage를 생성합니다.\\n    function_message = FunctionMessage(\\n        content=f\\\"{tool_name} response: {str(response)}\\\", name=action.tool\\n    )\\n    # 기존 리스트에 추가될 리스트를 반환합니다.\\n    return {\\\"messages\\\": [function_message]}\\n```\\n에지 로직 정의\\n에이전트의 결과에 따라 무엇을 할지 결정하는 데 필요한 일부 에지 로직을 정의할 수 있습니다.\\nrouter는 상태 정보를 받아서 다음 단계를 결정합니다. 상태 정보에서 마지막 메시지를 확인하고, 이 메시지에 특정 키워드가 포함되어 있는지에 따라 다음 단계를 반환합니다.\\n만약 마지막 메시지의 additional_kwargs에 function_call이 포함되어 있다면, 이전 에이전트가 도구를 호출한 것으로 간주하고 \\\"call_tool\\\"을 반환합니다. 만약 마지막 메시지의 내용에 \\\"FINAL ANSWER\\\"가 포함되어 있다면, 작업이 완료되었다고 판단하고 \\\"end\\\"를 반환합니다. 그렇지 않으면 작업을 계속 진행해야 하므로 \\\"continue\\\"를 반환합니다.\\ndef router(state):\\n    # 상태 정보를 기반으로 다음 단계를 결정하는 라우터 함수\\n    messages = state[\\\"messages\\\"]\\n    last_message = messages[-1]\\n    if \\\"function_call\\\" in last_message.additional_kwargs:\\n        # 이전 에이전트가 도구를 호출함\\n        return \\\"call_tool\\\"\\n    if \\\"FINAL ANSWER\\\" in last_message.content:\\n        # 어느 에이전트든 작업이 끝났다고 결정함\\n        return \\\"end\\\"\\n    return \\\"continue\\\"\\n그래프 정의하기\\n이제 모든 것을 종합하여 그래프를 정의할 수 있습니다!\\nStateGraph 클래스를 사용하여 상태 기반 워크플로우를 구성합니다.\\nAgentState를 기반으로 StateGraph 객체를 생성하고, add_node 메서드를 사용하여 여러 노드(Researcher, Chart Generator, call_tool)를 추가합니다.\\nadd_conditional_edges 메서드를 통해 조건부 엣지를 추가하여, 각 노드가 특정 조건에 따라 다른 노드로 이동할 수 있도록 합니다. 예를 들어, Researcher 노드는 router 함수의 결과에 따라 Chart Generator 또는 call_tool로 이동하거나 워크플로우를 종료할 수 있습니다. call_tool 노드는 sender 필드를 기반으로 원래 호출한 노드로 돌아갑니다.\\n마지막으로 set_entry_point 메서드로 시작점을 Researcher로 설정하고, compile 메서드로 워크플로우 그래프를 컴파일합니다.\\n```\\nworkflow = StateGraph(AgentState)\\nworkflow.add_node(\\\"Researcher\\\", research_node)\\nworkflow.add_node(\\\"Chart Generator\\\", chart_node)\\nworkflow.add_node(\\\"call_tool\\\", tool_node)\\nworkflow.add_conditional_edges(\\n    \\\"Researcher\\\",\\n    router,\\n    {\\\"continue\\\": \\\"Chart Generator\\\", \\\"call_tool\\\": \\\"call_tool\\\", \\\"end\\\": END},\\n)\\nworkflow.add_conditional_edges(\\n    \\\"Chart Generator\\\",\\n    router,\\n    {\\\"continue\\\": \\\"Researcher\\\", \\\"call_tool\\\": \\\"call_tool\\\", \\\"end\\\": END},\\n)\\nworkflow.add_conditional_edges(\\n    \\\"call_tool\\\",\\n    lambda x: x[\\\"sender\\\"],\\n    {\\n        \\\"Researcher\\\": \\\"Researcher\\\",\\n        \\\"Chart Generator\\\": \\\"Chart Generator\\\",\\n    },\\n)\\nworkflow.set_entry_point(\\\"Researcher\\\")\\ngraph = workflow.compile()\\n```\\n호출\\n그래프가 생성되었으니 이제 호출할 수 있습니다! 몇 가지 통계를 차트로 나타내도록 해봅시다.\\n이 코드는 graph 객체의 stream 메소드를 사용하여 데이터를 스트리밍합니다.\\nHumanMessage 객체를 사용하여 대한민국의 2018년부터 2022년까지의 출산율 데이터를 요청하고, 해당 데이터에 대한 그래프를 그리도록 요청합니다. 또한, 코드 실행이 완료되면 종료하도록 메시지에 포함되어 있습니다.\\n스트림은 최대 200번의 재귀 호출로 제한됩니다.\\nfor s in graph.stream(\\n    {\\n        \\\"messages\\\": [\\n            HumanMessage(\\n                content=\\\"대한민국의 2018년 ~ 2022년의 합계출산율에 대한 데이터를 찾아줘, \\\"\\n                \\\"그리고 2023, 2024, 2025년에 대한 전망도 찾아줘, \\\"\\n                \\\"마지막으로 수집한 데이터에 대한 그래프를 그려줘. \\\"\\n                \\\"코드 작성을 완료했다면 종료해줘.\\\"\\n            )\\n        ],\\n    },\\n    # 그래프에서 수행할 최대 단계 수\\n    {\\\"recursion_limit\\\": 200},\\n):\\n    print(s)\\n    print(\\\"----\\\")\\n{'Researcher': {'messages': [HumanMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\\"query\\\":\\\"South Korea Total Fertility Rate 2018-2022\\\"}', 'name': 'tavily_search_results_json'}}, name='Researcher')], 'sender': 'Researcher'}}\\n{'call_tool': {'messages': [FunctionMessage(content='tavily_search_results_json response: [{\\\\'url\\\\': \\\\'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9623034/\\\\', \\\\'content\\\\': \\\\'from 2.79 in 1970 to 1.74 in 1995, with a further decrease to 1.63 in 2018. In 2018, Korea (0.98) had the lowest TFR  The comprehensive graph of the changes in the trends of total live births, CBR, and TFR in Korea for the past 100 years  and trends in the population count, number of births, and birth rate in Korea, in the past and future.  rate (CBR, 5.3) and total fertility rate (TFR, 0.84), as compared with those in the previous year. Meanwhile, KoreaIn 2020, the number of births fell below 300,000 for the first time in South Korea. This year, a decline was observed in the values of both crude birth rate (CBR, 5.3) and total fertility rate (TFR, 0.84), as compared with those in the previous year. Meanwhile, Korea recorded 305,100 deaths per year, which was higher than the number of births ...\\\\'}, {\\\\'url\\\\': \\\\'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9733182/\\\\', \\\\'content\\\\': \\\\'The total fertility rate provided by Statistics Korea is a compilation of birth data reported to each local government  Korea, and it is in charge of setting standards for statistics, census, and various statistics. The total fertility  the relationship between changes in the Korean fertility rate and policies to encourage fertility.  The relationship between changes in the korean fertility rate and policies to encourage fertility Kyuhyoung JeongThis study utilized the longitudinal data from 2014 to 2018 on the total fertility rate of 250 local governments (the administration of a town, county, or district) provided by Statistics Korea to estimate changes in the fertility rate. ... the change in the fertility rate in South Korea showed a rapid increase in the rate of decline over time ...\\\\'}, {\\\\'url\\\\': \\\\'https://www.rand.org/pubs/commentary/2022/07/south-koreas-extraordinary-fertility-decline.html\\\\', \\\\'content\\\\': \\\"In 2021, South Korea\\\\'s total fertility rate (TFR)—the number of children born to a typical woman over her lifetime—fell  About South Korea\\\\'s Extraordinary Fertility Decline commentary (The RAND Blog)  Figure 1: Global Trends in Fertility  Author\\\\'s calculations using OECD data: Demography - Fertility rates - OECD DataJuly 22, 2022. In 2021, South Korea\\\\'s total fertility rate (TFR)—the number of children born to a typical woman over her lifetime— fell to 0.81, the lowest ever recorded in a highly developed democratic nation (see Figure 1). Of all 38 countries in the Organization for Economic Cooperation and Development (OECD), South Korea stands alone as ...\\\"}, {\\\\'url\\\\': \\\\'https://www.bbc.com/news/world-asia-62670717\\\\', \\\\'content\\\\': \\\"South Korea has again recorded the world\\\\'s lowest fertility rate with the number sinking to a new low.  South Korea records world\\\\'s lowest fertility rate again  In 2020 there was widespread alarm in South Korea when it recorded more deaths than births for the first time.  The rate in the country first dropped lower than one child per woman in 2018.South Korea has again recorded the world\\\\'s lowest fertility rate with the number sinking to a new low. The rate in the country first dropped lower than one child per woman in 2018. But on ...\\\"}, {\\\\'url\\\\': \\\\'https://www.npr.org/2023/03/19/1163341684/south-korea-fertility-rate\\\\', \\\\'content\\\\': \\\"see fertility rates more than double that of Korea at 1.67.  In South Korea, the fertility rate — the average number of children born to a woman in her reproductive years — is now  World South Korea has the world\\\\'s lowest fertility rate, a struggle with lessons for us all By Ashley Ahn  gender war in South Korea and countering efforts to solve the fertility issue.The fertility rate in South Korea, which has the world\\\\'s lowest rate, hit 0.78 in February. ... Both countries were among the top 10 countries for working women in 2022, while Korea ranked last, ...\\\"}]', name='tavily_search_results_json')]}}\\n{'Researcher': {'messages': [HumanMessage(content=\\\"Based on the search results, here are the total fertility rates (TFR) for South Korea from 2018 to 2022:\\\\n\\\\n- 2018: 0.98\\\\n- 2020: 0.84\\\\n- 2021: 0.81\\\\n\\\\nThere is no direct information for the years 2019 and 2022, and no projections for 2023, 2024, and 2025 were provided in the search results. We will need to conduct another search to find the missing TFR data for 2019 and 2022 and to find projections for 2023, 2024, and 2025.\\\\n\\\\nLet's conduct another search to attempt to fill in the gaps.\\\\n\\\", additional_kwargs={'function_call': {'arguments': '{\\\"query\\\":\\\"South Korea total fertility rate 2019 2022 projections 2023 2024 2025\\\"}', 'name': 'tavily_search_results_json'}}, name='Researcher')], 'sender': 'Researcher'}}\\n{'call_tool': {'messages': [FunctionMessage(content='tavily_search_results_json response: [{\\\\'url\\\\': \\\\'https://edition.cnn.com/2023/12/15/asia/south-korea-to-see-population-plummet-intl-hnk/index.html\\\\', \\\\'content\\\\': \\\"The United Nations Population Fund estimates North Korea’s fertility rate for 2023 at 1.8 births per woman.  as the median age will increase from 44.9 in 2022 to 63.4 in 2072, Statistics Korea said.  South Korea, the country with the world’s lowest birth rate, expects it to fall even further in the next two years  South Korea’s total fertility rate, the number of births from a woman in her lifetime, is now expected to drop fromSouth Korea\\\\'s total fertility rate, the number of births from a woman in her lifetime, is now expected to drop from 0.78 in 2022 to 0.65 in 2025, according to the government\\\\'s Statistics Korea.\\\"}, {\\\\'url\\\\': \\\\'https://time.com/6488894/south-korea-low-fertility-rate-trend-decline/\\\\', \\\\'content\\\\': \\\\'latest population forecasts. South Korea already has the world’s lowest fertility rate at 0.78 as of 2022.  South Korea Expects Its Already-World’s-Lowest Fertility Rate to Keep Falling  two years ago, when authorities forecast that the fertility rate would bottom out at 0.7 in 2024 before rising again.  Low fertility threatens to undermine South Korea’s economic future by shrinking its workforce and slowing consumption.The latest forecast by Statistics Korea puts the population in 2072 at 36.2 million, a 30% decline from the current 51.7 million, even though the fertility rate may recover a bit to 0.68 in 2026.\\\\'}, {\\\\'url\\\\': \\\\'https://theconversation.com/south-korea-has-the-lowest-fertility-rate-in-the-world-and-that-doesnt-bode-well-for-its-economy-207107\\\\', \\\\'content\\\\': \\\"which South Korea’s fertility rate fell from 6.0 to 0.8, the U.S. saw a more gradual decline from 3.0 to 1.7.  Edition South Korea has the lowest fertility rate in the world – and that doesn’t bode well for its\\\\\\\\xa0economy Author  With an extremely low fertility rate of 0.78, South Korea is losing population each year and experiencing more deaths  was 0.78. South Korea is the only country in the world to register a fertility rate of less than one child per woman,And South Korea\\\\'s fertility rate has been consistently below that number since 1984, when it dropped to 1.93, from 2.17 the year before. What makes the South Korean fertility rate decline more ...\\\"}, {\\\\'url\\\\': \\\\'https://phys.org/news/2023-06-south-korea-lowest-fertility-worldand.html\\\\', \\\\'content\\\\': \\\"which South Korea\\\\'s fertility rate fell from 6.0 to 0.8, the U.S. saw a more gradual decline from 3.0 to 1.7.  was 0.78. South Korea is the only country in the world to register a fertility rate of less than one child per woman,  proofread South Korea has the lowest fertility rate in the world—and that doesn\\\\'t bode well for its economy  With an extremely low fertility rate of 0.78, South Korea is losing population each year and experiencing more deathsAnd South Korea\\\\'s fertility rate has been consistently below that number since 1984, when it dropped to 1.93, from 2.17 the year before. What makes the South Korean fertility rate decline more ...\\\"}, {\\\\'url\\\\': \\\\'https://www.npr.org/2023/03/19/1163341684/south-korea-fertility-rate\\\\', \\\\'content\\\\': \\\"see fertility rates more than double that of Korea at 1.67.  In South Korea, the fertility rate — the average number of children born to a woman in her reproductive years — is now  World South Korea has the world\\\\'s lowest fertility rate, a struggle with lessons for us all By Ashley Ahn  Asia South Korea prepares the young for a rapidly aging populationIn South Korea, the fertility rate — the average number of children ... given to parents with a child under the age of 1 from 300,000 won per month (about $230) to 1 million won ($765) by 2024.\\\"}]', name='tavily_search_results_json')]}}\\n{'Researcher': {'messages': [HumanMessage(content=\\\"Based on the new search results, we have additional data for the total fertility rates (TFR) for South Korea and projections for the coming years:\\\\n\\\\n- 2019: Missing data, not provided in search results.\\\\n- 2022: 0.78\\\\n- 2023: No specific projection given in the search results.\\\\n- 2024: A forecast from two years ago expected the fertility rate to bottom out at 0.7.\\\\n- 2025: The fertility rate is expected to drop to 0.65, according to the government's Statistics Korea.\\\\n\\\\nUnfortunately, we still lack the TFR for 2019 and the projection for 2023. Given the available data, we can generate a graph for the TFR from 2018, 2020, 2021, and 2022 and include the projections for 2024 and 2025. We'll need to leave 2019 and 2023 as gaps unless we can find more information.\\\\n\\\\nHere is the data that can be used for the chart:\\\\n\\\\n| Year | Total Fertility Rate (TFR) |\\\\n|------|----------------------------|\\\\n| 2018 | 0.98                       |\\\\n| 2019 | Data Not Available         |\\\\n| 2020 | 0.84                       |\\\\n| 2021 | 0.81                       |\\\\n| 2022 | 0.78                       |\\\\n| 2023 | Projection Not Available   |\\\\n| 2024 | 0.7 (Projected)            |\\\\n| 2025 | 0.65 (Projected)           |\\\\n\\\\nPlease let me know if you would like to proceed with generating the graph with the available data, or if there are any other steps you'd like to take.\\\", name='Researcher')], 'sender': 'Researcher'}}\\n\\n{'Chart Generator': {'messages': [HumanMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\\"code\\\":\\\"import matplotlib.pyplot as plt\\\\\\\\n\\\\\\\\n# Data\\\\\\\\nyears = [2018, 2020, 2021, 2022, 2024, 2025]\\\\\\\\nfertility_rates = [0.98, 0.84, 0.81, 0.78, 0.7, 0.65]\\\\\\\\n\\\\\\\\n# Create the plot\\\\\\\\nplt.figure(figsize=(10, 5))\\\\\\\\nplt.plot(years, fertility_rates, marker=\\\\'o\\\\')\\\\\\\\n\\\\\\\\n# Add titles and labels\\\\\\\\nplt.title(\\\\'Total Fertility Rate in South Korea (2018 - 2025)\\\\')\\\\\\\\nplt.xlabel(\\\\'Year\\\\')\\\\\\\\nplt.ylabel(\\\\'Total Fertility Rate (TFR)\\\\')\\\\\\\\n\\\\\\\\n# Add grid\\\\\\\\nplt.grid(True)\\\\\\\\n\\\\\\\\n# Show the plot\\\\\\\\nplt.show()\\\"}', 'name': 'python_repl'}}, name='Chart Generator')], 'sender': 'Chart Generator'}}\\n{'call_tool': {'messages': [FunctionMessage(content=\\\"python_repl response: Succesfully executed:\\\\n```python\\\\nimport matplotlib.pyplot as plt\\\\n\\\\n# Data\\\\nyears = [2018, 2020, 2021, 2022, 2024, 2025]\\\\nfertility_rates = [0.98, 0.84, 0.81, 0.78, 0.7, 0.65]\\\\n\\\\n# Create the plot\\\\nplt.figure(figsize=(10, 5))\\\\nplt.plot(years, fertility_rates, marker='o')\\\\n\\\\n# Add titles and labels\\\\nplt.title('Total Fertility Rate in South Korea (2018 - 2025)')\\\\nplt.xlabel('Year')\\\\nplt.ylabel('Total Fertility Rate (TFR)')\\\\n\\\\n# Add grid\\\\nplt.grid(True)\\\\n\\\\n# Show the plot\\\\nplt.show()\\\\n```\\\\nStdout: \\\", name='python_repl')]}}\\n{'Chart Generator': {'messages': [HumanMessage(content='Here is the graph showing the Total Fertility Rate (TFR) in South Korea from 2018 to 2022, along with the projected rates for 2024 and 2025:\\\\n\\\\n![Total Fertility Rate in South Korea (2018 - 2025)](sandbox:/code)\\\\n\\\\nPlease note that data for 2019 and 2023 is not available, and the projections for 2024 and 2025 are based on forecasts, not actual data.', name='Chart Generator')], 'sender': 'Chart Generator'}}\\n{'Researcher': {'messages': [HumanMessage(content='FINAL ANSWER\\\\n\\\\nHere is the graph showing the Total Fertility Rate (TFR) in South Korea from 2018 to 2022, along with the projected rates for 2024 and 2025:\\\\n\\\\n![Total Fertility Rate in South Korea (2018 - 2025)](sandbox:/code)\\\\n\\\\nPlease note that data for 2019 and 2023 is not available, and the projections for 2024 and 2025 are based on forecasts, not actual data.', name='Researcher')], 'sender': 'Researcher'}}\\n{'__end__': {'messages': [HumanMessage(content='대한민국의 2018년 ~ 2022년의 합계출산율에 대한 데이터를 찾아줘, 그리고 2023, 2024, 2025년에 대한 전망도 찾아줘, 마지막으로 수집한 데이터에 대한 그래프를 그려줘. 코드 작성을 완료했다면 종료해줘.'), HumanMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\\"query\\\":\\\"South Korea Total Fertility Rate 2018-2022\\\"}', 'name': 'tavily_search_results_json'}}, name='Researcher'), FunctionMessage(content='tavily_search_results_json response: [{\\\\'url\\\\': \\\\'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9623034/\\\\', \\\\'content\\\\': \\\\'from 2.79 in 1970 to 1.74 in 1995, with a further decrease to 1.63 in 2018. In 2018, Korea (0.98) had the lowest TFR  The comprehensive graph of the changes in the trends of total live births, CBR, and TFR in Korea for the past 100 years  and trends in the population count, number of births, and birth rate in Korea, in the past and future.  rate (CBR, 5.3) and total fertility rate (TFR, 0.84), as compared with those in the previous year. Meanwhile, KoreaIn 2020, the number of births fell below 300,000 for the first time in South Korea. This year, a decline was observed in the values of both crude birth rate (CBR, 5.3) and total fertility rate (TFR, 0.84), as compared with those in the previous year. Meanwhile, Korea recorded 305,100 deaths per year, which was higher than the number of births ...\\\\'}, {\\\\'url\\\\': \\\\'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9733182/\\\\', \\\\'content\\\\': \\\\'The total fertility rate provided by Statistics Korea is a compilation of birth data reported to each local government  Korea, and it is in charge of setting standards for statistics, census, and various statistics. The total fertility  the relationship between changes in the Korean fertility rate and policies to encourage fertility.  The relationship between changes in the korean fertility rate and policies to encourage fertility Kyuhyoung JeongThis study utilized the longitudinal data from 2014 to 2018 on the total fertility rate of 250 local governments (the administration of a town, county, or district) provided by Statistics Korea to estimate changes in the fertility rate. ... the change in the fertility rate in South Korea showed a rapid increase in the rate of decline over time ...\\\\'}, {\\\\'url\\\\': \\\\'https://www.rand.org/pubs/commentary/2022/07/south-koreas-extraordinary-fertility-decline.html\\\\', \\\\'content\\\\': \\\"In 2021, South Korea\\\\'s total fertility rate (TFR)—the number of children born to a typical woman over her lifetime—fell  About South Korea\\\\'s Extraordinary Fertility Decline commentary (The RAND Blog)  Figure 1: Global Trends in Fertility  Author\\\\'s calculations using OECD data: Demography - Fertility rates - OECD DataJuly 22, 2022. In 2021, South Korea\\\\'s total fertility rate (TFR)—the number of children born to a typical woman over her lifetime— fell to 0.81, the lowest ever recorded in a highly developed democratic nation (see Figure 1). Of all 38 countries in the Organization for Economic Cooperation and Development (OECD), South Korea stands alone as ...\\\"}, {\\\\'url\\\\': \\\\'https://www.bbc.com/news/world-asia-62670717\\\\', \\\\'content\\\\': \\\"South Korea has again recorded the world\\\\'s lowest fertility rate with the number sinking to a new low.  South Korea records world\\\\'s lowest fertility rate again  In 2020 there was widespread alarm in South Korea when it recorded more deaths than births for the first time.  The rate in the country first dropped lower than one child per woman in 2018.South Korea has again recorded the world\\\\'s lowest fertility rate with the number sinking to a new low. The rate in the country first dropped lower than one child per woman in 2018. But on ...\\\"}, {\\\\'url\\\\': \\\\'https://www.npr.org/2023/03/19/1163341684/south-korea-fertility-rate\\\\', \\\\'content\\\\': \\\"see fertility rates more than double that of Korea at 1.67.  In South Korea, the fertility rate — the average number of children born to a woman in her reproductive years — is now  World South Korea has the world\\\\'s lowest fertility rate, a struggle with lessons for us all By Ashley Ahn  gender war in South Korea and countering efforts to solve the fertility issue.The fertility rate in South Korea, which has the world\\\\'s lowest rate, hit 0.78 in February. ... Both countries were among the top 10 countries for working women in 2022, while Korea ranked last, ...\\\"}]', name='tavily_search_results_json'), HumanMessage(content=\\\"Based on the search results, here are the total fertility rates (TFR) for South Korea from 2018 to 2022:\\\\n\\\\n- 2018: 0.98\\\\n- 2020: 0.84\\\\n- 2021: 0.81\\\\n\\\\nThere is no direct information for the years 2019 and 2022, and no projections for 2023, 2024, and 2025 were provided in the search results. We will need to conduct another search to find the missing TFR data for 2019 and 2022 and to find projections for 2023, 2024, and 2025.\\\\n\\\\nLet's conduct another search to attempt to fill in the gaps.\\\\n\\\", additional_kwargs={'function_call': {'arguments': '{\\\"query\\\":\\\"South Korea total fertility rate 2019 2022 projections 2023 2024 2025\\\"}', 'name': 'tavily_search_results_json'}}, name='Researcher'), FunctionMessage(content='tavily_search_results_json response: [{\\\\'url\\\\': \\\\'https://edition.cnn.com/2023/12/15/asia/south-korea-to-see-population-plummet-intl-hnk/index.html\\\\', \\\\'content\\\\': \\\"The United Nations Population Fund estimates North Korea’s fertility rate for 2023 at 1.8 births per woman.  as the median age will increase from 44.9 in 2022 to 63.4 in 2072, Statistics Korea said.  South Korea, the country with the world’s lowest birth rate, expects it to fall even further in the next two years  South Korea’s total fertility rate, the number of births from a woman in her lifetime, is now expected to drop fromSouth Korea\\\\'s total fertility rate, the number of births from a woman in her lifetime, is now expected to drop from 0.78 in 2022 to 0.65 in 2025, according to the government\\\\'s Statistics Korea.\\\"}, {\\\\'url\\\\': \\\\'https://time.com/6488894/south-korea-low-fertility-rate-trend-decline/\\\\', \\\\'content\\\\': \\\\'latest population forecasts. South Korea already has the world’s lowest fertility rate at 0.78 as of 2022.  South Korea Expects Its Already-World’s-Lowest Fertility Rate to Keep Falling  two years ago, when authorities forecast that the fertility rate would bottom out at 0.7 in 2024 before rising again.  Low fertility threatens to undermine South Korea’s economic future by shrinking its workforce and slowing consumption.The latest forecast by Statistics Korea puts the population in 2072 at 36.2 million, a 30% decline from the current 51.7 million, even though the fertility rate may recover a bit to 0.68 in 2026.\\\\'}, {\\\\'url\\\\': \\\\'https://theconversation.com/south-korea-has-the-lowest-fertility-rate-in-the-world-and-that-doesnt-bode-well-for-its-economy-207107\\\\', \\\\'content\\\\': \\\"which South Korea’s fertility rate fell from 6.0 to 0.8, the U.S. saw a more gradual decline from 3.0 to 1.7.  Edition South Korea has the lowest fertility rate in the world – and that doesn’t bode well for its\\\\\\\\xa0economy Author  With an extremely low fertility rate of 0.78, South Korea is losing population each year and experiencing more deaths  was 0.78. South Korea is the only country in the world to register a fertility rate of less than one child per woman,And South Korea\\\\'s fertility rate has been consistently below that number since 1984, when it dropped to 1.93, from 2.17 the year before. What makes the South Korean fertility rate decline more ...\\\"}, {\\\\'url\\\\': \\\\'https://phys.org/news/2023-06-south-korea-lowest-fertility-worldand.html\\\\', \\\\'content\\\\': \\\"which South Korea\\\\'s fertility rate fell from 6.0 to 0.8, the U.S. saw a more gradual decline from 3.0 to 1.7.  was 0.78. South Korea is the only country in the world to register a fertility rate of less than one child per woman,  proofread South Korea has the lowest fertility rate in the world—and that doesn\\\\'t bode well for its economy  With an extremely low fertility rate of 0.78, South Korea is losing population each year and experiencing more deathsAnd South Korea\\\\'s fertility rate has been consistently below that number since 1984, when it dropped to 1.93, from 2.17 the year before. What makes the South Korean fertility rate decline more ...\\\"}, {\\\\'url\\\\': \\\\'https://www.npr.org/2023/03/19/1163341684/south-korea-fertility-rate\\\\', \\\\'content\\\\': \\\"see fertility rates more than double that of Korea at 1.67.  In South Korea, the fertility rate — the average number of children born to a woman in her reproductive years — is now  World South Korea has the world\\\\'s lowest fertility rate, a struggle with lessons for us all By Ashley Ahn  Asia South Korea prepares the young for a rapidly aging populationIn South Korea, the fertility rate — the average number of children ... given to parents with a child under the age of 1 from 300,000 won per month (about $230) to 1 million won ($765) by 2024.\\\"}]', name='tavily_search_results_json'), HumanMessage(content=\\\"Based on the new search results, we have additional data for the total fertility rates (TFR) for South Korea and projections for the coming years:\\\\n\\\\n- 2019: Missing data, not provided in search results.\\\\n- 2022: 0.78\\\\n- 2023: No specific projection given in the search results.\\\\n- 2024: A forecast from two years ago expected the fertility rate to bottom out at 0.7.\\\\n- 2025: The fertility rate is expected to drop to 0.65, according to the government's Statistics Korea.\\\\n\\\\nUnfortunately, we still lack the TFR for 2019 and the projection for 2023. Given the available data, we can generate a graph for the TFR from 2018, 2020, 2021, and 2022 and include the projections for 2024 and 2025. We'll need to leave 2019 and 2023 as gaps unless we can find more information.\\\\n\\\\nHere is the data that can be used for the chart:\\\\n\\\\n| Year | Total Fertility Rate (TFR) |\\\\n|------|----------------------------|\\\\n| 2018 | 0.98                       |\\\\n| 2019 | Data Not Available         |\\\\n| 2020 | 0.84                       |\\\\n| 2021 | 0.81                       |\\\\n| 2022 | 0.78                       |\\\\n| 2023 | Projection Not Available   |\\\\n| 2024 | 0.7 (Projected)            |\\\\n| 2025 | 0.65 (Projected)           |\\\\n\\\\nPlease let me know if you would like to proceed with generating the graph with the available data, or if there are any other steps you'd like to take.\\\", name='Researcher'), HumanMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\\"code\\\":\\\"import matplotlib.pyplot as plt\\\\\\\\n\\\\\\\\n# Data\\\\\\\\nyears = [2018, 2020, 2021, 2022, 2024, 2025]\\\\\\\\nfertility_rates = [0.98, 0.84, 0.81, 0.78, 0.7, 0.65]\\\\\\\\n\\\\\\\\n# Create the plot\\\\\\\\nplt.figure(figsize=(10, 5))\\\\\\\\nplt.plot(years, fertility_rates, marker=\\\\'o\\\\')\\\\\\\\n\\\\\\\\n# Add titles and labels\\\\\\\\nplt.title(\\\\'Total Fertility Rate in South Korea (2018 - 2025)\\\\')\\\\\\\\nplt.xlabel(\\\\'Year\\\\')\\\\\\\\nplt.ylabel(\\\\'Total Fertility Rate (TFR)\\\\')\\\\\\\\n\\\\\\\\n# Add grid\\\\\\\\nplt.grid(True)\\\\\\\\n\\\\\\\\n# Show the plot\\\\\\\\nplt.show()\\\"}', 'name': 'python_repl'}}, name='Chart Generator'), FunctionMessage(content=\\\"python_repl response: Succesfully executed:\\\\n```python\\\\nimport matplotlib.pyplot as plt\\\\n\\\\n# Data\\\\nyears = [2018, 2020, 2021, 2022, 2024, 2025]\\\\nfertility_rates = [0.98, 0.84, 0.81, 0.78, 0.7, 0.65]\\\\n\\\\n# Create the plot\\\\nplt.figure(figsize=(10, 5))\\\\nplt.plot(years, fertility_rates, marker='o')\\\\n\\\\n# Add titles and labels\\\\nplt.title('Total Fertility Rate in South Korea (2018 - 2025)')\\\\nplt.xlabel('Year')\\\\nplt.ylabel('Total Fertility Rate (TFR)')\\\\n\\\\n# Add grid\\\\nplt.grid(True)\\\\n\\\\n# Show the plot\\\\nplt.show()\\\\n```\\\\nStdout: \\\", name='python_repl'), HumanMessage(content='Here is the graph showing the Total Fertility Rate (TFR) in South Korea from 2018 to 2022, along with the projected rates for 2024 and 2025:\\\\n\\\\n![Total Fertility Rate in South Korea (2018 - 2025)](sandbox:/code)\\\\n\\\\nPlease note that data for 2019 and 2023 is not available, and the projections for 2024 and 2025 are based on forecasts, not actual data.', name='Chart Generator'), HumanMessage(content='FINAL ANSWER\\\\n\\\\nHere is the graph showing the Total Fertility Rate (TFR) in South Korea from 2018 to 2022, along with the projected rates for 2024 and 2025:\\\\n\\\\n![Total Fertility Rate in South Korea (2018 - 2025)](sandbox:/code)\\\\n\\\\nPlease note that data for 2019 and 2023 is not available, and the projections for 2024 and 2025 are based on forecasts, not actual data.', name='Researcher')], 'sender': 'Researcher'}}\\n라이선스\\n```\\nMIT License\\nCopyright (c) LangChain, Inc.\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \\\"Software\\\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\nTHE SOFTWARE IS PROVIDED \\\"AS IS\\\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n```\\n태그: AutoGen, LangChain, LangGraph, LLM, Python, 그래프 기반 시스템, 노드, 다중 에이전트, 데이터 스트리밍, 딥러닝, 랭체인, 머신러닝, 멀티에이전트, 상태 정의, 에지 로직, 협업, 호출\\n카테고리: langgraph\\n업데이트: 2024년 01월 29일\\n공유하기\\nTwitter Facebook LinkedIn\\n이전 다음\\n댓글남기기\\n참고\\npoetry 의 거의 모든것 (튜토리얼)\\n2024년 03월 30일 5 분 소요\\nPython 개발에 있어서 poetry는 매우 강력한 도구로, 프로젝트의 의존성 관리와 패키지 배포를 간소화하는 데 큰 도움을 줍니다. 지금부터 poetry 활용 튜토리얼을 살펴 보겠습니다.\\nLangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\\n2024년 03월 06일 10 분 소요\\nLangGraph Retrieval Agent는 언어 처리, AI 모델 통합, 데이터베이스 관리, 그래프 기반 데이터 처리 등 다양한 기능을 제공하여 언어 기반 AI 애플리케이션 개발에 필수적인 도구입니다.\\n[Assistants API] Code Interpreter, Retrieval, Functions 활용법\\n2024년 02월 13일 35 분 소요\\nOpenAI의 새로운 Assistants API는 대화와 더불어 강력한 도구 접근성을 제공합니다. 본 튜토리얼은 OpenAI Assistants API를 활용하는 내용을 다룹니다. 특히, Assistant API 가 제공하는 도구인 Code Interpreter, Retrieval...\\n[LangChain] 에이전트(Agent)와 도구(tools)를 활용한 지능형 검색 시스템 구축 가이드\\n2024년 02월 09일 41 분 소요\\n이 글에서는 LangChain 의 Agent 프레임워크를 활용하여 복잡한 검색과 데이터 처리 작업을 수행하는 방법을 소개합니다. LangSmith 를 사용하여 Agent의 추론 단계를 추적합니다. Agent가 활용할 검색 도구(Tavily Search), PDF 기반 검색 리트리버...\\n\\n팔로우:\\nYouTube\\nGitHub\\nInstagram\\n피드\\n\\n© 2024 테디노트. Powered by Jekyll & Minimal Mistakes.\"}, {\"url\": \"https://teddylee777.github.io/langgraph/langgraph-agentic-rag/\", \"title\": \"LangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\", \"content\": \"{ 'messages': [ FunctionMessage(content='Table of Contents\\\\n\\\\n\\\\n\\\\nAgent System Overview\\\\n\\\\nComponent One: Planning\\\\n\\\\nTask Decomposition\\\\n\\\\nSelf-Reflection\\\\n\\\\n\\\\nComponent Two: Memory\\\\n\\\\nTypes of Memory\\\\n\\\\nMaximum Inner Product Search (MIPS)\\\\n\\\\n\\\\nComponent Three: Tool Use\\\\n\\\\nCase Studies\\\\n\\\\nScientific Discovery Agent\\\\n\\\\nGenerative Agents Simulation\\\\n\\\\nProof-of-Concept Examples\\\\n\\\\n\\\\nChallenges\\\\n\\\\nCitation\\\\n\\\\nReferences\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory\\\\n\\\\nMemory\\\\n\\\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\\\n\\\\n\\\\nTool use\\\\n\\\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.', name='retrieve_blog_posts')]}\", \"score\": 0.2270753, \"raw_content\": \"LangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리 - 테디노트\\n\\nSkip to primary navigation\\nSkip to content\\nSkip to footer\\n\\n테디노트 데이터와 인공지능을 좋아하는 개발자 노트\\n\\n검색\\n카테고리\\n태그\\n연도\\n강의\\n어바웃미\\n\\n토글 메뉴\\n\\nHome \\n/3.  Langgraph \\n/5.  LangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\\n\\n🔥알림🔥\\n① 테디노트 유튜브 - 구경하러 가기!\\n② LangChain 한국어 튜토리얼 바로가기 👀\\n③ 랭체인 노트 무료 전자책(wikidocs) 바로가기 🙌\\n④ RAG 비법노트 LangChain 강의오픈 바로가기 🙌\\n⑤ 서울대 PyTorch 딥러닝 강의 바로가기 🙌\\nLangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\\n2024년 03월 06일 10 분 소요\\n목차\\n\\n설치\\nLangGraph Retrieval Agent\\nRetriever\\nAgent state\\n노드와 엣지(Nodes and Edges)\\nGraph\\nReference\\n\\nLangGraph Retrieval Agent는 언어 처리, AI 모델 통합, 데이터베이스 관리, 그래프 기반 데이터 처리 등 다양한 기능을 제공하여 언어 기반 AI 애플리케이션 개발에 필수적인 도구입니다.\\n본 블로그에서는 LangGraph와 Retrieval Agent의 통합 과정, 구현 방법, 그리고 실제 사용 예시를 통해 이러한 도구들의 효과적인 활용 방법을 탐구합니다.\\nPython 코드를 중심으로 설명을 진행하며, 실제 구현 예시를 통해 문서 검색 및 처리의 전체 흐름을 이해할 수 있도록 구성되어 있습니다.\\n주요 내용\\n\\n📚 LangGraph와 Retrieval Agent 소개: 언어 기반 AI 애플리케이션 개발에 필수적인 도구들의 기능과 중요성을 설명합니다.\\n🛠️ 구현 방법: Python을 활용한 LangGraph Retrieval Agent의 구현 과정을 단계별로 설명합니다.\\n🌐 실제 사용 예시: 동적 문서 검색 및 처리의 실제 사용 예시를 통해 LangGraph와 Retrieval Agent의 통합 사용 방법을 탐구합니다.\\n📝 고급 기능과 활용: 검색 에이전트의 고급 기능과 다양한 활용 방안을 소개합니다.\\n🔄 상태 기반 그래프 작업 흐름: 상태 기반 그래프를 사용하여 복잡한 결정과 작업의 흐름을 관리하는 방법을 설명합니다.\\n\\n설치\\n다양한 언어 처리 및 AI 관련 라이브러리를 설치하는 명령어입니다. langchain_community, tiktoken, langchain-openai, langchainhub, chromadb, langchain, langgraph 등의 패키지를 포함합니다.\\n!pip install -qU langchain_community tiktoken langchain-openai langchainhub chromadb langchain langgraph\\nAPI KEY를 로드합니다.\\n```\\napi key\\nfrom dotenv import load_dotenv\\nload_dotenv()\\n```\\nTrue\\nLangGraph Retrieval Agent\\n검색 에이전트는 인덱스에서 검색할지 여부에 대한 결정을 내리고 싶을 때 유용합니다.\\n검색 에이전트를 구현하기 위해서는 LLM에 검색 도구에 대한 접근 권한을 제공하기만 하면 됩니다. 이를 LangGraph로 구현해 봅시다!\\nRetriever\\n첫 번째로, 3개의 블로그 게시물을 인덱싱합니다.\\n\\nWebBaseLoader를 사용하여 주어진 URL 목록에서 문서를 로드합니다.\\nRecursiveCharacterTextSplitter는 문서를 특정 크기의 청크로 분할하는 데 사용됩니다.\\n분할된 문서는 Chroma 벡터 저장소에 저장되며, OpenAIEmbeddings를 사용하여 임베딩됩니다.\\n이후, 저장된 문서는 검색을 위해 검색기(retriever)로 변환됩니다.\\n\\n```\\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\\nfrom langchain_community.document_loaders import WebBaseLoader\\nfrom langchain_community.vectorstores import Chroma\\nfrom langchain_openai import OpenAIEmbeddings\\nurls = [\\n    \\\"https://lilianweng.github.io/posts/2023-06-23-agent/\\\",\\n    \\\"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\\\",\\n    \\\"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\\\",\\n]\\ndocs = [WebBaseLoader(url).load() for url in urls]\\ndocs_list = [item for sublist in docs for item in sublist]\\ntext_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\\n    chunk_size=100, chunk_overlap=50\\n)\\ndoc_splits = text_splitter.split_documents(docs_list)\\n벡터 데이터베이스에 문서 추가\\nvectorstore = Chroma.from_documents(\\n    documents=doc_splits,\\n    collection_name=\\\"rag-chroma\\\",\\n    embedding=OpenAIEmbeddings(),\\n)\\nretriever = vectorstore.as_retriever()\\n```\\nLangChain의 create_retriever_tool 함수를 사용하여 특정 주제에 대한 블로그 게시물을 검색하고 정보를 반환하는 도구를 생성합니다. 이 예제에서는 Lilian Weng의 블로그 게시물 중 LLM 에이전트, 프롬프트 엔지니어링, LLM에 대한 적대적 공격에 관한 정보를 검색합니다.\\n생성된 도구는 ToolExecutor 클래스의 인스턴스에 등록되어 실행될 준비가 됩니다. ToolExecutor는 등록된 모든 도구를 관리하고 실행하는 역할을 담당합니다.\\n```\\nfrom langgraph.prebuilt import ToolExecutor\\nfrom langchain.tools.retriever import create_retriever_tool\\n릴리안 웡의 블로그 게시물에 대한 정보를 검색하고 반환하는 도구를 생성합니다.\\ntool = create_retriever_tool(\\n    retriever,\\n    \\\"retrieve_blog_posts\\\",\\n    \\\"Search and return information about Lilian Weng blog posts on LLM agents, prompt engineering, and adversarial attacks on LLMs.\\\",\\n)\\ntools = [tool]\\n도구들을 실행할 ToolExecutor 객체를 생성합니다.\\ntool_executor = ToolExecutor(tools)\\n```\\nAgent state\\n그래프를 정의해야 합니다.\\n\\nAgentState 는 각 노드에 전달하는 state 객체입니다.\\nAgentState 는 messages의 리스트로 담깁니다.\\n그런 다음 그래프의 각 노드는 AgentState 를 추가합니다.\\n\\n```\\nimport operator\\nfrom typing import Annotated, Sequence, TypedDict\\nfrom langchain_core.messages import BaseMessage\\nclass AgentState(TypedDict):\\n    # AgentState 클래스는 메시지 시퀀스를 포함하는 타입 딕셔너리입니다.\\n    messages: Annotated[Sequence[BaseMessage], operator.add]\\n```\\n노드와 엣지(Nodes and Edges)\\n우리는 agentic RAG 그래프를 다음과 같이 구성할 수 있습니다\\n\\n\\n상태는 메시지의 집합입니다\\n\\n\\n각 노드는 상태를 업데이트(추가)합니다\\n\\n\\n조건부 엣지는 다음에 방문할 노드를 결정합니다\\n\\n\\n\\n문서 검색, 관련성 평가, 질문 재구성, 그리고 답변 생성을 포함하는 정보 검색 및 처리 프로세스를 구현합니다.\\n\\n첫 단계에서는 에이전트가 추가 정보를 검색해야 하는지 결정합니다(should_retrieve).\\n다음으로, 검색된 문서가 주어진 질문과 관련이 있는지 평가합니다(grade_documents).\\n이후, 질문을 재구성하여 더 나은 질문을 생성합니다(rewrite).\\n마지막으로, 최종적으로 검색된 문서를 바탕으로 답변을 생성합니다(generate).\\n\\n각 단계는 특정 입력에 따라 동작하며, 이 과정은 대화형 에이전트나 정보 검색 시스템에서 유용하게 사용될 수 있습니다.\\n```\\nimport json\\nimport operator\\nfrom typing import Annotated, Sequence, TypedDict\\nfrom langchain import hub\\nfrom langchain.output_parsers import PydanticOutputParser\\nfrom langchain.prompts import PromptTemplate\\nfrom langchain.tools.render import format_tool_to_openai_function\\nfrom langchain_core.utils.function_calling import convert_to_openai_tool\\nfrom langchain_core.messages import BaseMessage, FunctionMessage\\nfrom langchain.output_parsers.openai_tools import PydanticToolsParser\\nfrom langchain_core.pydantic_v1 import BaseModel, Field\\nfrom langchain_openai import ChatOpenAI\\nfrom langgraph.prebuilt import ToolInvocation\\nfrom langchain_core.output_parsers import StrOutputParser\\nEdges\\ndef should_retrieve(state):\\n    \\\"\\\"\\\"\\n    에이전트가 더 많은 정보를 검색해야 하는지 또는 프로세스를 종료해야 하는지 결정합니다.\\n이 함수는 상태의 마지막 메시지에서 함수 호출을 확인합니다. 함수 호출이 있으면 정보 검색 프로세스를 계속합니다. 그렇지 않으면 프로세스를 종료합니다.\\n\\nArgs:\\n    state (messages): 현재 상태\\n\\nReturns:\\n    str: 검색 프로세스를 \\\"계속\\\"하거나 \\\"종료\\\"하는 결정\\n\\\"\\\"\\\"\\n\\nprint(\\\"---DECIDE TO RETRIEVE---\\\")\\nmessages = state[\\\"messages\\\"]\\nlast_message = messages[-1]\\n\\n# 함수 호출이 없으면 종료합니다.\\nif \\\"function_call\\\" not in last_message.additional_kwargs:\\n    print(\\\"---DECISION: DO NOT RETRIEVE / DONE---\\\")\\n    return \\\"end\\\"\\n# 그렇지 않으면 함수 호출이 있으므로 계속합니다.\\nelse:\\n    print(\\\"---DECISION: RETRIEVE---\\\")\\n    return \\\"continue\\\"\\n\\ndef grade_documents(state):\\n    \\\"\\\"\\\"\\n    검색된 문서가 질문과 관련이 있는지 여부를 결정합니다.\\nArgs:\\n    state (messages): 현재 상태\\n\\nReturns:\\n    str: 문서가 관련이 있는지 여부에 대한 결정\\n\\\"\\\"\\\"\\n\\nprint(\\\"---CHECK RELEVANCE---\\\")\\n\\n# 데이터 모델\\nclass grade(BaseModel):\\n    \\\"\\\"\\\"관련성 검사를 위한 이진 점수.\\\"\\\"\\\"\\n\\n    binary_score: str = Field(description=\\\"'yes' 또는 'no'의 관련성 점수\\\")\\n\\n# LLM\\nmodel = ChatOpenAI(\\n    temperature=0, model=\\\"gpt-4-0125-preview\\\", streaming=True)\\n\\n# 도구\\ngrade_tool_oai = convert_to_openai_tool(grade)\\n\\n# 도구와 강제 호출을 사용한 LLM\\nllm_with_tool = model.bind(\\n    tools=[convert_to_openai_tool(grade_tool_oai)],\\n    tool_choice={\\\"type\\\": \\\"function\\\", \\\"function\\\": {\\\"name\\\": \\\"grade\\\"}},\\n)\\n\\n# 파서\\nparser_tool = PydanticToolsParser(tools=[grade])\\n\\n# 프롬프트\\nprompt = PromptTemplate(\\n    template=\\\"\\\"\\\"You are a grader assessing relevance of a retrieved document to a user question. \\\\n \\n    Here is the retrieved document: \\\\n\\\\n {context} \\\\n\\\\n\\n    Here is the user question: {question} \\\\n\\n    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\\\n\\n    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\\\"\\\"\\\",\\n    input_variables=[\\\"context\\\", \\\"question\\\"],\\n)\\n\\n# 체인\\nchain = prompt | llm_with_tool | parser_tool\\n\\nmessages = state[\\\"messages\\\"]\\nlast_message = messages[-1]\\n\\nquestion = messages[0].content\\ndocs = last_message.content\\n\\nscore = chain.invoke({\\\"question\\\": question, \\\"context\\\": docs})\\n\\ngrade = score[0].binary_score\\n\\nif grade == \\\"yes\\\":\\n    print(\\\"---DECISION: DOCS RELEVANT---\\\")\\n    return \\\"yes\\\"\\n\\nelse:\\n    print(\\\"---DECISION: DOCS NOT RELEVANT---\\\")\\n    print(grade)\\n    return \\\"no\\\"\\n\\nNodes\\ndef agent(state):\\n    \\\"\\\"\\\"\\n    현재 상태를 기반으로 에이전트 모델을 호출하여 응답을 생성합니다. 질문에 따라 검색 도구를 사용하여 검색을 결정하거나 단순히 종료합니다.\\nArgs:\\n    state (messages): 현재 상태\\n\\nReturns:\\n    dict: 메시지에 에이전트 응답이 추가된 업데이트된 상태\\n\\\"\\\"\\\"\\nprint(\\\"---CALL AGENT---\\\")\\nmessages = state[\\\"messages\\\"]\\nmodel = ChatOpenAI(temperature=0, streaming=True,\\n                   model=\\\"gpt-4-0125-preview\\\")\\nfunctions = [format_tool_to_openai_function(t) for t in tools]\\nmodel = model.bind_functions(functions)\\nresponse = model.invoke(messages)\\n# 이것은 기존 목록에 추가될 것이므로 리스트를 반환합니다.\\nreturn {\\\"messages\\\": [response]}\\n\\ndef retrieve(state):\\n    \\\"\\\"\\\"\\n    도구를 사용하여 검색을 실행합니다.\\nArgs:\\n    state (messages): 현재 상태\\n\\nReturns:\\n    dict: 검색된 문서가 추가된 업데이트된 상태\\n\\\"\\\"\\\"\\nprint(\\\"---EXECUTE RETRIEVAL---\\\")\\nmessages = state[\\\"messages\\\"]\\n# 계속 조건을 기반으로 마지막 메시지가 함수 호출을 포함하고 있음을 알 수 있습니다.\\nlast_message = messages[-1]\\n# 함수 호출에서 ToolInvocation을 구성합니다.\\naction = ToolInvocation(\\n    tool=last_message.additional_kwargs[\\\"function_call\\\"][\\\"name\\\"],\\n    tool_input=json.loads(\\n        last_message.additional_kwargs[\\\"function_call\\\"][\\\"arguments\\\"]\\n    ),\\n)\\n# 도구 실행자를 호출하고 응답을 받습니다.\\nresponse = tool_executor.invoke(action)\\nfunction_message = FunctionMessage(content=str(response), name=action.tool)\\n\\n# 이것은 기존 목록에 추가될 것이므로 리스트를 반환합니다.\\nreturn {\\\"messages\\\": [function_message]}\\n\\ndef rewrite(state):\\n    \\\"\\\"\\\"\\n    질문을 변형하여 더 나은 질문을 생성합니다.\\nArgs:\\n    state (messages): 현재 상태\\n\\nReturns:\\n    dict: 재구성된 질문이 추가된 업데이트된 상태\\n\\\"\\\"\\\"\\n\\nprint(\\\"---TRANSFORM QUERY---\\\")\\nmessages = state[\\\"messages\\\"]\\nquestion = messages[0].content\\n\\nmsg = [\\n    HumanMessage(\\n        content=f\\\"\\\"\\\" \\\\n \\nLook at the input and try to reason about the underlying semantic intent / meaning. \\\\n \\nHere is the initial question:\\n\\\\n ------- \\\\n\\n{question} \\n\\\\n ------- \\\\n\\nFormulate an improved question: \\\"\\\"\\\",\\n    )\\n]\\n\\n# 평가자\\nmodel = ChatOpenAI(\\n    temperature=0, model=\\\"gpt-4-0125-preview\\\", streaming=True)\\nresponse = model.invoke(msg)\\nreturn {\\\"messages\\\": [response]}\\n\\ndef generate(state):\\n    \\\"\\\"\\\"\\n    답변 생성\\nArgs:\\n    state (messages): 현재 상태\\n\\nReturns:\\n     dict: 재구성된 질문이 추가된 업데이트된 상태\\n\\\"\\\"\\\"\\nprint(\\\"---GENERATE---\\\")\\nmessages = state[\\\"messages\\\"]\\nquestion = messages[0].content\\nlast_message = messages[-1]\\n\\nquestion = messages[0].content\\ndocs = last_message.content\\n\\n# 프롬프트\\nprompt = hub.pull(\\\"rlm/rag-prompt\\\")\\n\\n# LLM\\nllm = ChatOpenAI(model_name=\\\"gpt-4-turbo-preview\\\",\\n                 temperature=0, streaming=True)\\n\\n# 후처리\\ndef format_docs(docs):\\n    return \\\"\\\\n\\\\n\\\".join(doc.page_content for doc in docs)\\n\\n# 체인\\nrag_chain = prompt | llm | StrOutputParser()\\n\\n# 실행\\nresponse = rag_chain.invoke({\\\"context\\\": docs, \\\"question\\\": question})\\nreturn {\\\"messages\\\": [response]}\\n\\n```\\nGraph\\n\\n\\n에이전트로 시작하며, call_model\\n\\n\\n에이전트는 함수를 호출할지 결정합니다\\n\\n\\n만약 호출한다면, 도구(검색기)를 호출하는 action을 수행합니다\\n\\n\\n그 다음 메시지(state)에 도구의 출력을 추가하여 에이전트를 호출합니다\\n\\n\\nStateGraph 클래스는 상태 기반 그래프를 정의하고 관리하는 데 사용됩니다.\\n```\\nfrom langgraph.graph import END, StateGraph\\nlanggraph.graph에서 StateGraph와 END를 가져옵니다.\\nworkflow = StateGraph(AgentState)\\n순환할 노드들을 정의합니다.\\nworkflow.add_node(\\\"agent\\\", agent)  # 에이전트 노드를 추가합니다.\\nworkflow.add_node(\\\"retrieve\\\", retrieve)  # 정보 검색 노드를 추가합니다.\\nworkflow.add_node(\\\"rewrite\\\", rewrite)  # 정보 재작성 노드를 추가합니다.\\nworkflow.add_node(\\\"generate\\\", generate)  # 정보 생성 노드를 추가합니다.\\n```\\n주어진 코드는 워크플로우를 설정하여 에이전트의 결정에 따라 문서를 검색하거나 다른 작업을 수행하는 과정을 정의합니다.\\n처음에는 agent 노드를 시작점으로 설정하고, 에이전트의 결정(should_retrieve)에 따라 retrieve 노드를 호출하거나 작업을 종료합니다.\\nretrieve 노드 이후에는 문서의 평가(grade_documents)를 통해 generate 또는 rewrite 작업을 결정하고, 각각의 경로를 따라 최종적으로 작업을 마무리하거나 에이전트로 돌아가는 과정을 포함합니다.\\n이 과정은 복잡한 결정과 작업의 흐름을 관리하는 데 사용될 수 있으며, 최종적으로 워크플로우를 컴파일하여 실행 가능한 애플리케이션을 생성합니다.\\n```\\n에이전트 노드 호출하여 검색 여부 결정\\nworkflow.set_entry_point(\\\"agent\\\")\\n검색 여부 결정\\nworkflow.add_conditional_edges(\\n    \\\"agent\\\",\\n    # 에이전트 결정 평가\\n    should_retrieve,\\n    {\\n        # 도구 노드 호출\\n        \\\"continue\\\": \\\"retrieve\\\",\\n        \\\"end\\\": END,\\n    },\\n)\\naction 노드 호출 후 진행될 경로\\nworkflow.add_conditional_edges(\\n    \\\"retrieve\\\",\\n    # 에이전트 결정 평가\\n    grade_documents,\\n    {\\n        \\\"yes\\\": \\\"generate\\\",\\n        \\\"no\\\": \\\"rewrite\\\",\\n    },\\n)\\nworkflow.add_edge(\\\"generate\\\", END)\\nworkflow.add_edge(\\\"rewrite\\\", \\\"agent\\\")\\n컴파일\\napp = workflow.compile()\\n```\\n다음은 langchain_core.messages 모듈의 HumanMessage 클래스를 활용하여 사용자의 질문을 정의하고, app.stream 메소드를 통해 이 질문에 대한 응답을 스트리밍하는 과정을 보여줍니다.\\n```\\nimport pprint\\nfrom langchain_core.messages import HumanMessage\\nHumanMessage 객체를 사용하여 질문 메시지를 정의합니다.\\ninputs = {\\n    \\\"messages\\\": [\\n        HumanMessage(\\n            content=\\\"What does Lilian Weng say about the types of agent memory?\\\"\\n        )\\n    ]\\n}\\napp.stream을 통해 입력된 메시지에 대한 출력을 스트리밍합니다.\\nfor output in app.stream(inputs):\\n    # 출력된 결과에서 키와 값을 순회합니다.\\n    for key, value in output.items():\\n        # 노드의 이름과 해당 노드에서 나온 출력을 출력합니다.\\n        pprint.pprint(f\\\"Output from node '{key}':\\\")\\n        pprint.pprint(\\\"---\\\")\\n        # 출력 값을 예쁘게 출력합니다.\\n        pprint.pprint(value, indent=2, width=80, depth=None)\\n    # 각 출력 사이에 구분선을 추가합니다.\\n    pprint.pprint(\\\"\\\\n---\\\\n\\\")\\n```\\n---CALL AGENT---\\n\\\"Output from node 'agent':\\\"\\n'---'\\n{ 'messages': [ AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\\"query\\\":\\\"types of agent memory\\\"}', 'name': 'retrieve_blog_posts'}})]}\\n'\\\\n---\\\\n'\\n---DECIDE TO RETRIEVE---\\n---DECISION: RETRIEVE---\\n---EXECUTE RETRIEVAL---\\n\\\"Output from node 'retrieve':\\\"\\n'---'\\n{ 'messages': [ FunctionMessage(content='Table of Contents\\\\n\\\\n\\\\n\\\\nAgent System Overview\\\\n\\\\nComponent One: Planning\\\\n\\\\nTask Decomposition\\\\n\\\\nSelf-Reflection\\\\n\\\\n\\\\nComponent Two: Memory\\\\n\\\\nTypes of Memory\\\\n\\\\nMaximum Inner Product Search (MIPS)\\\\n\\\\n\\\\nComponent Three: Tool Use\\\\n\\\\nCase Studies\\\\n\\\\nScientific Discovery Agent\\\\n\\\\nGenerative Agents Simulation\\\\n\\\\nProof-of-Concept Examples\\\\n\\\\n\\\\nChallenges\\\\n\\\\nCitation\\\\n\\\\nReferences\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory\\\\n\\\\nMemory\\\\n\\\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\\\n\\\\n\\\\nTool use\\\\n\\\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.', name='retrieve_blog_posts')]}\\n'\\\\n---\\\\n'\\n---CHECK RELEVANCE---\\n---DECISION: DOCS RELEVANT---\\n---GENERATE---\\n\\\"Output from node 'generate':\\\"\\n'---'\\n{ 'messages': [ 'Lilian Weng discusses two types of agent memory: short-term '\\n                'memory, which involves in-context learning and utilizes the '\\n                \\\"model's immediate memory to learn, and long-term memory, \\\"\\n                'which allows an agent to retain and recall information over '\\n                'extended periods, often through the use of an external vector '\\n                'store for fast retrieval.']}\\n'\\\\n---\\\\n'\\n\\\"Output from node '__end__':\\\"\\n'---'\\n{ 'messages': [ HumanMessage(content='What does Lilian Weng say about the types of agent memory?'),\\n                AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\\"query\\\":\\\"types of agent memory\\\"}', 'name': 'retrieve_blog_posts'}}),\\n                FunctionMessage(content='Table of Contents\\\\n\\\\n\\\\n\\\\nAgent System Overview\\\\n\\\\nComponent One: Planning\\\\n\\\\nTask Decomposition\\\\n\\\\nSelf-Reflection\\\\n\\\\n\\\\nComponent Two: Memory\\\\n\\\\nTypes of Memory\\\\n\\\\nMaximum Inner Product Search (MIPS)\\\\n\\\\n\\\\nComponent Three: Tool Use\\\\n\\\\nCase Studies\\\\n\\\\nScientific Discovery Agent\\\\n\\\\nGenerative Agents Simulation\\\\n\\\\nProof-of-Concept Examples\\\\n\\\\n\\\\nChallenges\\\\n\\\\nCitation\\\\n\\\\nReferences\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory\\\\n\\\\nMemory\\\\n\\\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\\\n\\\\n\\\\nTool use\\\\n\\\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.', name='retrieve_blog_posts'),\\n                'Lilian Weng discusses two types of agent memory: short-term '\\n                'memory, which involves in-context learning and utilizes the '\\n                \\\"model's immediate memory to learn, and long-term memory, \\\"\\n                'which allows an agent to retain and recall information over '\\n                'extended periods, often through the use of an external vector '\\n                'store for fast retrieval.']}\\n'\\\\n---\\\\n'\\nReference\\n본 튜토리얼은 langchain-ai 튜토리얼 노트북 파일을 참조하여 작성하였습니다.\\n본 내용의 저작권은 2024년 테디노트(https://teddylee777.github.io)에 있습니다. 모든 권리는 저작권자에게 있으며, teddylee777@gmail.com으로 문의할 수 있습니다.\\n본 내용의 무단 전재 및 재배포를 금지합니다. 본 내용의 전체 혹은 일부를 인용할 경우, 출처를 명확히 밝혀주시기 바랍니다.\\n본 문서는 다른 문서의 내용을 참고하여 작성되었을 수 있습니다. 참고 자료는 본 문서 하단의 출처 목록에서 확인하실 수 있습니다.\\n\\n본 문서의 원 저작권자는 langchain-ai 이며, 코드는 MIT License 에 따라 사용이 허가된 파일입니다.\\n원문 바로가기\\n\\n태그: AI 애플리케이션, langchain, langgraph, openai, python, retrieval agent, 검색 에이전트, 그래프 기반 데이터 처리, 데이터베이스 관리, 문서 검색, 정보 처리\\n카테고리: langgraph\\n업데이트: 2024년 03월 06일\\n공유하기\\nTwitter Facebook LinkedIn\\n이전 다음\\n댓글남기기\\n참고\\npoetry 의 거의 모든것 (튜토리얼)\\n2024년 03월 30일 5 분 소요\\nPython 개발에 있어서 poetry는 매우 강력한 도구로, 프로젝트의 의존성 관리와 패키지 배포를 간소화하는 데 큰 도움을 줍니다. 지금부터 poetry 활용 튜토리얼을 살펴 보겠습니다.\\n[Assistants API] Code Interpreter, Retrieval, Functions 활용법\\n2024년 02월 13일 34 분 소요\\nOpenAI의 새로운 Assistants API는 대화와 더불어 강력한 도구 접근성을 제공합니다. 본 튜토리얼은 OpenAI Assistants API를 활용하는 내용을 다룹니다. 특히, Assistant API 가 제공하는 도구인 Code Interpreter, Retrieval...\\n[LangChain] 에이전트(Agent)와 도구(tools)를 활용한 지능형 검색 시스템 구축 가이드\\n2024년 02월 09일 41 분 소요\\n이 글에서는 LangChain 의 Agent 프레임워크를 활용하여 복잡한 검색과 데이터 처리 작업을 수행하는 방법을 소개합니다. LangSmith 를 사용하여 Agent의 추론 단계를 추적합니다. Agent가 활용할 검색 도구(Tavily Search), PDF 기반 검색 리트리버...\\nLangChain RAG 파헤치기: 문서 기반 QA 시스템 설계 방법 - 심화편\\n2024년 02월 06일 22 분 소요\\nLangChain의 RAG 시스템을 통해 문서(PDF, txt, 웹페이지 등)에 대한 질문-답변을 찾는 과정을 정리하였습니다.\\n\\n팔로우:\\nYouTube\\nGitHub\\nInstagram\\n피드\\n\\n© 2024 테디노트. Powered by Jekyll & Minimal Mistakes.\"}, {\"url\": \"https://teddylee777.github.io/langchain/langchain-agent/\", \"title\": \"[LangChain] 에이전트(Agent)와 도구(tools)를 활용한 지능형 ...\", \"content\": \"Document(page_content='SPRi AI Brief |  \\\\n2023-12 월호\\\\n14유튜브 , 2024년부터 AI 생성 콘텐츠 표시 의무화 \\\\nn유튜브가 몇 달 안에 생성 AI를 사용한 콘텐츠에 AI 라벨 표시를 의무화하기로 했으며 , 이를 \\\\n준수하지 않는 콘텐츠는 삭제하고 크리에이터에 대한 수익 배분도 중단할 수 있다고 설명\\\\nn유튜브는 AI 생성 콘텐츠가 신원 파악이 가능한 개인을 모방한 경우 개인정보 침해 신고 \\\\n절차에 따라 콘텐츠 삭제 요청도 받을 계획KEY Contents\\\\n£유튜브 , 생성 AI 콘텐츠에 AI 라벨 표시 안 하면 콘텐츠 삭제\\\\nn유튜브가 2023 년 11월 14일 공식 블로그를 통해 몇 달 안에 생성 AI를 사용한 콘텐츠에 AI \\\\n라벨을 표시하는 새로운 규칙을 시행한다고 발표 \\\\n∙실제로 일어나지 않은 사건을 사실적으로 묘사하거나 실제로 하지 않은 말이나 행동을 보여주는 콘텐츠와 \\\\n같이 AI 도구를 사용해 사실적으로 변경되거나 합성된 콘텐츠에는 AI 라벨을 표시 필요\\\\n∙유튜브는 이러한 규칙이 선거나 분쟁 상황, 공중 보건, 공직자 관련 문제와 같이 민감한 주제를 다루는 \\\\n콘텐츠에서 특히 중요하다고 강조했으며 , 크리에이터가 AI로 제작한 콘텐츠에 AI 라벨을 표시하지 않으면 \\\\n해당 콘텐츠는 삭제되고 광고 수익을 배분하는 유튜브 파트너 프로그램도 정지될 수 있음\\\\n∙유튜브는 두 가지 방식으로 AI를 이용한 콘텐츠의 변경이나 합성 여부를 시청자에게 전달할 계획으로 \\\\n동영상 설명 패널에 라벨을 표시하는 방식이 기본이며 , 민감한 주제를 다루는 특정 유형의 콘텐츠는 동영상 \\\\n플레이어에 더욱 눈에 띄는 라벨을 적용 \\\\n∙유튜브는 커뮤니티 정책에 위반되는 일부 합성 콘텐츠에 대해서는 라벨 지정 여부와 관계없이 삭제할 \\\\n방침으로 , 가령 사실적인 폭력을 보여주는 합성 동영상이 시청자에게 충격이나 혐오감을 줄 수 있다면 \\\\n삭제될 수 있음\\\\n£유튜브 , 특정인을 모방한 AI 생성 콘텐츠에 대한 삭제 요청에도 대응 계획', metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 16})\", \"score\": 0.022839706, \"raw_content\": \"Published Time: 2024-02-09T00:00:00+00:00\\n[LangChain] 에이전트(Agent)와 도구(tools)를 활용한 지능형 검색 시스템 구축 가이드 - 테디노트\\n\\nSkip to primary navigation\\nSkip to content\\nSkip to footer\\n\\n테디노트 데이터와 인공지능을 좋아하는 개발자 노트\\n\\n검색\\n카테고리\\n태그\\n연도\\n강의\\n어바웃미\\n\\n토글 메뉴\\n\\nHome \\n/3.  Langchain \\n/5.  [LangChain] 에이전트(Agent)와 도구(tools)를 활용한 지능형 검색 시스템 구축 가이드\\n\\n🔥알림🔥\\n① 테디노트 유튜브 - 구경하러 가기!\\n② LangChain 한국어 튜토리얼 바로가기 👀\\n③ 랭체인 노트 무료 전자책(wikidocs) 바로가기 🙌\\n④ RAG 비법노트 LangChain 강의오픈 바로가기 🙌\\n⑤ 서울대 PyTorch 딥러닝 강의 바로가기 🙌\\n[LangChain] 에이전트(Agent)와 도구(tools)를 활용한 지능형 검색 시스템 구축 가이드\\n2024년 02월 09일 41 분 소요\\n목차\\n\\n🤖 Agent 란?\\n단계별 추적을 위한 LangSmith 설정\\n\\n\\n① 도구(Tools)\\n검색도구: Tavily Search\\nPDF 기반 문서 검색 도구: Retriever\\nAgent 가 사용할 도구 목록 정의\\n\\n\\n② 에이전트 생성\\n③ 에이전트 실행하기\\n④ 메모리 추가하기\\n📍 전체 템플릿 코드\\nReference\\n\\n이 글에서는 LangChain 의 Agent 프레임워크를 활용하여 복잡한 검색과 데이터 처리 작업을 수행하는 방법을 소개합니다. LangSmith 를 사용하여 Agent의 추론 단계를 추적합니다. Agent가 활용할 검색 도구(Tavily Search), PDF 기반 검색 리트리버(Retriever) 와 같은 도구(tools) 를 사용하여 에이전트를 구축하고 실행하는 과정을 단계별로 알아보도록 하겠습니다.\\n주요내용\\n\\n🤖 에이전트의 개념과 구축 방법에 대한 설명\\n🔍 Tavily Search와 같은 검색 도구, PDF 기반 검색 도구를 정의하는 법\\n🛠 에이전트가 사용할 도구 목록 생성 및 정의\\n🚀 AgentExecutor를 통한 에이전트 실행 및 상호작용\\n🧠 상태 유지를 위한 메모리 기능 구현\\n📍 완성형 템플릿 코드\\n\\n🤖 Agent 란?\\n에이전트 프레임워크를 가장 잘 이해하기 위해서, 온라인에서 정보를 찾는 도구 하나와 우리가 인덱스로 로드한 특정 데이터를 찾는 도구 하나를 가진 에이전트를 만들어 보겠습니다.\\n아래의 링크에서 LangChain 의 Agent 프레임워크 컨셉을 자세히 살펴보실 수 있습니다.\\n\\n공식 도큐먼트 - Agent Concepts\\n\\n단계별 추적을 위한 LangSmith 설정\\nLangChain으로 구축한 애플리케이션은 여러 단계에 걸쳐 LLM 호출을 여러 번 사용하게 됩니다.\\n단계별로 호출되는 로직이 더 복잡해짐에 따라, 체인이나 에이전트 내부에서 정확히 무슨 일이 일어나고 있는지 조사할 수 있는 능력이 매우 중요해집니다. 이를 위한 최선의 방법은 LangSmith를 사용하는 것입니다.\\nLangSmith가 필수는 아니지만, 매우 유용한 도구입니다. LangSmith를 사용하고 싶다면, 위의 링크에서 가입한 후, 로깅 추적을 시작하기 위해 환경 변수를 설정해야 합니다.\\n① 도구(Tools)\\nAgent 가 활용할 도구를 정의하여 Agent 가 추론(reasoning)을 수행할 때 활용하도록 만들 수 있습니다.\\nTavily Search 는 그 중 대표적인 검색 도구 입니다. 검색을 통해 최신 정보에 접근하여 검색 결과를 가지고 답변을 생성할 수 있습니다. 도구는 이처럼 검색 도구 뿐만아니라 Python 코드를 실행할 수 있는 도구, 직접 정의한 함수를 실행하는 도구 등 다양한 종류와 방법론을 제공합니다.\\n검색도구: Tavily Search\\nLangChain에는 Tavily 검색 엔진을 도구로 쉽게 사용할 수 있는 내장 도구가 있습니다.\\nTavily Search 를 사용하기 위해서는 API KEY를 발급 받아야 합니다.\\n\\nTavily Search API 발급받기\\n\\n발급 받은 API KEY 를 다음과 같이 환경변수에 등록 합니다.\\n아래 코드의 주석을 풀고 발급받은 API KEY 를 설정합니다.\\n```\\nimport os\\nTAVILY API KEY를 기입합니다.\\nos.environ[\\\"TAVILY_API_KEY\\\"] = \\\"TAVILY API KEY 입력\\\"\\n디버깅을 위한 프로젝트명을 기입합니다.\\nos.environ[\\\"LANGCHAIN_PROJECT\\\"] = \\\"AGENT TUTORIAL\\\"\\n```\\n```\\nAPI KEY를 환경변수로 관리하기 위한 설정 파일\\nfrom dotenv import load_dotenv\\nAPI KEY 정보로드\\nload_dotenv()\\n```\\nTrue\\n```\\nTavilySearchResults 클래스를 langchain_community.tools.tavily_search 모듈에서 가져옵니다.\\nfrom langchain_community.tools.tavily_search import TavilySearchResults\\nTavilySearchResults 클래스의 인스턴스를 생성합니다\\nk=5은 검색 결과를 5개까지 가져오겠다는 의미입니다\\nsearch = TavilySearchResults(k=5)\\n```\\nsearch.invoke 함수는 주어진 문자열에 대한 검색을 실행합니다.\\ninvoke() 함수에 검색하고 싶은 검색어를 넣어 검색을 수행합니다.\\n```\\n검색 결과를 가져옵니다.\\nsearch.invoke(\\\"판교 카카오 프렌즈샵 아지트점의 전화번호는 무엇인가요?\\\")\\n```\\n[{'url': 'https://smilemonkey.tistory.com/entry/판교-아지트-건물-카카오-프렌즈-샵-오픈-예정-22년-가을',\\n  'content': '카카오 신규 오피스인 판교 아지트에 위치한 카카오 프렌즈 샵이 22년 가을에 오픈 예정입니다. 아직 오픈 전이라 다른 카카오 프렌즈 샵과 차별화되는 포인트가 무엇이 될지 오픈에 대한 기대감이 있습니다.  여담이지만 카카오 직원들이 근무하는 아지트 건물에 있는 만큼 공장 도매가로 살 수 있다면 좋겠다는 생각을 잠시 해봤습니다. 현재 판교 아지트가 위치한 판교에는 현대백화점 판교점에 카카오프렌즈샵이 운영 중에  카카오프렌즈샵이\\\\xa0현재\\\\xa0판교\\\\xa0아지트\\\\xa0건물\\\\xa01층에\\\\xa0오픈을\\\\xa0위해\\\\xa0공사  행복신사 판교 아지트 건물 내에 카카오 프렌즈 샵 오픈카카오 신규 오피스인 판교 아지트에 위치한 카카오 프렌즈 샵이 22년 가을에 오픈 예정 입니다. 아직 오픈 전이라 다른 카카오 프렌즈 샵과 차별화되는 포인트가 무엇이 될지 오픈에 대한 기대감이 있습니다. # 함께 보면 좋은 글 이마트 일렉트로마트 애플 제품 - 수험생 할인 혜택/프로모션 (수험생 선물 추천) [2023년 연말정산 준비] 직장인 연말정산 총정리 (작년과 달라진 점, 환급액 늘리는 방법, 세테크) 미슐랭 가이드 서울 2023 레스토랑 리스트 총정리 (지도 위치, 신규 등극) 제주도 국제공항 내에 면세점에 입점되어 있는 카카오 프렌즈 샵과 같이 차별화된 제품 판매나 이벤트가 있으면 좋겠습니다.'},\\n {'url': 'https://m.blog.naver.com/hj961030/222923648353',\\n  'content': '블로그 카테고리 이동 ♥n2u1_늘이의 여행일기♥ 카카오프렌즈 판교 아지트점 판교의 카카오프렌즈를 소개합니다. 2022. 11. 8. 21:39 카카오프렌즈 판교 아지트점 문구, 펜시 \\\\u200b  \\\\u200b 모두 모두 카카오프렌즈 판교 아지트점에서 만나요-! 경기도 성남시 분당구 판교역로 166 \\\\u200b ♥n2u1_늘이의 여행일기♥ 이 블로그 경기도 카테고리 글 카테고리 이 블로그 경기도 카테고리 글  \\\\u200b 카카오프렌즈 판교 아지트점은 2022년 11월 07일 바로 어제 오픈을 한 따끈따근한 곳이랍니다!!! 입구에 발을 들이자마자 보이는 건 아주 아주 커다란 춘식이에요~!!  아참-! 판교 아지트점에서 숨은 라이언 찾기 이벤트도 진행하고 있으니 참여하면 좋겠죠?!! 그럼 오늘은 여기까지 소개를 드리도록 하겠습니다! 직접 보면 더 예쁜 카카오프렌즈 판교 아지트점 \\\\u200b카카오프렌즈 판교 아지트점 문구, 펜시 주소 : 경기 성남시 분당구 판교역로 166 1층 시간 : 월 - 금 10:00 - 21:00 / 토 - 일 12:00 - 20:00 주차장 : 지하 주차장이 있어요! 카카오아지트는 회차 20분 무료, 기본 30분에 1,000원 입니다! 판교역 4번출구에서 걸어서 1분 거리에 위치해요! 카카오프렌즈 판교 아지트점을 방문해야하는 이유-! 01. 어제 오픈한 따끈한 신상 매장이에요! 02. 가격에 상관없이 구매만 하면 춘식이 얼굴 풍선을 받을 수 있어요! (11월 7일 부터 소진시까지) 03. 3만원 이상 구매 시 라이언 또는 어피치 문구 세트를 받을 수 있어요! 04.'},\\n {'url': 'https://m.blog.naver.com/celina_827/222924602339',\\n  'content': '판교에 드디어 카카오 프렌즈샵이 카카오 본사 아지트 건물 1층에 오픈 했어요!! \\\\u200b 들어가는 입구는 많지만 지금 설명하는 방향은.... 흐음.... 4번출구에서부터 시작 입니다 ㅎㅎ  사원증한 프렌즈들 너무 귀엽다!!! 너무 귀여운 카카오 속 세상이예요ㅠㅠ \\\\u200b 경기도 성남시 분당구 판교역로 166 💬카카오프렌즈샵 아지트점은 판교역 1번 출구, 4번 출구를 이용하셔도 되고,  블로그 카테고리 이동 셀리나의 DAILY EPISODE [판교] 카카오(본사) 아지트에도 사내 카카오 프렌즈샵이 오픈 완료 2022. 11. 9. 22:16 판교에 드디어 카카오 프렌즈샵이  카카오프렌즈 문구세트도 증정하고, 선착순이겠지만 춘식이 풍선도 준다고 해요◡̈ 판교에 프렌즈샵 방문했다는걸 인증하는듯 다들 퇴근길에 춘식이 하나씩 들고 가시더라구요ㅎㅎㅎ 그 모습들도 귀여움 ㅠㅠ \\\\u200b2022. 11. 9. 22:16 이웃추가 위치 카카오프렌즈 판교아지트점 판교에 드디어 카카오 프렌즈샵이 카카오 본사 아지트 건물 1층에 오픈 했어요!! 들어가는 입구는 많지만 지금 설명하는 방향은.... 흐음.... 4번출구에서부터 시작 입니다 ㅎㅎ 존재하지 않는 이미지입니다. 저 완전 친절했죠? ٩ (•̤̀ᵕ•̤́๑)ᵍᵒᵒᵈᵎᵎ 존재하지 않는 이미지입니다. 존재하지 않는 이미지입니다. 아지트 건물로 들어가면 저 귀여운 춘식이가 길을 안내해 줍니다 ̈ 존재하지 않는 이미지입니다. 새로 생긴듯한 카카오 쇼핑 라이브 스튜디오?를 지나면 존재하지 않는 이미지입니다. 카카오 프렌즈샵이 나옵니다!!'},\\n {'url': 'https://blog.naver.com/PostView.nhn?blogId=4julove&logNo=223303504755',\\n  'content': \\\"판교 카카오 아지트, 아방 베이커리 판교카카오점, 커카오 프렌즈 그리고 새로운 장소들: LA GRILLIA, Lounge'Xr', fysd flower&cake/성탄절 판교 나들이 by 자메스의 대만사랑  \\\\u200b *** \\\\u200b 경기도 성남시 분당구 판교역로 166 1층 3호 ▲ 아방베이커리 판교카카오점 오늘의 카페 탐방, 약도로 확인을 합니다. \\\\u200b \\\\u200b *** \\\\u200b \\\\u200b \\\\u200b ▲ 다양한 베이커리로 준비  \\\\u200b \\\\u200b \\\\u200b ▲ 아방베이커리 소호판교카카오점 \\\\u200b T. 031-601-7220 \\\\u200b ▲ 오늘의 선택은 오트라떼(6,400), 에비앙(2,000), 에멘탈치즈바게트(4,200), 브리오슈샌드위치(3,900) \\\\u200b *** \\\\u200b  판교역 주변의 풍경도 담고 물론 이번은 '판교 카카오아지트'만 담아 드리는 것으로 \\\\u200b \\\\u200b \\\\u200b ▲ 그래 오늘은 이곳에서 커피 한잔하자고! '아방 베이커리' 중에서는 이곳 '판교카카오점'이 최고라는 사실경기도 성남시 분당구 판교역로 166 카카오판교아지트 1층 카카오프렌즈 라그릴리아 판교점 경기도 성남시 분당구 판교역로 166 1층 일부(17)호\\\"},\\n {'url': 'https://blog.naver.com/PostView.naver?blogId=winternew1&logNo=223316189201',\\n  'content': '일상을 여행하는 중 blog 판교 카카오아지트 및 프렌즈샵 판교아지트점 뉴스에서 자주 등장하는 판교 카카오. 출입증이 없어도 일부 공간은 둘러볼 수 있다. 자연 친화 녹색 조경 카카오아지트에서 본 판교역 광장.  카카오아지트에서 본 판교역 광장. 거대한 춘식이, 어피치, 튜브 조르디 빤쥬토끼, 잔망루비, 몰티즈도 있다. 플라워카페 fysd 앞의 라춘(라이언과 춘식이)  알파리움타워 알파돔타워. 카카오게임즈와 카카오 모빌리티, 카카오브레인, 카카오페이손해보험, 그라운드... m.blog.naver.com tags 검색 서재안에 글 53 neighbor ^ activity  더 궁금하신 사항은 고객센터로 문의하시면 자세히 알려드리겠습니다. 수정하신 후 다시 등록해 주세요. 회원님의 안전한 서비스 이용을 위해 비밀번호를 확인해 주세요.naver 블로그. 일상을 여행하는 중. 블로그 검색'}]\\nPDF 기반 문서 검색 도구: Retriever\\n우리의 데이터에 대해 조회를 수행할 retriever도 생성합니다.\\n이 코드는 웹 기반 문서 로더, 문서 분할기, 벡터 저장소, 그리고 OpenAI 임베딩을 사용하여 문서 검색 시스템을 구축합니다.\\n여기서는 PDF 문서를 FAISS DB 에 저장하고 조회하는 retriever 를 생성합니다.\\n```\\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\\nfrom langchain_community.vectorstores import FAISS\\nfrom langchain_openai import OpenAIEmbeddings\\nfrom langchain.document_loaders import PyPDFLoader\\nPDF 파일 로드. 파일의 경로 입력\\nloader = PyPDFLoader(\\\"data/SPRI_AI_Brief_2023년12월호_F.pdf\\\")\\n텍스트 분할기를 사용하여 문서를 분할합니다.\\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\\n문서를 로드하고 분할합니다.\\nsplit_docs = loader.load_and_split(text_splitter)\\nVectorStore를 생성합니다.\\nvector = FAISS.from_documents(split_docs, OpenAIEmbeddings())\\nRetriever를 생성합니다.\\nretriever = vector.as_retriever()\\n```\\n이 함수는 retriever 객체의 get_relevant_documents 메소드를 사용하여 “YouTube의 2024년부터 AI 생성콘텐츠 표시 의무화에 대한 내용을 알려줘” 와 관련된 문서들 중 첫 번째 문서를 반환합니다.\\n이는 특정 쿼리에 대한 가장 관련성 높은 문서 를 찾는 데 사용됩니다.\\n```\\nPDf 문서에서 Query 에 대한 관련성 높은 Chunk 를 가져옵니다.\\nretriever.get_relevant_documents(\\n    \\\"YouTube의 2024년부터 AI 생성콘텐츠 표시 의무화에 대한 내용을 알려줘\\\"\\n)[0]\\n```\\nDocument(page_content='SPRi AI Brief |  \\\\n2023-12 월호\\\\n14유튜브 , 2024년부터 AI 생성 콘텐츠 표시 의무화 \\\\nn유튜브가 몇 달 안에 생성 AI를 사용한 콘텐츠에 AI 라벨 표시를 의무화하기로 했으며 , 이를 \\\\n준수하지 않는 콘텐츠는 삭제하고 크리에이터에 대한 수익 배분도 중단할 수 있다고 설명\\\\nn유튜브는 AI 생성 콘텐츠가 신원 파악이 가능한 개인을 모방한 경우 개인정보 침해 신고 \\\\n절차에 따라 콘텐츠 삭제 요청도 받을 계획KEY Contents\\\\n£유튜브 , 생성 AI 콘텐츠에 AI 라벨 표시 안 하면 콘텐츠 삭제\\\\nn유튜브가 2023 년 11월 14일 공식 블로그를 통해 몇 달 안에 생성 AI를 사용한 콘텐츠에 AI \\\\n라벨을 표시하는 새로운 규칙을 시행한다고 발표 \\\\n∙실제로 일어나지 않은 사건을 사실적으로 묘사하거나 실제로 하지 않은 말이나 행동을 보여주는 콘텐츠와 \\\\n같이 AI 도구를 사용해 사실적으로 변경되거나 합성된 콘텐츠에는 AI 라벨을 표시 필요\\\\n∙유튜브는 이러한 규칙이 선거나 분쟁 상황, 공중 보건, 공직자 관련 문제와 같이 민감한 주제를 다루는 \\\\n콘텐츠에서 특히 중요하다고 강조했으며 , 크리에이터가 AI로 제작한 콘텐츠에 AI 라벨을 표시하지 않으면 \\\\n해당 콘텐츠는 삭제되고 광고 수익을 배분하는 유튜브 파트너 프로그램도 정지될 수 있음\\\\n∙유튜브는 두 가지 방식으로 AI를 이용한 콘텐츠의 변경이나 합성 여부를 시청자에게 전달할 계획으로 \\\\n동영상 설명 패널에 라벨을 표시하는 방식이 기본이며 , 민감한 주제를 다루는 특정 유형의 콘텐츠는 동영상 \\\\n플레이어에 더욱 눈에 띄는 라벨을 적용 \\\\n∙유튜브는 커뮤니티 정책에 위반되는 일부 합성 콘텐츠에 대해서는 라벨 지정 여부와 관계없이 삭제할 \\\\n방침으로 , 가령 사실적인 폭력을 보여주는 합성 동영상이 시청자에게 충격이나 혐오감을 줄 수 있다면 \\\\n삭제될 수 있음\\\\n£유튜브 , 특정인을 모방한 AI 생성 콘텐츠에 대한 삭제 요청에도 대응 계획', metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 16})\\n이제 우리가 검색을 수행할 인덱스를 채웠으므로, 이를 에이전트가 제대로 사용할 수 있는 도구로 쉽게 변환할 수 있습니다.\\ncreate_retriever_tool 함수는 langchain 라이브러리의 tools.retriever 모듈에서 가져온다. 이 함수는 특정 데이터를 검색하기 위한 도구를 생성하는 데 사용된다. langchain은 언어 모델과 관련된 다양한 기능을 제공하는 라이브러리로, 이 중 검색 도구 생성 기능은 데이터 검색 및 처리 작업을 용이하게 한다.\\n```\\nlangchain 패키지의 tools 모듈에서 retriever 도구를 생성하는 함수를 가져옵니다.\\nfrom langchain.tools.retriever import create_retriever_tool\\n```\\n이 함수는 create_retriever_tool을 호출하여 retriever_tool을 생성합니다. 이 도구는 LangSmith에 대한 정보를 검색하는 데 사용됩니다.\\n사용자가 LangSmith에 대해 궁금한 점이 있을 때, 이 도구를 통해 질문을 해결할 수 있습니다. 함수는 retriever 인스턴스, 검색 도구의 이름인 langsmith_search, 그리고 사용자에게 도구 사용 방법을 안내하는 메시지를 인자로 받습니다.\\nretriever_tool = create_retriever_tool(\\n    retriever,\\n    name=\\\"pdf_search\\\",\\n    description=\\\"2023년 12월 AI 관련 정보를 PDF 문서에서 검색합니다. '2023년 12월 AI 산업동향' 과 관련된 질문은 이 도구를 사용해야 합니다!\\\",\\n)\\nAgent 가 사용할 도구 목록 정의\\n이제 두 가지를 모두 만들었으므로, Agent 가 사용할 도구 목록을 만들 수 있습니다.\\ntools 리스트는 search와 retriever_tool을 포함합니다. 이 리스트는 검색 및 정보 검색 도구를 저장하는 데 사용됩니다. 각 요소는 특정 작업을 수행하는 데 필요한 기능을 제공합니다.\\n```\\ntools 리스트에 search와 retriever_tool을 추가합니다.\\ntools = [search, retriever_tool]\\n```\\n② 에이전트 생성\\n이제 도구를 정의했으니 에이전트를 생성할 수 있습니다. OpenAI Functions 에이전트를 사용할 것입니다.\\n먼저, 에이전트가 활용할 LLM을 정의합니다.\\nChatOpenAI 클래스는 langchain_openai 모듈에서 가져온 것으로, OpenAI의 언어 모델을 활용하여 대화형 AI를 구현할 수 있게 해줍니다.\\n이 예제에서는 gpt-4-turbo-preview 모델을 사용하며, temperature 매개변수를 0으로 설정하여 예측의 변동성을 최소화합니다.\\n```\\nfrom langchain_openai import ChatOpenAI\\nChatOpenAI 클래스를 langchain_openai 모듈에서 가져옵니다.\\nllm = ChatOpenAI(model=\\\"gpt-4-turbo-preview\\\", temperature=0)\\n```\\n다음으로, 에이전트를 안내하기 위해 사용하고 싶은 프롬프트를 선택합니다.\\n이 프롬프트의 내용을 보고 싶고 LangSmith에 접근할 수 있다면, 다음으로 이동하세요:\\n다운로드 받아 활용할 프롬프트: https://smith.langchain.com/hub/hwchase17/openai-functions-agent\\nhub.pull() 함수를 사용하여 리소스를 가져온 후, prompt.messages를 통해 해당 리소스의 메시지에 접근합니다.\\n```\\nfrom langchain import hub\\nhub에서 prompt를 가져옵니다 - 이 부분을 수정할 수 있습니다!\\nprompt = hub.pull(\\\"hwchase17/openai-functions-agent\\\")\\nprompt 의 messages를 출력합니다.\\nprompt.messages\\n```\\n[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\\n MessagesPlaceholder(variable_name='chat_history', optional=True),\\n HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\\n MessagesPlaceholder(variable_name='agent_scratchpad')]\\n이제 LLM, 프롬프트 및 도구로 에이전트를 초기화할 수 있습니다. 에이전트는 입력을 받아 어떤 Action 을 취할지 결정하는 역할을 합니다.\\n중요한 것은 에이전트가 Action 들을 실행하지 않는다는 것입니다 - 그것은 AgentExecutor(다음 단계)에 의해 수행됩니다.\\n```\\nfrom langchain.agents import create_openai_functions_agent\\nOpenAI 함수 기반 에이전트를 생성합니다.\\nllm, tools, prompt를 인자로 사용합니다.\\nagent = create_openai_functions_agent(llm, tools, prompt)\\n```\\n마지막으로, 우리는 에이전트(agent)를 AgentExecutor 내부의 도구들과 결합합니다(이는 반복적으로 에이전트를 호출하고 도구들을 실행할 것입니다).\\n이 코드는 langchain.agents 모듈에서 AgentExecutor 클래스를 가져와 인스턴스를 생성합니다. 생성 시, agent, tools 객체를 인자로 전달하고, verbose=True를 설정하여 상세한 로그 출력을 활성화합니다. AgentExecutor는 주어진 에이전트와 도구들을 사용하여 작업을 실행하는 역할을 합니다.\\n```\\nfrom langchain.agents import AgentExecutor\\nAgentExecutor 클래스를 사용하여 agent와 tools를 설정하고, 상세한 로그를 출력하도록 verbose를 True로 설정합니다.\\nagent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\\n```\\n③ 에이전트 실행하기\\n이제 몇 가지 질의에 대해 에이전트를 실행할 수 있습니다!\\n현재 이러한 모든 질의는 상태(Stateless) 가 없는 질의입니다(이전 상호작용을 기억하지 않습니다).\\nagent_executor 객체의 invoke 메소드는 딕셔너리 형태의 인자를 받아 처리합니다. 이 예제에서는 input 키에 hi! 값을 할당한 딕셔너리를 인자로 전달하고 있습니다. 이는 일반적으로 AI 에이전트, 함수 실행기, 또는 명령 처리기 등의 객체에서 입력을 처리하기 위해 사용됩니다.\\n```\\n'agent_executor' 객체의 'invoke' 메소드를 호출하여,\\n'input' 키와 '안녕, 반가워' 값을 가진 딕셔너리를 인자로 전달합니다.\\nresponse = agent_executor.invoke({\\\"input\\\": \\\"안녕, 반가워!\\\"})\\nprint(f'답변: {response[\\\"output\\\"]}')\\n```\\n\\u001b[1m> Entering new AgentExecutor chain...\\u001b[0m\\n\\u001b[32;1m\\u001b[1;3m안녕하세요! 반가워요. 무엇을 도와드릴까요?\\u001b[0m\\n\\u001b[1m> Finished chain.\\u001b[0m\\n답변: 안녕하세요! 반가워요. 무엇을 도와드릴까요?\\nagent_executor 객체의 invoke 메소드를 사용하여, 질문을 입력으로 제공합니다.\\n\\n다음의 추적 링크에서 자세한 단계별 수행 결과를 확인할 수 있습니다\\n\\nLangSmith 추적\\n```\\n'agent_executor' 객체의 'invoke' 메소드를 호출하여, 'langsmith'가 테스팅에 어떻게 도움을 줄 수 있는지에 대한 질문을 입력으로 제공합니다.\\nresponse = agent_executor.invoke(\\n    {\\n        \\\"input\\\": \\\"YouTube 2024년부터 AI 생성콘텐츠 표시 의무화에 대한 내용을 PDF 문서에서 알려줘\\\"\\n    }\\n)\\nprint(f'답변: {response[\\\"output\\\"]}')\\n```\\n\\u001b[1m> Entering new AgentExecutor chain...\\u001b[0m\\n\\u001b[32;1m\\u001b[1;3m\\nInvoking: `pdf_search` with `{'query': 'YouTube 2024년 AI 생성콘텐츠 표시 의무화'}`\\n\\u001b[0m\\u001b[33;1m\\u001b[1;3mSPRi AI Brief |\\n2023-12 월호\\n14유튜브 , 2024년부터 AI 생성 콘텐츠 표시 의무화 \\nn유튜브가 몇 달 안에 생성 AI를 사용한 콘텐츠에 AI 라벨 표시를 의무화하기로 했으며 , 이를 \\n준수하지 않는 콘텐츠는 삭제하고 크리에이터에 대한 수익 배분도 중단할 수 있다고 설명\\nn유튜브는 AI 생성 콘텐츠가 신원 파악이 가능한 개인을 모방한 경우 개인정보 침해 신고 \\n절차에 따라 콘텐츠 삭제 요청도 받을 계획KEY Contents\\n£유튜브 , 생성 AI 콘텐츠에 AI 라벨 표시 안 하면 콘텐츠 삭제\\nn유튜브가 2023 년 11월 14일 공식 블로그를 통해 몇 달 안에 생성 AI를 사용한 콘텐츠에 AI \\n라벨을 표시하는 새로운 규칙을 시행한다고 발표 \\n∙실제로 일어나지 않은 사건을 사실적으로 묘사하거나 실제로 하지 않은 말이나 행동을 보여주는 콘텐츠와 \\n같이 AI 도구를 사용해 사실적으로 변경되거나 합성된 콘텐츠에는 AI 라벨을 표시 필요\\n∙유튜브는 이러한 규칙이 선거나 분쟁 상황, 공중 보건, 공직자 관련 문제와 같이 민감한 주제를 다루는 \\n콘텐츠에서 특히 중요하다고 강조했으며 , 크리에이터가 AI로 제작한 콘텐츠에 AI 라벨을 표시하지 않으면 \\n해당 콘텐츠는 삭제되고 광고 수익을 배분하는 유튜브 파트너 프로그램도 정지될 수 있음\\n∙유튜브는 두 가지 방식으로 AI를 이용한 콘텐츠의 변경이나 합성 여부를 시청자에게 전달할 계획으로 \\n동영상 설명 패널에 라벨을 표시하는 방식이 기본이며 , 민감한 주제를 다루는 특정 유형의 콘텐츠는 동영상 \\n플레이어에 더욱 눈에 띄는 라벨을 적용 \\n∙유튜브는 커뮤니티 정책에 위반되는 일부 합성 콘텐츠에 대해서는 라벨 지정 여부와 관계없이 삭제할 \\n방침으로 , 가령 사실적인 폭력을 보여주는 합성 동영상이 시청자에게 충격이나 혐오감을 줄 수 있다면 \\n삭제될 수 있음\\n£유튜브 , 특정인을 모방한 AI 생성 콘텐츠에 대한 삭제 요청에도 대응 계획\\n삭제될 수 있음\\n£유튜브 , 특정인을 모방한 AI 생성 콘텐츠에 대한 삭제 요청에도 대응 계획\\nn유튜브는 몇 달 내에 신원 파악이 가능한 개인의 얼굴이나 음성을 모방한 AI 생성 콘텐츠에 대하\\n여 개인정보 침해 신고 절차를 마련해 삭제 요청을 받을 계획\\n∙단, 모든 콘텐츠가 삭제 대상은 아니며 유튜브는 콘텐츠가 패러디나 풍자인지 , 해당 영상에서 삭제 요청을 \\n한 특정인을 식별할 수 있는지 , 공직자나 유명인이 등장하는지 등 다양한 요소를 고려할 예정\\n∙유튜브는 음반사가 아티스트의 고유한 노래나 목소리를 모방한 AI 생성 음악에 대하여 삭제를 요청할 수 \\n있는 기능도 도입할 방침\\n☞ 출처 : Youtube, Our approach to responsible AI innovation, 2023.11.14.\\n▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································ 11\\n   ▹ IDC, 2027 년 AI 소프트웨어 매출 2,500 억 달러 돌파 전망··········································· 12\\n   ▹ 빌 게이츠 , AI 에이전트로 인한 컴퓨터 사용의 패러다임 변화 전망································ 13\\n   ▹ 유튜브 , 2024 년부터 AI 생성 콘텐츠 표시 의무화 ···························································· 14\\n 3. 기술/연구\\n   ▹ 영국 과학혁신기술부 , AI 안전 연구소 설립 발표······························································ 15\\n   ▹ 구글 딥마인드 , 범용 AI 모델의 기능과 동작에 대한 분류 체계 발표······························ 16\\n   ▹ 갈릴레오의 LLM 환각 지수 평가에서 GPT-4 가 가장 우수 ··········································· 17\\n\\n인력/교육   \\n   ▹ 영국 옥스퍼드 인터넷 연구소 , AI 기술자의 임금이 평균 21% 높아······························· 18\\n\\nⅡ. 주요 행사\\n   ▹CES 2024 ····························································································································· 19\\nSPRi AI Brief |\\n2023-12 월호\\n4미국 법원, 예술가들이 생성 AI 기업에 제기한 저작권 소송 기각\\nn미국 캘리포니아 북부지방법원은 미드저니 , 스태빌리티 AI, 디비언트아트를 대상으로 예술가 \\n3인이 제기한 저작권 침해 소송을 기각\\nn법원은 기각 이유로 고소장에 제시된 상당수 작품이 저작권청에 등록되지 않았으며 , AI로 \\n생성된 이미지와 특정 작품 간 유사성을 입증하기 어렵다는 점을 제시 KEY Contents\\n£예술가들의 AI 저작권 침해 소송, 저작권 미등록과 증거불충분으로 기각\\nn미국 캘리포니아 북부지방법원의 윌리엄 오릭(W illiam Orrick) 판사는 2023년 10월 30일 미드저니\\n(M idjourney),  스태빌리티 AI(Stability AI), 디비언트아트 (DeviantArt) 에 제기된 저작권 침해 소송을 기각 \\n∙2023 년 1월 예술가 사라 앤더슨 (Sarah Anderson), 캘리 맥커넌 (Kelly McKernan), 칼라 \\n오르티즈 (Karla Ortiz) 는 이미지 생성 AI 서비스를 개발한 3개 기업을 상대로 저작권 침해 소송을 제기\\n∙예술가들은 3개 기업이 AI 모델을 학습시키기 위해 원작자 동의 없이 작품을 학습 데이터셋에 \\n포함하여 저작권을 침해했다고 주장했으며 , 법원은 지난 4월 피소 기업들이 제출한 기각 신청을 \\n수용해 소송을 기각 \\nn오릭 판사는 판결문에서 소송을 기각한 핵심 이유로 예술가들의 저작권 미등록을 제시\\n∙판결문은 소송을 제기한 캘리 맥커넌과 칼라 오르티즈가 미국 저작권청에 예술 작품에 대한 저작권을 \\n제출하지 않았다는 점을 지적했으며 , 사라 앤더슨은 고소장에 인용된 수백 개의 작품 중 16개 작품에 \\n대해서만 저작권을 보유\\nn판결문은 또한 생성 AI 모델 훈련에 사용된 모든 이미지에 저작권이 있다거나 , 생성 AI로 만든 \\n이미지가 저작물을 이용해 훈련되었으므로 저작물의 파생 이미지라는 주장은 개연성이  부족하다고\\n지적\\u001b[0m\\u001b[32;1m\\u001b[1;3m2024년부터 YouTube는 AI를 사용하여 생성된 콘텐츠에 AI 라벨을 표시하는 것을 의무화할 예정입니다. 이 규칙을 준수하지 않는 콘텐츠는 삭제될 수 있으며, 해당 크리에이터에 대한 수익 배분도 중단될 수 있습니다. YouTube는 특히 선거, 분쟁 상황, 공중 보건, 공직자 관련 문제와 같이 민감한 주제를 다루는 콘텐츠에서 이 규칙의 중요성을 강조했습니다. AI로 제작된 콘텐츠에 AI 라벨을 표시하지 않으면 해당 콘텐츠는 삭제되고, YouTube 파트너 프로그램을 통한 광고 수익 배분도 정지될 수 있습니다.\\nYouTube는 AI를 이용한 콘텐츠의 변경이나 합성 여부를 시청자에게 전달하기 위해 두 가지 방식을 계획하고 있습니다. 기본적으로 동영상 설명 패널에 라벨을 표시하며, 민감한 주제를 다루는 특정 유형의 콘텐츠는 동영상 플레이어에 더욱 눈에 띄는 라벨을 적용할 예정입니다. 또한, 커뮤니티 정책에 위반되는 일부 합성 콘텐츠는 라벨 지정 여부와 관계없이 삭제될 수 있습니다.\\nYouTube는 신원 파악이 가능한 개인의 얼굴이나 음성을 모방한 AI 생성 콘텐츠에 대해 개인정보 침해 신고 절차를 마련해 삭제 요청을 받을 계획입니다. 모든 콘텐츠가 삭제 대상은 아니며, 콘텐츠가 패러디나 풍자인지, 해당 영상에서 삭제 요청을 한 특정인을 식별할 수 있는지, 공직자나 유명인이 등장하는지 등 다양한 요소를 고려할 예정입니다. 음반사는 아티스트의 고유한 노래나 목소리를 모방한 AI 생성 음악에 대하여 삭제를 요청할 수 있는 기능도 도입될 예정입니다.\\u001b[0m\\n\\u001b[1m> Finished chain.\\u001b[0m\\n답변: 2024년부터 YouTube는 AI를 사용하여 생성된 콘텐츠에 AI 라벨을 표시하는 것을 의무화할 예정입니다. 이 규칙을 준수하지 않는 콘텐츠는 삭제될 수 있으며, 해당 크리에이터에 대한 수익 배분도 중단될 수 있습니다. YouTube는 특히 선거, 분쟁 상황, 공중 보건, 공직자 관련 문제와 같이 민감한 주제를 다루는 콘텐츠에서 이 규칙의 중요성을 강조했습니다. AI로 제작된 콘텐츠에 AI 라벨을 표시하지 않으면 해당 콘텐츠는 삭제되고, YouTube 파트너 프로그램을 통한 광고 수익 배분도 정지될 수 있습니다.\\nYouTube는 AI를 이용한 콘텐츠의 변경이나 합성 여부를 시청자에게 전달하기 위해 두 가지 방식을 계획하고 있습니다. 기본적으로 동영상 설명 패널에 라벨을 표시하며, 민감한 주제를 다루는 특정 유형의 콘텐츠는 동영상 플레이어에 더욱 눈에 띄는 라벨을 적용할 예정입니다. 또한, 커뮤니티 정책에 위반되는 일부 합성 콘텐츠는 라벨 지정 여부와 관계없이 삭제될 수 있습니다.\\nYouTube는 신원 파악이 가능한 개인의 얼굴이나 음성을 모방한 AI 생성 콘텐츠에 대해 개인정보 침해 신고 절차를 마련해 삭제 요청을 받을 계획입니다. 모든 콘텐츠가 삭제 대상은 아니며, 콘텐츠가 패러디나 풍자인지, 해당 영상에서 삭제 요청을 한 특정인을 식별할 수 있는지, 공직자나 유명인이 등장하는지 등 다양한 요소를 고려할 예정입니다. 음반사는 아티스트의 고유한 노래나 목소리를 모방한 AI 생성 음악에 대하여 삭제를 요청할 수 있는 기능도 도입될 예정입니다.\\n\\n다음의 추적 링크에서 자세한 단계별 수행 결과를 확인할 수 있습니다\\n\\nLangSmith 추적\\n```\\n검색 결과를 요청 후 질문에 대한 답변을 출력합니다.\\nresponse = agent_executor.invoke(\\n    {\\\"input\\\": \\\"판교 카카오 프렌즈샵 아지트점의 전화번호를 검색하여 결과를 알려주세요.\\\"}\\n)\\nprint(f'답변: {response[\\\"output\\\"]}')\\n```\\n\\u001b[1m> Entering new AgentExecutor chain...\\u001b[0m\\n\\u001b[32;1m\\u001b[1;3m\\nInvoking: `tavily_search_results_json` with `{'query': '판교 카카오 프렌즈샵 아지트점 전화번호'}`\\n\\u001b[0m\\u001b[36;1m\\u001b[1;3m[{'url': 'https://m.blog.naver.com/hj961030/222923648353', 'content': '블로그 카테고리 이동 ♥n2u1_늘이의 여행일기♥ 카카오프렌즈 판교 아지트점 판교의 카카오프렌즈를 소개합니다. 2022. 11. 8. 21:39 카카오프렌즈 판교 아지트점 문구, 펜시 \\\\u200b  \\\\u200b 카카오프렌즈 판교 아지트점은 2022년 11월 07일 바로 어제 오픈을 한 따끈따근한 곳이랍니다!!! 입구에 발을 들이자마자 보이는 건 아주 아주 커다란 춘식이에요~!!  \\\\u200b 모두 모두 카카오프렌즈 판교 아지트점에서 만나요-! 경기도 성남시 분당구 판교역로 166 \\\\u200b ♥n2u1_늘이의 여행일기♥ 이 블로그 경기도 카테고리 글 카테고리 이 블로그 경기도 카테고리 글  아참-! 판교 아지트점에서 숨은 라이언 찾기 이벤트도 진행하고 있으니 참여하면 좋겠죠?!! 그럼 오늘은 여기까지 소개를 드리도록 하겠습니다! 직접 보면 더 예쁜 카카오프렌즈 판교 아지트점 \\\\u200b2022. 11. 8. 21:39 이웃추가 존재하지 않는 이미지입니다. 카카오프렌즈 판교 아지트점 문구, 펜시 주소 : 경기 성남시 분당구 판교역로 166 1층 시간 : 월 - 금 10:00 - 21:00 / 토 - 일 12:00 - 20:00 주차장 : 지하 주차장이 있어요! 카카오아지트는 회차 20분 무료, 기본 30분에 1,000원 입니다! 판교역 4번출구에서 걸어서 1분 거리에 위치해요! 카카오프렌즈 판교 아지트점을 방문해야하는 이유-! 01. 어제 오픈한 따끈한 신상 매장이에요! 02. 가격에 상관없이 구매만 하면 춘식이 얼굴 풍선을 받을 수 있어요! (11월 7일 부터 소진시까지)'}, {'url': 'https://m.blog.naver.com/celina_827/222924602339', 'content': '판교에 드디어 카카오 프렌즈샵이 카카오 본사 아지트 건물 1층에 오픈 했어요!! \\\\u200b 들어가는 입구는 많지만 지금 설명하는 방향은.... 흐음.... 4번출구에서부터 시작 입니다 ㅎㅎ  사원증한 프렌즈들 너무 귀엽다!!! 너무 귀여운 카카오 속 세상이예요ㅠㅠ \\\\u200b 경기도 성남시 분당구 판교역로 166 💬카카오프렌즈샵 아지트점은 판교역 1번 출구, 4번 출구를 이용하셔도 되고,  블로그 카테고리 이동 셀리나의 DAILY EPISODE [판교] 카카오(본사) 아지트에도 사내 카카오 프렌즈샵이 오픈 완료 2022. 11. 9. 22:16 판교에 드디어 카카오 프렌즈샵이  카카오프렌즈 문구세트도 증정하고, 선착순이겠지만 춘식이 풍선도 준다고 해요◡̈ 판교에 프렌즈샵 방문했다는걸 인증하는듯 다들 퇴근길에 춘식이 하나씩 들고 가시더라구요ㅎㅎㅎ 그 모습들도 귀여움 ㅠㅠ \\\\u200b9. 22:16 이웃추가 위치 카카오프렌즈 판교아지트점 판교에 드디어 카카오 프렌즈샵이 카카오 본사 아지트 건물 1층에 오픈 했어요!! 들어가는 입구는 많지만 지금 설명하는 방향은.... 흐음.... 4번출구에서부터 시작 입니다 ㅎㅎ 존재하지 않는 이미지입니다. 저 완전 친절했죠? ٩ (•̤̀ᵕ•̤́๑)ᵍᵒᵒᵈᵎᵎ 존재하지 않는 이미지입니다. 존재하지 않는 이미지입니다. 아지트 건물로 들어가면 저 귀여운 춘식이가 길을 안내해 줍니다 ̈ 존재하지 않는 이미지입니다. 새로 생긴듯한 카카오 쇼핑 라이브 스튜디오?를 지나면 존재하지 않는 이미지입니다. 카카오 프렌즈샵이 나옵니다!! 들어가자마자 나오는 대왕 춘식이!!!! 뚜둥'}, {'url': 'https://blog.naver.com/PostView.naver?blogId=0_0hy&logNo=222982732699', 'content': '\\\\u200b \\\\u200b \\\\u200b \\\\u200b 카카오프렌즈 판교아지트점 경기 성남시 분당구 판교역로 166 카카오판교아지트 1층 카카오프렌즈 평일 10:00 - 21:00, 토일 12:00 - 20:00 031-601-7225  031-601-7225 판교 카카오 본사 건물 1층에 있음 ! 오빠랑 항상 주차 편한곳만 돌아다니는데 주차 왕편했다bb \\\\u200b \\\\u200b 무드등 졸귀탱이잖아 ? \\\\u200b  \\\\u200b \\\\u200b \\\\u200b \\\\u200b 지도첨부 경기도 성남시 분당구 판교역로 166 카카오판교아지트 1층 카카오프렌즈 물건 구매시, 주차 1시간 무료 ! 판교역 4번출구에서 가까우니 대중교통도 좋을듯 하다  하블리의 그림일기 blog 판교 카카오프렌즈 판교아지트점 방문후기 감자 추천으로 다녀온 카카오프렌즈 판교아지트점 요새 일만 하느라 어디 다니질 못하니까 포스팅 업로드 할 내용이 없다 (눈물..) \\\\u200b \\\\u200b \\\\u200b \\\\u200b카카오프렌즈 판교아지트점 경기 성남시 분당구 판교역로 166 카카오판교아지트 1층 카카오프렌즈 평일 10:00 - 21:00, 토일 12:00 - 20:00 031-601-7225 존재하지 않는 이미지입니다. 판교 카카오 본사 건물 1층에 있음 ! 오빠랑 항상 주차 편한곳만 돌아다니는데 주차 왕편했다bb 존재하지 않는 이미지입니다. 무드등 졸귀탱이잖아 ? 존재하지 않는 이미지입니다. 에어프라이기 너무 작아서 실용성 없어보였지만 (막말) 라이언 와플기계는 갖고 싶단 말이지 존재하지 않는 이미지입니다. 존재하지 않는 이미지입니다. 에어팟 꽂은 라이언ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 존재하지 않는 이미지입니다.'}, {'url': 'https://m.blog.naver.com/chjw930928/223188524886', 'content': '블로그 카테고리 이동 아무거나 카카오프렌즈 판교 아지트점, 너무 귀여워 춘식이굿즈 기절 2023. 8. 20. 16:00 안녕하세요 오늘은 판교역 바로 앞에 있는 카카오 판교아지트,  그 안에 있는 카카오프렌즈 스토어를 다녀왔어요! 아지트 건물에 이렇게 이어져 있어요 1층부터 푸릇푸릇.. 춘식이 하이 흑 넘 귀엽.. 미쳐.. 속도가 이제 감당이 안되는 29개월 아가 데리고 가보겠습니다 \\\\u200b  근데 전 사실 튜브가 제일 좋아요(?) \\\\u200b 경기도 성남시 분당구 판교역로 166 카카오판교아지트 1층 카카오프렌즈 #카카오프렌즈 #춘식이 #카카오프렌즈스토어 #카카오프렌즈아지트 #카카오프렌즈판교아지트  \\\\u200b 여름방학이 끝나기 전에 아이랑 가는 곳으로 추천해요 쾌적하고 (실내라서 안더움..굿..) 꽤 커서 시간도 훌훌 잘갑니다 껄껄 카카오프렌즈 판교아지트점 오늘 주말에 다녀왔더니, 사람이 꽤나 있었어요. \\\\u200b안녕하세요 오늘은 판교역 바로 앞에 있는 카카오 판교아지트, 그 안에 있는 카카오프렌즈 스토어를 다녀왔어요! 존재하지 않는 이미지입니다. 아지트 건물에 이렇게 이어져 있어요 1층부터 푸릇푸릇.. 존재하지 않는 이미지입니다. 춘식이 하이 흑 넘 귀엽.. 미쳐.. 존재하지 않는 이미지입니다. 속도가 이제 감당이 안되는 29개월 아가 데리고 가보겠습니다 여름방학이 끝나기 전에 아이랑 가는 곳으로 추천해요 쾌적하고 (실내라서 안더움..굿..) 꽤 커서 시간도 훌훌 잘갑니다 껄껄 카카오프렌즈 판교아지트점 존재하지 않는 이미지입니다. 존재하지 않는 이미지입니다. 오늘 주말에 다녀왔더니, 사람이 꽤나 있었어요.'}, {'url': 'https://blog.naver.com/PostView.naver?blogId=winternew1&logNo=223316189201', 'content': '일상을 여행하는 중 blog 판교 카카오아지트 및 프렌즈샵 판교아지트점 뉴스에서 자주 등장하는 판교 카카오. 출입증이 없어도 일부 공간은 둘러볼 수 있다. 자연 친화 녹색 조경 카카오아지트에서 본 판교역 광장.  카카오아지트에서 본 판교역 광장. 거대한 춘식이, 어피치, 튜브 조르디 빤쥬토끼, 잔망루비, 몰티즈도 있다. 플라워카페 fysd 앞의 라춘(라이언과 춘식이)  알파리움타워 알파돔타워. 카카오게임즈와 카카오 모빌리티, 카카오브레인, 카카오페이손해보험, 그라운드... m.blog.naver.com tags 검색 서재안에 글 53 neighbor ^ activity  더 궁금하신 사항은 고객센터로 문의하시면 자세히 알려드리겠습니다. 수정하신 후 다시 등록해 주세요. 회원님의 안전한 서비스 이용을 위해 비밀번호를 확인해 주세요.naver 블로그. 일상을 여행하는 중. 블로그 검색'}]\\u001b[0m\\u001b[32;1m\\u001b[1;3m판교 카카오 프렌즈샵 아지트점의 전화번호는 **031-601-7225** 입니다. 매장은 경기 성남시 분당구 판교역로 166, 카카오판교아지트 1층에 위치해 있습니다. 운영 시간은 평일 10:00 - 21:00, 토일 12:00 - 20:00입니다.\\u001b[0m\\n\\u001b[1m> Finished chain.\\u001b[0m\\n답변: 판교 카카오 프렌즈샵 아지트점의 전화번호는 **031-601-7225** 입니다. 매장은 경기 성남시 분당구 판교역로 166, 카카오판교아지트 1층에 위치해 있습니다. 운영 시간은 평일 10:00 - 21:00, 토일 12:00 - 20:00입니다.\\n④ 메모리 추가하기\\n앞서 언급했듯이, 이 에이전트는 상태가 없습니다. 이는 이전 상호작용을 기억하지 않는다는 것을 의미합니다. 이에게 메모리를 부여하기 위해서는 이전 chat_history를 전달해야 합니다.\\n[참고]\\n우리가 사용하는 프롬프트 때문에 chat_history라고 불러야 합니다. 다른 프롬프트를 사용한다면 변수 이름을 변경할 수 있습니다.\\n함수는 사용자의 입력(input)과 채팅 기록(chat_history)을 매개변수로 받습니다. 여기서, chat_history는 채팅의 첫 번째 메시지를 처리할 때 빈 리스트([])로 전달됩니다. 이는 채팅 세션을 시작할 때 기존의 대화 기록이 없음을 나타냅니다.\\n```\\n채팅의 첫 번째 메시지이므로 chat_history에 빈 리스트를 전달합니다.\\nresponse = agent_executor.invoke(\\n    {\\\"input\\\": \\\"Hi! I'm Teddy. Glad to meet you.\\\", \\\"chat_history\\\": []}\\n)\\nprint(f'답변: {response[\\\"output\\\"]}')\\n```\\n\\u001b[1m> Entering new AgentExecutor chain...\\u001b[0m\\n\\u001b[32;1m\\u001b[1;3mHi Teddy! It's great to meet you too. How can I assist you today?\\u001b[0m\\n\\u001b[1m> Finished chain.\\u001b[0m\\n답변: Hi Teddy! It's great to meet you too. How can I assist you today?\\n이 모듈은 langchain_core.messages에서 AIMessage와 HumanMessage 클래스를 가져옵니다. AI와 인간 간의 메시지 교환을 처리하는 데 사용될 수 있습니다.\\nAIMessage는 AI가 생성한 메시지를 나타내며, HumanMessage는 사용자가 입력한 메시지를 나타냅니다.\\n```\\nlangchain_core.messages에서 AIMessage와 HumanMessage를 가져옵니다.\\nfrom langchain_core.messages import AIMessage, HumanMessage\\n```\\n이 함수는 대화 에이전트를 실행하여 사용자와 AI 간의 대화 이력과 새로운 사용자 입력을 처리합니다. agent_executor.invoke 메소드는 대화 이력(chat_history)과 사용자의 새로운 입력(input)을 매개변수로 받습니다. chat_history는 HumanMessage와 AIMessage 객체의 리스트로, 각각 사용자와 AI의 메시지를 나타냅니다. 이 예시에서는 사용자가 “hi! my name is bob”이라고 인사하고, AI가 “Hello Bob! How can I assist you today?”라고 응답한 이후, 사용자가 “what’s my name?”이라고 새로운 질문을 합니다.\\nresponse = agent_executor.invoke(\\n    {\\n        \\\"chat_history\\\": [\\n            HumanMessage(content=\\\"Hi! I'm Teddy. Glad to meet you.\\\"),\\n            AIMessage(\\n                content=\\\"Hello Teddy! I'm glad to meet you too. How can I assist you today?\\\"\\n            ),\\n        ],\\n        \\\"input\\\": \\\"What's my name?\\\",\\n    }\\n)\\nprint(f'답변: {response[\\\"output\\\"]}')\\n\\u001b[1m> Entering new AgentExecutor chain...\\u001b[0m\\n\\u001b[32;1m\\u001b[1;3mYour name is Teddy. How can I help you today, Teddy?\\u001b[0m\\n\\u001b[1m> Finished chain.\\u001b[0m\\n답변: Your name is Teddy. How can I help you today, Teddy?\\n만약 이 메시지들을 자동으로 추적하고 싶다면, 이를 RunnableWithMessageHistory로 감싸면 됩니다.\\nfrom langchain_community.chat_message_histories import ChatMessageHistory\\nfrom langchain_core.runnables.history import RunnableWithMessageHistory\\nChatMessageHistory 클래스의 인스턴스를 생성하여 message_history 변수에 할당합니다. 이 인스턴스는 채팅 메시지의 기록을 관리하는 데 사용됩니다.\\n```\\n채팅 메시지 기록을 관리하는 객체를 생성합니다.\\nmessage_history = ChatMessageHistory()\\n```\\nRunnableWithMessageHistory 클래스는 에이전트 실행자(agent_executor)와 메시지 기록을 관리합니다. 이 클래스는 세션 ID를 기반으로 메시지 기록을 처리하는 람다 함수와, 입력 메시지 및 채팅 기록의 키를 인자로 받습니다.\\n여기서 세션 ID는 실제로 사용되지 않으며, 단순한 메모리 내 ChatMessageHistory를 사용하는 예시입니다.\\n기본적으로 실행 가능 항목은 문자열인 session_id라는 단일 구성 매개변수를 받습니다.\\n이 매개변수는 주어진 session_id와 일치하는 새 채팅 메시지 기록을 만들거나 기존 채팅 메시지 기록을 조회하는 데 사용됩니다.\\n이 경우 호출은 다음과 같습니다.\\nwith_history.invoke(..., config={\\\"configurable\\\": {\\\"session_id\\\": \\\"bar\\\"}});\\n예: {\\\"configurable\\\": {\\\"session_id\\\": \\\"<세션_id>\\\"}}.\\nagent_with_chat_history = RunnableWithMessageHistory(\\n    agent_executor,\\n    # 대부분의 실제 시나리오에서 세션 ID가 필요하기 때문에 이것이 필요합니다\\n    # 여기서는 간단한 메모리 내 ChatMessageHistory를 사용하기 때문에 실제로 사용되지 않습니다\\n    lambda session_id: message_history,\\n    # 프롬프트의 질문이 입력되는 key: \\\"input\\\"\\n    input_messages_key=\\\"input\\\",\\n    # 프롬프트의 메시지가 입력되는 key: \\\"chat_history\\\"\\n    history_messages_key=\\\"chat_history\\\",\\n)\\nagent_with_chat_history.invoke 함수는 사용자 입력과 설정을 인자로 받아 처리합니다. 이 예제에서는 사용자의 입력(\\\"hi! I'm bob\\\")과 설정(config)을 전달합니다. 설정에는 session_id가 포함되어 있으나, 이는 간단한 메모리 내 ChatMessageHistory를 사용하는 예제이므로 실제로는 사용되지 않습니다. 이 코드는 대부분의 실제 상황에서 세션 ID가 필요함을 보여주지만, 특정 구현에서는 그렇지 않을 수 있음을 보여줍니다.\\nresponse = agent_with_chat_history.invoke(\\n    {\\\"input\\\": \\\"Hi! I'm Teddy. Glad to meet you.\\\"},\\n    # 세션 ID를 설정합니다.\\n    # 여기서는 간단한 메모리 내 ChatMessageHistory를 사용하기 때문에 실제로 사용되지 않습니다\\n    config={\\\"configurable\\\": {\\\"session_id\\\": \\\"MyTestSessionID\\\"}},\\n)\\nprint(f\\\"답변: {response['output']}\\\")\\n\\u001b[1m> Entering new AgentExecutor chain...\\u001b[0m\\n\\u001b[32;1m\\u001b[1;3mHi Teddy! It's great to meet you too. How can I assist you today?\\u001b[0m\\n\\u001b[1m> Finished chain.\\u001b[0m\\n답변: Hi Teddy! It's great to meet you too. How can I assist you today?\\n이 함수 호출은 agent_with_chat_history 객체를 사용하여 입력된 질문에 대한 응답을 생성합니다. 입력은 input 키를 통해 제공되며, 여기서는 “what’s my name?”이 사용됩니다. 또한, config 매개변수를 통해 추가 설정을 제공할 수 있으며, 이 예제에서는 session_id를 <foo>로 설정합니다. 이는 대부분의 실제 시나리오에서 세션 ID가 필요하지만, 이 경우 간단한 메모리 내 ChatMessageHistory를 사용하기 때문에 실제로는 사용되지 않음을 나타냅니다.\\nresponse = agent_with_chat_history.invoke(\\n    {\\\"input\\\": \\\"What's my name?\\\"},\\n    # 세션 ID를 설정합니다.\\n    # 여기서는 간단한 메모리 내 ChatMessageHistory를 사용하기 때문에 실제로 사용되지 않습니다\\n    config={\\\"configurable\\\": {\\\"session_id\\\": \\\"MyTestSessionID\\\"}},\\n)\\nprint(f\\\"답변: {response['output']}\\\")\\n\\u001b[1m> Entering new AgentExecutor chain...\\u001b[0m\\n\\u001b[32;1m\\u001b[1;3mYour name is Teddy. How can I help you today, Teddy?\\u001b[0m\\n\\u001b[1m> Finished chain.\\u001b[0m\\n답변: Your name is Teddy. How can I help you today, Teddy?\\nresponse = agent_with_chat_history.invoke(\\n    {\\\"input\\\": \\\"판교 카카오 프렌즈샵 아지트점의 전화번호를 검색하여 결과를 알려주세요.\\\"},\\n    # 세션 ID를 설정합니다.\\n    # 여기서는 간단한 메모리 내 ChatMessageHistory를 사용하기 때문에 실제로 사용되지 않습니다\\n    config={\\\"configurable\\\": {\\\"session_id\\\": \\\"MyTestSessionID\\\"}},\\n)\\nprint(f\\\"답변: {response['output']}\\\")\\n\\u001b[1m> Entering new AgentExecutor chain...\\u001b[0m\\n\\u001b[32;1m\\u001b[1;3m\\nInvoking: `tavily_search_results_json` with `{'query': '판교 카카오 프렌즈샵 아지트점 전화번호'}`\\n\\u001b[0m\\u001b[36;1m\\u001b[1;3m[{'url': 'https://m.blog.naver.com/hj961030/222923648353', 'content': '블로그 카테고리 이동 ♥n2u1_늘이의 여행일기♥ 카카오프렌즈 판교 아지트점 판교의 카카오프렌즈를 소개합니다. 2022. 11. 8. 21:39 카카오프렌즈 판교 아지트점 문구, 펜시 \\\\u200b  \\\\u200b 카카오프렌즈 판교 아지트점은 2022년 11월 07일 바로 어제 오픈을 한 따끈따근한 곳이랍니다!!! 입구에 발을 들이자마자 보이는 건 아주 아주 커다란 춘식이에요~!!  \\\\u200b 모두 모두 카카오프렌즈 판교 아지트점에서 만나요-! 경기도 성남시 분당구 판교역로 166 \\\\u200b ♥n2u1_늘이의 여행일기♥ 이 블로그 경기도 카테고리 글 카테고리 이 블로그 경기도 카테고리 글  아참-! 판교 아지트점에서 숨은 라이언 찾기 이벤트도 진행하고 있으니 참여하면 좋겠죠?!! 그럼 오늘은 여기까지 소개를 드리도록 하겠습니다! 직접 보면 더 예쁜 카카오프렌즈 판교 아지트점 \\\\u200b2022. 11. 8. 21:39 이웃추가 존재하지 않는 이미지입니다. 카카오프렌즈 판교 아지트점 문구, 펜시 주소 : 경기 성남시 분당구 판교역로 166 1층 시간 : 월 - 금 10:00 - 21:00 / 토 - 일 12:00 - 20:00 주차장 : 지하 주차장이 있어요! 카카오아지트는 회차 20분 무료, 기본 30분에 1,000원 입니다! 판교역 4번출구에서 걸어서 1분 거리에 위치해요! 카카오프렌즈 판교 아지트점을 방문해야하는 이유-! 01. 어제 오픈한 따끈한 신상 매장이에요! 02. 가격에 상관없이 구매만 하면 춘식이 얼굴 풍선을 받을 수 있어요! (11월 7일 부터 소진시까지)'}, {'url': 'https://blog.naver.com/PostView.naver?blogId=mmno&logNo=223315998458', 'content': '\\\\u200b \\\\u200b 경기도 가볼 만한 곳 카카오 프렌즈 판교 아지트  검색 블로그 경기도 가볼 만한 곳 카카오 프렌즈 판교 아지트점 방문기 \\\\u200b 경기도 가볼 만한 곳 판교 카카오 빌딩 투어 카카오 아지트 위치 주소 : 경기도 성남시 판교역로 166 \\\\u200b  \\\\u200b \\\\u200b 경기도 성남시 분당구 판교역로 166 카카오판교아지트 1층 카카오프렌즈 저녁 먹어주고 맥주 한잔 마실때 배안부르게 자꾸만 손이가는 먹태 고소한 마요네즈 청양고추 간장 소스랑 ... blog.naver.com  드디어 도착한 카카오 프렌즈 판교 아지트. 입구부터 캐릭터가 우릴 반겨 주더군요. 안쪽으로 들어가면 캐릭터 문구 용품 리빙 용품 옷도 보이고요 잘못도 보이더군요 정말 볼거리 가득하고 살 거리 그득한 쇼핑경기도 가볼 만한 곳 판교 카카오 본사 빌딩 투어 카카오 본사 위치 주소 : 경기도 성남시 판교역로 160 안...'}, {'url': 'https://blog.naver.com/PostView.naver?blogId=0_0hy&logNo=222982732699', 'content': '\\\\u200b \\\\u200b \\\\u200b \\\\u200b 카카오프렌즈 판교아지트점 경기 성남시 분당구 판교역로 166 카카오판교아지트 1층 카카오프렌즈 평일 10:00 - 21:00, 토일 12:00 - 20:00 031-601-7225  031-601-7225 판교 카카오 본사 건물 1층에 있음 ! 오빠랑 항상 주차 편한곳만 돌아다니는데 주차 왕편했다bb \\\\u200b \\\\u200b 무드등 졸귀탱이잖아 ? \\\\u200b  \\\\u200b \\\\u200b \\\\u200b \\\\u200b 지도첨부 경기도 성남시 분당구 판교역로 166 카카오판교아지트 1층 카카오프렌즈 물건 구매시, 주차 1시간 무료 ! 판교역 4번출구에서 가까우니 대중교통도 좋을듯 하다  하블리의 그림일기 blog 판교 카카오프렌즈 판교아지트점 방문후기 감자 추천으로 다녀온 카카오프렌즈 판교아지트점 요새 일만 하느라 어디 다니질 못하니까 포스팅 업로드 할 내용이 없다 (눈물..) \\\\u200b \\\\u200b \\\\u200b \\\\u200b카카오프렌즈 판교아지트점 경기 성남시 분당구 판교역로 166 카카오판교아지트 1층 카카오프렌즈 평일 10:00 - 21:00, 토일 12:00 - 20:00 031-601-7225 존재하지 않는 이미지입니다. 판교 카카오 본사 건물 1층에 있음 ! 오빠랑 항상 주차 편한곳만 돌아다니는데 주차 왕편했다bb 존재하지 않는 이미지입니다. 무드등 졸귀탱이잖아 ? 존재하지 않는 이미지입니다. 에어프라이기 너무 작아서 실용성 없어보였지만 (막말) 라이언 와플기계는 갖고 싶단 말이지 존재하지 않는 이미지입니다. 존재하지 않는 이미지입니다. 에어팟 꽂은 라이언ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 존재하지 않는 이미지입니다.'}, {'url': 'https://m.blog.naver.com/celina_827/222924602339', 'content': '판교에 드디어 카카오 프렌즈샵이 카카오 본사 아지트 건물 1층에 오픈 했어요!! \\\\u200b 들어가는 입구는 많지만 지금 설명하는 방향은.... 흐음.... 4번출구에서부터 시작 입니다 ㅎㅎ  사원증한 프렌즈들 너무 귀엽다!!! 너무 귀여운 카카오 속 세상이예요ㅠㅠ \\\\u200b 경기도 성남시 분당구 판교역로 166 💬카카오프렌즈샵 아지트점은 판교역 1번 출구, 4번 출구를 이용하셔도 되고,  블로그 카테고리 이동 셀리나의 DAILY EPISODE [판교] 카카오(본사) 아지트에도 사내 카카오 프렌즈샵이 오픈 완료 2022. 11. 9. 22:16 판교에 드디어 카카오 프렌즈샵이  카카오프렌즈 문구세트도 증정하고, 선착순이겠지만 춘식이 풍선도 준다고 해요◡̈ 판교에 프렌즈샵 방문했다는걸 인증하는듯 다들 퇴근길에 춘식이 하나씩 들고 가시더라구요ㅎㅎㅎ 그 모습들도 귀여움 ㅠㅠ \\\\u200b9. 22:16 이웃추가 위치 카카오프렌즈 판교아지트점 판교에 드디어 카카오 프렌즈샵이 카카오 본사 아지트 건물 1층에 오픈 했어요!! 들어가는 입구는 많지만 지금 설명하는 방향은.... 흐음.... 4번출구에서부터 시작 입니다 ㅎㅎ 존재하지 않는 이미지입니다. 저 완전 친절했죠? ٩ (•̤̀ᵕ•̤́๑)ᵍᵒᵒᵈᵎᵎ 존재하지 않는 이미지입니다. 존재하지 않는 이미지입니다. 아지트 건물로 들어가면 저 귀여운 춘식이가 길을 안내해 줍니다 ̈ 존재하지 않는 이미지입니다. 새로 생긴듯한 카카오 쇼핑 라이브 스튜디오?를 지나면 존재하지 않는 이미지입니다. 카카오 프렌즈샵이 나옵니다!! 들어가자마자 나오는 대왕 춘식이!!!! 뚜둥'}, {'url': 'https://m.blog.naver.com/chjw930928/223188524886', 'content': '블로그 카테고리 이동 아무거나 카카오프렌즈 판교 아지트점, 너무 귀여워 춘식이굿즈 기절 2023. 8. 20. 16:00 안녕하세요 오늘은 판교역 바로 앞에 있는 카카오 판교아지트,  그 안에 있는 카카오프렌즈 스토어를 다녀왔어요! 아지트 건물에 이렇게 이어져 있어요 1층부터 푸릇푸릇.. 춘식이 하이 흑 넘 귀엽.. 미쳐.. 속도가 이제 감당이 안되는 29개월 아가 데리고 가보겠습니다 \\\\u200b  근데 전 사실 튜브가 제일 좋아요(?) \\\\u200b 경기도 성남시 분당구 판교역로 166 카카오판교아지트 1층 카카오프렌즈 #카카오프렌즈 #춘식이 #카카오프렌즈스토어 #카카오프렌즈아지트 #카카오프렌즈판교아지트  \\\\u200b 여름방학이 끝나기 전에 아이랑 가는 곳으로 추천해요 쾌적하고 (실내라서 안더움..굿..) 꽤 커서 시간도 훌훌 잘갑니다 껄껄 카카오프렌즈 판교아지트점 오늘 주말에 다녀왔더니, 사람이 꽤나 있었어요. \\\\u200b안녕하세요 오늘은 판교역 바로 앞에 있는 카카오 판교아지트, 그 안에 있는 카카오프렌즈 스토어를 다녀왔어요! 존재하지 않는 이미지입니다. 아지트 건물에 이렇게 이어져 있어요 1층부터 푸릇푸릇.. 존재하지 않는 이미지입니다. 춘식이 하이 흑 넘 귀엽.. 미쳐.. 존재하지 않는 이미지입니다. 속도가 이제 감당이 안되는 29개월 아가 데리고 가보겠습니다 여름방학이 끝나기 전에 아이랑 가는 곳으로 추천해요 쾌적하고 (실내라서 안더움..굿..) 꽤 커서 시간도 훌훌 잘갑니다 껄껄 카카오프렌즈 판교아지트점 존재하지 않는 이미지입니다. 존재하지 않는 이미지입니다. 오늘 주말에 다녀왔더니, 사람이 꽤나 있었어요.'}]\\u001b[0m\\u001b[32;1m\\u001b[1;3m판교 카카오 프렌즈샵 아지트점의 전화번호는 **031-601-7225**입니다. 위치는 경기도 성남시 분당구 판교역로 166, 카카오판교아지트 1층에 있습니다. 운영 시간은 평일 10:00 - 21:00, 토일 12:00 - 20:00입니다. 방문하시기 전에 운영 시간이나 기타 사항을 확인하시려면 전화로 문의하시는 것이 좋습니다.\\u001b[0m\\n\\u001b[1m> Finished chain.\\u001b[0m\\n답변: 판교 카카오 프렌즈샵 아지트점의 전화번호는 **031-601-7225**입니다. 위치는 경기도 성남시 분당구 판교역로 166, 카카오판교아지트 1층에 있습니다. 운영 시간은 평일 10:00 - 21:00, 토일 12:00 - 20:00입니다. 방문하시기 전에 운영 시간이나 기타 사항을 확인하시려면 전화로 문의하시는 것이 좋습니다.\\nresponse = agent_with_chat_history.invoke(\\n    {\\n        \\\"input\\\": \\\"YouTube 2024년부터 AI 생성콘텐츠 표시 의무화에 대한 내용을 PDF 문서에서 알려줘\\\"\\n    },\\n    # 세션 ID를 설정합니다.\\n    # 여기서는 간단한 메모리 내 ChatMessageHistory를 사용하기 때문에 실제로 사용되지 않습니다\\n    config={\\\"configurable\\\": {\\\"session_id\\\": \\\"MyTestSessionID\\\"}},\\n)\\nprint(f\\\"답변: {response['output']}\\\")\\n\\u001b[1m> Entering new AgentExecutor chain...\\u001b[0m\\n\\u001b[32;1m\\u001b[1;3m\\nInvoking: `pdf_search` with `{'query': 'YouTube 2024년 AI 생성콘텐츠 표시 의무화'}`\\n\\u001b[0m\\u001b[33;1m\\u001b[1;3mSPRi AI Brief |\\n2023-12 월호\\n14유튜브 , 2024년부터 AI 생성 콘텐츠 표시 의무화 \\nn유튜브가 몇 달 안에 생성 AI를 사용한 콘텐츠에 AI 라벨 표시를 의무화하기로 했으며 , 이를 \\n준수하지 않는 콘텐츠는 삭제하고 크리에이터에 대한 수익 배분도 중단할 수 있다고 설명\\nn유튜브는 AI 생성 콘텐츠가 신원 파악이 가능한 개인을 모방한 경우 개인정보 침해 신고 \\n절차에 따라 콘텐츠 삭제 요청도 받을 계획KEY Contents\\n£유튜브 , 생성 AI 콘텐츠에 AI 라벨 표시 안 하면 콘텐츠 삭제\\nn유튜브가 2023 년 11월 14일 공식 블로그를 통해 몇 달 안에 생성 AI를 사용한 콘텐츠에 AI \\n라벨을 표시하는 새로운 규칙을 시행한다고 발표 \\n∙실제로 일어나지 않은 사건을 사실적으로 묘사하거나 실제로 하지 않은 말이나 행동을 보여주는 콘텐츠와 \\n같이 AI 도구를 사용해 사실적으로 변경되거나 합성된 콘텐츠에는 AI 라벨을 표시 필요\\n∙유튜브는 이러한 규칙이 선거나 분쟁 상황, 공중 보건, 공직자 관련 문제와 같이 민감한 주제를 다루는 \\n콘텐츠에서 특히 중요하다고 강조했으며 , 크리에이터가 AI로 제작한 콘텐츠에 AI 라벨을 표시하지 않으면 \\n해당 콘텐츠는 삭제되고 광고 수익을 배분하는 유튜브 파트너 프로그램도 정지될 수 있음\\n∙유튜브는 두 가지 방식으로 AI를 이용한 콘텐츠의 변경이나 합성 여부를 시청자에게 전달할 계획으로 \\n동영상 설명 패널에 라벨을 표시하는 방식이 기본이며 , 민감한 주제를 다루는 특정 유형의 콘텐츠는 동영상 \\n플레이어에 더욱 눈에 띄는 라벨을 적용 \\n∙유튜브는 커뮤니티 정책에 위반되는 일부 합성 콘텐츠에 대해서는 라벨 지정 여부와 관계없이 삭제할 \\n방침으로 , 가령 사실적인 폭력을 보여주는 합성 동영상이 시청자에게 충격이나 혐오감을 줄 수 있다면 \\n삭제될 수 있음\\n£유튜브 , 특정인을 모방한 AI 생성 콘텐츠에 대한 삭제 요청에도 대응 계획\\n삭제될 수 있음\\n£유튜브 , 특정인을 모방한 AI 생성 콘텐츠에 대한 삭제 요청에도 대응 계획\\nn유튜브는 몇 달 내에 신원 파악이 가능한 개인의 얼굴이나 음성을 모방한 AI 생성 콘텐츠에 대하\\n여 개인정보 침해 신고 절차를 마련해 삭제 요청을 받을 계획\\n∙단, 모든 콘텐츠가 삭제 대상은 아니며 유튜브는 콘텐츠가 패러디나 풍자인지 , 해당 영상에서 삭제 요청을 \\n한 특정인을 식별할 수 있는지 , 공직자나 유명인이 등장하는지 등 다양한 요소를 고려할 예정\\n∙유튜브는 음반사가 아티스트의 고유한 노래나 목소리를 모방한 AI 생성 음악에 대하여 삭제를 요청할 수 \\n있는 기능도 도입할 방침\\n☞ 출처 : Youtube, Our approach to responsible AI innovation, 2023.11.14.\\n▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································ 11\\n   ▹ IDC, 2027 년 AI 소프트웨어 매출 2,500 억 달러 돌파 전망··········································· 12\\n   ▹ 빌 게이츠 , AI 에이전트로 인한 컴퓨터 사용의 패러다임 변화 전망································ 13\\n   ▹ 유튜브 , 2024 년부터 AI 생성 콘텐츠 표시 의무화 ···························································· 14\\n 3. 기술/연구\\n   ▹ 영국 과학혁신기술부 , AI 안전 연구소 설립 발표······························································ 15\\n   ▹ 구글 딥마인드 , 범용 AI 모델의 기능과 동작에 대한 분류 체계 발표······························ 16\\n   ▹ 갈릴레오의 LLM 환각 지수 평가에서 GPT-4 가 가장 우수 ··········································· 17\\n\\n인력/교육   \\n   ▹ 영국 옥스퍼드 인터넷 연구소 , AI 기술자의 임금이 평균 21% 높아······························· 18\\n\\nⅡ. 주요 행사\\n   ▹CES 2024 ····························································································································· 19\\nSPRi AI Brief |\\n2023-12 월호\\n4미국 법원, 예술가들이 생성 AI 기업에 제기한 저작권 소송 기각\\nn미국 캘리포니아 북부지방법원은 미드저니 , 스태빌리티 AI, 디비언트아트를 대상으로 예술가 \\n3인이 제기한 저작권 침해 소송을 기각\\nn법원은 기각 이유로 고소장에 제시된 상당수 작품이 저작권청에 등록되지 않았으며 , AI로 \\n생성된 이미지와 특정 작품 간 유사성을 입증하기 어렵다는 점을 제시 KEY Contents\\n£예술가들의 AI 저작권 침해 소송, 저작권 미등록과 증거불충분으로 기각\\nn미국 캘리포니아 북부지방법원의 윌리엄 오릭(W illiam Orrick) 판사는 2023년 10월 30일 미드저니\\n(M idjourney),  스태빌리티 AI(Stability AI), 디비언트아트 (DeviantArt) 에 제기된 저작권 침해 소송을 기각 \\n∙2023 년 1월 예술가 사라 앤더슨 (Sarah Anderson), 캘리 맥커넌 (Kelly McKernan), 칼라 \\n오르티즈 (Karla Ortiz) 는 이미지 생성 AI 서비스를 개발한 3개 기업을 상대로 저작권 침해 소송을 제기\\n∙예술가들은 3개 기업이 AI 모델을 학습시키기 위해 원작자 동의 없이 작품을 학습 데이터셋에 \\n포함하여 저작권을 침해했다고 주장했으며 , 법원은 지난 4월 피소 기업들이 제출한 기각 신청을 \\n수용해 소송을 기각 \\nn오릭 판사는 판결문에서 소송을 기각한 핵심 이유로 예술가들의 저작권 미등록을 제시\\n∙판결문은 소송을 제기한 캘리 맥커넌과 칼라 오르티즈가 미국 저작권청에 예술 작품에 대한 저작권을 \\n제출하지 않았다는 점을 지적했으며 , 사라 앤더슨은 고소장에 인용된 수백 개의 작품 중 16개 작품에 \\n대해서만 저작권을 보유\\nn판결문은 또한 생성 AI 모델 훈련에 사용된 모든 이미지에 저작권이 있다거나 , 생성 AI로 만든 \\n이미지가 저작물을 이용해 훈련되었으므로 저작물의 파생 이미지라는 주장은 개연성이  부족하다고\\n지적\\u001b[0m\\u001b[32;1m\\u001b[1;3m유튜브는 2024년부터 생성 AI를 사용한 콘텐츠에 AI 라벨 표시를 의무화하기로 결정했습니다. 이 규칙을 준수하지 않는 콘텐츠는 삭제될 수 있으며, 크리에이터에 대한 수익 배분도 중단될 수 있습니다. 유튜브는 AI 생성 콘텐츠가 신원 파악이 가능한 개인을 모방한 경우, 개인정보 침해 신고 절차에 따라 콘텐츠 삭제 요청을 받을 계획입니다.\\n유튜브는 2023년 11월 14일 공식 블로그를 통해 이러한 새로운 규칙을 발표했습니다. AI 도구를 사용해 사실적으로 변경되거나 합성된 콘텐츠, 예를 들어 실제로 일어나지 않은 사건을 사실적으로 묘사하거나 실제로 하지 않은 말이나 행동을 보여주는 콘텐츠에는 AI 라벨을 표시해야 합니다. 이 규칙은 선거나 분쟁 상황, 공중 보건, 공직자 관련 문제와 같이 민감한 주제를 다루는 콘텐츠에서 특히 중요하다고 강조되었습니다.\\n유튜브는 두 가지 방식으로 AI를 이용한 콘텐츠의 변경이나 합성 여부를 시청자에게 전달할 계획입니다. 기본적으로 동영상 설명 패널에 라벨을 표시하며, 민감한 주제를 다루는 특정 유형의 콘텐츠는 동영상 플레이어에 더욱 눈에 띄는 라벨을 적용할 예정입니다. 커뮤니티 정책에 위반되는 일부 합성 콘텐츠는 라벨 지정 여부와 관계없이 삭제될 수 있습니다.\\n또한, 유튜브는 몇 달 내에 신원 파악이 가능한 개인의 얼굴이나 음성을 모방한 AI 생성 콘텐츠에 대하여 개인정보 침해 신고 절차를 마련해 삭제 요청을 받을 계획입니다. 모든 콘텐츠가 삭제 대상은 아니며, 유튜브는 콘텐츠가 패러디나 풍자인지, 해당 영상에서 삭제 요청을 한 특정인을 식별할 수 있는지, 공직자나 유명인이 등장하는지 등 다양한 요소를 고려할 예정입니다.\\u001b[0m\\n\\u001b[1m> Finished chain.\\u001b[0m\\n답변: 유튜브는 2024년부터 생성 AI를 사용한 콘텐츠에 AI 라벨 표시를 의무화하기로 결정했습니다. 이 규칙을 준수하지 않는 콘텐츠는 삭제될 수 있으며, 크리에이터에 대한 수익 배분도 중단될 수 있습니다. 유튜브는 AI 생성 콘텐츠가 신원 파악이 가능한 개인을 모방한 경우, 개인정보 침해 신고 절차에 따라 콘텐츠 삭제 요청을 받을 계획입니다.\\n유튜브는 2023년 11월 14일 공식 블로그를 통해 이러한 새로운 규칙을 발표했습니다. AI 도구를 사용해 사실적으로 변경되거나 합성된 콘텐츠, 예를 들어 실제로 일어나지 않은 사건을 사실적으로 묘사하거나 실제로 하지 않은 말이나 행동을 보여주는 콘텐츠에는 AI 라벨을 표시해야 합니다. 이 규칙은 선거나 분쟁 상황, 공중 보건, 공직자 관련 문제와 같이 민감한 주제를 다루는 콘텐츠에서 특히 중요하다고 강조되었습니다.\\n유튜브는 두 가지 방식으로 AI를 이용한 콘텐츠의 변경이나 합성 여부를 시청자에게 전달할 계획입니다. 기본적으로 동영상 설명 패널에 라벨을 표시하며, 민감한 주제를 다루는 특정 유형의 콘텐츠는 동영상 플레이어에 더욱 눈에 띄는 라벨을 적용할 예정입니다. 커뮤니티 정책에 위반되는 일부 합성 콘텐츠는 라벨 지정 여부와 관계없이 삭제될 수 있습니다.\\n또한, 유튜브는 몇 달 내에 신원 파악이 가능한 개인의 얼굴이나 음성을 모방한 AI 생성 콘텐츠에 대하여 개인정보 침해 신고 절차를 마련해 삭제 요청을 받을 계획입니다. 모든 콘텐츠가 삭제 대상은 아니며, 유튜브는 콘텐츠가 패러디나 풍자인지, 해당 영상에서 삭제 요청을 한 특정인을 식별할 수 있는지, 공직자나 유명인이 등장하는지 등 다양한 요소를 고려할 예정입니다.\\n📍 전체 템플릿 코드\\n\\n다음의 추적 링크에서 자세한 단계별 수행 결과를 확인할 수 있습니다\\n\\nLangSmith 추적\\n```\\n필요한 모듈 import\\nfrom langchain_community.tools.tavily_search import TavilySearchResults\\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\\nfrom langchain_community.vectorstores import FAISS\\nfrom langchain_openai import OpenAIEmbeddings\\nfrom langchain.document_loaders import PyPDFLoader\\nfrom langchain.tools.retriever import create_retriever_tool\\nfrom langchain_openai import ChatOpenAI\\nfrom langchain import hub\\nfrom langchain.agents import create_openai_functions_agent, AgentExecutor\\nfrom langchain_community.chat_message_histories import ChatMessageHistory\\nfrom langchain_core.runnables.history import RunnableWithMessageHistory\\n#### 1. 도구를 정의합니다\\n1-1. Search 도구\\nTavilySearchResults 클래스의 인스턴스를 생성합니다\\nk=5은 검색 결과를 5개까지 가져오겠다는 의미입니다\\nsearch = TavilySearchResults(k=5)\\n1-2. PDF 문서 검색 도구 (Retriever)\\nPDF 파일 로드. 파일의 경로 입력\\nloader = PyPDFLoader(\\\"data/SPRI_AI_Brief_2023년12월호_F.pdf\\\")\\n텍스트 분할기를 사용하여 문서를 분할합니다.\\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\\n문서를 로드하고 분할합니다.\\nsplit_docs = loader.load_and_split(text_splitter)\\nVectorStore를 생성합니다.\\nvector = FAISS.from_documents(split_docs, OpenAIEmbeddings())\\nRetriever를 생성합니다.\\nretriever = vector.as_retriever()\\nlangchain 패키지의 tools 모듈에서 retriever 도구를 생성\\nretriever_tool = create_retriever_tool(\\n    retriever,\\n    name=\\\"pdf_search\\\",\\n    # 도구에 대한 설명을 자세히 기입해야 합니다!!!\\n    description=\\\"2023년 12월 AI 관련 정보를 PDF 문서에서 검색합니다. '2023년 12월 AI 산업동향' 과 관련된 질문은 이 도구를 사용해야 합니다!\\\",\\n)\\n1-3. tools 리스트에 도구 목록을 추가합니다\\ntools 리스트에 search와 retriever_tool을 추가합니다.\\ntools = [search, retriever_tool]\\n#### 2. LLM 을 정의합니다\\nLLM 모델을 생성합니다.\\nllm = ChatOpenAI(model=\\\"gpt-4-turbo-preview\\\", temperature=0)\\n#### 3. Prompt 를 정의합니다\\nhub에서 prompt를 가져옵니다 - 이 부분을 수정할 수 있습니다!\\nprompt = hub.pull(\\\"hwchase17/openai-functions-agent\\\")\\n#### 4. Agent 를 정의합니다\\nOpenAI 함수 기반 에이전트를 생성합니다.\\nllm, tools, prompt를 인자로 사용합니다.\\nagent = create_openai_functions_agent(llm, tools, prompt)\\n#### 5. AgentExecutor 를 정의합니다\\nAgentExecutor 클래스를 사용하여 agent와 tools를 설정하고, 상세한 로그를 출력하도록 verbose를 True로 설정합니다.\\nagent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\\n#### 6. 채팅 기록을 수행하는 메모리를 추가합니다.\\n채팅 메시지 기록을 관리하는 객체를 생성합니다.\\nmessage_history = ChatMessageHistory()\\n채팅 메시지 기록이 추가된 에이전트를 생성합니다.\\nagent_with_chat_history = RunnableWithMessageHistory(\\n    agent_executor,\\n    # 대부분의 실제 시나리오에서 세션 ID가 필요하기 때문에 이것이 필요합니다\\n    # 여기서는 간단한 메모리 내 ChatMessageHistory를 사용하기 때문에 실제로 사용되지 않습니다\\n    lambda session_id: message_history,\\n    # 프롬프트의 질문이 입력되는 key: \\\"input\\\"\\n    input_messages_key=\\\"input\\\",\\n    # 프롬프트의 메시지가 입력되는 key: \\\"chat_history\\\"\\n    history_messages_key=\\\"chat_history\\\",\\n)\\n#### 7. 질의-응답 테스트를 수행합니다.\\n질의에 대한 답변을 출력합니다.\\nresponse = agent_with_chat_history.invoke(\\n    {\\n        \\\"input\\\": \\\"YouTube 2024년부터 AI 생성콘텐츠 표시 의무화에 대한 내용을 PDF 문서에서 알려줘\\\"\\n    },\\n    # 세션 ID를 설정합니다.\\n    # 여기서는 간단한 메모리 내 ChatMessageHistory를 사용하기 때문에 실제로 사용되지 않습니다\\n    config={\\\"configurable\\\": {\\\"session_id\\\": \\\"MyTestSessionID\\\"}},\\n)\\nprint(f\\\"답변: {response['output']}\\\")\\n```\\n\\u001b[1m> Entering new AgentExecutor chain...\\u001b[0m\\n\\u001b[32;1m\\u001b[1;3m\\nInvoking: `pdf_search` with `{'query': 'YouTube 2024년 AI 생성콘텐츠 표시 의무화'}`\\n\\u001b[0m\\u001b[33;1m\\u001b[1;3mSPRi AI Brief |\\n2023-12 월호\\n14유튜브 , 2024년부터 AI 생성 콘텐츠 표시 의무화 \\nn유튜브가 몇 달 안에 생성 AI를 사용한 콘텐츠에 AI 라벨 표시를 의무화하기로 했으며 , 이를 \\n준수하지 않는 콘텐츠는 삭제하고 크리에이터에 대한 수익 배분도 중단할 수 있다고 설명\\nn유튜브는 AI 생성 콘텐츠가 신원 파악이 가능한 개인을 모방한 경우 개인정보 침해 신고 \\n절차에 따라 콘텐츠 삭제 요청도 받을 계획KEY Contents\\n£유튜브 , 생성 AI 콘텐츠에 AI 라벨 표시 안 하면 콘텐츠 삭제\\nn유튜브가 2023 년 11월 14일 공식 블로그를 통해 몇 달 안에 생성 AI를 사용한 콘텐츠에 AI \\n라벨을 표시하는 새로운 규칙을 시행한다고 발표 \\n∙실제로 일어나지 않은 사건을 사실적으로 묘사하거나 실제로 하지 않은 말이나 행동을 보여주는 콘텐츠와 \\n같이 AI 도구를 사용해 사실적으로 변경되거나 합성된 콘텐츠에는 AI 라벨을 표시 필요\\n∙유튜브는 이러한 규칙이 선거나 분쟁 상황, 공중 보건, 공직자 관련 문제와 같이 민감한 주제를 다루는 \\n콘텐츠에서 특히 중요하다고 강조했으며 , 크리에이터가 AI로 제작한 콘텐츠에 AI 라벨을 표시하지 않으면 \\n해당 콘텐츠는 삭제되고 광고 수익을 배분하는 유튜브 파트너 프로그램도 정지될 수 있음\\n∙유튜브는 두 가지 방식으로 AI를 이용한 콘텐츠의 변경이나 합성 여부를 시청자에게 전달할 계획으로 \\n동영상 설명 패널에 라벨을 표시하는 방식이 기본이며 , 민감한 주제를 다루는 특정 유형의 콘텐츠는 동영상 \\n플레이어에 더욱 눈에 띄는 라벨을 적용 \\n∙유튜브는 커뮤니티 정책에 위반되는 일부 합성 콘텐츠에 대해서는 라벨 지정 여부와 관계없이 삭제할 \\n방침으로 , 가령 사실적인 폭력을 보여주는 합성 동영상이 시청자에게 충격이나 혐오감을 줄 수 있다면 \\n삭제될 수 있음\\n£유튜브 , 특정인을 모방한 AI 생성 콘텐츠에 대한 삭제 요청에도 대응 계획\\n삭제될 수 있음\\n£유튜브 , 특정인을 모방한 AI 생성 콘텐츠에 대한 삭제 요청에도 대응 계획\\nn유튜브는 몇 달 내에 신원 파악이 가능한 개인의 얼굴이나 음성을 모방한 AI 생성 콘텐츠에 대하\\n여 개인정보 침해 신고 절차를 마련해 삭제 요청을 받을 계획\\n∙단, 모든 콘텐츠가 삭제 대상은 아니며 유튜브는 콘텐츠가 패러디나 풍자인지 , 해당 영상에서 삭제 요청을 \\n한 특정인을 식별할 수 있는지 , 공직자나 유명인이 등장하는지 등 다양한 요소를 고려할 예정\\n∙유튜브는 음반사가 아티스트의 고유한 노래나 목소리를 모방한 AI 생성 음악에 대하여 삭제를 요청할 수 \\n있는 기능도 도입할 방침\\n☞ 출처 : Youtube, Our approach to responsible AI innovation, 2023.11.14.\\n▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································ 11\\n   ▹ IDC, 2027 년 AI 소프트웨어 매출 2,500 억 달러 돌파 전망··········································· 12\\n   ▹ 빌 게이츠 , AI 에이전트로 인한 컴퓨터 사용의 패러다임 변화 전망································ 13\\n   ▹ 유튜브 , 2024 년부터 AI 생성 콘텐츠 표시 의무화 ···························································· 14\\n 3. 기술/연구\\n   ▹ 영국 과학혁신기술부 , AI 안전 연구소 설립 발표······························································ 15\\n   ▹ 구글 딥마인드 , 범용 AI 모델의 기능과 동작에 대한 분류 체계 발표······························ 16\\n   ▹ 갈릴레오의 LLM 환각 지수 평가에서 GPT-4 가 가장 우수 ··········································· 17\\n\\n인력/교육   \\n   ▹ 영국 옥스퍼드 인터넷 연구소 , AI 기술자의 임금이 평균 21% 높아······························· 18\\n\\nⅡ. 주요 행사\\n   ▹CES 2024 ····························································································································· 19\\nSPRi AI Brief |\\n2023-12 월호\\n4미국 법원, 예술가들이 생성 AI 기업에 제기한 저작권 소송 기각\\nn미국 캘리포니아 북부지방법원은 미드저니 , 스태빌리티 AI, 디비언트아트를 대상으로 예술가 \\n3인이 제기한 저작권 침해 소송을 기각\\nn법원은 기각 이유로 고소장에 제시된 상당수 작품이 저작권청에 등록되지 않았으며 , AI로 \\n생성된 이미지와 특정 작품 간 유사성을 입증하기 어렵다는 점을 제시 KEY Contents\\n£예술가들의 AI 저작권 침해 소송, 저작권 미등록과 증거불충분으로 기각\\nn미국 캘리포니아 북부지방법원의 윌리엄 오릭(W illiam Orrick) 판사는 2023년 10월 30일 미드저니\\n(M idjourney),  스태빌리티 AI(Stability AI), 디비언트아트 (DeviantArt) 에 제기된 저작권 침해 소송을 기각 \\n∙2023 년 1월 예술가 사라 앤더슨 (Sarah Anderson), 캘리 맥커넌 (Kelly McKernan), 칼라 \\n오르티즈 (Karla Ortiz) 는 이미지 생성 AI 서비스를 개발한 3개 기업을 상대로 저작권 침해 소송을 제기\\n∙예술가들은 3개 기업이 AI 모델을 학습시키기 위해 원작자 동의 없이 작품을 학습 데이터셋에 \\n포함하여 저작권을 침해했다고 주장했으며 , 법원은 지난 4월 피소 기업들이 제출한 기각 신청을 \\n수용해 소송을 기각 \\nn오릭 판사는 판결문에서 소송을 기각한 핵심 이유로 예술가들의 저작권 미등록을 제시\\n∙판결문은 소송을 제기한 캘리 맥커넌과 칼라 오르티즈가 미국 저작권청에 예술 작품에 대한 저작권을 \\n제출하지 않았다는 점을 지적했으며 , 사라 앤더슨은 고소장에 인용된 수백 개의 작품 중 16개 작품에 \\n대해서만 저작권을 보유\\nn판결문은 또한 생성 AI 모델 훈련에 사용된 모든 이미지에 저작권이 있다거나 , 생성 AI로 만든 \\n이미지가 저작물을 이용해 훈련되었으므로 저작물의 파생 이미지라는 주장은 개연성이  부족하다고\\n지적\\u001b[0m\\u001b[32;1m\\u001b[1;3m2024년부터 YouTube는 생성 AI를 사용한 콘텐츠에 AI 라벨 표시를 의무화할 예정입니다. 이 규칙을 준수하지 않는 콘텐츠는 삭제될 수 있으며, 크리에이터에 대한 수익 배분도 중단될 수 있습니다. YouTube는 AI 생성 콘텐츠가 신원 파악이 가능한 개인을 모방한 경우, 개인정보 침해 신고 절차에 따라 콘텐츠 삭제 요청을 받을 계획입니다.\\n새로운 규칙에 따르면, 실제로 일어나지 않은 사건을 사실적으로 묘사하거나 실제로 하지 않은 말이나 행동을 보여주는 콘텐츠와 같이 AI 도구를 사용해 사실적으로 변경되거나 합성된 콘텐츠에는 AI 라벨을 표시해야 합니다. YouTube는 이러한 규칙이 선거나 분쟁 상황, 공중 보건, 공직자 관련 문제와 같이 민감한 주제를 다루는 콘텐츠에서 특히 중요하다고 강조했습니다.\\nAI를 이용한 콘텐츠의 변경이나 합성 여부를 시청자에게 전달하기 위해 YouTube는 두 가지 방식을 계획하고 있습니다. 기본적으로 동영상 설명 패널에 라벨을 표시하며, 민감한 주제를 다루는 특정 유형의 콘텐츠는 동영상 플레이어에 더욱 눈에 띄는 라벨을 적용할 예정입니다. 커뮤니티 정책에 위반되는 일부 합성 콘텐츠는 라벨 지정 여부와 관계없이 삭제될 수 있습니다.\\n또한, YouTube는 몇 달 내에 신원 파악이 가능한 개인의 얼굴이나 음성을 모방한 AI 생성 콘텐츠에 대하여 개인정보 침해 신고 절차를 마련해 삭제 요청을 받을 계획입니다. 모든 콘텐츠가 삭제 대상은 아니며, 콘텐츠가 패러디나 풍자인지, 해당 영상에서 삭제 요청을 한 특정인을 식별할 수 있는지, 공직자나 유명인이 등장하는지 등 다양한 요소를 고려할 예정입니다. YouTube는 음반사가 아티스트의 고유한 노래나 목소리를 모방한 AI 생성 음악에 대하여 삭제를 요청할 수 있는 기능도 도입할 방침입니다.\\u001b[0m\\n\\u001b[1m> Finished chain.\\u001b[0m\\n답변: 2024년부터 YouTube는 생성 AI를 사용한 콘텐츠에 AI 라벨 표시를 의무화할 예정입니다. 이 규칙을 준수하지 않는 콘텐츠는 삭제될 수 있으며, 크리에이터에 대한 수익 배분도 중단될 수 있습니다. YouTube는 AI 생성 콘텐츠가 신원 파악이 가능한 개인을 모방한 경우, 개인정보 침해 신고 절차에 따라 콘텐츠 삭제 요청을 받을 계획입니다.\\n새로운 규칙에 따르면, 실제로 일어나지 않은 사건을 사실적으로 묘사하거나 실제로 하지 않은 말이나 행동을 보여주는 콘텐츠와 같이 AI 도구를 사용해 사실적으로 변경되거나 합성된 콘텐츠에는 AI 라벨을 표시해야 합니다. YouTube는 이러한 규칙이 선거나 분쟁 상황, 공중 보건, 공직자 관련 문제와 같이 민감한 주제를 다루는 콘텐츠에서 특히 중요하다고 강조했습니다.\\nAI를 이용한 콘텐츠의 변경이나 합성 여부를 시청자에게 전달하기 위해 YouTube는 두 가지 방식을 계획하고 있습니다. 기본적으로 동영상 설명 패널에 라벨을 표시하며, 민감한 주제를 다루는 특정 유형의 콘텐츠는 동영상 플레이어에 더욱 눈에 띄는 라벨을 적용할 예정입니다. 커뮤니티 정책에 위반되는 일부 합성 콘텐츠는 라벨 지정 여부와 관계없이 삭제될 수 있습니다.\\n또한, YouTube는 몇 달 내에 신원 파악이 가능한 개인의 얼굴이나 음성을 모방한 AI 생성 콘텐츠에 대하여 개인정보 침해 신고 절차를 마련해 삭제 요청을 받을 계획입니다. 모든 콘텐츠가 삭제 대상은 아니며, 콘텐츠가 패러디나 풍자인지, 해당 영상에서 삭제 요청을 한 특정인을 식별할 수 있는지, 공직자나 유명인이 등장하는지 등 다양한 요소를 고려할 예정입니다. YouTube는 음반사가 아티스트의 고유한 노래나 목소리를 모방한 AI 생성 음악에 대하여 삭제를 요청할 수 있는 기능도 도입할 방침입니다.\\n마무리입니다!\\n이번 튜토리얼에서는 우리는 간단한 에이전트를 만드는 방법을 다뤘습니다.\\n에이전트는 복잡한 주제이며 배울 것이 많습니다! 개념 가이드, 다양한 유형의 에이전트, 맞춤형 도구를 만드는 방법 등 더 많은 자료를 찾으려면 한국어 튜토리얼(Agent) 를 참고해 주세요!\\nReference\\n본 튜토리얼은 LangChain 튜토리얼 노트북 파일을 참조하여 작성하였습니다.\\n\\n본 문서의 원 저작권자는 langchain-ai 이며, 코드는 MIT License 에 따라 사용이 허가된 파일입니다.\\n원문 바로가기\\n\\n태그: Agent, API KEY, FAISS, LangChain, LangSmith, memory, OpenAI, Python, Retriever, Tavily Search, tools, 검색도구, 랭체인, 에이전트\\n카테고리: langchain\\n업데이트: 2024년 02월 09일\\n공유하기\\nTwitter Facebook LinkedIn\\n이전 다음\\n댓글남기기\\n참고\\npoetry 의 거의 모든것 (튜토리얼)\\n2024년 03월 30일 5 분 소요\\nPython 개발에 있어서 poetry는 매우 강력한 도구로, 프로젝트의 의존성 관리와 패키지 배포를 간소화하는 데 큰 도움을 줍니다. 지금부터 poetry 활용 튜토리얼을 살펴 보겠습니다.\\nLangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\\n2024년 03월 06일 10 분 소요\\nLangGraph Retrieval Agent는 언어 처리, AI 모델 통합, 데이터베이스 관리, 그래프 기반 데이터 처리 등 다양한 기능을 제공하여 언어 기반 AI 애플리케이션 개발에 필수적인 도구입니다.\\n[Assistants API] Code Interpreter, Retrieval, Functions 활용법\\n2024년 02월 13일 35 분 소요\\nOpenAI의 새로운 Assistants API는 대화와 더불어 강력한 도구 접근성을 제공합니다. 본 튜토리얼은 OpenAI Assistants API를 활용하는 내용을 다룹니다. 특히, Assistant API 가 제공하는 도구인 Code Interpreter, Retrieval...\\nLangChain RAG 파헤치기: 문서 기반 QA 시스템 설계 방법 - 심화편\\n2024년 02월 06일 22 분 소요\\nLangChain의 RAG 시스템을 통해 문서(PDF, txt, 웹페이지 등)에 대한 질문-답변을 찾는 과정을 정리하였습니다.\\n\\n팔로우:\\nYouTube\\nGitHub\\nInstagram\\n피드\\n\\n© 2024 테디노트. Powered by Jekyll & Minimal Mistakes.\"}]\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "LangGraph에 대한 철저한 정보를 원하신다면, 아래의 자료를 추천합니다:\n",
      "\n",
      "1. **[LangGraph - Multi-Agent Collaboration](https://teddylee777.github.io/langgraph/langgraph-multi-agent-collaboration/)** \n",
      "   - 이 자료는 LangGraph 라이브러리를 활용하여 다중 에이전트가 협업하는 방식으로 복잡한 문제를 해결하는 방법에 대해 상세히 설명합니다. 기본 개념과 에이전트 생성, 도구 정의, 그래프 생성 및 호출 방법 등을 다룹니다.\n",
      "\n",
      "2. **[LangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리](https://teddylee777.github.io/langgraph/langgraph-agentic-rag/)**\n",
      "   - 이 게시물에서는 LangGraph와 Retrieval Agent의 결합 과정과 구현 방법, 실제 사용 예시를 통해 문서 검색 및 처리의 효과적인 활용 방안을 제시합니다. Python 코드를 통한 상세한 설명이 포함되어 있습니다.\n",
      "\n",
      "3. **[LangChain 에이전트와 도구를 활용한 지능형 검색 시스템 구축 가이드](https://teddylee777.github.io/langchain/langchain-agent/)**\n",
      "   - LangChain의 Agent 프레임워크를 활용하여 복잡한 검색 및 데이터 처리 작업을 수행하는 방법을 설명합니다. 다양한 도구 정의와 함께 에이전트를 구축하고 실행하는 단계를 소개합니다.\n",
      "\n",
      "이 자료들은 LangGraph의 기초부터 고급 활용법까지 포괄적으로 다루고 있어, 학습에 큰 도움이 될 것입니다.\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:03:27.479474Z",
     "start_time": "2025-04-23T08:03:11.411229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 이벤트 스트림 생성\n",
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": (\n",
    "            \"user\",\n",
    "            \"내가 지금까지 배운 내용에 대해서 매우 친절하고 정성스럽게 한국어로 답변해줘! 출처를 반드시 포함해줘!\",\n",
    "        )\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "\n",
    "# 메시지 이벤트 처리\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        # 마지막 메시지 출력\n",
    "        event[\"messages\"][-1].pretty_print()"
   ],
   "id": "9353f17ef8b5ef14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "내가 지금까지 배운 내용에 대해서 매우 친절하고 정성스럽게 한국어로 답변해줘! 출처를 반드시 포함해줘!\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "물론입니다! 지금까지 배운 LangGraph에 대한 내용을 정리해 드리겠습니다.\n",
      "\n",
      "### LangGraph란?\n",
      "LangGraph는 다중 에이전트 협업을 통해 복잡한 문제를 해결하는 데 도움을 주는 Python 라이브러리입니다. 이 라이브러리는 다양한 에이전트가 각기 다른 도메인에서 전문화된 지식을 활용하여 공동으로 작업을 수행하도록 돕습니다. LangGraph는 특히 AI와 언어 모델(Large Language Models, LLMs)을 활용하여 문제 해결에 접근할 수 있는 강력한 도구입니다.\n",
      "\n",
      "### 주요 개념\n",
      "1. **다중 에이전트 협업**: 여러 AI 에이전트가 협력하여 각자의 전문 영역에서 정보를 공유하고 문제를 해결합니다. 이를 통해 복잡한 작업을 보다 효과적으로 처리할 수 있습니다.\n",
      "   \n",
      "2. **도구 정의**: 각 에이전트는 특정 작업을 수행할 수 있는 도구를 정의하고 사용할 수 있습니다. 예를 들어, 문서 검색 도구나 데이터 처리 도구 등이 있습니다.\n",
      "\n",
      "3. **그래프 생성**: LangGraph는 에이전트들이 서로 통신하고 협력하는 그래프 구조를 생성합니다. 이를 통해 각 에이전트의 상태를 관리하고 작업 흐름을 제어할 수 있습니다.\n",
      "\n",
      "### 사용 예시\n",
      "- 예를 들어, 한 에이전트가 데이터를 수집하고, 다른 에이전트는 그 데이터를 분석하여 최종 결과를 도출하는 방식으로 협업할 수 있습니다. 이러한 방식은 \"나누고 정복하기(divide-and-conquer)\" 접근법에 기반합니다.\n",
      "\n",
      "### 관련 자료\n",
      "1. **[LangGraph - Multi-Agent Collaboration](https://teddylee777.github.io/langgraph/langgraph-multi-agent-collaboration/)**: 이 자료에서는 다중 에이전트 협업을 통해 복잡한 문제를 해결하는 방법을 설명합니다. 특히 LangGraph를 활용한 에이전트 생성 및 호출 방법에 대해 다룹니다.\n",
      "\n",
      "2. **[LangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리](https://teddylee777.github.io/langgraph/langgraph-agentic-rag/)**: 이 자료에서는 LangGraph와 Retrieval Agent의 통합 과정, 구현 방법, 실제 사용 예시를 통해 이러한 도구들의 효과적인 활용 방법을 설명합니다.\n",
      "\n",
      "3. **[LangChain 에이전트와 도구를 활용한 지능형 검색 시스템 구축 가이드](https://teddylee777.github.io/langchain/langchain-agent/)**: LangChain의 Agent 프레임워크를 통해 복잡한 검색과 데이터 처리 작업을 수행하는 방법을 소개합니다.\n",
      "\n",
      "이 자료들은 LangGraph의 기초부터 고급 활용법까지 포괄적으로 다루고 있어, 여러분의 학습에 큰 도움이 될 것입니다. 계속해서 공부하시고, 좋은 결과 얻으시길 바랍니다!\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:03:46.907012Z",
     "start_time": "2025-04-23T08:03:46.900689Z"
    }
   },
   "cell_type": "code",
   "source": "graph.get_state(config).values[\"messages\"][-1].pretty_print()",
   "id": "3e8c710e58c3a37f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "물론입니다! 지금까지 배운 LangGraph에 대한 내용을 정리해 드리겠습니다.\n",
      "\n",
      "### LangGraph란?\n",
      "LangGraph는 다중 에이전트 협업을 통해 복잡한 문제를 해결하는 데 도움을 주는 Python 라이브러리입니다. 이 라이브러리는 다양한 에이전트가 각기 다른 도메인에서 전문화된 지식을 활용하여 공동으로 작업을 수행하도록 돕습니다. LangGraph는 특히 AI와 언어 모델(Large Language Models, LLMs)을 활용하여 문제 해결에 접근할 수 있는 강력한 도구입니다.\n",
      "\n",
      "### 주요 개념\n",
      "1. **다중 에이전트 협업**: 여러 AI 에이전트가 협력하여 각자의 전문 영역에서 정보를 공유하고 문제를 해결합니다. 이를 통해 복잡한 작업을 보다 효과적으로 처리할 수 있습니다.\n",
      "   \n",
      "2. **도구 정의**: 각 에이전트는 특정 작업을 수행할 수 있는 도구를 정의하고 사용할 수 있습니다. 예를 들어, 문서 검색 도구나 데이터 처리 도구 등이 있습니다.\n",
      "\n",
      "3. **그래프 생성**: LangGraph는 에이전트들이 서로 통신하고 협력하는 그래프 구조를 생성합니다. 이를 통해 각 에이전트의 상태를 관리하고 작업 흐름을 제어할 수 있습니다.\n",
      "\n",
      "### 사용 예시\n",
      "- 예를 들어, 한 에이전트가 데이터를 수집하고, 다른 에이전트는 그 데이터를 분석하여 최종 결과를 도출하는 방식으로 협업할 수 있습니다. 이러한 방식은 \"나누고 정복하기(divide-and-conquer)\" 접근법에 기반합니다.\n",
      "\n",
      "### 관련 자료\n",
      "1. **[LangGraph - Multi-Agent Collaboration](https://teddylee777.github.io/langgraph/langgraph-multi-agent-collaboration/)**: 이 자료에서는 다중 에이전트 협업을 통해 복잡한 문제를 해결하는 방법을 설명합니다. 특히 LangGraph를 활용한 에이전트 생성 및 호출 방법에 대해 다룹니다.\n",
      "\n",
      "2. **[LangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리](https://teddylee777.github.io/langgraph/langgraph-agentic-rag/)**: 이 자료에서는 LangGraph와 Retrieval Agent의 통합 과정, 구현 방법, 실제 사용 예시를 통해 이러한 도구들의 효과적인 활용 방법을 설명합니다.\n",
      "\n",
      "3. **[LangChain 에이전트와 도구를 활용한 지능형 검색 시스템 구축 가이드](https://teddylee777.github.io/langchain/langchain-agent/)**: LangChain의 Agent 프레임워크를 통해 복잡한 검색과 데이터 처리 작업을 수행하는 방법을 소개합니다.\n",
      "\n",
      "이 자료들은 LangGraph의 기초부터 고급 활용법까지 포괄적으로 다루고 있어, 여러분의 학습에 큰 도움이 될 것입니다. 계속해서 공부하시고, 좋은 결과 얻으시길 바랍니다!\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 지난 스냅샷의 결과 수정 및 Replay\n",
   "id": "fdc6eb6568e43b6c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:04:13.247654Z",
     "start_time": "2025-04-23T08:04:13.235962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "to_replay_state = None\n",
    "\n",
    "# 상태 기록 가져오기\n",
    "for state in graph.get_state_history(config):\n",
    "\n",
    "    messages = state.values[\"messages\"]\n",
    "\n",
    "    if len(messages) > 0:\n",
    "        print(state.values[\"messages\"][-1].id)\n",
    "        # 메시지 수 및 다음 상태 출력\n",
    "        print(\"메시지 수: \", len(state.values[\"messages\"]), \"다음 노드: \", state.next)\n",
    "        print(\"-\" * 80)\n",
    "        # 특정 상태 선택 기준: 채팅 메시지 수\n",
    "        if len(state.values[\"messages\"]) == 2:\n",
    "            # 특정 메시지 ID 선택\n",
    "            to_replay_state = state"
   ],
   "id": "8f54eec0d85cb98d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run-b6274d83-0f6f-4b6d-9b51-c2290625edcc-0\n",
      "메시지 수:  6 다음 노드:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "2401e4ac-e06d-4f4b-aa04-33af1aa24c83\n",
      "메시지 수:  5 다음 노드:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "run-4b4df3d1-af67-4085-ab06-140d419bc46d-0\n",
      "메시지 수:  4 다음 노드:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n",
      "run-4b4df3d1-af67-4085-ab06-140d419bc46d-0\n",
      "메시지 수:  4 다음 노드:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "b9a973b1-88a8-4740-8959-5b24c54725e0\n",
      "메시지 수:  3 다음 노드:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "run-d4934350-ee04-4cb8-a32f-b3c7ea24d77e-0\n",
      "메시지 수:  2 다음 노드:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "run-d4934350-ee04-4cb8-a32f-b3c7ea24d77e-0\n",
      "메시지 수:  2 다음 노드:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "795d7da5-59f3-458d-8bd8-b66b4efb9030\n",
      "메시지 수:  1 다음 노드:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:04:22.625809Z",
     "start_time": "2025-04-23T08:04:21.814585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_teddynote.messages import display_message_tree\n",
    "\n",
    "# 선택한 메시지 가져오기\n",
    "existing_message = to_replay_state.values[\"messages\"][-1]\n",
    "\n",
    "# 메시지 트리 출력\n",
    "display_message_tree(existing_message)"
   ],
   "id": "90c8169664d6119f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \u001B[93mcontent\u001B[0m: \"\"\n",
      "    \u001B[93madditional_kwargs\u001B[0m:\n",
      "        \u001B[94mtool_calls\u001B[0m:\n",
      "            \u001B[94mindex [0]\u001B[0m\n",
      "                \u001B[92mid\u001B[0m: \"call_x97g4sjFCID0y9R8W42AUelP\"\n",
      "                \u001B[92mfunction\u001B[0m: {\"arguments\": \"{\"query\":\"LangGraph 소개\"}\", \"name\": \"tavily_web_search\"}\n",
      "                \u001B[92mtype\u001B[0m: \"function\"\n",
      "        \u001B[94mrefusal\u001B[0m: None\n",
      "    \u001B[93mresponse_metadata\u001B[0m:\n",
      "        \u001B[94mtoken_usage\u001B[0m:\n",
      "            \u001B[95mcompletion_tokens\u001B[0m: 20\n",
      "            \u001B[95mprompt_tokens\u001B[0m: 110\n",
      "            \u001B[95mtotal_tokens\u001B[0m: 130\n",
      "            \u001B[95mcompletion_tokens_details\u001B[0m: {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}\n",
      "            \u001B[95mprompt_tokens_details\u001B[0m: {\"audio_tokens\": 0, \"cached_tokens\": 0}\n",
      "        \u001B[94mmodel_name\u001B[0m: \"gpt-4o-mini-2024-07-18\"\n",
      "        \u001B[94msystem_fingerprint\u001B[0m: \"fp_dbaca60df0\"\n",
      "        \u001B[94mid\u001B[0m: \"chatcmpl-BPPImqhvE57TjF6ytKZ0lohltol0F\"\n",
      "        \u001B[94mfinish_reason\u001B[0m: \"tool_calls\"\n",
      "        \u001B[94mlogprobs\u001B[0m: None\n",
      "    \u001B[93mtype\u001B[0m: \"ai\"\n",
      "    \u001B[93mname\u001B[0m: None\n",
      "    \u001B[93mid\u001B[0m: \"run-d4934350-ee04-4cb8-a32f-b3c7ea24d77e-0\"\n",
      "    \u001B[93mexample\u001B[0m: False\n",
      "    \u001B[93mtool_calls\u001B[0m:\n",
      "        \u001B[93mindex [0]\u001B[0m\n",
      "            \u001B[95mname\u001B[0m: \"tavily_web_search\"\n",
      "            \u001B[95margs\u001B[0m: {\"query\": \"LangGraph 소개\"}\n",
      "            \u001B[95mid\u001B[0m: \"call_x97g4sjFCID0y9R8W42AUelP\"\n",
      "            \u001B[95mtype\u001B[0m: \"tool_call\"\n",
      "    \u001B[93minvalid_tool_calls\u001B[0m:\n",
      "    \u001B[93musage_metadata\u001B[0m:\n",
      "        \u001B[94minput_tokens\u001B[0m: 110\n",
      "        \u001B[94moutput_tokens\u001B[0m: 20\n",
      "        \u001B[94mtotal_tokens\u001B[0m: 130\n",
      "        \u001B[94minput_token_details\u001B[0m: {\"audio\": 0, \"cache_read\": 0}\n",
      "        \u001B[94moutput_token_details\u001B[0m: {\"audio\": 0, \"reasoning\": 0}\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:04:43.177566Z",
     "start_time": "2025-04-23T08:04:43.170228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tool_call = existing_message.tool_calls[0].copy()\n",
    "tool_call[\"args\"] = {\"query\": \"LangGraph human-in-the-loop workflow site:reddit.com\"}\n",
    "tool_call"
   ],
   "id": "2bfe3fb5538aa5ba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'tavily_web_search',\n",
       " 'args': {'query': 'LangGraph human-in-the-loop workflow site:reddit.com'},\n",
       " 'id': 'call_x97g4sjFCID0y9R8W42AUelP',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:05:11.019856Z",
     "start_time": "2025-04-23T08:05:11.014399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# AIMessage 생성\n",
    "new_message = AIMessage(\n",
    "    content=existing_message.content,\n",
    "    tool_calls=[tool_call],\n",
    "    # 중요! ID는 메시지를 상태에 추가하는 대신 교체하는 방법\n",
    "    id=existing_message.id,\n",
    ")\n",
    "\n",
    "# 수정한 메시지 출력\n",
    "new_message.tool_calls[0][\"args\"]"
   ],
   "id": "3578445c2aeaec2b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'LangGraph human-in-the-loop workflow site:reddit.com'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:05:36.990829Z",
     "start_time": "2025-04-23T08:05:36.984676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 업데이트 전 메시지 확인\n",
    "graph.get_state(to_replay_state.config).values[\"messages\"][-1].tool_calls"
   ],
   "id": "8f46106385e3051a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_web_search',\n",
       "  'args': {'query': 'LangGraph 소개'},\n",
       "  'id': 'call_x97g4sjFCID0y9R8W42AUelP',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:05:51.837020Z",
     "start_time": "2025-04-23T08:05:51.824714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 상태 업데이트\n",
    "updated_state = graph.update_state(\n",
    "    to_replay_state.config,\n",
    "    {\"messages\": [new_message]},\n",
    ")\n",
    "updated_state"
   ],
   "id": "cedb2c8c6fdd3f2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': 'da7be0',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f02019c-619d-6387-8002-1e2c8ae3c363'}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:06:11.973521Z",
     "start_time": "2025-04-23T08:06:03.010659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# config 에는 updated_state 를 전달합니다. 이는 임의로 갱신한 상태를 전달하는 것입니다.\n",
    "for event in graph.stream(None, updated_state, stream_mode=\"values\"):\n",
    "    # 메시지가 이벤트에 포함된 경우\n",
    "    if \"messages\" in event:\n",
    "        # 마지막 메시지 출력\n",
    "        event[\"messages\"][-1].pretty_print()"
   ],
   "id": "edd9a60246253672",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_x97g4sjFCID0y9R8W42AUelP)\n",
      " Call ID: call_x97g4sjFCID0y9R8W42AUelP\n",
      "  Args:\n",
      "    query: LangGraph human-in-the-loop workflow site:reddit.com\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: tavily_web_search\n",
      "\n",
      "[{\"title\": \"Human intervention in agent workflows : r/LangChain - Reddit\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1bjnmu4/human_intervention_in_agent_workflows/\", \"content\": \"Reddit - Dive into anything Open menu Open navigation  Go to Reddit Home Go to LangChain r/LangChain r/LangChain When building LLM workflows with LangChain/LangGraph what's the best way to build a node in the workflow where a human can validate/approve/reject a flow? Top Posts Reddit Reddit Reddit Action Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion Communities Best of Reddit Topics Reddit Rules Privacy Policy User Agreement Reddit, Inc.\", \"score\": 0.65359193, \"raw_content\": \"Reddit - Dive into anything\\nSkip to main content\\nOpen menu Open navigation  Go to Reddit Home\\nr/LangChain A chip A close button\\nGet App Get the Reddit app Log In Log in to Reddit\\nExpand user menu Open settings menu\\n Go to LangChain\\nr/LangChain\\nr/LangChain\\nLangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.\\n\\nMembers Online\\n•\\ntisi3000\\nHuman intervention in agent workflows\\nWhen building LLM workflows with LangChain/LangGraph what's the best way to build a node in the workflow where a human can validate/approve/reject a flow? I know there is a Human-in-the-loop component in LangGraph that will prompt the user for input. But what if I'm not creating a user-initiated chat conversation, but a flow that reacts to e.g. incoming emails?\\nI guess I'd have to design my UI so that it's not only a simple single-threaded chat interface, but some sort of inbox, right? Or is there any standard way that comes to mind?\\nRead more\\nTop 3% Rank by size\\nPublic\\nAnyone can view, post, and comment to this community\\nTop Posts\\n\\n\\n\\nReddit\\nreReddit: Top posts of March 20, 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of March 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of 2024 * * *\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\nTOPICS\\n\\n\\nInternet Culture (Viral)\\n\\n\\nAmazing Animals & Pets Cringe & Facepalm Funny Interesting Memes Oddly Satisfying Reddit Meta Wholesome & Heartwarming\\n\\n\\nGames\\n\\n\\nAction Games Adventure Games Esports Gaming Consoles & Gear Gaming News & Discussion Mobile Games Other Games Role-Playing Games Simulation Games Sports & Racing Games Strategy Games*   Tabletop Games\\n\\n\\nQ&As\\n\\n\\nQ&As*   Stories & Confessions\\n\\n\\nTechnology\\n\\n\\n3D Printing Artificial Intelligence & Machine Learning Computers & Hardware Consumer Electronics DIY Electronics Programming Software & Apps Streaming Services Tech News & Discussion*   Virtual & Augmented Reality\\n\\n\\nPop Culture\\n\\n\\nCelebrities Creators & Influencers Generations & Nostalgia Podcasts Streamers*   Tarot & Astrology\\n\\n\\nMovies & TV\\n\\n\\nAction Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\nAbout Reddit Advertise Help Blog Careers*   Press\\n\\n\\n\\n\\nCommunities Best of Reddit Topics\\n\\n\\n\\nReddit Rules Privacy Policy User Agreement\\n\\nReddit, Inc. © 2025. All rights reserved.\"}, {\"title\": \"LangGraph Workflow for Quality Assurance : r/LangChain - Reddit\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1bsblmu/langgraph_workflow_for_quality_assurance/\", \"content\": \"Reddit - Dive into anything Go to LangChain I've been working on a concept to automate the Quality Assurance (QA) process for complex legal documents using LangGraph, aiming to streamline the workflow, reduce manual effort, and improve compliance efficiency. Handling specific parts of the QA process using AI rather human reviews, from initial document submission to final approval. Document Submission (Manual User Action): Entry point for examiners to submit documents. Policy Compliance Checker Node (PCCN): Checks documents against policy rules. Quality Assurance Node (QAN): Final review to ensure document quality. Approval and Compliance Marking Node (ACMN): Marks documents as approved. Has anyone automated a Quality Assurance process with langchain/graph? Reddit Reddit Reddit Communities Best of Reddit Topics Reddit, Inc.\", \"score\": 0.6347929, \"raw_content\": \"Reddit - Dive into anything\\nSkip to main content\\nOpen menu Open navigation  Go to Reddit Home\\nr/LangChain A chip A close button\\nGet App Get the Reddit app Log In Log in to Reddit\\nExpand user menu Open settings menu\\n Go to LangChain\\nr/LangChain\\nr/LangChain\\nLangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.\\n\\nMembers Online\\n•\\nSwimminInIt\\nLangGraph Workflow for Quality Assurance\\nQuestion | Help\\nI've been working on a concept to automate the Quality Assurance (QA) process for complex legal documents using LangGraph, aiming to streamline the workflow, reduce manual effort, and improve compliance efficiency. Handling specific parts of the QA process using AI rather human reviews, from initial document submission to final approval.\\nI see a ton of people talking about document chat and integration with knowledge repos. Rather than just providing information I am looking to perform QA on the documents itself.\\nHere's a brief overview of the workflow:\\n\\n\\nDocument Submission (Manual User Action): Entry point for examiners to submit documents.\\n\\n\\nPre-Processing Node (Script for Data Manipulation): Handles initial formatting and basic validation.\\n\\n\\nPolicy Compliance Checker Node (PCCN): Checks documents against policy rules.\\n\\n\\nError Suggestion Node (ESN): Identifies compliance issues and suggests corrections.\\n\\n\\nQuality Assurance Node (QAN): Final review to ensure document quality.\\n\\n\\nFeedback and Interaction Node (FIN): Where examiners review AI suggestions and apply corrections.\\n\\n\\nApproval and Compliance Marking Node (ACMN): Marks documents as approved.\\n\\n\\nSome questions I have are:\\n\\n\\nHas anyone automated a Quality Assurance process with langchain/graph?\\n\\n\\nIf yes, what was successful or what did not work?\\n\\n\\nAny suggestions on how to improve my approach?\\n\\n\\nAre there any examples you are aware of I could use as a reference?\\n\\n\\nI appreciate any help and thoughts on the topic!\\nRead more\\nTop 3% Rank by size\\nPublic\\nAnyone can view, post, and comment to this community\\nTop Posts\\n\\n\\n\\nReddit\\nreReddit: Top posts of March 31, 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of March 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of 2024 * * *\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\nTOPICS\\n\\n\\nInternet Culture (Viral)\\n\\n\\nAmazing Animals & Pets Cringe & Facepalm Funny Interesting Memes Oddly Satisfying Reddit Meta Wholesome & Heartwarming\\n\\n\\nGames\\n\\n\\nAction Games Adventure Games Esports Gaming Consoles & Gear Gaming News & Discussion Mobile Games Other Games Role-Playing Games Simulation Games Sports & Racing Games Strategy Games*   Tabletop Games\\n\\n\\nQ&As\\n\\n\\nQ&As*   Stories & Confessions\\n\\n\\nTechnology\\n\\n\\n3D Printing Artificial Intelligence & Machine Learning Computers & Hardware Consumer Electronics DIY Electronics Programming Software & Apps Streaming Services Tech News & Discussion*   Virtual & Augmented Reality\\n\\n\\nPop Culture\\n\\n\\nCelebrities Creators & Influencers Generations & Nostalgia Podcasts Streamers*   Tarot & Astrology\\n\\n\\nMovies & TV\\n\\n\\nAction Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\nAbout Reddit Advertise Help Blog Careers*   Press\\n\\n\\n\\n\\nCommunities Best of Reddit Topics\\n\\n\\n\\nReddit Rules Privacy Policy User Agreement\\n\\nReddit, Inc. © 2025. All rights reserved.\"}, {\"title\": \"Tool-calling agents: Human approval before tool invocation?\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1ci3m0k/toolcalling_agents_human_approval_before_tool/\", \"content\": \"Reddit - Dive into anything Open menu Open navigation  Go to Reddit Home Get App Get the Reddit app Log In Log in to Reddit Go to LangChain r/LangChain r/LangChain I'd like to be able to ask for human confirmation before the agent executor invokes a certain tool. I can actually put the confirmation logic in the tool function itself and get it to work, but that doesn't seem right. Reddit Reddit Reddit Action Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion About Reddit Advertise Help Blog Careers*   Press Communities Best of Reddit Topics Reddit, Inc.\", \"score\": 0.20606238, \"raw_content\": \"Reddit - Dive into anything\\nSkip to main content\\nOpen menu Open navigation  Go to Reddit Home\\nr/LangChain A chip A close button\\nGet App Get the Reddit app Log In Log in to Reddit\\nExpand user menu Open settings menu\\n Go to LangChain\\nr/LangChain\\nr/LangChain\\nLangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.\\n\\nMembers Online\\n•\\ntranswarpconduit1\\nTool-calling agents: Human approval before tool invocation?\\nQuestion | Help\\nI'd like to be able to ask for human confirmation before the agent executor invokes a certain tool. For example, let's say I have asend_emailtool, and I'd like to confirm before it is run.\\nDoes the Langchain agent framework provide a way to hook into the lifecycle in order to do this? Ideally, a hook that would run before the invocation, has tool name and arguments passed in, and then you can return True or False (or an *Exception for an error). I could have the email displayed to standard out there, and collect input.\\nIt doesn't seem like callback handlers work, and they weren't intended for that anyway. They are for introspection (like logging, instrumentation, etc.).\\nI can actually put the confirmation logic in the tool function itself and get it to work, but that doesn't seem right. I could create a special wrapper function \\\"add_human_approval(tool_func)\\\" that returns a new function that asks for human approval, and if it passes invokes the passed in func, otherwise returns. Again, that's still at the tool level, instead as part of the lifecycle.\\nThoughts?\\nRead more\\nTop 3% Rank by size\\nPublic\\nAnyone can view, post, and comment to this community\\nTop Posts\\n\\n\\n\\nReddit\\nreReddit: Top posts of May 2, 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of May 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of 2024 * * *\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\nTOPICS\\n\\n\\nInternet Culture (Viral)\\n\\n\\nAmazing Animals & Pets Cringe & Facepalm Funny Interesting Memes Oddly Satisfying Reddit Meta Wholesome & Heartwarming\\n\\n\\nGames\\n\\n\\nAction Games Adventure Games Esports Gaming Consoles & Gear Gaming News & Discussion Mobile Games Other Games Role-Playing Games Simulation Games Sports & Racing Games Strategy Games*   Tabletop Games\\n\\n\\nQ&As\\n\\n\\nQ&As*   Stories & Confessions\\n\\n\\nTechnology\\n\\n\\n3D Printing Artificial Intelligence & Machine Learning Computers & Hardware Consumer Electronics DIY Electronics Programming Software & Apps Streaming Services Tech News & Discussion*   Virtual & Augmented Reality\\n\\n\\nPop Culture\\n\\n\\nCelebrities Creators & Influencers Generations & Nostalgia Podcasts Streamers*   Tarot & Astrology\\n\\n\\nMovies & TV\\n\\n\\nAction Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\nAbout Reddit Advertise Help Blog Careers*   Press\\n\\n\\n\\n\\nCommunities Best of Reddit Topics\\n\\n\\n\\nReddit Rules Privacy Policy User Agreement\\n\\nReddit, Inc. © 2025. All rights reserved.\"}]\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "LangGraph에 대한 유용한 자료는 다음과 같습니다:\n",
      "\n",
      "1. **[Human intervention in agent workflows](https://www.reddit.com/r/LangChain/comments/1bjnmu4/human_intervention_in_agent_workflows/)**:\n",
      "   - 이 게시글에서는 LangGraph로 LLM 워크플로우를 구축하면서 인간이 검증하거나 승인, 거부할 수 있는 노드를 만드는 방법에 대해 다룹니다. 다양한 시나리오에서 인간의 개입이 어떻게 이루어질 수 있는지에 대한 논의가 포함되어 있습니다.\n",
      "\n",
      "2. **[LangGraph Workflow for Quality Assurance](https://www.reddit.com/r/LangChain/comments/1bsblmu/langgraph_workflow_for_quality_assurance/)**:\n",
      "   - LangGraph를 사용하여 복잡한 법률 문서의 품질 보증 프로세스를 자동화하는 개념에 대해 설명합니다. 문서 제출에서부터 최종 승인까지의 프로세스 흐름을 안내하며, AI를 사용하여 특정 QA 프로세스를 처리하는 방법에 대해 논의합니다.\n",
      "\n",
      "3. **[Tool-calling agents: Human approval before tool invocation?](https://www.reddit.com/r/LangChain/comments/1ci3m0k/toolcalling_agents_human_approval_before_tool/)**:\n",
      "   - 이 게시글은 툴을 호출하기 전 인간의 승인을 요구하는 방법에 대해 이야기합니다. LangChain 에이전트 프레임워크에서 이러한 승인 로직을 구현하는 다양한 접근 방식에 대해 논의하고 있습니다.\n",
      "\n",
      "이 자료들을 통해 LangGraph의 기능과 활용 사례에 대해 더 깊이 이해할 수 있을 것입니다.\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:06:19.536356Z",
     "start_time": "2025-04-23T08:06:19.532090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 최종 결과 출력\n",
    "for msg in graph.get_state(config).values[\"messages\"]:\n",
    "    msg.pretty_print()"
   ],
   "id": "51e12cc8a7aeb39c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "LangGraph 에 대해서 배워보고 싶습니다. 유용한 자료를 추천해 주세요!\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_x97g4sjFCID0y9R8W42AUelP)\n",
      " Call ID: call_x97g4sjFCID0y9R8W42AUelP\n",
      "  Args:\n",
      "    query: LangGraph human-in-the-loop workflow site:reddit.com\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: tavily_web_search\n",
      "\n",
      "[{\"title\": \"Human intervention in agent workflows : r/LangChain - Reddit\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1bjnmu4/human_intervention_in_agent_workflows/\", \"content\": \"Reddit - Dive into anything Open menu Open navigation  Go to Reddit Home Go to LangChain r/LangChain r/LangChain When building LLM workflows with LangChain/LangGraph what's the best way to build a node in the workflow where a human can validate/approve/reject a flow? Top Posts Reddit Reddit Reddit Action Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion Communities Best of Reddit Topics Reddit Rules Privacy Policy User Agreement Reddit, Inc.\", \"score\": 0.65359193, \"raw_content\": \"Reddit - Dive into anything\\nSkip to main content\\nOpen menu Open navigation  Go to Reddit Home\\nr/LangChain A chip A close button\\nGet App Get the Reddit app Log In Log in to Reddit\\nExpand user menu Open settings menu\\n Go to LangChain\\nr/LangChain\\nr/LangChain\\nLangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.\\n\\nMembers Online\\n•\\ntisi3000\\nHuman intervention in agent workflows\\nWhen building LLM workflows with LangChain/LangGraph what's the best way to build a node in the workflow where a human can validate/approve/reject a flow? I know there is a Human-in-the-loop component in LangGraph that will prompt the user for input. But what if I'm not creating a user-initiated chat conversation, but a flow that reacts to e.g. incoming emails?\\nI guess I'd have to design my UI so that it's not only a simple single-threaded chat interface, but some sort of inbox, right? Or is there any standard way that comes to mind?\\nRead more\\nTop 3% Rank by size\\nPublic\\nAnyone can view, post, and comment to this community\\nTop Posts\\n\\n\\n\\nReddit\\nreReddit: Top posts of March 20, 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of March 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of 2024 * * *\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\nTOPICS\\n\\n\\nInternet Culture (Viral)\\n\\n\\nAmazing Animals & Pets Cringe & Facepalm Funny Interesting Memes Oddly Satisfying Reddit Meta Wholesome & Heartwarming\\n\\n\\nGames\\n\\n\\nAction Games Adventure Games Esports Gaming Consoles & Gear Gaming News & Discussion Mobile Games Other Games Role-Playing Games Simulation Games Sports & Racing Games Strategy Games*   Tabletop Games\\n\\n\\nQ&As\\n\\n\\nQ&As*   Stories & Confessions\\n\\n\\nTechnology\\n\\n\\n3D Printing Artificial Intelligence & Machine Learning Computers & Hardware Consumer Electronics DIY Electronics Programming Software & Apps Streaming Services Tech News & Discussion*   Virtual & Augmented Reality\\n\\n\\nPop Culture\\n\\n\\nCelebrities Creators & Influencers Generations & Nostalgia Podcasts Streamers*   Tarot & Astrology\\n\\n\\nMovies & TV\\n\\n\\nAction Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\nAbout Reddit Advertise Help Blog Careers*   Press\\n\\n\\n\\n\\nCommunities Best of Reddit Topics\\n\\n\\n\\nReddit Rules Privacy Policy User Agreement\\n\\nReddit, Inc. © 2025. All rights reserved.\"}, {\"title\": \"LangGraph Workflow for Quality Assurance : r/LangChain - Reddit\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1bsblmu/langgraph_workflow_for_quality_assurance/\", \"content\": \"Reddit - Dive into anything Go to LangChain I've been working on a concept to automate the Quality Assurance (QA) process for complex legal documents using LangGraph, aiming to streamline the workflow, reduce manual effort, and improve compliance efficiency. Handling specific parts of the QA process using AI rather human reviews, from initial document submission to final approval. Document Submission (Manual User Action): Entry point for examiners to submit documents. Policy Compliance Checker Node (PCCN): Checks documents against policy rules. Quality Assurance Node (QAN): Final review to ensure document quality. Approval and Compliance Marking Node (ACMN): Marks documents as approved. Has anyone automated a Quality Assurance process with langchain/graph? Reddit Reddit Reddit Communities Best of Reddit Topics Reddit, Inc.\", \"score\": 0.6347929, \"raw_content\": \"Reddit - Dive into anything\\nSkip to main content\\nOpen menu Open navigation  Go to Reddit Home\\nr/LangChain A chip A close button\\nGet App Get the Reddit app Log In Log in to Reddit\\nExpand user menu Open settings menu\\n Go to LangChain\\nr/LangChain\\nr/LangChain\\nLangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.\\n\\nMembers Online\\n•\\nSwimminInIt\\nLangGraph Workflow for Quality Assurance\\nQuestion | Help\\nI've been working on a concept to automate the Quality Assurance (QA) process for complex legal documents using LangGraph, aiming to streamline the workflow, reduce manual effort, and improve compliance efficiency. Handling specific parts of the QA process using AI rather human reviews, from initial document submission to final approval.\\nI see a ton of people talking about document chat and integration with knowledge repos. Rather than just providing information I am looking to perform QA on the documents itself.\\nHere's a brief overview of the workflow:\\n\\n\\nDocument Submission (Manual User Action): Entry point for examiners to submit documents.\\n\\n\\nPre-Processing Node (Script for Data Manipulation): Handles initial formatting and basic validation.\\n\\n\\nPolicy Compliance Checker Node (PCCN): Checks documents against policy rules.\\n\\n\\nError Suggestion Node (ESN): Identifies compliance issues and suggests corrections.\\n\\n\\nQuality Assurance Node (QAN): Final review to ensure document quality.\\n\\n\\nFeedback and Interaction Node (FIN): Where examiners review AI suggestions and apply corrections.\\n\\n\\nApproval and Compliance Marking Node (ACMN): Marks documents as approved.\\n\\n\\nSome questions I have are:\\n\\n\\nHas anyone automated a Quality Assurance process with langchain/graph?\\n\\n\\nIf yes, what was successful or what did not work?\\n\\n\\nAny suggestions on how to improve my approach?\\n\\n\\nAre there any examples you are aware of I could use as a reference?\\n\\n\\nI appreciate any help and thoughts on the topic!\\nRead more\\nTop 3% Rank by size\\nPublic\\nAnyone can view, post, and comment to this community\\nTop Posts\\n\\n\\n\\nReddit\\nreReddit: Top posts of March 31, 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of March 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of 2024 * * *\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\nTOPICS\\n\\n\\nInternet Culture (Viral)\\n\\n\\nAmazing Animals & Pets Cringe & Facepalm Funny Interesting Memes Oddly Satisfying Reddit Meta Wholesome & Heartwarming\\n\\n\\nGames\\n\\n\\nAction Games Adventure Games Esports Gaming Consoles & Gear Gaming News & Discussion Mobile Games Other Games Role-Playing Games Simulation Games Sports & Racing Games Strategy Games*   Tabletop Games\\n\\n\\nQ&As\\n\\n\\nQ&As*   Stories & Confessions\\n\\n\\nTechnology\\n\\n\\n3D Printing Artificial Intelligence & Machine Learning Computers & Hardware Consumer Electronics DIY Electronics Programming Software & Apps Streaming Services Tech News & Discussion*   Virtual & Augmented Reality\\n\\n\\nPop Culture\\n\\n\\nCelebrities Creators & Influencers Generations & Nostalgia Podcasts Streamers*   Tarot & Astrology\\n\\n\\nMovies & TV\\n\\n\\nAction Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\nAbout Reddit Advertise Help Blog Careers*   Press\\n\\n\\n\\n\\nCommunities Best of Reddit Topics\\n\\n\\n\\nReddit Rules Privacy Policy User Agreement\\n\\nReddit, Inc. © 2025. All rights reserved.\"}, {\"title\": \"Tool-calling agents: Human approval before tool invocation?\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1ci3m0k/toolcalling_agents_human_approval_before_tool/\", \"content\": \"Reddit - Dive into anything Open menu Open navigation  Go to Reddit Home Get App Get the Reddit app Log In Log in to Reddit Go to LangChain r/LangChain r/LangChain I'd like to be able to ask for human confirmation before the agent executor invokes a certain tool. I can actually put the confirmation logic in the tool function itself and get it to work, but that doesn't seem right. Reddit Reddit Reddit Action Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion About Reddit Advertise Help Blog Careers*   Press Communities Best of Reddit Topics Reddit, Inc.\", \"score\": 0.20606238, \"raw_content\": \"Reddit - Dive into anything\\nSkip to main content\\nOpen menu Open navigation  Go to Reddit Home\\nr/LangChain A chip A close button\\nGet App Get the Reddit app Log In Log in to Reddit\\nExpand user menu Open settings menu\\n Go to LangChain\\nr/LangChain\\nr/LangChain\\nLangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.\\n\\nMembers Online\\n•\\ntranswarpconduit1\\nTool-calling agents: Human approval before tool invocation?\\nQuestion | Help\\nI'd like to be able to ask for human confirmation before the agent executor invokes a certain tool. For example, let's say I have asend_emailtool, and I'd like to confirm before it is run.\\nDoes the Langchain agent framework provide a way to hook into the lifecycle in order to do this? Ideally, a hook that would run before the invocation, has tool name and arguments passed in, and then you can return True or False (or an *Exception for an error). I could have the email displayed to standard out there, and collect input.\\nIt doesn't seem like callback handlers work, and they weren't intended for that anyway. They are for introspection (like logging, instrumentation, etc.).\\nI can actually put the confirmation logic in the tool function itself and get it to work, but that doesn't seem right. I could create a special wrapper function \\\"add_human_approval(tool_func)\\\" that returns a new function that asks for human approval, and if it passes invokes the passed in func, otherwise returns. Again, that's still at the tool level, instead as part of the lifecycle.\\nThoughts?\\nRead more\\nTop 3% Rank by size\\nPublic\\nAnyone can view, post, and comment to this community\\nTop Posts\\n\\n\\n\\nReddit\\nreReddit: Top posts of May 2, 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of May 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of 2024 * * *\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\nTOPICS\\n\\n\\nInternet Culture (Viral)\\n\\n\\nAmazing Animals & Pets Cringe & Facepalm Funny Interesting Memes Oddly Satisfying Reddit Meta Wholesome & Heartwarming\\n\\n\\nGames\\n\\n\\nAction Games Adventure Games Esports Gaming Consoles & Gear Gaming News & Discussion Mobile Games Other Games Role-Playing Games Simulation Games Sports & Racing Games Strategy Games*   Tabletop Games\\n\\n\\nQ&As\\n\\n\\nQ&As*   Stories & Confessions\\n\\n\\nTechnology\\n\\n\\n3D Printing Artificial Intelligence & Machine Learning Computers & Hardware Consumer Electronics DIY Electronics Programming Software & Apps Streaming Services Tech News & Discussion*   Virtual & Augmented Reality\\n\\n\\nPop Culture\\n\\n\\nCelebrities Creators & Influencers Generations & Nostalgia Podcasts Streamers*   Tarot & Astrology\\n\\n\\nMovies & TV\\n\\n\\nAction Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\nAbout Reddit Advertise Help Blog Careers*   Press\\n\\n\\n\\n\\nCommunities Best of Reddit Topics\\n\\n\\n\\nReddit Rules Privacy Policy User Agreement\\n\\nReddit, Inc. © 2025. All rights reserved.\"}]\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "LangGraph에 대한 유용한 자료는 다음과 같습니다:\n",
      "\n",
      "1. **[Human intervention in agent workflows](https://www.reddit.com/r/LangChain/comments/1bjnmu4/human_intervention_in_agent_workflows/)**:\n",
      "   - 이 게시글에서는 LangGraph로 LLM 워크플로우를 구축하면서 인간이 검증하거나 승인, 거부할 수 있는 노드를 만드는 방법에 대해 다룹니다. 다양한 시나리오에서 인간의 개입이 어떻게 이루어질 수 있는지에 대한 논의가 포함되어 있습니다.\n",
      "\n",
      "2. **[LangGraph Workflow for Quality Assurance](https://www.reddit.com/r/LangChain/comments/1bsblmu/langgraph_workflow_for_quality_assurance/)**:\n",
      "   - LangGraph를 사용하여 복잡한 법률 문서의 품질 보증 프로세스를 자동화하는 개념에 대해 설명합니다. 문서 제출에서부터 최종 승인까지의 프로세스 흐름을 안내하며, AI를 사용하여 특정 QA 프로세스를 처리하는 방법에 대해 논의합니다.\n",
      "\n",
      "3. **[Tool-calling agents: Human approval before tool invocation?](https://www.reddit.com/r/LangChain/comments/1ci3m0k/toolcalling_agents_human_approval_before_tool/)**:\n",
      "   - 이 게시글은 툴을 호출하기 전 인간의 승인을 요구하는 방법에 대해 이야기합니다. LangChain 에이전트 프레임워크에서 이러한 승인 로직을 구현하는 다양한 접근 방식에 대해 논의하고 있습니다.\n",
      "\n",
      "이 자료들을 통해 LangGraph의 기능과 활용 사례에 대해 더 깊이 이해할 수 있을 것입니다.\n"
     ]
    }
   ],
   "execution_count": 37
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
