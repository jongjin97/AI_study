{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-23T08:59:11.839084Z",
     "start_time": "2025-04-23T08:59:11.831507Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH17-LangGraph-Modules\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH17-LangGraph-Modules\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 사람에게 의견을 묻는 노드 설정",
   "id": "e4a1ab6c047debe0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:59:11.862218Z",
     "start_time": "2025-04-23T08:59:11.858091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition"
   ],
   "id": "a00d576d74a25f86",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:59:11.878034Z",
     "start_time": "2025-04-23T08:59:11.874227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class State(TypedDict):\n",
    "    # 메시지 목록\n",
    "    messages: Annotated[list, add_messages]\n",
    "    # 사람에게 질문할지 여부를 묻는 상태 추가\n",
    "    ask_human: bool"
   ],
   "id": "9c9f6d89f0195bd",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:59:11.904365Z",
     "start_time": "2025-04-23T08:59:11.898748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class HumanRequest(BaseModel):\n",
    "    \"\"\"Forward the conversation to an expert. Use when you can't assist directly or the user needs assistance that exceeds your authority.\n",
    "    To use this function, pass the user's 'request' so that an expert can provide appropriate guidance.\n",
    "    \"\"\"\n",
    "\n",
    "    request: str"
   ],
   "id": "bdfafcaf40ad3870",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:59:12.601103Z",
     "start_time": "2025-04-23T08:59:11.911375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 도구 추가\n",
    "tool = TavilySearch(max_results=3)\n",
    "\n",
    "# 도구 목록 추가(HumanRequest 도구)\n",
    "tools = [tool, HumanRequest]\n",
    "\n",
    "# LLM 추가\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 도구 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    # LLM 도구 호출을 통한 응답 생성\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "\n",
    "    # 사람에게 질문할지 여부 초기화\n",
    "    ask_human = False\n",
    "\n",
    "    # 도구 호출이 있고 이름이 'HumanRequest' 인 경우\n",
    "    if response.tool_calls and response.tool_calls[0][\"name\"] == HumanRequest.__name__:\n",
    "        ask_human = True\n",
    "\n",
    "    # 메시지와 ask_human 상태 반환\n",
    "    return {\"messages\": [response], \"ask_human\": ask_human}"
   ],
   "id": "3de6050d455d0c17",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:59:12.628289Z",
     "start_time": "2025-04-23T08:59:12.622463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 상태 그래프 초기화\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 챗봇 노드 추가\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# 도구 노드 추가\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools=[tool]))"
   ],
   "id": "299497dfddb2886f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2592544bdd0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Human 노드 설정",
   "id": "bd3282fddb6e6fbd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:59:12.655583Z",
     "start_time": "2025-04-23T08:59:12.648155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "# 응답 메시지 생성(ToolMessage 생성을 위한 함수)\n",
    "def create_response(response: str, ai_message: AIMessage):\n",
    "    return AIMessage(\n",
    "        content=response,\n",
    "        tool_call_id=ai_message.tool_calls[0][\"id\"]\n",
    "    )\n",
    "\n",
    "# 인간 노드 처리\n",
    "def human_node(state: State):\n",
    "    new_messages = []\n",
    "    if not isinstance(state[\"messages\"][-1], ToolMessage):\n",
    "        # 사람으로부터 응답이 없는 경우\n",
    "        new_messages.append(\n",
    "            create_response(\"No response from human.\", state[\"messages\"][-1])\n",
    "        )\n",
    "    return {\n",
    "        \"messages\": new_messages,\n",
    "        \"ask_human\": False\n",
    "    }\n",
    "\n",
    "# 그래프에 인간 노드 추가\n",
    "graph_builder.add_node(\"human\", human_node)"
   ],
   "id": "2ae33c1dca6b4120",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2592544bdd0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:59:12.682617Z",
     "start_time": "2025-04-23T08:59:12.676065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import END\n",
    "\n",
    "# 다음 노드 선택\n",
    "def select_next_node(state: State):\n",
    "    # 인간에게 질문 여부 확인\n",
    "    if state[\"ask_human\"]:\n",
    "        return \"human\"\n",
    "    # 이전과 동일한 경로 설정\n",
    "    return tools_condition(state)\n",
    "\n",
    "# 조건부 엣지 추가\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    select_next_node,\n",
    "    {\"human\": \"human\", \"tools\": \"tools\", END: END},\n",
    ")"
   ],
   "id": "54cba0127ae119dd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2592544bdd0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:59:12.718869Z",
     "start_time": "2025-04-23T08:59:12.705821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 엣지 추가: 'tools'에서 'chatbot'으로\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# 엣지 추가: 'human'에서 'chatbot'으로\n",
    "graph_builder.add_edge(\"human\", \"chatbot\")\n",
    "\n",
    "# 엣지 추가: START에서 'chatbot'으로\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# 메모리 저장소 초기화\n",
    "memory = MemorySaver()\n",
    "\n",
    "# 그래프 컴파일: 메모리 체크포인터 사용\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    # 'human' 이전에 인터럽트 설정\n",
    "    interrupt_before=[\"human\"],\n",
    ")"
   ],
   "id": "59eac03e3f46462a",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:59:12.734248Z",
     "start_time": "2025-04-23T08:59:12.728818Z"
    }
   },
   "cell_type": "code",
   "source": "graph.get_graph().print_ascii()",
   "id": "39d5ed86ef2a6411",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                +-----------+                   \r\n",
      "                | __start__ |                   \r\n",
      "                +-----------+                   \r\n",
      "                       *                        \r\n",
      "                       *                        \r\n",
      "                       *                        \r\n",
      "                  +---------+                   \r\n",
      "                  | chatbot |                   \r\n",
      "                ..+---------+..                 \r\n",
      "             ...       *       ...              \r\n",
      "          ...          *          ...           \r\n",
      "        ..             *             ..         \r\n",
      "+-------+         +-------+         +---------+ \r\n",
      "| human |         | tools |         | __end__ | \r\n",
      "+-------+         +-------+         +---------+ \n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:59:13.905701Z",
     "start_time": "2025-04-23T08:59:12.761486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_input = \"이 AI 에이전트를 구축하기 위해 전문가의 도움이 필요합니다. 도움을 요청할 수 있나요?\"\n",
    "\n",
    "# config 설정\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# 스트림 또는 호출의 두 번째 위치 인수로서의 구성\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        # 마지막 메시지의 예쁜 출력\n",
    "        event[\"messages\"][-1].pretty_print()"
   ],
   "id": "9a4061542a7910e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "이 AI 에이전트를 구축하기 위해 전문가의 도움이 필요합니다. 도움을 요청할 수 있나요?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  HumanRequest (call_wmf2ZllMAsp27GrRyddaRbI6)\n",
      " Call ID: call_wmf2ZllMAsp27GrRyddaRbI6\n",
      "  Args:\n",
      "    request: 이 AI 에이전트를 구축하기 위해 전문가의 도움이 필요합니다.\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:59:13.919542Z",
     "start_time": "2025-04-23T08:59:13.913932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 그래프 상태 스냅샷 생성\n",
    "snapshot = graph.get_state(config)\n",
    "\n",
    "# 다음 스냅샷 상태 접근\n",
    "snapshot.next"
   ],
   "id": "adf4fd9171af768a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('human',)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:59:13.957340Z",
     "start_time": "2025-04-23T08:59:13.946470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# AI 메시지 추출\n",
    "ai_message = snapshot.values[\"messages\"][-1]\n",
    "\n",
    "# 인간 응답 생성\n",
    "human_response = (\n",
    "    \"전문가들이 도와드리겠습니다! 에이전트 구축을 위해 LangGraph를 확인해 보시기를 적극 추천드립니다. \"\n",
    "    \"단순한 자율 에이전트보다 훨씬 더 안정적이고 확장성이 뛰어납니다. \"\n",
    "    \"https://wikidocs.net/233785 에서 더 많은 정보를 확인할 수 있습니다.\"\n",
    ")\n",
    "\n",
    "# 도구 메시지 생성\n",
    "tool_message = create_response(human_response, ai_message)\n",
    "\n",
    "# 그래프 상태 업데이트\n",
    "graph.update_state(config, {\"messages\": [tool_message]})"
   ],
   "id": "7b1b8517e9a1f56d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f020213-ab68-6361-8002-2d305e5f507c'}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:59:13.996031Z",
     "start_time": "2025-04-23T08:59:13.990560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 그래프 상태에서 메시지 값 가져오기\n",
    "graph.get_state(config).values[\"messages\"]"
   ],
   "id": "41e879b6306caa82",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='이 AI 에이전트를 구축하기 위해 전문가의 도움이 필요합니다. 도움을 요청할 수 있나요?', additional_kwargs={}, response_metadata={}, id='0804452c-7fa1-4e6a-be8c-5a3d0a6400cf'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_wmf2ZllMAsp27GrRyddaRbI6', 'function': {'arguments': '{\"request\":\"이 AI 에이전트를 구축하기 위해 전문가의 도움이 필요합니다.\"}', 'name': 'HumanRequest'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 171, 'total_tokens': 201, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BPQEjmgeAoTGMx9ucNm5J7Aqx69II', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6bb7e039-b21a-4b6d-a38e-0aeee52a454b-0', tool_calls=[{'name': 'HumanRequest', 'args': {'request': '이 AI 에이전트를 구축하기 위해 전문가의 도움이 필요합니다.'}, 'id': 'call_wmf2ZllMAsp27GrRyddaRbI6', 'type': 'tool_call'}], usage_metadata={'input_tokens': 171, 'output_tokens': 30, 'total_tokens': 201, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " AIMessage(content='전문가들이 도와드리겠습니다! 에이전트 구축을 위해 LangGraph를 확인해 보시기를 적극 추천드립니다. 단순한 자율 에이전트보다 훨씬 더 안정적이고 확장성이 뛰어납니다. https://wikidocs.net/233785 에서 더 많은 정보를 확인할 수 있습니다.', additional_kwargs={}, response_metadata={}, id='78506d4b-0f97-4020-acd9-7075b88e3239', tool_call_id='call_wmf2ZllMAsp27GrRyddaRbI6')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:59:14.280215Z",
     "start_time": "2025-04-23T08:59:14.121847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 그래프에서 이벤트 스트림 생성\n",
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "\n",
    "# 각 이벤트에 대한 처리\n",
    "for event in events:\n",
    "    # 메시지가 있는 경우 마지막 메시지 출력\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ],
   "id": "db30b38fec186102",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "전문가들이 도와드리겠습니다! 에이전트 구축을 위해 LangGraph를 확인해 보시기를 적극 추천드립니다. 단순한 자율 에이전트보다 훨씬 더 안정적이고 확장성이 뛰어납니다. https://wikidocs.net/233785 에서 더 많은 정보를 확인할 수 있습니다.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIndexError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[47]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      2\u001B[39m events = graph.stream(\u001B[38;5;28;01mNone\u001B[39;00m, config, stream_mode=\u001B[33m\"\u001B[39m\u001B[33mvalues\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      4\u001B[39m \u001B[38;5;66;03m# 각 이벤트에 대한 처리\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m \u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mevents\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# 메시지가 있는 경우 마지막 메시지 출력\u001B[39;49;00m\n\u001B[32m      7\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmessages\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m        \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmessages\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43m-\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpretty_print\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2046\u001B[39m, in \u001B[36mPregel.stream\u001B[39m\u001B[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001B[39m\n\u001B[32m   2040\u001B[39m     \u001B[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001B[39;00m\n\u001B[32m   2041\u001B[39m     \u001B[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001B[39;00m\n\u001B[32m   2042\u001B[39m     \u001B[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001B[39;00m\n\u001B[32m   2043\u001B[39m     \u001B[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001B[39;00m\n\u001B[32m   2044\u001B[39m     \u001B[38;5;66;03m# with channel updates applied only at the transition between steps.\u001B[39;00m\n\u001B[32m   2045\u001B[39m     \u001B[38;5;28;01mwhile\u001B[39;00m loop.tick(input_keys=\u001B[38;5;28mself\u001B[39m.input_channels):\n\u001B[32m-> \u001B[39m\u001B[32m2046\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m_\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrunner\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtick\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2047\u001B[39m \u001B[43m            \u001B[49m\u001B[43mloop\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m.\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2048\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstep_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2049\u001B[39m \u001B[43m            \u001B[49m\u001B[43mretry_policy\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mretry_policy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2050\u001B[39m \u001B[43m            \u001B[49m\u001B[43mget_waiter\u001B[49m\u001B[43m=\u001B[49m\u001B[43mget_waiter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2051\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   2052\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;66;43;03m# emit output\u001B[39;49;00m\n\u001B[32m   2053\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01myield from\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43moutput\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2054\u001B[39m \u001B[38;5;66;03m# emit output\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:146\u001B[39m, in \u001B[36mPregelRunner.tick\u001B[39m\u001B[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001B[39m\n\u001B[32m    144\u001B[39m t = tasks[\u001B[32m0\u001B[39m]\n\u001B[32m    145\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m146\u001B[39m     \u001B[43mrun_with_retry\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    147\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    148\u001B[39m \u001B[43m        \u001B[49m\u001B[43mretry_policy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    149\u001B[39m \u001B[43m        \u001B[49m\u001B[43mconfigurable\u001B[49m\u001B[43m=\u001B[49m\u001B[43m{\u001B[49m\n\u001B[32m    150\u001B[39m \u001B[43m            \u001B[49m\u001B[43mCONFIG_KEY_CALL\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpartial\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    151\u001B[39m \u001B[43m                \u001B[49m\u001B[43m_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    152\u001B[39m \u001B[43m                \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    153\u001B[39m \u001B[43m                \u001B[49m\u001B[43mretry\u001B[49m\u001B[43m=\u001B[49m\u001B[43mretry_policy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    154\u001B[39m \u001B[43m                \u001B[49m\u001B[43mfutures\u001B[49m\u001B[43m=\u001B[49m\u001B[43mweakref\u001B[49m\u001B[43m.\u001B[49m\u001B[43mref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfutures\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    155\u001B[39m \u001B[43m                \u001B[49m\u001B[43mschedule_task\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mschedule_task\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    156\u001B[39m \u001B[43m                \u001B[49m\u001B[43msubmit\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msubmit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    157\u001B[39m \u001B[43m                \u001B[49m\u001B[43mreraise\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreraise\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    158\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    159\u001B[39m \u001B[43m        \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    160\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    161\u001B[39m     \u001B[38;5;28mself\u001B[39m.commit(t, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m    162\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001B[39m, in \u001B[36mrun_with_retry\u001B[39m\u001B[34m(task, retry_policy, configurable)\u001B[39m\n\u001B[32m     38\u001B[39m     task.writes.clear()\n\u001B[32m     39\u001B[39m     \u001B[38;5;66;03m# run the task\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m40\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtask\u001B[49m\u001B[43m.\u001B[49m\u001B[43mproc\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtask\u001B[49m\u001B[43m.\u001B[49m\u001B[43minput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     41\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m ParentCommand \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m     42\u001B[39m     ns: \u001B[38;5;28mstr\u001B[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:546\u001B[39m, in \u001B[36mRunnableSeq.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m    542\u001B[39m config = patch_config(\n\u001B[32m    543\u001B[39m     config, callbacks=run_manager.get_child(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mseq:step:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m\u001B[32m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m    544\u001B[39m )\n\u001B[32m    545\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m i == \u001B[32m0\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m546\u001B[39m     \u001B[38;5;28minput\u001B[39m = \u001B[43mstep\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    547\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    548\u001B[39m     \u001B[38;5;28minput\u001B[39m = step.invoke(\u001B[38;5;28minput\u001B[39m, config)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AI_study\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:310\u001B[39m, in \u001B[36mRunnableCallable.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m    308\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    309\u001B[39m     context.run(_set_config_context, config)\n\u001B[32m--> \u001B[39m\u001B[32m310\u001B[39m     ret = \u001B[43mcontext\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    311\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(ret, Runnable) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m.recurse:\n\u001B[32m    312\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m ret.invoke(\u001B[38;5;28minput\u001B[39m, config)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[39]\u001B[39m\u001B[32m, line 16\u001B[39m, in \u001B[36mhuman_node\u001B[39m\u001B[34m(state)\u001B[39m\n\u001B[32m     12\u001B[39m new_messages = []\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(state[\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m][-\u001B[32m1\u001B[39m], ToolMessage):\n\u001B[32m     14\u001B[39m     \u001B[38;5;66;03m# 사람으로부터 응답이 없는 경우\u001B[39;00m\n\u001B[32m     15\u001B[39m     new_messages.append(\n\u001B[32m---> \u001B[39m\u001B[32m16\u001B[39m         \u001B[43mcreate_response\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mNo response from human.\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmessages\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43m-\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     17\u001B[39m     )\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[32m     19\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m: new_messages,\n\u001B[32m     20\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mask_human\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m     21\u001B[39m }\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[39]\u001B[39m\u001B[32m, line 7\u001B[39m, in \u001B[36mcreate_response\u001B[39m\u001B[34m(response, ai_message)\u001B[39m\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcreate_response\u001B[39m(response: \u001B[38;5;28mstr\u001B[39m, ai_message: AIMessage):\n\u001B[32m      5\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m AIMessage(\n\u001B[32m      6\u001B[39m         content=response,\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m         tool_call_id=\u001B[43mai_message\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtool_calls\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m[\u001B[33m\"\u001B[39m\u001B[33mid\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m      8\u001B[39m     )\n",
      "\u001B[31mIndexError\u001B[39m: list index out of range",
      "During task with name 'human' and id 'f27c2d2e-a5ec-b22f-81eb-3c7d84dfc80e'"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T08:59:34.654622Z",
     "start_time": "2025-04-23T08:59:34.649749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 최종 상태 확인\n",
    "state = graph.get_state(config)\n",
    "\n",
    "# 단계별 메시지 출력\n",
    "for message in state.values[\"messages\"]:\n",
    "    message.pretty_print()"
   ],
   "id": "7fd0e1eadfe1f416",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "이 AI 에이전트를 구축하기 위해 전문가의 도움이 필요합니다. 도움을 요청할 수 있나요?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  HumanRequest (call_wmf2ZllMAsp27GrRyddaRbI6)\n",
      " Call ID: call_wmf2ZllMAsp27GrRyddaRbI6\n",
      "  Args:\n",
      "    request: 이 AI 에이전트를 구축하기 위해 전문가의 도움이 필요합니다.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "전문가들이 도와드리겠습니다! 에이전트 구축을 위해 LangGraph를 확인해 보시기를 적극 추천드립니다. 단순한 자율 에이전트보다 훨씬 더 안정적이고 확장성이 뛰어납니다. https://wikidocs.net/233785 에서 더 많은 정보를 확인할 수 있습니다.\n"
     ]
    }
   ],
   "execution_count": 48
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
