{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-24T13:09:02.269366Z",
     "start_time": "2025-04-24T13:09:02.250757Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH17-LangGraph-Structures\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH17-LangGraph-Structures\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 기본 PDF 기반 Retrieval Chain 생성\n",
   "id": "6283d3af31105e50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:10:09.891650Z",
     "start_time": "2025-04-24T13:09:59.928478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from rag.pdf import PDFRetrievalChain\n",
    "\n",
    "# PDF 문서를 로드합니다.\n",
    "pdf = PDFRetrievalChain([\"data/SPRI_AI_Brief_2023년12월호_F.pdf\"]).create_chain()\n",
    "\n",
    "# retriever 생성\n",
    "pdf_retriever = pdf.retriever\n",
    "\n",
    "# chain 생성\n",
    "pdf_chain = pdf.chain"
   ],
   "id": "d538bbe630de32c6",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 쿼리 라우팅과 문서 평가\n",
   "id": "29663d2c74c99dd6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:14:50.370564Z",
     "start_time": "2025-04-24T13:14:48.362786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_teddynote.models import get_model_name, LLMs\n",
    "\n",
    "# 최신 LLM 모델 이름 가져오기\n",
    "MODEL_NAME = get_model_name(LLMs.GPT4)\n",
    "\n",
    "# 사용자 쿼리를 가자 관련성 높은 데이터 소스로 라우팅하는 데이터 모델\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
    "    # 데이터 소스 선택을 위한 리터럴 타입 필드\n",
    "    datasource: Literal[\"vectorstore\", \"web_search\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question choose to route it to web search or a vectorstore.\"\n",
    "    )\n",
    "\n",
    "# LLM 초기화 및 함수 호출을 통한 구조화된 출력 생성\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "structured_llm_router = llm.with_structured_output(RouteQuery)\n",
    "\n",
    "# 시스템 메시지와 사용자 질문을 포함한 프롬프트 템플릿 생성\n",
    "system = \"\"\"You are an expert at routing a user question to a vectorstore or web search.\n",
    "The vectorstore contains documents related to DEC 2023 AI Brief Report(SPRI) with Samsung Gause, Anthropic, etc.\n",
    "Use the vectorstore for questions on these topics. Otherwise, use web-search.\"\"\"\n",
    "\n",
    "# Routing 을 위한 프롬프트 템플릿 생성\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"user\", \"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 프롬프트 템플릿과 구조화된  LLM 라우터를 결합하여 질문 라우터 생성\n",
    "question_router = route_prompt | structured_llm_router"
   ],
   "id": "52853b7762b859cb",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:14:55.694019Z",
     "start_time": "2025-04-24T13:14:54.444840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 문서 검색이 필요한 질문\n",
    "print(\n",
    "    question_router.invoke(\n",
    "        {\"question\": \"AI Brief 에서 삼성전자가 만든 생성형 AI 의 이름은?\"}\n",
    "    )\n",
    ")"
   ],
   "id": "3affdfc26290d8d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='vectorstore'\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:15:08.269300Z",
     "start_time": "2025-04-24T13:15:06.755797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 웹 검색이 필요한 질문\n",
    "print(question_router.invoke({\"question\": \"판교에서 가장 맛있는 딤섬집 찾아줘\"}))"
   ],
   "id": "9a2d05f591554155",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='web_search'\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 검색 평가기(Retrieval Grader)",
   "id": "4063488114849a98"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:15:38.359802Z",
     "start_time": "2025-04-24T13:15:37.547580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "# 문서 평가를 위한 데이터 모델 정의\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM 초기화 및 함수 호출을 통한 구조화된 출력 생성\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# 시스템 메시지와 사용자 질문을 포함한 프롬프트 템플릿 생성\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
    "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 문서 검색결과 평가기 생성\n",
    "retrieval_grader = grade_prompt | structured_llm_grader"
   ],
   "id": "1251a344cf001b95",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:15:44.373338Z",
     "start_time": "2025-04-24T13:15:43.269872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 사용자 질문 설정\n",
    "question = \"삼성전자가 만든 생성형 AI 의 이름은?\"\n",
    "\n",
    "# 질문에 대한 관련 문서 검색\n",
    "docs = pdf_retriever.invoke(question)\n",
    "\n",
    "# 검색된 문서의 내용 가져오기\n",
    "retrieved_doc = docs[1].page_content\n",
    "\n",
    "# 평가 결과 출력\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": retrieved_doc}))"
   ],
   "id": "a2ba385e9a81c9ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 답변 생성을 위한 RAG 체인 생성",
   "id": "c7ba37af309b3d37"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:16:06.458549Z",
     "start_time": "2025-04-24T13:16:05.296384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LangChain Hub에서 프롬프트 가져오기(RAG 프롬프트는 자유롭게 수정 가능)\n",
    "prompt = hub.pull(\"teddynote/rag-prompt\")\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(model_name=MODEL_NAME, temperature=0)\n",
    "\n",
    "\n",
    "# 문서 포맷팅 함수\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(\n",
    "        [\n",
    "            f'<document><content>{doc.page_content}</content><source>{doc.metadata[\"source\"]}</source><page>{doc.metadata[\"page\"]+1}</page></document>'\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "# RAG 체인 생성\n",
    "rag_chain = prompt | llm | StrOutputParser()"
   ],
   "id": "f659ead052c1f586",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:16:13.867528Z",
     "start_time": "2025-04-24T13:16:12.051906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# RAG 체인에 질문을 전달하여 답변 생성\n",
    "generation = rag_chain.invoke({\"context\": format_docs(docs), \"question\": question})\n",
    "print(generation)"
   ],
   "id": "58f5f49eca242637",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삼성전자가 만든 생성형 AI의 이름은 '삼성 가우스'입니다.\n",
      "\n",
      "**Source**\n",
      "- data/SPRI_AI_Brief_2023년12월호_F.pdf (page 13)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 답변의 Hallucination 체커 추가",
   "id": "c6a11bcc1ec09a00"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:16:37.347999Z",
     "start_time": "2025-04-24T13:16:36.201975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 할루시네이션 체크를 위한 데이터 모델 정의\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# 함수 호출을 통한 LLM 초기화\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
    "\n",
    "# 프롬프트 설정\n",
    "system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n\n",
    "    Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\"\"\"\n",
    "\n",
    "# 프롬프트 템플릿 생성\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 환각 평가기 생성\n",
    "hallucination_grader = hallucination_prompt | structured_llm_grader"
   ],
   "id": "182b6a08da2c8cb9",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:16:43.448002Z",
     "start_time": "2025-04-24T13:16:42.482302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 평가기를 사용하여 생성된 답변의 환각 여부 평가\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ],
   "id": "131f19f5e069c6b2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeHallucinations(binary_score='no')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:16:53.493809Z",
     "start_time": "2025-04-24T13:16:52.548768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"Binary scoring to evaluate the appropriateness of answers to questions\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Indicate 'yes' or 'no' whether the answer solves the question\"\n",
    "    )\n",
    "\n",
    "\n",
    "# 함수 호출을 통한 LLM 초기화\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeAnswer)\n",
    "\n",
    "# 프롬프트 설정\n",
    "system = \"\"\"You are a grader assessing whether an answer addresses / resolves a question \\n\n",
    "     Give a binary score 'yes' or 'no'. Yes' means that the answer resolves the question.\"\"\"\n",
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 프롬프트 템플릿과 구조화된 LLM 평가기를 결합하여 답변 평가기 생성\n",
    "answer_grader = answer_prompt | structured_llm_grader"
   ],
   "id": "ea5950ff9380950c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:16:59.211315Z",
     "start_time": "2025-04-24T13:16:58.318955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 평가기를 사용하여 생성된 답변이 질문을 해결하는지 여부 평가\n",
    "answer_grader.invoke({\"question\": question, \"generation\": generation})"
   ],
   "id": "19fba3f3102aea53",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeAnswer(binary_score='yes')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 쿼리 재작성(Query Rewriter)",
   "id": "eb63a85b85cef24"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:17:15.472412Z",
     "start_time": "2025-04-24T13:17:14.405733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "\n",
    "# Query Rewriter 프롬프트 정의(자유롭게 수정이 가능합니다)\n",
    "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n\n",
    "for vectorstore retrieval. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "\n",
    "# Query Rewriter 프롬프트 템플릿 생성\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Query Rewriter 생성\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()"
   ],
   "id": "3658bf148d3d8061",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:17:20.535495Z",
     "start_time": "2025-04-24T13:17:19.477313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 질문 재작성기에 질문을 전달하여 개선된 질문 생성\n",
    "question_rewriter.invoke({\"question\": question})"
   ],
   "id": "ae7fb2f52348d840",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'삼성전자가 개발한 생성형 AI의 명칭은 무엇인가요?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 웹 검색 도구",
   "id": "357d307c3a090014"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:17:38.887062Z",
     "start_time": "2025-04-24T13:17:35.190619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "\n",
    "# 웹 검색 도구 생성\n",
    "web_search_tool = TavilySearch(max_results=3)\n",
    "# 웹 검색 도구 호출\n",
    "result = web_search_tool.search(\"테디노트 위키독스 랭체인 튜토리얼 URL 을 알려주세요\")\n",
    "print(result)"
   ],
   "id": "f6c02d802447e119",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'linktr.ee/teddynote | Linktree', 'url': 'https://linktr.ee/teddynote', 'content': '03/04 LangGraph Hands On 튜토리얼 (2시간 분량) [FastCampus] 테디노트의 RAG 비법노트🙌. 🔥[100% 무료] 테디노트 YouTube 콘텐츠 학습 순서🔥. 📘 랭체인 한국어 튜토리얼🇰🇷 ... Github. 9/21 테디노트-Gencon2024-ModularRAG-20240921.pdf.', 'score': 0.6072213, 'raw_content': None}, {'title': ' - LangChain 한국어 튜토리얼 - WikiDocs', 'url': 'https://wikidocs.net/book/14314', 'content': \"대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL) 01. 구조화된 출력 체인(with_structered_output) CH15 평가(Evaluations) 01. 온라인 평가를 활용한 평가 자동화 CH16 에이전트(Agent) 01. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH17 LangGraph 01. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 - shcheon99@naver.com, Jan. 9, 2025, 12:28 p.m. 출력된 결과를 비교했을 때, kiwi tokenizer을 사용한 결과와 kkma, okt 를 사용한 결과가 큰 차이가 없다고 봐도 되는 건가요? CH01 LangChain 시작하기 - NamHyeon, Dec. 8, 2024, 1:17 p.m. 좋은 자료를 무료로 공유해 주셔서, 감사한 마음에 '테디노트의 RAG 비법노트' 강의 등록했습니다 ! 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) - Jan. 16, 2025, 12:23 a.m. 멀티 에이전트 감독자(Multi-Agent Supervisor) - Dec. 23, 2024, 3:04 a.m. 계층적 멀티 에이전트 팀(Hierarchical Multi-Agent Teams) - Dec. 23, 2024, 3:04 a.m.\", 'score': 0.5999311, 'raw_content': '<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 - WikiDocs\\n<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기 01. 설치 영상보고 따라하기 02. OpenAI API 키 발급 및 테스트 03. LangSmith 추적 설정 04. OpenAI API 사용(GPT-4o 멀티모달) 05. LangChain Expression Language(LCEL) 06. LCEL 인터페이스 07. Runnable CH02 프롬프트(Prompt) 01. 프롬프트(Prompt) 02. 퓨샷 프롬프트(FewShotPromptTemplate) 03. LangChain Hub 04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers) 01. Pydantic 출력 파서(PydanticOutputParser) 02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser) 03. 구조화된 출력 파서(StructuredOuputParser) 04. JSON 출력 파서(JsonOutputParser) 05. 데이터프레임 출력 파서(PandasDataFrameOutputParser) 06. 날짜 형식 출력 파서(DatetimeOutputParser) 07. 열거형 출력 파서(EnumOutputParser) 08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model) 01. 다양한 LLM 모델 활용 02. 캐싱(Cache) 03. 모델 직렬화(Serialization) - 저장 및 불러오기 04. 토큰 사용량 확인 05. 구글 생성 AI(Google Generative AI) 06. 허깅페이스 엔드포인트(HuggingFace Endpoints) 07. 허깅페이스 로컬(HuggingFace Local) 08. 허깅페이스 파이프라인(HuggingFace Pipeline) 09. 올라마(Ollama) 10. GPT4ALL 11. 비디오(Video) 질의 응답 LLM (Gemini) CH05 메모리(Memory) 01. 대화 버퍼 메모리(ConversationBufferMemory) 02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory) 03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) 04. 대화 엔티티 메모리(ConversationEntityMemory) 05. 대화 지식그래프 메모리(ConversationKGMemory) 06. 대화 요약 메모리(ConversationSummaryMemory) 07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory) 08. LCEL Chain 에 메모리 추가 09. SQLite 에 대화내용 저장 10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader) 01. 도큐먼트(Document) 의 구조 02. PDF 03. 한글(HWP) 04. CSV 05. Excel 06. Word 07. PowerPoint 08. 웹 문서(WebBaseLoader) 09. 텍스트(TextLoader) 10. JSON 11. Arxiv 12. UpstageLayoutAnalysisLoader 13. LlamaParser CH07 텍스트 분할(Text Splitter) 01. 문자 텍스트 분할(CharacterTextSplitter) 02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter) 03. 토큰 텍스트 분할(TokenTextSplitter) 04. 시멘틱 청커(SemanticChunker) 05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등) 06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter) 07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter) 08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding) 01. OpenAIEmbeddings 02. 캐시 임베딩(CacheBackedEmbeddings) 03. 허깅페이스 임베딩(HuggingFace Embeddings) 04. UpstageEmbeddings 05. OllamaEmbeddings 06. GPT4ALL 임베딩 07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore) 01. Chroma 02. FAISS 03. Pinecone CH10 검색기(Retriever) 01. 벡터스토어 기반 검색기(VectorStore-backed Retriever) 02. 문맥 압축 검색기(ContextualCompressionRetriever) 03. 앙상블 검색기(EnsembleRetriever) 04. 긴 문맥 재정렬(LongContextReorder) 05. 상위 문서 검색기(ParentDocumentRetriever) 06. 다중 쿼리 검색기(MultiQueryRetriever) 07. 다중 벡터저장소 검색기(MultiVectorRetriever) 08. 셀프 쿼리 검색기(SelfQueryRetriever) 09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever) 10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 11. Convex Combination(CC) 적용된 앙상블 검색기(EnsembleRetriever) CH11 리랭커(Reranker) 01. Cross Encoder Reranker 02. Cohere Reranker 03. Jina Reranker 04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG) 01. PDF 문서 기반 QA(Question-Answer) 02. 네이버 뉴스기사 QA(Question-Answer) 03. RAG 의 기능별 다양한 모듈 활용기 04. RAPTOR: 긴 문맥 요약(Long Context Summary) 05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL) 01. RunnablePassthrough 02. Runnable 구조(그래프) 검토 03. RunnableLambda 04. LLM 체인 라우팅(RunnableLambda, RunnableBranch) 05. RunnableParallel 06. 동적 속성 지정(configurable_fields, configurable_alternatives) 07. @chain 데코레이터로 Runnable 구성 08. RunnableWithMessageHistory 09. 사용자 정의 제네레이터(generator) 10. Runtime Arguments 바인딩 11. 폴백(fallback) 모델 지정 CH14 체인(Chains) 01. 문서 요약 02. SQL 03. 구조화된 출력 체인(with_structered_output) CH15 평가(Evaluations) 01. 합성 테스트 데이터셋 생성(RAGAS) 02. RAGAS 를 활용한 평가 03. 생성한 평가용 데이터셋 업로드(HuggingFace Dataset) 04. LangSmith 데이터셋 생성 05. LLM-as-Judge 06. 임베딩 기반 평가(embedding_distance) 07. 사용자 정의(Custom) LLM 평가 08. Rouge, BLEU, METEOR, SemScore 기반 휴리스틱 평가 09. 실험(Experiment) 평가 비교 10. 요약(Summary) 방식의 평가 11. Groundedness(할루시네이션) 평가 12. 실험 비교(Pairwise Evaluation) 13. 반복 평가 14. 온라인 평가를 활용한 평가 자동화 CH16 에이전트(Agent) 01. 도구(Tools) 02. 도구 바인딩(Binding Tools) 03. 에이전트(Agent) 04. Claude, Gemini, Ollama, Together.ai 를 활용한 Agent 05. Iteration 기능과 사람 개입(Human-in-the-loop) 06. Agentic RAG 07. CSVExcel 데이터 분석 Agent 08. Toolkits 활용 Agent 09. RAG + Image Generator Agent(보고서 작성) 10. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH17 LangGraph 01. 핵심 기능 01. LangGraph 에 자주 등장하는 Python 문법이해 02. LangGraph를 활용한 챗봇 구축 03. LangGraph를 활용한 Agent 구축 04. Agent 에 메모리(memory) 추가 05. 노드의 단계별 스트리밍 출력 06. Human-in-the-loop(사람의 개입) 07. 중간단계 개입 되돌림을 통한 상태 수정과 Replay 08. 사람(Human)에게 물어보는 노드 추가 09. 메시지 삭제(RemoveMessage) 10. ToolNode 를 사용하여 도구를 호출하는 방법 11. 병렬 노드 실행을 위한 분기 생성 방법 12. 대화 기록 요약을 추가하는 방법 13. 서브그래프 추가 및 사용 방법 14. 서브그래프의 입력과 출력을 변환하는 방법 15. LangGraph 스트리밍 모드의 모든 것 02. 구조 설계 01. 기본 그래프 생성 02. Naive RAG 03. 관련성 체커(Relevance Checker) 모듈 추가 04. 웹 검색 모듈 추가 05. 쿼리 재작성 모듈 추가 06. Agentic RAG 07. Adaptive RAG 03. Use Cases 01. 에이전트 대화 시뮬레이션 (고객 응대 시나리오) 02. 사용자 요구사항 기반 메타 프롬프트 생성 에이전트 03. CRAG(Corrective RAG) 04. Self-RAG 05. 계획 후 실행(Plan-and-Execute) 06. 멀티 에이전트 협업 네트워크(Multi-Agent Collaboration Network) 07. 멀티 에이전트 감독자(Multi-Agent Supervisor) 08. 계층적 멀티 에이전트 팀(Hierarchical Multi-Agent Teams) 09. SQL 데이터베이스와 상호작용하는 에이전트 10. STORM 개념을 도입한 연구를 위한 멀티 에이전트 CH18 기타 정보 01. StreamEvent 타입별 정리\\nPublished with WikiDocs\\n\\n\\n<랭체인LangChain 노트> - Lang…\\n\\n\\n도서 증정 이벤트 !!\\n\\nWikiDocs\\n\\n<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷\\n\\nAuthor: 테디노트\\nLast edited by : Jan. 16, 2025, 12:23 a.m.\\nCopyright : \\n2,553 Like; \"추천\")\\n추천은 공유할 수 있는 무료 전자책을 집필하는데 정말 큰 힘이 됩니다. \"추천\" 한 번씩만 부탁 드리겠습니다🙏🙏\\n✅ 랭체인 한국어 튜토리얼 강의\\n패스트캠퍼스 - RAG 비법노트\\n✅ 랭체인 한국어 튜토리얼 코드저장소(GitHub) 📘🖥️\\nhttps://github.com/teddylee777/langchain-kr\\n✅ 유튜브 \"테디노트\" 🎥📚\\nhttps://www.youtube.com/c/@teddynote\\n✅ 데이터 분석 블로그 https://teddylee777.github.io\\n✅ 문의 teddylee777@gmail.com\\nLICENSE\\n인용 및 출처 표기\\n\\n본 저작물을 블로그, 유튜브 등 온라인 매체에 인용하여 게재할 경우, Creative Commons Attribution-NonCommercial-NoDerivs 2.0 Korea 라이선스에 따라 반드시 출처를 명시해야 합니다.\\n\\n상업적 사용에 대한 사전 협의\\n\\n본 저작물(Wikidocs 및 관련 실습 코드 포함)을 강의, 강연 등 상업적 목적으로 활용하고자 하는 경우, 저작권자와의 사전 서면 협의가 필수적으로 요구됩니다. 해당 협의는 teddylee777@gmail.com으로 문의하여 진행하실 수 있습니다.\\n\\n본 저작물은 2024년 테디노트에 의해 작성되었습니다. \\n모든 권리는 저작권자에게 있으며, 본 저작물은 Creative Commons Attribution-NonCommercial-NoDerivs 2.0 Korea 라이선스에 따라 배포됩니다.\\n본 저작물의 무단 전재 및 재배포를 금지하며, 전체 혹은 일부를 인용할 경우 출처를 명확히 밝혀주시기 바랍니다.\\n본 문서는 다른 문서의 내용을 참고하여 작성되었을 수 있습니다. 참고 자료는 본 문서 하단의 출처 목록에서 확인하실 수 있습니다.\\nCopyright (c) 테디노트.\\nReference\\n\\nLangChain Github\\nLangGraph Github\\nLangChain Document\\n\\nRecent Comments (8) Recent Modifications (10) RSS\\n02. 네이버 뉴스기사 QA(Question-Answer) - 김민겸, Feb. 2, 2025, 12:17 p.m.\\n\"bullet points 형식으로 정리\"에서 \"주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다.\" 라고 나오는데 이유를 알려주실 수 있나요? kmk582@naver.com\\n10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 - shcheon99@naver.com, Jan. 9, 2025, 12:28 p.m.\\n출력된 결과를 비교했을 때, kiwi tokenizer을 사용한 결과와 kkma, okt 를 사용한 결과가 큰 차이가 없다고 봐도 되는 건가요?\\nCH01 LangChain 시작하기 - NamHyeon, Dec. 8, 2024, 1:17 p.m.\\n좋은 자료를 무료로 공유해 주셔서, 감사한 마음에 \\'테디노트의 RAG 비법노트\\' 강의 등록했습니다 ! 물론 제 현업에 필요한 기술이라서, 강의 또한 기쁜 마음에 신청했구요 ~ 정주행 해서, 창공을 날아가 보겠습니다 ^^\\n06. Word - Paul, Oct. 27, 2024, 5:38 p.m.\\npython-docx도 설치해야 할까요?\\n10. JSON - Paul, Oct. 27, 2024, 5:37 p.m.\\n!pip install jq 부분이 들어가야 할 것 같습니다.\\n02. PDF - Paul, Oct. 27, 2024, 3:29 p.m.\\n<html><head> <meta http-equiv=\"Content-Type\" content=\"text/html\"> </head><body> <span style=\"position:absolute; border: gray 1px solid; left:0px; top:50px; width:612px; height:858px;\"></span> <div style=\"position:absolute; top:50px;\"><a name=\"1\">Page 1</a></div> <div style=\"position:absolute; border 이 부분이 출력 결과가 아니라 코드인 것처럼 표시되어 있네요~\\n12. UpstageLayoutAnalysisLoader - Paul, Oct. 27, 2024, 10:59 a.m.\\n감사히 잘 참고하고 있습니다. 아주 사소한 오기이지만... 11번 Arxiv 다음에 12번이 와야 할 텐데, 원래 넣으시려던 다른 목차가 빠진 것인지 바로 13번이 나왔네요^^\\n03. 모델 직렬화(Serialization) - 저장 및 불러오기 - 동구, Sept. 20, 2024, 12:58 p.m.\\nloads는 뭐에요?\\n10. JSON - Jan. 16, 2025, 12:23 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) - Jan. 16, 2025, 12:23 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등) - Jan. 16, 2025, 12:19 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n04. Self-RAG - Dec. 23, 2024, 3:48 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n10. STORM 개념을 도입한 연구를 위한 멀티 에이전트 - Dec. 23, 2024, 3:16 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n03. CRAG(Corrective RAG) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n05. 계획 후 실행(Plan-and-Execute) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n07. 멀티 에이전트 감독자(Multi-Agent Supervisor) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n08. 계층적 멀티 에이전트 팀(Hierarchical Multi-Agent Teams) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n09. SQL 데이터베이스와 상호작용하는 에이전트 - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n\\nNext : CH01 LangChain 시작하기\\n\\n\\n×\\n책갈피\\n추가 닫기\\n\\n×\\nLeave feedback on this page\\nEmail address to reply to\\nWhat you want to say\\n※ Feedback is delivered to the author by email.\\nClose Send'}, {'title': 'GitHub - teddylee777/langchain-kr: LangChain 공식 Document, Cookbook, 그 ...', 'url': 'https://github.com/teddylee777/langchain-kr', 'content': 'GitHub - teddylee777/langchain-kr: LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. GitHub Copilot Write better code with AI GitHub Copilot Enterprise-grade AI features Search code, repositories, users, issues, pull requests... LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 🌟 LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 🔥성능이 놀라워요🔥 무료로 한국어🇰🇷 파인튜닝 모델 받아서 나만의 로컬 LLM 호스팅 하기(#LangServe) + #RAG 까지!! 무료로 한국어🇰🇷 파인튜닝 모델 받아서 나만의 로컬 LLM 호스팅 하기(LangServe) + RAG 까지!! 참고 자료는 본 문서 하단의 출처 목록에서 확인하실 수 있습니다. langchain-ai 📖 LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. tutorial cookbook openai huggingface gpt-3 openai-api gpt-4 generative-ai chatgpt langchain chatgpt-api langchain-python', 'score': 0.3684744, 'raw_content': 'GitHub - teddylee777/langchain-kr: LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 본 튜토리얼을 통해 LangChain을 더 쉽고 효과적으로 사용하는 방법을 배울 수 있습니다.\\nSkip to content \\nNavigation Menu\\nToggle navigation\\n\\nSign in\\n\\n\\nProduct\\n\\nGitHub Copilot Write better code with AI\\nSecurity Find and fix vulnerabilities\\nActions Automate any workflow\\nCodespaces Instant dev environments\\nIssues Plan and track work\\nCode Review Manage code changes\\nDiscussions Collaborate outside of code\\nCode Search Find more, search less\\n\\nExplore\\n\\nAll features\\nDocumentation\\nGitHub Skills\\nBlog\\n\\n\\n\\nSolutions\\nBy company size\\n\\nEnterprises\\nSmall and medium teams\\nStartups\\nNonprofits\\n\\nBy use case\\n\\nDevSecOps\\nDevOps\\nCI/CD\\nView all use cases\\n\\nBy industry\\n\\nHealthcare\\nFinancial services\\nManufacturing\\nGovernment\\nView all industries\\n\\nView all solutions\\n\\n\\nResources\\nTopics\\n\\nAI\\nDevOps\\nSecurity\\nSoftware Development\\nView all\\n\\nExplore\\n\\nLearning Pathways\\nWhite papers, Ebooks, Webinars\\nCustomer Stories\\nPartners\\nExecutive Insights\\n\\n\\n\\nOpen Source\\n\\n\\nGitHub Sponsors Fund open source developers\\n\\n\\nThe ReadME Project GitHub community articles\\n\\n\\nRepositories\\n\\nTopics\\nTrending\\nCollections\\n\\n\\n\\nEnterprise\\n\\nEnterprise platform AI-powered developer platform\\n\\nAvailable add-ons\\n\\nAdvanced Security Enterprise-grade security features\\nGitHub Copilot Enterprise-grade AI features\\nPremium Support Enterprise-grade 24/7 support\\n\\n\\n\\nPricing\\n\\n\\nSearch or jump to...\\nSearch code, repositories, users, issues, pull requests...\\nSearch\\nClear\\nSearch syntax tips\\nProvide feedback\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\nCancel Submit feedback\\nSaved searches\\nUse saved searches to filter your results more quickly\\nName  \\nQuery \\nTo see all available qualifiers, see our documentation.\\nCancel Create saved search\\nSign in\\nSign up Reseting focus\\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\\n{{ message }}\\nteddylee777 / langchain-kr Public\\n\\nNotifications You must be signed in to change notification settings\\nFork 407\\nStar 1.4k\\n\\nLangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 본 튜토리얼을 통해 LangChain을 더 쉽고 효과적으로 사용하는 방법을 배울 수 있습니다.\\nwikidocs.net/book/14314\\nLicense\\nApache-2.0 license\\n1.4k stars 407 forks Branches Tags Activity\\nStar\\nNotifications You must be signed in to change notification settings\\n\\nCode\\nIssues 2\\nPull requests 0\\nActions\\nProjects 0\\nSecurity\\nInsights\\n\\nAdditional navigation options\\n\\nCode\\nIssues\\nPull requests\\nActions\\nProjects\\nSecurity\\nInsights\\n\\nteddylee777/langchain-kr\\nmain\\nBranchesTags\\n\\nGo to file\\nCode\\nFolders and files\\n| Name | Name | \\nLast commit message\\n| \\nLast commit date\\n|\\n| --- | --- | --- | --- |\\n| \\nLatest commit\\nHistory\\n391 Commits\\n\\n|\\n| \\n01-Basic\\n| \\n01-Basic\\n| \\n| \\n|\\n| \\n02-Prompt\\n| \\n02-Prompt\\n| \\n| \\n|\\n| \\n03-OutputParser\\n| \\n03-OutputParser\\n| \\n| \\n|\\n| \\n04-Model\\n| \\n04-Model\\n| \\n| \\n|\\n| \\n05-Memory\\n| \\n05-Memory\\n| \\n| \\n|\\n| \\n06-DocumentLoader\\n| \\n06-DocumentLoader\\n| \\n| \\n|\\n| \\n07-TextSplitter\\n| \\n07-TextSplitter\\n| \\n| \\n|\\n| \\n08-Embeddings\\n| \\n08-Embeddings\\n| \\n| \\n|\\n| \\n09-VectorStore\\n| \\n09-VectorStore\\n| \\n| \\n|\\n| \\n10-Retriever\\n| \\n10-Retriever\\n| \\n| \\n|\\n| \\n11-Reranker\\n| \\n11-Reranker\\n| \\n| \\n|\\n| \\n12-RAG\\n| \\n12-RAG\\n| \\n| \\n|\\n| \\n13-LangChain-Expression-Language\\n| \\n13-LangChain-Expression-Language\\n| \\n| \\n|\\n| \\n14-Chains\\n| \\n14-Chains\\n| \\n| \\n|\\n| \\n15-Agent\\n| \\n15-Agent\\n| \\n| \\n|\\n| \\n16-Evaluations\\n| \\n16-Evaluations\\n| \\n| \\n|\\n| \\n17-LangGraph\\n| \\n17-LangGraph\\n| \\n| \\n|\\n| \\n18-FineTuning\\n| \\n18-FineTuning\\n| \\n| \\n|\\n| \\n19-Streamlit\\n| \\n19-Streamlit\\n| \\n| \\n|\\n| \\n20-Projects/01-ParsingOutput\\n| \\n20-Projects/01-ParsingOutput\\n| \\n| \\n|\\n| \\n22-OpenAI\\n| \\n22-OpenAI\\n| \\n| \\n|\\n| \\n99-Projects\\n| \\n99-Projects\\n| \\n| \\n|\\n| \\nimages\\n| \\nimages\\n| \\n| \\n|\\n| \\n.env_sample\\n| \\n.env_sample\\n| \\n| \\n|\\n| \\n.gitignore\\n| \\n.gitignore\\n| \\n| \\n|\\n| \\nLICENSE\\n| \\nLICENSE\\n| \\n| \\n|\\n| \\nREADME.md\\n| \\nREADME.md\\n| \\n| \\n|\\n| \\npoetry.lock\\n| \\npoetry.lock\\n| \\n| \\n|\\n| \\npyproject.toml\\n| \\npyproject.toml\\n| \\n| \\n|\\n| \\nrequirements-mini.txt\\n| \\nrequirements-mini.txt\\n| \\n| \\n|\\n| \\nrequirements-onnx.txt\\n| \\nrequirements-onnx.txt\\n| \\n| \\n|\\n| \\nrequirements.txt\\n| \\nrequirements.txt\\n| \\n| \\n|\\n| \\nView all files\\n|\\nRepository files navigation\\n\\nREADME\\nApache-2.0 license\\n\\n📘 LangChain 한국어 튜토리얼\\n\\n\\n🌟 LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다.\\n본 튜토리얼을 통해 LangChain을 더 쉽고 효과적으로 사용하는 방법을 배울 수 있습니다.\\n📔 위키독스 전자책(무료)\\n\\n\\n위키독스에 무료 전자책을 등록하였습니다✌️\\n위키독스 페이지에서 책 \"추천\" 버튼 한 번씩만 눌러 주시면 제작에 큰 힘이 됩니다. 미리 감사 드립니다🫶\\n틈나는대로 열심히 업데이트 하고 있습니다. 앞으로도 신규 기능이 추가 될 때마다 빠르게 x100 업데이트 예정입니다.\\n\\n랭체인LangChain 노트 by 테디노트 구경하러 가기\\n\\n🍿 유튜브\\n\\n\\n🤗 huggingface 에 공개된 오픈모델을 💻 로컬PC 에서 빠르게 실행🔥 해보고 테스트 하는 방법 + 모델 서빙🚀 + 업무자동화🤖 에 적용하는 방법까지!\\n👀 코드 기반 답변하는 💻 GitHub 소스코드 기반 Q&A 챗봇🤖 제작기\\nllama3 출시🔥 로컬에서 Llama3-8B 모델 돌려보기👀\\n🔥성능이 놀라워요🔥 무료로 한국어🇰🇷 파인튜닝 모델 받아서 나만의 로컬 LLM 호스팅 하기(#LangServe) + #RAG 까지!!\\n무료로 한국어🇰🇷 파인튜닝 모델 받아서 나만의 로컬 LLM 호스팅 하기(LangServe) + RAG 까지!!\\nStreamlit 으로 ChatGPT 클론 서비스 제작하는 방법\\n대화내용을 기록하는 LLM Chain 생성 방법 + 도큐먼트 참조하는 tip!\\n(Self Learning GPT) LangSmith 피드백으로 원하는 형식의 답변을 학습하는 GPT\\n(LangServe 리뷰) 초간편 LLM 웹앱 제작 & 배포기능까지! 과연, Streamlit 대체할 수 있을까?\\nAI vs AI 의대 증원에 대한 모의 찬반토론 (AI 더빙본)\\n토론 AI 에이전트 - 의대 입학정원 증원에 대한 찬반토론을 AI 끼리 한다면?\\n긴 문서(long context) 에 대한 참신한 RAG 방법론: RAPTOR! 논문 리뷰와 코드를 준비했습니다\\nLangChain 밋업 발표 / R.A.G. 우리가 절대 쉽게결과물을 얻을 수 없는 이유\\n노코딩으로 쇼핑몰 리뷰 분석 (크롤링 + Q&A 챗봇)\\nChatGPT 의 GPTS 에 API 호출기능을 붙이면 어떻게 될까?\\nLangChain Agent 를 활용하여 ChatGPT를 업무자동화 에 적용하는 방법🔥🔥\\nPrivate GPT! 나만의 ChatGPT 만들기 (HuggingFace Open LLM 활용)\\nLangGraph 의 멀티 에이전트 콜라보레이션 찍먹하기\\n마법같은 문법 LangChain Expression Language(LCEL)\\n이미지를 matplotlib 파이썬 코드로, 원하는 문장을 입력하면 파이썬 코드로 변환하는 방법\\nRAG 파이프라인 이해해보기 - 네이버 뉴스기사 기반 Q&A 챗봇 제작\\nOpenAI 의 새로운 기능 Assistant API 완벽히 이해해보기\\nOpenAI 의 새로운 기능 Assistant API 3가지 도구 활용법\\n\\n✏️ 블로그 글 목록\\n\\nGeneral\\n\\n\\nOpenAI API 모델 리스트 / 요금표\\n\\nOpenAI Python API\\n\\n\\nOpenAI Python API 키 발급방법, 요금체계\\n채팅(chat) 함수 사용하기(1)\\nDALL·E를 사용하여 이미지 생성, 수정, 다양화하기(2)\\nWhisper API를 사용하여 TTS, STT 구현하기(3)\\n\\nLangChain\\n\\n\\nOpenAI GPT 모델(ChatOpenAI) 사용법\\n허깅페이스(HuggingFace) 모델 사용법\\n챗(chat) - ConversationChain, 템플릿 사용법\\n정형데이터(CSV, Excel) - ChatGPT 기반 데이터분석\\n웹사이트 크롤링 - 웹사이트 문서 요약\\n웹사이트 정보 추출 - 스키마 활용법\\nPDF 문서요약, Map-Reduce\\nPDF 기반 질의응답(Question-Answering)\\n문장을 파이썬 코드로, 이미지를 파이썬 코드로 변경하는 방법\\nLangChain Expression Language(LCEL) 원리 이해와 파이프라인 구축 가이드\\nLLMs를 활용한 문서 요약 가이드: Stuff, Map-Reduce, Refine 방법 총정리\\n자동화된 메타데이터 태깅으로 문서의 메타데이터(metadata) 생성 및 자동 라벨링\\n네이버 뉴스 기반 Q&A 애플리케이션 구축하기 - 기본편\\nRAG 파헤치기: 문서 기반 QA 시스템 설계 방법 - 심화편\\n에이전트(Agent)와 도구(tools)를 활용한 지능형 검색 시스템 구축 가이드\\n\\nLangGraph\\n\\n\\nMulti-Agent Collaboration(다중 협업 에이전트) 로 복잡한 테스크를 수행하는 LLM 어플리케이션 제작\\nLangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\\n\\n👥 LangChain 밋업 2024 Q1 발표자료\\n\\n\\nRAG - 우리가 절대 쉽게 원하는 결과물을 얻을 수 없는 이유 - 테디노트\\n프름프트 흐름과 LLM 모델 평가 - 이재석님\\n인공지능을 통한 게임 제작 파이프라인의 변화 - 김한얼님\\nOpenAI SORA 살짝 맛보기 - 박정현님\\nSemantic Kernel로 만드는 AI Copilot - 이종인님\\nStreamlit 과 langchain으로 나만의 웹서비스 개발하기 - 최재혁님\\nLlama2-koen을 만들기까지 - 최태균님\\n올바른 한국어 언어 모델 평가를 위해: HAE-RAE Bench, KMMLU - 손규진님\\n랭체인 네이버 기사 크롤링 - 우성우님\\nGemma와 LangChain을 이용한 SQL 체인만들기 - 김태영님\\n\\n📜 라이선스\\n\\n본 프로젝트는 Apache License 2.0에 따라 라이선스가 부여됩니다.\\n🚫 라이선스 고지\\n\\n🔒 본 내용의 저작권은 2024년 테디노트에 있습니다. 모든 권리는 저작권자에게 있으며, teddylee777@gmail.com 으로 문의할 수 있습니다.\\n```\\nCopyright 2024 테디노트(teddylee777@gmail.com)\\nLicensed under the Apache License, Version 2.0 (the \"License\");\\nyou may not use this file except in compliance with the License.\\nYou may obtain a copy of the License at\\nhttp://www.apache.org/licenses/LICENSE-2.0\\n\\nUnless required by applicable law or agreed to in writing, software\\ndistributed under the License is distributed on an \"AS IS\" BASIS,\\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\nSee the License for the specific language governing permissions and\\nlimitations under the License.\\n```\\n인용 및 출처 표기\\n\\n본 저작물의 내용을 블로그, 유튜브 등 온라인 매체에 인용하여 게재하는 경우, 저작권법에 따라 반드시 출처를 명시 해야 합니다.\\n\\n상업적 사용에 대한 사전 협의\\n\\n본 저작물(Wikidocs 및 관련 실습 코드 포함)을 강의, 강연 등 상업적 목적으로 활용하고자 하는 경우, 저작권자와의 사전 서면 협의가 필수적으로 요구됩니다.\\n\\n본 내용의 무단 전재 및 재배포를 금지합니다. 본 내용의 전체 혹은 일부를 인용할 경우, 출처를 명확히 밝혀주시기 바랍니다. 본 문서는 다른 문서의 내용을 참고하여 작성되었을 수 있습니다. 참고 자료는 본 문서 하단의 출처 목록에서 확인하실 수 있습니다.\\n📚 출처\\n\\n\\nlangchain-ai 📖\\nOpenAI API Reference 🤖\\n\\n🌐 추가 자료\\n\\n\\n유튜브 채널: LangChain 한국어 튜토리얼 🎥\\n블로그: 테디노트 📝\\nPlayground: LangChain LLM Playground 🎮\\n\\n🚀 시작하기\\n\\n본 튜토리얼을 시작하기 전에, LangChain과 관련된 기본적인 지식을 갖추는 것이 좋습니다. 위의 출처 링크를 통해 기본적인 정보를 얻을 수 있습니다.\\nStart History\\n\\n\\n💡 컨트리뷰션\\n\\n본 튜토리얼에 기여하고자 하는 분들은 언제든지 풀 리퀘스트를 보내주시거나, 이슈를 등록하여 의견을 공유해 주시기 바랍니다. 모든 기여는 본 프로젝트의 발전에 큰 도움이 됩니다. 💖\\n\\nAbout\\nLangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 본 튜토리얼을 통해 LangChain을 더 쉽고 효과적으로 사용하는 방법을 배울 수 있습니다.\\nwikidocs.net/book/14314\\nTopics\\ntutorial cookbook openai huggingface gpt-3 openai-api gpt-4 generative-ai chatgpt langchain chatgpt-api langchain-python\\nResources\\nReadme\\nLicense\\nApache-2.0 license\\nActivity\\nStars\\n1.4k stars\\nWatchers\\n37 watching\\nForks\\n407 forks\\nReport repository\\nReleases\\nNo releases published\\nPackages 0\\nNo packages published  \\nContributors 5\\nLanguages\\n\\nJupyter Notebook 97.8%\\nPython 2.0%\\nHTML 0.2%\\n\\nFooter\\n© 2025 GitHub,\\xa0Inc.\\nFooter navigation\\n\\nTerms\\nPrivacy\\nSecurity\\nStatus\\nDocs\\nContact\\nManage cookies\\nDo not share my personal information\\n\\nYou can’t perform that action at this time.'}]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:17:43.092011Z",
     "start_time": "2025-04-24T13:17:43.086772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 웹 검색 결과의 첫 번째 결과 확인\n",
    "result[0]"
   ],
   "id": "2fbf12e6db098e7f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'linktr.ee/teddynote | Linktree',\n",
       " 'url': 'https://linktr.ee/teddynote',\n",
       " 'content': '03/04 LangGraph Hands On 튜토리얼 (2시간 분량) [FastCampus] 테디노트의 RAG 비법노트🙌. 🔥[100% 무료] 테디노트 YouTube 콘텐츠 학습 순서🔥. 📘 랭체인 한국어 튜토리얼🇰🇷 ... Github. 9/21 테디노트-Gencon2024-ModularRAG-20240921.pdf.',\n",
       " 'score': 0.6072213,\n",
       " 'raw_content': None}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 그래프 구성",
   "id": "ede7401c564945e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:17:59.407140Z",
     "start_time": "2025-04-24T13:17:59.402922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "\n",
    "\n",
    "# 그래프의 상태 정의\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    그래프의 상태를 나타내는 데이터 모델\n",
    "\n",
    "    Attributes:\n",
    "        question: 질문\n",
    "        generation: LLM 생성된 답변\n",
    "        documents: 도큐먼틑 리스트\n",
    "    \"\"\"\n",
    "\n",
    "    question: Annotated[str, \"User question\"]\n",
    "    generation: Annotated[str, \"LLM generated answer\"]\n",
    "    documents: Annotated[List[str], \"List of documents\"]"
   ],
   "id": "1872dde4d365cae3",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 그래프 흐름 정의",
   "id": "1ede7d69465c8c5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:18:17.512050Z",
     "start_time": "2025-04-24T13:18:17.502520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "# 문서 검색 노드\n",
    "def retrieve(state):\n",
    "    print(\"==== [RETRIEVE] ====\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # 문서 검색 수행\n",
    "    documents = pdf_retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "\n",
    "# 답변 생성 노드\n",
    "def generate(state):\n",
    "    print(\"==== [GENERATE] ====\")\n",
    "    # 질문과 문서 검색 결과 가져오기\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG 답변 생성\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "\n",
    "# 문서 관련성 평가 노드\n",
    "def grade_documents(state):\n",
    "    print(\"==== [CHECK DOCUMENT RELEVANCE TO QUESTION] ====\")\n",
    "    # 질문과 문서 검색 결과 가져오기\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # 각 문서에 대한 관련성 점수 계산\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            # 관련성이 있는 문서 추가\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            # 관련성이 없는 문서는 건너뛰기\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question}\n",
    "\n",
    "\n",
    "# 질문 재작성 노드\n",
    "def transform_query(state):\n",
    "    print(\"==== [TRANSFORM QUERY] ====\")\n",
    "    # 질문과 문서 검색 결과 가져오기\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # 질문 재작성\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"documents\": documents, \"question\": better_question}\n",
    "\n",
    "\n",
    "# 웹 검색 노드\n",
    "def web_search(state):\n",
    "    print(\"==== [WEB SEARCH] ====\")\n",
    "    # 질문과 문서 검색 결과 가져오기\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # 웹 검색 수행\n",
    "    web_results = web_search_tool.invoke({\"query\": question})\n",
    "    web_results_docs = [\n",
    "        Document(\n",
    "            page_content=web_result[\"content\"],\n",
    "            metadata={\"source\": web_result[\"url\"]},\n",
    "        )\n",
    "        for web_result in web_results\n",
    "    ]\n",
    "\n",
    "    return {\"documents\": web_results_docs, \"question\": question}"
   ],
   "id": "c1cc2863094fa927",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:18:27.013014Z",
     "start_time": "2025-04-24T13:18:27.000681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 질문 라우팅 노드\n",
    "def route_question(state):\n",
    "    print(\"==== [ROUTE QUESTION] ====\")\n",
    "    # 질문 가져오기\n",
    "    question = state[\"question\"]\n",
    "    # 질문 라우팅\n",
    "    source = question_router.invoke({\"question\": question})\n",
    "    # 질문 라우팅 결과에 따른 노드 라우팅\n",
    "    if source.datasource == \"web_search\":\n",
    "        print(\"==== [ROUTE QUESTION TO WEB SEARCH] ====\")\n",
    "        return \"web_search\"\n",
    "    elif source.datasource == \"vectorstore\":\n",
    "        print(\"==== [ROUTE QUESTION TO VECTORSTORE] ====\")\n",
    "        return \"vectorstore\"\n",
    "\n",
    "\n",
    "# 문서 관련성 평가 노드\n",
    "def decide_to_generate(state):\n",
    "    print(\"==== [DECISION TO GENERATE] ====\")\n",
    "    # 질문과 문서 검색 결과 가져오기\n",
    "    question = state[\"question\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if not filtered_documents:\n",
    "        # 모든 문서가 관련성 없는 경우 질문 재작성\n",
    "        print(\n",
    "            \"==== [DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY] ====\"\n",
    "        )\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # 관련성 있는 문서가 있는 경우 답변 생성\n",
    "        print(\"==== [DECISION: GENERATE] ====\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "def hallucination_check(state):\n",
    "    print(\"==== [CHECK HALLUCINATIONS] ====\")\n",
    "    # 질문과 문서 검색 결과 가져오기\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    # 환각 평가\n",
    "    score = hallucination_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "    grade = score.binary_score\n",
    "\n",
    "    # Hallucination 여부 확인\n",
    "    if grade == \"yes\":\n",
    "        print(\"==== [DECISION: GENERATION IS GROUNDED IN DOCUMENTS] ====\")\n",
    "\n",
    "        # 답변의 관련성(Relevance) 평가\n",
    "        print(\"==== [GRADE GENERATED ANSWER vs QUESTION] ====\")\n",
    "        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "        grade = score.binary_score\n",
    "\n",
    "        # 관련성 평가 결과에 따른 처리\n",
    "        if grade == \"yes\":\n",
    "            print(\"==== [DECISION: GENERATED ANSWER ADDRESSES QUESTION] ====\")\n",
    "            return \"relevant\"\n",
    "        else:\n",
    "            print(\"==== [DECISION: GENERATED ANSWER DOES NOT ADDRESS QUESTION] ====\")\n",
    "            return \"not relevant\"\n",
    "    else:\n",
    "        print(\"==== [DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY] ====\")\n",
    "        return \"hallucination\""
   ],
   "id": "9859cc6e8b3f4253",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:19:10.731872Z",
     "start_time": "2025-04-24T13:19:10.614937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# 그래프 상태 초기화\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# 노드 정의\n",
    "workflow.add_node(\"web_search\", web_search)  # 웹 검색\n",
    "workflow.add_node(\"retrieve\", retrieve)  # 문서 검색\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # 문서 평가\n",
    "workflow.add_node(\"generate\", generate)  # 답변 생성\n",
    "workflow.add_node(\"transform_query\", transform_query)  # 쿼리 변환\n",
    "\n",
    "# 그래프 빌드\n",
    "workflow.add_conditional_edges(\n",
    "    START,\n",
    "    route_question,\n",
    "    {\n",
    "        \"web_search\": \"web_search\",  # 웹 검색으로 라우팅\n",
    "        \"vectorstore\": \"retrieve\",  # 벡터스토어로 라우팅\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"web_search\", \"generate\")  # 웹 검색 후 답변 생성\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")  # 문서 검색 후 평가\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",  # 쿼리 변환 필요\n",
    "        \"generate\": \"generate\",  # 답변 생성 가능\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")  # 쿼리 변환 후 문서 검색\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    hallucination_check,\n",
    "    {\n",
    "        \"hallucination\": \"generate\",  # Hallucination 발생 시 재생성\n",
    "        \"relevant\": END,  # 답변의 관련성 여부 통과\n",
    "        \"not relevant\": \"transform_query\",  # 답변의 관련성 여부 통과 실패 시 쿼리 변환\n",
    "    },\n",
    ")\n",
    "\n",
    "# 그래프 컴파일\n",
    "app = workflow.compile(checkpointer=MemorySaver())"
   ],
   "id": "77eb226022a973e5",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 그래프 사용",
   "id": "b972e80e25971d67"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:20:18.999145Z",
     "start_time": "2025-04-24T13:20:05.023544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_teddynote.messages import stream_graph\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "import uuid\n",
    "\n",
    "# config 설정(재귀 최대 횟수, thread_id)\n",
    "config = RunnableConfig(recursion_limit=20, configurable={\"thread_id\": uuid.uuid4()})\n",
    "\n",
    "# 질문 입력\n",
    "inputs = {\n",
    "    \"question\": \"삼성전자가 개발한 생성형 AI 의 이름은?\",\n",
    "}\n",
    "\n",
    "# 그래프 실행\n",
    "stream_graph(app, inputs, config, [\"agent\", \"rewrite\", \"generate\"])"
   ],
   "id": "1507c413683c4cc0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== [ROUTE QUESTION] ====\n",
      "==== [ROUTE QUESTION TO VECTORSTORE] ====\n",
      "==== [RETRIEVE] ====\n",
      "==== [CHECK DOCUMENT RELEVANCE TO QUESTION] ====\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "==== [DECISION TO GENERATE] ====\n",
      "==== [DECISION: GENERATE] ====\n",
      "==== [GENERATE] ====\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mgenerate\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "삼성전자가 개발한 생성형 AI의 이름은 '삼성 가우스'입니다.\n",
      "\n",
      "**Source**\n",
      "- data/SPRI_AI_Brief_2023년12월호_F.pdf (page 12)==== [CHECK HALLUCINATIONS] ====\n",
      "{\"binary_score\":\"yes\"}==== [DECISION: GENERATION IS GROUNDED IN DOCUMENTS] ====\n",
      "==== [GRADE GENERATED ANSWER vs QUESTION] ====\n",
      "{\"binary_score\":\"yes\"}==== [DECISION: GENERATED ANSWER ADDRESSES QUESTION] ====\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:20:41.828296Z",
     "start_time": "2025-04-24T13:20:32.680262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 질문 입력\n",
    "inputs = {\n",
    "    \"question\": \"2024년 노벨 문학상 수상자는 누구인가요?\",\n",
    "}\n",
    "\n",
    "# 그래프 실행\n",
    "stream_graph(app, inputs, config, [\"agent\", \"rewrite\", \"generate\"])"
   ],
   "id": "915a0cf6a3ce71b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== [ROUTE QUESTION] ====\n",
      "==== [ROUTE QUESTION TO WEB SEARCH] ====\n",
      "==== [WEB SEARCH] ====\n",
      "==== [GENERATE] ====\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mgenerate\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "2024년 노벨 문학상 수상자는 한국의 작가 한강입니다. \n",
      "\n",
      "**Source**\n",
      "- https://imnews.imbc.com/replay/2024/nwtoday/article/6645060_36523.html\n",
      "- https://www.yna.co.kr/view/MYH20241010024300704\n",
      "- https://www.khan.co.kr/article/202410102231001==== [CHECK HALLUCINATIONS] ====\n",
      "{\"binary_score\":\"yes\"}==== [DECISION: GENERATION IS GROUNDED IN DOCUMENTS] ====\n",
      "==== [GRADE GENERATED ANSWER vs QUESTION] ====\n",
      "{\"binary_score\":\"yes\"}==== [DECISION: GENERATED ANSWER ADDRESSES QUESTION] ====\n"
     ]
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
