{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-24T12:55:40.071764Z",
     "start_time": "2025-04-24T12:55:40.053303Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API í‚¤ ì •ë³´ ë¡œë“œ\n",
    "load_dotenv()\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "logging.langsmith(\"CH17-LangGraph-Structures\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "CH17-LangGraph-Structures\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ê¸°ë³¸ PDF ê¸°ë°˜ Retrieval Chain ìƒì„±",
   "id": "669f85bd99b34065"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T12:56:02.659934Z",
     "start_time": "2025-04-24T12:55:47.338971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from rag.pdf import PDFRetrievalChain\n",
    "\n",
    "# PDF ë¬¸ì„œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "pdf = PDFRetrievalChain([\"data/SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf\"]).create_chain()\n",
    "\n",
    "# retrieverì™€ chainì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "pdf_retriever = pdf.retriever\n",
    "pdf_chain = pdf.chain"
   ],
   "id": "276addf80158cd85",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# State ì •ì˜\n",
   "id": "a8dc99849c5999aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T12:56:02.759714Z",
     "start_time": "2025-04-24T12:56:02.665939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# GraphState ìƒíƒœ ì •ì˜\n",
    "class GraphState(TypedDict):\n",
    "    question: Annotated[list, add_messages]  # ì§ˆë¬¸(ëˆ„ì ë˜ëŠ” list)\n",
    "    context: Annotated[str, \"Context\"]  # ë¬¸ì„œì˜ ê²€ìƒ‰ ê²°ê³¼\n",
    "    answer: Annotated[str, \"Answer\"]  # ë‹µë³€\n",
    "    messages: Annotated[list, add_messages]  # ë©”ì‹œì§€(ëˆ„ì ë˜ëŠ” list)\n",
    "    relevance: Annotated[str, \"Relevance\"]  # ê´€ë ¨ì„±"
   ],
   "id": "986e709e27587940",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ë…¸ë“œ(Node) ì •ì˜",
   "id": "72f9fadf76bd44e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T12:56:42.079204Z",
     "start_time": "2025-04-24T12:56:40.770598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_teddynote.evaluator import GroundednessChecker\n",
    "from langchain_teddynote.messages import messages_to_history\n",
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "from rag.utils import format_docs\n",
    "\n",
    "\n",
    "# ë¬¸ì„œ ê²€ìƒ‰ ë…¸ë“œ\n",
    "def retrieve_document(state: GraphState) -> GraphState:\n",
    "    # ì§ˆë¬¸ì„ ìƒíƒœì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "    latest_question = state[\"question\"][-1].content\n",
    "\n",
    "    # ë¬¸ì„œì—ì„œ ê²€ìƒ‰í•˜ì—¬ ê´€ë ¨ì„± ìˆëŠ” ë¬¸ì„œë¥¼ ì°¾ìŠµë‹ˆë‹¤.\n",
    "    retrieved_docs = pdf_retriever.invoke(latest_question)\n",
    "\n",
    "    # ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ í˜•ì‹í™”í•©ë‹ˆë‹¤.(í”„ë¡¬í”„íŠ¸ ì…ë ¥ìœ¼ë¡œ ë„£ì–´ì£¼ê¸° ìœ„í•¨)\n",
    "    retrieved_docs = format_docs(retrieved_docs)\n",
    "\n",
    "    # ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ context í‚¤ì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "    return GraphState(context=retrieved_docs)\n",
    "\n",
    "\n",
    "# ë‹µë³€ ìƒì„± ë…¸ë“œ\n",
    "def llm_answer(state: GraphState) -> GraphState:\n",
    "    # ì§ˆë¬¸ì„ ìƒíƒœì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "    latest_question = state[\"question\"][-1].content\n",
    "\n",
    "    # ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ìƒíƒœì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "    context = state[\"context\"]\n",
    "\n",
    "    # ì²´ì¸ì„ í˜¸ì¶œí•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    response = pdf_chain.invoke(\n",
    "        {\n",
    "            \"question\": latest_question,\n",
    "            \"context\": context,\n",
    "            \"chat_history\": messages_to_history(state[\"messages\"]),\n",
    "        }\n",
    "    )\n",
    "    # ìƒì„±ëœ ë‹µë³€, (ìœ ì €ì˜ ì§ˆë¬¸, ë‹µë³€) ë©”ì‹œì§€ë¥¼ ìƒíƒœì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "    return GraphState(\n",
    "        answer=response, messages=[(\"user\", latest_question), (\"assistant\", response)]\n",
    "    )\n",
    "\n",
    "\n",
    "# ê´€ë ¨ì„± ì²´í¬ ë…¸ë“œ\n",
    "def relevance_check(state: GraphState) -> GraphState:\n",
    "    # ê´€ë ¨ì„± í‰ê°€ê¸°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    question_answer_relevant = GroundednessChecker(\n",
    "        llm=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0), target=\"question-retrieval\"\n",
    "    ).create()\n",
    "\n",
    "    # ê´€ë ¨ì„± ì²´í¬ë¥¼ ì‹¤í–‰(\"yes\" or \"no\")\n",
    "    response = question_answer_relevant.invoke(\n",
    "        {\"question\": state[\"question\"][-1].content, \"context\": state[\"context\"]}\n",
    "    )\n",
    "\n",
    "    # ì°¸ê³ : ì—¬ê¸°ì„œì˜ ê´€ë ¨ì„± í‰ê°€ê¸°ëŠ” ê°ìì˜ Prompt ë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ëŸ¬ë¶„ë“¤ì˜ Groundedness Check ë¥¼ ë§Œë“¤ì–´ ì‚¬ìš©í•´ ë³´ì„¸ìš”!\n",
    "    return GraphState(relevance=response.score)\n",
    "\n",
    "\n",
    "# ê´€ë ¨ì„± ì²´í¬í•˜ëŠ” í•¨ìˆ˜(router)\n",
    "def is_relevant(state: GraphState) -> GraphState:\n",
    "    return state[\"relevance\"]\n",
    "\n",
    "\n",
    "# Web Search ë…¸ë“œ\n",
    "def web_search(state: GraphState) -> GraphState:\n",
    "    # ê²€ìƒ‰ ë„êµ¬ ìƒì„±\n",
    "    tavily_tool = TavilySearch()\n",
    "\n",
    "    search_query = state[\"question\"][-1].content\n",
    "\n",
    "    # ë‹¤ì–‘í•œ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•œ ê²€ìƒ‰ ì˜ˆì œ\n",
    "    search_result = tavily_tool.search(\n",
    "        query=search_query,  # ê²€ìƒ‰ ì¿¼ë¦¬\n",
    "        topic=\"general\",  # ì¼ë°˜ ì£¼ì œ\n",
    "        max_results=3,  # ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼\n",
    "        format_output=True,  # ê²°ê³¼ í¬ë§·íŒ…\n",
    "    )\n",
    "\n",
    "    return GraphState(context=\"\\n\".join(search_result))"
   ],
   "id": "c66ef73323b66e0e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Query Rewrite ë…¸ë“œ ì¶”ê°€\n",
   "id": "ed53d890ae52e658"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T12:56:56.537756Z",
     "start_time": "2025-04-24T12:56:55.487940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Query Rewrite í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
    "re_write_prompt = PromptTemplate(\n",
    "    template=\"\"\"Reformulate the given question to enhance its effectiveness for vectorstore retrieval.\n",
    "\n",
    "- Analyze the initial question to identify areas for improvement such as specificity, clarity, and relevance.\n",
    "- Consider the context and potential keywords that would optimize retrieval.\n",
    "- Maintain the intent of the original question while enhancing its structure and vocabulary.\n",
    "\n",
    "# Steps\n",
    "\n",
    "1. **Understand the Original Question**: Identify the core intent and any keywords.\n",
    "2. **Enhance Clarity**: Simplify language and ensure the question is direct and to the point.\n",
    "3. **Optimize for Retrieval**: Add or rearrange keywords for better alignment with vectorstore indexing.\n",
    "4. **Review**: Ensure the improved question accurately reflects the original intent and is free of ambiguity.\n",
    "\n",
    "# Output Format\n",
    "\n",
    "- Provide a single, improved question.\n",
    "- Do not include any introductory or explanatory text; only the reformulated question.\n",
    "\n",
    "# Examples\n",
    "\n",
    "**Input**:\n",
    "\"What are the benefits of using renewable energy sources over fossil fuels?\"\n",
    "\n",
    "**Output**:\n",
    "\"How do renewable energy sources compare to fossil fuels in terms of benefits?\"\n",
    "\n",
    "**Input**:\n",
    "\"How does climate change impact polar bear populations?\"\n",
    "\n",
    "**Output**:\n",
    "\"What effects does climate change have on polar bear populations?\"\n",
    "\n",
    "# Notes\n",
    "\n",
    "- Ensure the improved question is concise and contextually relevant.\n",
    "- Avoid altering the fundamental intent or meaning of the original question.\n",
    "\n",
    "\n",
    "[REMEMBER] Re-written question should be in the same language as the original question.\n",
    "\n",
    "# Here is the original question that needs to be rewritten:\n",
    "{question}\n",
    "\"\"\",\n",
    "    input_variables=[\"generation\", \"question\"],\n",
    ")\n",
    "\n",
    "question_rewriter = (\n",
    "    re_write_prompt | ChatOpenAI(model=\"gpt-4o-mini\", temperature=0) | StrOutputParser()\n",
    ")"
   ],
   "id": "5a4f660990bd3b26",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T12:57:00.707111Z",
     "start_time": "2025-04-24T12:56:59.568888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ì§ˆë¬¸ ì¬ì‘ì„±\n",
    "question = \"ì•¤ìŠ¤ë¡œí”½ì— íˆ¬ìí•œ ë¯¸êµ­ê¸°ì—…\"\n",
    "\n",
    "question_rewriter.invoke({\"question\": question})"
   ],
   "id": "ed94a1ff62e49c0c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì•¤ìŠ¤ë¡œí”½ì— íˆ¬ìí•œ ë¯¸êµ­ ê¸°ì—…ì€ ì–´ë–¤ ê³³ë“¤ì´ ìˆë‚˜ìš”?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T12:57:08.281899Z",
     "start_time": "2025-04-24T12:57:08.277842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Query Rewrite ë…¸ë“œ\n",
    "def query_rewrite(state: GraphState) -> GraphState:\n",
    "    latest_question = state[\"question\"][-1].content\n",
    "    question_rewritten = question_rewriter.invoke({\"question\": latest_question})\n",
    "    return GraphState(question=question_rewritten)"
   ],
   "id": "e6fa8785afd7831e",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Edges",
   "id": "8169838277160688"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T12:57:21.064037Z",
     "start_time": "2025-04-24T12:57:21.041647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# ê·¸ë˜í”„ ì •ì˜\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "workflow.add_node(\"retrieve\", retrieve_document)\n",
    "workflow.add_node(\"relevance_check\", relevance_check)\n",
    "workflow.add_node(\"llm_answer\", llm_answer)\n",
    "workflow.add_node(\"web_search\", web_search)\n",
    "\n",
    "# Query Rewrite ë…¸ë“œ ì¶”ê°€\n",
    "workflow.add_node(\"query_rewrite\", query_rewrite)\n",
    "\n",
    "# ì—£ì§€ ì¶”ê°€\n",
    "workflow.add_edge(\"retrieve\", \"relevance_check\")  # ê²€ìƒ‰ -> ê´€ë ¨ì„± ì²´í¬\n",
    "# workflow.add_edge(\"relevance_check\", \"llm_answer\")  # ê´€ë ¨ì„± ì²´í¬ -> ë‹µë³€\n",
    "workflow.add_edge(\"query_rewrite\", \"retrieve\")  # ì§ˆë¬¸ ì¬ì‘ì„± -> ê²€ìƒ‰\n",
    "\n",
    "# # ì¡°ê±´ë¶€ ì—£ì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "workflow.add_conditional_edges(\n",
    "    \"relevance_check\",  # ê´€ë ¨ì„± ì²´í¬ ë…¸ë“œì—ì„œ ë‚˜ì˜¨ ê²°ê³¼ë¥¼ is_relevant í•¨ìˆ˜ì— ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "    is_relevant,\n",
    "    {\n",
    "        \"yes\": \"llm_answer\",  # ê´€ë ¨ì„±ì´ ìˆìœ¼ë©´ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "        \"no\": \"web_search\",  # ê´€ë ¨ì„±ì´ ì—†ìœ¼ë©´ ë‹¤ì‹œ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"web_search\", \"llm_answer\")  # ê²€ìƒ‰ -> ë‹µë³€\n",
    "workflow.add_edge(\"llm_answer\", END)  # ë‹µë³€ -> ì¢…ë£Œ\n",
    "\n",
    "# ê·¸ë˜í”„ ì§„ì…ì  ì„¤ì •\n",
    "workflow.set_entry_point(\"query_rewrite\")\n",
    "\n",
    "# ì²´í¬í¬ì¸í„° ì„¤ì •\n",
    "memory = MemorySaver()\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "app = workflow.compile(checkpointer=memory)"
   ],
   "id": "a508bab8916e2ee1",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ê·¸ë˜í”„ ì‹¤í–‰",
   "id": "fe7bc3cfcb0a53c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T12:57:35.839697Z",
     "start_time": "2025-04-24T12:57:31.113402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import stream_graph, random_uuid\n",
    "\n",
    "# config ì„¤ì •(ì¬ê·€ ìµœëŒ€ íšŸìˆ˜, thread_id)\n",
    "config = RunnableConfig(recursion_limit=10, configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "# ì§ˆë¬¸ ì…ë ¥\n",
    "inputs = GraphState(question=\"ì•¤ìŠ¤ë¡œí”½ íˆ¬ì ê¸ˆì•¡\")\n",
    "\n",
    "# ê·¸ë˜í”„ ì‹¤í–‰\n",
    "stream_graph(app, inputs, config, [\"query_rewrite\", \"llm_answer\"])"
   ],
   "id": "220a9da68bdf199f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001B[1;36mquery_rewrite\u001B[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "ì•¤ìŠ¤ë¡œí”½ì— ëŒ€í•œ íˆ¬ì ê¸ˆì•¡ì€ ì–¼ë§ˆì¸ê°€ìš”?\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001B[1;36mllm_answer\u001B[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "êµ¬ê¸€ì€ ì•¤ìŠ¤ë¡œí”½ì— ìµœëŒ€ 20ì–µ ë‹¬ëŸ¬ë¥¼ íˆ¬ìí•˜ê¸°ë¡œ í•©ì˜í•˜ì˜€ìœ¼ë©°, ì´ ì¤‘ 5ì–µ ë‹¬ëŸ¬ë¥¼ ìš°ì„  íˆ¬ìí•˜ê³  í–¥í›„ 15ì–µ ë‹¬ëŸ¬ë¥¼ ì¶”ê°€ë¡œ íˆ¬ìí•  ê³„íšì…ë‹ˆë‹¤.\n",
      "\n",
      "**Source**\n",
      "- data/SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf (page 14)"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T12:57:52.777467Z",
     "start_time": "2025-04-24T12:57:52.771431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "outputs = app.get_state(config).values\n",
    "\n",
    "print(f'Original Question: {outputs[\"question\"][0].content}')\n",
    "print(f'Rewritten Question: {outputs[\"question\"][-1].content}')\n",
    "print(\"===\" * 20)\n",
    "print(f'Answer:\\n{outputs[\"answer\"]}')"
   ],
   "id": "ff888f405382a72c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Question: ì•¤ìŠ¤ë¡œí”½ íˆ¬ì ê¸ˆì•¡\n",
      "Rewritten Question: ì•¤ìŠ¤ë¡œí”½ì— ëŒ€í•œ íˆ¬ì ê¸ˆì•¡ì€ ì–¼ë§ˆì¸ê°€ìš”?\n",
      "============================================================\n",
      "Answer:\n",
      "êµ¬ê¸€ì€ ì•¤ìŠ¤ë¡œí”½ì— ìµœëŒ€ 20ì–µ ë‹¬ëŸ¬ë¥¼ íˆ¬ìí•˜ê¸°ë¡œ í•©ì˜í•˜ì˜€ìœ¼ë©°, ì´ ì¤‘ 5ì–µ ë‹¬ëŸ¬ë¥¼ ìš°ì„  íˆ¬ìí•˜ê³  í–¥í›„ 15ì–µ ë‹¬ëŸ¬ë¥¼ ì¶”ê°€ë¡œ íˆ¬ìí•  ê³„íšì…ë‹ˆë‹¤.\n",
      "\n",
      "**Source**\n",
      "- data/SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf (page 14)\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
