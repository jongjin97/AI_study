{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-24T09:56:09.925721Z",
     "start_time": "2025-04-24T09:56:09.905265Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH17-LangGraph-Structures\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH17-LangGraph-Structures\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 기본 PDF 기반 Retrieval Chain 생성",
   "id": "c6d22b63d736bb98"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T09:58:48.104652Z",
     "start_time": "2025-04-24T09:58:36.824752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from rag.pdf import PDFRetrievalChain\n",
    "\n",
    "# PDF 문서를 로드합니다.\n",
    "pdf = PDFRetrievalChain([\"data/SPRI_AI_Brief_2023년12월호_F.pdf\"]).create_chain()\n",
    "\n",
    "# retriever와 chain을 생성합니다.\n",
    "pdf_retriever = pdf.retriever\n",
    "pdf_chain = pdf.chain"
   ],
   "id": "96d78d8514628681",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# State 정의",
   "id": "e80001dcec867541"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T09:58:49.562537Z",
     "start_time": "2025-04-24T09:58:49.471085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# GraphState 상태 정의\n",
    "class GraphState(TypedDict):\n",
    "    question: Annotated[str, \"Question\"]  # 질문\n",
    "    context: Annotated[str, \"Context\"]  # 문서의 검색 결과\n",
    "    answer: Annotated[str, \"Answer\"]  # 답변\n",
    "    messages: Annotated[list, add_messages]  # 메시지(누적되는 list)\n",
    "    relevance: Annotated[str, \"Relevance\"]  # 관련성"
   ],
   "id": "8951d5ad98c49f04",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 노드(Node) 정의",
   "id": "db337611bdeffd2f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T10:00:20.300272Z",
     "start_time": "2025-04-24T10:00:19.294119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_teddynote.evaluator import GroundednessChecker\n",
    "from langchain_teddynote.messages import messages_to_history\n",
    "from rag.utils import format_docs\n",
    "\n",
    "\n",
    "# 문서 검색 노드\n",
    "def retrieve_document(state: GraphState) -> GraphState:\n",
    "    # 질문을 상태에서 가져옵니다.\n",
    "    latest_question = state[\"question\"]\n",
    "\n",
    "    # 문서에서 검색하여 관련성 있는 문서를 찾습니다.\n",
    "    retrieved_docs = pdf_retriever.invoke(latest_question)\n",
    "\n",
    "    # 검색된 문서를 형식화합니다.(프롬프트 입력으로 넣어주기 위함)\n",
    "    retrieved_docs = format_docs(retrieved_docs)\n",
    "\n",
    "    # 검색된 문서를 context 키에 저장합니다.\n",
    "    return GraphState(context=retrieved_docs)\n",
    "\n",
    "\n",
    "# 답변 생성 노드\n",
    "def llm_answer(state: GraphState) -> GraphState:\n",
    "    # 질문을 상태에서 가져옵니다.\n",
    "    latest_question = state[\"question\"]\n",
    "\n",
    "    # 검색된 문서를 상태에서 가져옵니다.\n",
    "    context = state[\"context\"]\n",
    "\n",
    "    # 체인을 호출하여 답변을 생성합니다.\n",
    "    response = pdf_chain.invoke(\n",
    "        {\n",
    "            \"question\": latest_question,\n",
    "            \"context\": context,\n",
    "            \"chat_history\": messages_to_history(state[\"messages\"]),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # 생성된 답변, (유저의 질문, 답변) 메시지를 상태에 저장합니다.\n",
    "    return GraphState(\n",
    "        answer=response, messages=[(\"user\", latest_question), (\"assistant\", response)]\n",
    "    )\n",
    "\n",
    "\n",
    "# 관련성 체크 노드\n",
    "def relevance_check(state: GraphState) -> GraphState:\n",
    "    # 관련성 평가기를 생성합니다.\n",
    "    question_answer_relevant = GroundednessChecker(\n",
    "        llm=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0), target=\"question-retrieval\"\n",
    "    ).create()\n",
    "\n",
    "    # 관련성 체크를 실행(\"yes\" or \"no\")\n",
    "    response = question_answer_relevant.invoke(\n",
    "        {\"question\": state[\"question\"], \"context\": state[\"context\"]}\n",
    "    )\n",
    "\n",
    "    print(\"==== [RELEVANCE CHECK] ====\")\n",
    "    print(response.score)\n",
    "\n",
    "    # 참고: 여기서의 관련성 평가기는 각자의 Prompt 를 사용하여 수정할 수 있습니다. 여러분들의 Groundedness Check 를 만들어 사용해 보세요!\n",
    "    return GraphState(relevance=response.score)\n",
    "\n",
    "\n",
    "# 관련성 체크하는 함수(router)\n",
    "def is_relevant(state: GraphState) -> GraphState:\n",
    "    return state[\"relevance\"]"
   ],
   "id": "3e51ec745faf2f9c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Edges",
   "id": "778acd88649e23cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T10:01:15.991294Z",
     "start_time": "2025-04-24T10:01:15.974054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# 그래프 정의\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# 노드 추가\n",
    "workflow.add_node(\"retrieve\", retrieve_document)\n",
    "# 관련성 체크 노드 추가\n",
    "workflow.add_node(\"relevance_check\", relevance_check)\n",
    "workflow.add_node(\"llm_answer\", llm_answer)\n",
    "\n",
    "# 엣지 추가\n",
    "workflow.add_edge(\"retrieve\", \"relevance_check\")  # 검색 -> 관련성 체크\n",
    "\n",
    "\n",
    "# # 조건부 엣지를 추가합니다.\n",
    "workflow.add_conditional_edges(\n",
    "    \"relevance_check\",  # 관련성 체크 노드에서 나온 결과를 is_relevant 함수에 전달합니다.\n",
    "    is_relevant,\n",
    "    {\n",
    "        \"yes\": \"llm_answer\",  # 관련성이 있으면 답변을 생성합니다.\n",
    "        \"no\": \"retrieve\",  # 관련성이 없으면 다시 검색합니다.\n",
    "    },\n",
    ")\n",
    "\n",
    "# 그래프 진입점 설정\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "\n",
    "# 체크포인터 설정\n",
    "memory = MemorySaver()\n",
    "\n",
    "# 그래프 컴파일\n",
    "app = workflow.compile(checkpointer=memory)"
   ],
   "id": "3829548363ac9a38",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 그래프 실행",
   "id": "6f49a38f60cd38bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T10:01:40.484333Z",
     "start_time": "2025-04-24T10:01:35.264738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import stream_graph, random_uuid\n",
    "\n",
    "# config 설정(재귀 최대 횟수, thread_id)\n",
    "config = RunnableConfig(recursion_limit=20, configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "# 질문 입력\n",
    "inputs = GraphState(question=\"앤스로픽에 투자한 기업과 투자금액을 알려주세요.\")\n",
    "\n",
    "# 그래프 실행\n",
    "stream_graph(app, inputs, config, [\"relevance_check\", \"llm_answer\"])"
   ],
   "id": "f70fd58f9e1fbd2a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mrelevance_check\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "{\"score\":\"yes\"}==== [RELEVANCE CHECK] ====\n",
      "yes\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mllm_answer\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "구글은 앤스로픽에 최대 20억 달러를 투자하기로 합의하였으며, 이 중 5억 달러를 우선 투자했습니다. 아마존은 앤스로픽에 최대 40억 달러의 투자 계획을 발표했습니다.\n",
      "\n",
      "**Source**\n",
      "- data/SPRI_AI_Brief_2023년12월호_F.pdf (page 14)"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T10:01:54.288409Z",
     "start_time": "2025-04-24T10:01:54.283876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "outputs = app.get_state(config).values\n",
    "\n",
    "print(f'Question: {outputs[\"question\"]}')\n",
    "print(\"===\" * 20)\n",
    "print(f'Answer:\\n{outputs[\"answer\"]}')"
   ],
   "id": "a1642176b373b7eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 앤스로픽에 투자한 기업과 투자금액을 알려주세요.\n",
      "============================================================\n",
      "Answer:\n",
      "구글은 앤스로픽에 최대 20억 달러를 투자하기로 합의하였으며, 이 중 5억 달러를 우선 투자했습니다. 아마존은 앤스로픽에 최대 40억 달러의 투자 계획을 발표했습니다.\n",
      "\n",
      "**Source**\n",
      "- data/SPRI_AI_Brief_2023년12월호_F.pdf (page 14)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T10:01:57.449487Z",
     "start_time": "2025-04-24T10:01:57.444980Z"
    }
   },
   "cell_type": "code",
   "source": "print(outputs[\"relevance\"])",
   "id": "ec24f8a51b105f98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T10:02:40.177069Z",
     "start_time": "2025-04-24T10:02:09.016327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.errors import GraphRecursionError\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# config 설정(재귀 최대 횟수, thread_id)\n",
    "config = RunnableConfig(recursion_limit=10, configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "# 질문 입력\n",
    "inputs = GraphState(question=\"테디노트의 랭체인 튜토리얼에 대한 정보를 알려주세요.\")\n",
    "\n",
    "try:\n",
    "    # 그래프 실행\n",
    "    stream_graph(app, inputs, config, [\"relevance_check\", \"llm_answer\"])\n",
    "except GraphRecursionError as recursion_error:\n",
    "    print(f\"GraphRecursionError: {recursion_error}\")"
   ],
   "id": "7cf3a3faadc56e38",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mrelevance_check\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "{\"score\":\"no\"}==== [RELEVANCE CHECK] ====\n",
      "no\n",
      "{\"score\":\"no\"}==== [RELEVANCE CHECK] ====\n",
      "no\n",
      "{\"score\":\"no\"}==== [RELEVANCE CHECK] ====\n",
      "no\n",
      "{\"score\":\"no==== [RELEVANCE CHECK] ====\n",
      "no\n",
      "\"}{\"score\":\"no\"}==== [RELEVANCE CHECK] ====\n",
      "no\n",
      "GraphRecursionError: Recursion limit of 10 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
