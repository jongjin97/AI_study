{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-24T12:58:52.347765Z",
     "start_time": "2025-04-24T12:58:52.329575Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH17-LangGraph-Structures\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH17-LangGraph-Structures\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 기본 PDF 기반 Retrieval Chain 생성\n",
   "id": "8fdd84a08bca434c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T12:59:13.611861Z",
     "start_time": "2025-04-24T12:59:00.340696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from rag.pdf import PDFRetrievalChain\n",
    "\n",
    "# PDF 문서를 로드합니다.\n",
    "pdf = PDFRetrievalChain([\"data/SPRI_AI_Brief_2023년12월호_F.pdf\"]).create_chain()\n",
    "\n",
    "# retriever와 chain을 생성합니다.\n",
    "pdf_retriever = pdf.retriever\n",
    "pdf_chain = pdf.chain"
   ],
   "id": "cec2c5c5d5347666",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T12:59:22.115154Z",
     "start_time": "2025-04-24T12:59:22.110262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# PDF 문서를 기반으로 검색 도구 생성\n",
    "retriever_tool = create_retriever_tool(\n",
    "    pdf_retriever,\n",
    "    \"pdf_retriever\",\n",
    "    \"Search and return information about SPRI AI Brief PDF file. It contains useful information on recent AI trends. The document is published on Dec 2023.\",\n",
    "    document_prompt=PromptTemplate.from_template(\n",
    "        \"<document><context>{page_content}</context><metadata><source>{source}</source><page>{page}</page></metadata></document>\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# 생성된 검색 도구를 도구 리스트에 추가하여 에이전트에서 사용 가능하도록 설정\n",
    "tools = [retriever_tool]"
   ],
   "id": "1479769e88c2744b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Agent 상태",
   "id": "f8c36a9f6ecba4f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T12:59:34.189164Z",
     "start_time": "2025-04-24T12:59:34.098943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Annotated, Sequence, TypedDict\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# 에이전트 상태를 정의하는 타입 딕셔너리, 메시지 시퀀스를 관리하고 추가 동작 정의\n",
    "class AgentState(TypedDict):\n",
    "    # add_messages reducer 함수를 사용하여 메시지 시퀀스를 관리\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ],
   "id": "9752d3bb39128d0d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 노드와 엣지",
   "id": "37ac8a50c085a525"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:00:49.239335Z",
     "start_time": "2025-04-24T13:00:46.663335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Literal\n",
    "from langchain import hub\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langchain_teddynote.models import get_model_name, LLMs\n",
    "\n",
    "# 최신 모델이름 가져오기\n",
    "MODEL_NAME = get_model_name(LLMs.GPT4)\n",
    "\n",
    "\n",
    "# 데이터 모델 정의\n",
    "class grade(BaseModel):\n",
    "    \"\"\"A binary score for relevance checks\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Response 'yes' if the document is relevant to the question or 'no' if it is not.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def grade_documents(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    # LLM 모델 초기화\n",
    "    model = ChatOpenAI(temperature=0, model=MODEL_NAME, streaming=True)\n",
    "\n",
    "    # 구조화된 출력을 위한 LLM 설정\n",
    "    llm_with_tool = model.with_structured_output(grade)\n",
    "\n",
    "    # 프롬프트 템플릿 정의\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
    "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    # llm + tool 바인딩 체인 생성\n",
    "    chain = prompt | llm_with_tool\n",
    "\n",
    "    # 현재 상태에서 메시지 추출\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # 가장 마지막 메시지 추출\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    # 원래 질문 추출\n",
    "    question = messages[0].content\n",
    "\n",
    "    # 검색된 문서 추출\n",
    "    retrieved_docs = last_message.content\n",
    "\n",
    "    # 관련성 평가 실행\n",
    "    scored_result = chain.invoke({\"question\": question, \"context\": retrieved_docs})\n",
    "\n",
    "    # 관련성 여부 추출\n",
    "    score = scored_result.binary_score\n",
    "\n",
    "    # 관련성 여부에 따른 결정\n",
    "    if score == \"yes\":\n",
    "        print(\"==== [DECISION: DOCS RELEVANT] ====\")\n",
    "        return \"generate\"\n",
    "\n",
    "    else:\n",
    "        print(\"==== [DECISION: DOCS NOT RELEVANT] ====\")\n",
    "        print(score)\n",
    "        return \"rewrite\"\n",
    "\n",
    "\n",
    "def agent(state):\n",
    "    # 현재 상태에서 메시지 추출\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # LLM 모델 초기화\n",
    "    model = ChatOpenAI(temperature=0, streaming=True, model=MODEL_NAME)\n",
    "\n",
    "    # retriever tool 바인딩\n",
    "    model = model.bind_tools(tools)\n",
    "\n",
    "    # 에이전트 응답 생성\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    # 기존 리스트에 추가되므로 리스트 형태로 반환\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def rewrite(state):\n",
    "    print(\"==== [QUERY REWRITE] ====\")\n",
    "    # 현재 상태에서 메시지 추출\n",
    "    messages = state[\"messages\"]\n",
    "    # 원래 질문 추출\n",
    "    question = messages[0].content\n",
    "\n",
    "    # 질문 개선을 위한 프롬프트 구성\n",
    "    msg = [\n",
    "        HumanMessage(\n",
    "            content=f\"\"\" \\n\n",
    "    Look at the input and try to reason about the underlying semantic intent / meaning. \\n\n",
    "    Here is the initial question:\n",
    "    \\n ------- \\n\n",
    "    {question}\n",
    "    \\n ------- \\n\n",
    "    Formulate an improved question: \"\"\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # LLM 모델로 질문 개선\n",
    "    model = ChatOpenAI(temperature=0, model=MODEL_NAME, streaming=True)\n",
    "    # Query-Transform 체인 실행\n",
    "    response = model.invoke(msg)\n",
    "\n",
    "    # 재작성된 질문 반환\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    # 현재 상태에서 메시지 추출\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # 원래 질문 추출\n",
    "    question = messages[0].content\n",
    "\n",
    "    # 가장 마지막 메시지 추출\n",
    "    docs = messages[-1].content\n",
    "\n",
    "    # RAG 프롬프트 템플릿 가져오기\n",
    "    prompt = hub.pull(\"teddynote/rag-prompt\")\n",
    "\n",
    "    # LLM 모델 초기화\n",
    "    llm = ChatOpenAI(model_name=MODEL_NAME, temperature=0, streaming=True)\n",
    "\n",
    "    # RAG 체인 구성\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    # 답변 생성 실행\n",
    "    response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "    return {\"messages\": [response]}"
   ],
   "id": "75fb072402f5f6f6",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 그래프",
   "id": "5ba2e15366a3673b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:01:00.233091Z",
     "start_time": "2025-04-24T13:01:00.204727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LangGraph 라이브러리의 그래프 및 도구 노드 컴포넌트 임포트\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# AgentState 기반 상태 그래프 워크플로우 초기화\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# 워크플로우 내 순환 노드 정의 및 추가\n",
    "workflow.add_node(\"agent\", agent)  # 에이전트 노드\n",
    "retrieve = ToolNode([retriever_tool])\n",
    "workflow.add_node(\"retrieve\", retrieve)  # 검색 노드\n",
    "workflow.add_node(\"rewrite\", rewrite)  # 질문 재작성 노드\n",
    "workflow.add_node(\"generate\", generate)  # 관련 문서 확인 후 응답 생성 노드\n",
    "\n",
    "# 시작점에서 에이전트 노드로 연결\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# 검색 여부 결정을 위한 조건부 엣지 추가\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    # 에이전트 결정 평가\n",
    "    tools_condition,\n",
    "    {\n",
    "        # 조건 출력을 그래프 노드에 매핑\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# 액션 노드 실행 후 처리될 엣지 정의\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    # 문서 품질 평가\n",
    "    grade_documents,\n",
    ")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "workflow.add_edge(\"rewrite\", \"agent\")\n",
    "\n",
    "# 워크플로우 그래프 컴파일\n",
    "graph = workflow.compile()"
   ],
   "id": "7e7f709fb4725cb0",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:01:16.092462Z",
     "start_time": "2025-04-24T13:01:07.865332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_teddynote.messages import stream_graph\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# config 설정(재귀 최대 횟수, thread_id)\n",
    "config = RunnableConfig(recursion_limit=10, configurable={\"thread_id\": \"1\"})\n",
    "\n",
    "# 사용자의 에이전트 메모리 유형에 대한 질문을 포함하는 입력 데이터 구조 정의\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"삼성전자가 개발한 생성형 AI 의 이름은?\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 그래프 실행\n",
    "stream_graph(graph, inputs, config, [\"agent\", \"rewrite\", \"generate\"])"
   ],
   "id": "72cf37cc30c4727d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36magent\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==== [DECISION: DOCS RELEVANT] ====\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mgenerate\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "삼성전자가 개발한 생성형 AI의 이름은 '삼성 가우스'입니다.\n",
      "\n",
      "**Source**\n",
      "- data/SPRI_AI_Brief_2023년12월호_F.pdf (page 12)"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:01:26.285089Z",
     "start_time": "2025-04-24T13:01:24.432425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 문서 검색이 불가능한 질문 예시\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"대한민국의 수도는?\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 그래프 실행\n",
    "stream_graph(graph, inputs, config, [\"agent\", \"rewrite\", \"generate\"])"
   ],
   "id": "f0346d650f69fc6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36magent\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "대한민국의 수도는 서울입니다."
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:01:56.190513Z",
     "start_time": "2025-04-24T13:01:32.961857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.errors import GraphRecursionError\n",
    "\n",
    "# 문서 검색이 불가능한 질문 예시\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"테디노트의 LangChain 튜토리얼 주소는?\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    # 그래프 실행\n",
    "    stream_graph(graph, inputs, config, [\"agent\", \"rewrite\", \"generate\"])\n",
    "except GraphRecursionError as recursion_error:\n",
    "    print(f\"GraphRecursionError: {recursion_error}\")"
   ],
   "id": "2dd3fa7a4f9ee44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36magent\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==== [DECISION: DOCS NOT RELEVANT] ====\n",
      "no\n",
      "==== [QUERY REWRITE] ====\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mrewrite\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "테디노트에서 제공하는 LangChain 튜토리얼의 링크를 알려줄 수 있나요?\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36magent\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==== [DECISION: DOCS NOT RELEVANT] ====\n",
      "no\n",
      "==== [QUERY REWRITE] ====\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mrewrite\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "테디노트에서 제공하는 LangChain 튜토리얼의 링크를 알려주세요.\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36magent\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==== [DECISION: DOCS NOT RELEVANT] ====\n",
      "no\n",
      "==== [QUERY REWRITE] ====\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36mrewrite\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "테디노트에서 제공하는 LangChain 튜토리얼의 링크를 알려줄 수 있나요?\n",
      "==================================================\n",
      "🔄 Node: \u001B[1;36magent\u001B[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "GraphRecursionError: Recursion limit of 10 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
