{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-24T12:58:52.347765Z",
     "start_time": "2025-04-24T12:58:52.329575Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API í‚¤ ì •ë³´ ë¡œë“œ\n",
    "load_dotenv()\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "logging.langsmith(\"CH17-LangGraph-Structures\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "CH17-LangGraph-Structures\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ê¸°ë³¸ PDF ê¸°ë°˜ Retrieval Chain ìƒì„±\n",
   "id": "8fdd84a08bca434c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T12:59:13.611861Z",
     "start_time": "2025-04-24T12:59:00.340696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from rag.pdf import PDFRetrievalChain\n",
    "\n",
    "# PDF ë¬¸ì„œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "pdf = PDFRetrievalChain([\"data/SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf\"]).create_chain()\n",
    "\n",
    "# retrieverì™€ chainì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "pdf_retriever = pdf.retriever\n",
    "pdf_chain = pdf.chain"
   ],
   "id": "cec2c5c5d5347666",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T12:59:22.115154Z",
     "start_time": "2025-04-24T12:59:22.110262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# PDF ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰ ë„êµ¬ ìƒì„±\n",
    "retriever_tool = create_retriever_tool(\n",
    "    pdf_retriever,\n",
    "    \"pdf_retriever\",\n",
    "    \"Search and return information about SPRI AI Brief PDF file. It contains useful information on recent AI trends. The document is published on Dec 2023.\",\n",
    "    document_prompt=PromptTemplate.from_template(\n",
    "        \"<document><context>{page_content}</context><metadata><source>{source}</source><page>{page}</page></metadata></document>\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# ìƒì„±ëœ ê²€ìƒ‰ ë„êµ¬ë¥¼ ë„êµ¬ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•˜ì—¬ ì—ì´ì „íŠ¸ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •\n",
    "tools = [retriever_tool]"
   ],
   "id": "1479769e88c2744b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Agent ìƒíƒœ",
   "id": "f8c36a9f6ecba4f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T12:59:34.189164Z",
     "start_time": "2025-04-24T12:59:34.098943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Annotated, Sequence, TypedDict\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ìƒíƒœë¥¼ ì •ì˜í•˜ëŠ” íƒ€ì… ë”•ì…”ë„ˆë¦¬, ë©”ì‹œì§€ ì‹œí€€ìŠ¤ë¥¼ ê´€ë¦¬í•˜ê³  ì¶”ê°€ ë™ì‘ ì •ì˜\n",
    "class AgentState(TypedDict):\n",
    "    # add_messages reducer í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”ì‹œì§€ ì‹œí€€ìŠ¤ë¥¼ ê´€ë¦¬\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ],
   "id": "9752d3bb39128d0d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ë…¸ë“œì™€ ì—£ì§€",
   "id": "37ac8a50c085a525"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:00:49.239335Z",
     "start_time": "2025-04-24T13:00:46.663335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Literal\n",
    "from langchain import hub\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langchain_teddynote.models import get_model_name, LLMs\n",
    "\n",
    "# ìµœì‹  ëª¨ë¸ì´ë¦„ ê°€ì ¸ì˜¤ê¸°\n",
    "MODEL_NAME = get_model_name(LLMs.GPT4)\n",
    "\n",
    "\n",
    "# ë°ì´í„° ëª¨ë¸ ì •ì˜\n",
    "class grade(BaseModel):\n",
    "    \"\"\"A binary score for relevance checks\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Response 'yes' if the document is relevant to the question or 'no' if it is not.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def grade_documents(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    # LLM ëª¨ë¸ ì´ˆê¸°í™”\n",
    "    model = ChatOpenAI(temperature=0, model=MODEL_NAME, streaming=True)\n",
    "\n",
    "    # êµ¬ì¡°í™”ëœ ì¶œë ¥ì„ ìœ„í•œ LLM ì„¤ì •\n",
    "    llm_with_tool = model.with_structured_output(grade)\n",
    "\n",
    "    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
    "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    # llm + tool ë°”ì¸ë”© ì²´ì¸ ìƒì„±\n",
    "    chain = prompt | llm_with_tool\n",
    "\n",
    "    # í˜„ì¬ ìƒíƒœì—ì„œ ë©”ì‹œì§€ ì¶”ì¶œ\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # ê°€ì¥ ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì¶”ì¶œ\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    # ì›ë˜ ì§ˆë¬¸ ì¶”ì¶œ\n",
    "    question = messages[0].content\n",
    "\n",
    "    # ê²€ìƒ‰ëœ ë¬¸ì„œ ì¶”ì¶œ\n",
    "    retrieved_docs = last_message.content\n",
    "\n",
    "    # ê´€ë ¨ì„± í‰ê°€ ì‹¤í–‰\n",
    "    scored_result = chain.invoke({\"question\": question, \"context\": retrieved_docs})\n",
    "\n",
    "    # ê´€ë ¨ì„± ì—¬ë¶€ ì¶”ì¶œ\n",
    "    score = scored_result.binary_score\n",
    "\n",
    "    # ê´€ë ¨ì„± ì—¬ë¶€ì— ë”°ë¥¸ ê²°ì •\n",
    "    if score == \"yes\":\n",
    "        print(\"==== [DECISION: DOCS RELEVANT] ====\")\n",
    "        return \"generate\"\n",
    "\n",
    "    else:\n",
    "        print(\"==== [DECISION: DOCS NOT RELEVANT] ====\")\n",
    "        print(score)\n",
    "        return \"rewrite\"\n",
    "\n",
    "\n",
    "def agent(state):\n",
    "    # í˜„ì¬ ìƒíƒœì—ì„œ ë©”ì‹œì§€ ì¶”ì¶œ\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # LLM ëª¨ë¸ ì´ˆê¸°í™”\n",
    "    model = ChatOpenAI(temperature=0, streaming=True, model=MODEL_NAME)\n",
    "\n",
    "    # retriever tool ë°”ì¸ë”©\n",
    "    model = model.bind_tools(tools)\n",
    "\n",
    "    # ì—ì´ì „íŠ¸ ì‘ë‹µ ìƒì„±\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    # ê¸°ì¡´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ë˜ë¯€ë¡œ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë°˜í™˜\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def rewrite(state):\n",
    "    print(\"==== [QUERY REWRITE] ====\")\n",
    "    # í˜„ì¬ ìƒíƒœì—ì„œ ë©”ì‹œì§€ ì¶”ì¶œ\n",
    "    messages = state[\"messages\"]\n",
    "    # ì›ë˜ ì§ˆë¬¸ ì¶”ì¶œ\n",
    "    question = messages[0].content\n",
    "\n",
    "    # ì§ˆë¬¸ ê°œì„ ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "    msg = [\n",
    "        HumanMessage(\n",
    "            content=f\"\"\" \\n\n",
    "    Look at the input and try to reason about the underlying semantic intent / meaning. \\n\n",
    "    Here is the initial question:\n",
    "    \\n ------- \\n\n",
    "    {question}\n",
    "    \\n ------- \\n\n",
    "    Formulate an improved question: \"\"\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # LLM ëª¨ë¸ë¡œ ì§ˆë¬¸ ê°œì„ \n",
    "    model = ChatOpenAI(temperature=0, model=MODEL_NAME, streaming=True)\n",
    "    # Query-Transform ì²´ì¸ ì‹¤í–‰\n",
    "    response = model.invoke(msg)\n",
    "\n",
    "    # ì¬ì‘ì„±ëœ ì§ˆë¬¸ ë°˜í™˜\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    # í˜„ì¬ ìƒíƒœì—ì„œ ë©”ì‹œì§€ ì¶”ì¶œ\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # ì›ë˜ ì§ˆë¬¸ ì¶”ì¶œ\n",
    "    question = messages[0].content\n",
    "\n",
    "    # ê°€ì¥ ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì¶”ì¶œ\n",
    "    docs = messages[-1].content\n",
    "\n",
    "    # RAG í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê°€ì ¸ì˜¤ê¸°\n",
    "    prompt = hub.pull(\"teddynote/rag-prompt\")\n",
    "\n",
    "    # LLM ëª¨ë¸ ì´ˆê¸°í™”\n",
    "    llm = ChatOpenAI(model_name=MODEL_NAME, temperature=0, streaming=True)\n",
    "\n",
    "    # RAG ì²´ì¸ êµ¬ì„±\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    # ë‹µë³€ ìƒì„± ì‹¤í–‰\n",
    "    response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "    return {\"messages\": [response]}"
   ],
   "id": "75fb072402f5f6f6",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ê·¸ë˜í”„",
   "id": "5ba2e15366a3673b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:01:00.233091Z",
     "start_time": "2025-04-24T13:01:00.204727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LangGraph ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ê·¸ë˜í”„ ë° ë„êµ¬ ë…¸ë“œ ì»´í¬ë„ŒíŠ¸ ì„í¬íŠ¸\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# AgentState ê¸°ë°˜ ìƒíƒœ ê·¸ë˜í”„ ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™”\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# ì›Œí¬í”Œë¡œìš° ë‚´ ìˆœí™˜ ë…¸ë“œ ì •ì˜ ë° ì¶”ê°€\n",
    "workflow.add_node(\"agent\", agent)  # ì—ì´ì „íŠ¸ ë…¸ë“œ\n",
    "retrieve = ToolNode([retriever_tool])\n",
    "workflow.add_node(\"retrieve\", retrieve)  # ê²€ìƒ‰ ë…¸ë“œ\n",
    "workflow.add_node(\"rewrite\", rewrite)  # ì§ˆë¬¸ ì¬ì‘ì„± ë…¸ë“œ\n",
    "workflow.add_node(\"generate\", generate)  # ê´€ë ¨ ë¬¸ì„œ í™•ì¸ í›„ ì‘ë‹µ ìƒì„± ë…¸ë“œ\n",
    "\n",
    "# ì‹œì‘ì ì—ì„œ ì—ì´ì „íŠ¸ ë…¸ë“œë¡œ ì—°ê²°\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# ê²€ìƒ‰ ì—¬ë¶€ ê²°ì •ì„ ìœ„í•œ ì¡°ê±´ë¶€ ì—£ì§€ ì¶”ê°€\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    # ì—ì´ì „íŠ¸ ê²°ì • í‰ê°€\n",
    "    tools_condition,\n",
    "    {\n",
    "        # ì¡°ê±´ ì¶œë ¥ì„ ê·¸ë˜í”„ ë…¸ë“œì— ë§¤í•‘\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# ì•¡ì…˜ ë…¸ë“œ ì‹¤í–‰ í›„ ì²˜ë¦¬ë  ì—£ì§€ ì •ì˜\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    # ë¬¸ì„œ í’ˆì§ˆ í‰ê°€\n",
    "    grade_documents,\n",
    ")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "workflow.add_edge(\"rewrite\", \"agent\")\n",
    "\n",
    "# ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "graph = workflow.compile()"
   ],
   "id": "7e7f709fb4725cb0",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:01:16.092462Z",
     "start_time": "2025-04-24T13:01:07.865332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_teddynote.messages import stream_graph\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# config ì„¤ì •(ì¬ê·€ ìµœëŒ€ íšŸìˆ˜, thread_id)\n",
    "config = RunnableConfig(recursion_limit=10, configurable={\"thread_id\": \"1\"})\n",
    "\n",
    "# ì‚¬ìš©ìì˜ ì—ì´ì „íŠ¸ ë©”ëª¨ë¦¬ ìœ í˜•ì— ëŒ€í•œ ì§ˆë¬¸ì„ í¬í•¨í•˜ëŠ” ì…ë ¥ ë°ì´í„° êµ¬ì¡° ì •ì˜\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"ì‚¼ì„±ì „ìê°€ ê°œë°œí•œ ìƒì„±í˜• AI ì˜ ì´ë¦„ì€?\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ê·¸ë˜í”„ ì‹¤í–‰\n",
    "stream_graph(graph, inputs, config, [\"agent\", \"rewrite\", \"generate\"])"
   ],
   "id": "72cf37cc30c4727d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001B[1;36magent\u001B[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==== [DECISION: DOCS RELEVANT] ====\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001B[1;36mgenerate\u001B[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "ì‚¼ì„±ì „ìê°€ ê°œë°œí•œ ìƒì„±í˜• AIì˜ ì´ë¦„ì€ 'ì‚¼ì„± ê°€ìš°ìŠ¤'ì…ë‹ˆë‹¤.\n",
      "\n",
      "**Source**\n",
      "- data/SPRI_AI_Brief_2023ë…„12ì›”í˜¸_F.pdf (page 12)"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:01:26.285089Z",
     "start_time": "2025-04-24T13:01:24.432425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ë¬¸ì„œ ê²€ìƒ‰ì´ ë¶ˆê°€ëŠ¥í•œ ì§ˆë¬¸ ì˜ˆì‹œ\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ”?\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ê·¸ë˜í”„ ì‹¤í–‰\n",
    "stream_graph(graph, inputs, config, [\"agent\", \"rewrite\", \"generate\"])"
   ],
   "id": "f0346d650f69fc6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001B[1;36magent\u001B[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤."
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T13:01:56.190513Z",
     "start_time": "2025-04-24T13:01:32.961857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.errors import GraphRecursionError\n",
    "\n",
    "# ë¬¸ì„œ ê²€ìƒ‰ì´ ë¶ˆê°€ëŠ¥í•œ ì§ˆë¬¸ ì˜ˆì‹œ\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"í…Œë””ë…¸íŠ¸ì˜ LangChain íŠœí† ë¦¬ì–¼ ì£¼ì†ŒëŠ”?\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    # ê·¸ë˜í”„ ì‹¤í–‰\n",
    "    stream_graph(graph, inputs, config, [\"agent\", \"rewrite\", \"generate\"])\n",
    "except GraphRecursionError as recursion_error:\n",
    "    print(f\"GraphRecursionError: {recursion_error}\")"
   ],
   "id": "2dd3fa7a4f9ee44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001B[1;36magent\u001B[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==== [DECISION: DOCS NOT RELEVANT] ====\n",
      "no\n",
      "==== [QUERY REWRITE] ====\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001B[1;36mrewrite\u001B[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "í…Œë””ë…¸íŠ¸ì—ì„œ ì œê³µí•˜ëŠ” LangChain íŠœí† ë¦¬ì–¼ì˜ ë§í¬ë¥¼ ì•Œë ¤ì¤„ ìˆ˜ ìˆë‚˜ìš”?\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001B[1;36magent\u001B[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==== [DECISION: DOCS NOT RELEVANT] ====\n",
      "no\n",
      "==== [QUERY REWRITE] ====\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001B[1;36mrewrite\u001B[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "í…Œë””ë…¸íŠ¸ì—ì„œ ì œê³µí•˜ëŠ” LangChain íŠœí† ë¦¬ì–¼ì˜ ë§í¬ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001B[1;36magent\u001B[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==== [DECISION: DOCS NOT RELEVANT] ====\n",
      "no\n",
      "==== [QUERY REWRITE] ====\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001B[1;36mrewrite\u001B[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "í…Œë””ë…¸íŠ¸ì—ì„œ ì œê³µí•˜ëŠ” LangChain íŠœí† ë¦¬ì–¼ì˜ ë§í¬ë¥¼ ì•Œë ¤ì¤„ ìˆ˜ ìˆë‚˜ìš”?\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001B[1;36magent\u001B[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "GraphRecursionError: Recursion limit of 10 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
