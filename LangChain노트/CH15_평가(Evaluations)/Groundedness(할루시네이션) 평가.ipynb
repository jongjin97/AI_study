{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-17T05:48:41.293724Z",
     "start_time": "2025-04-17T05:48:41.255946Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH16-Evaluations\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH16-Evaluations\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# RAG 성능 테스트를 위한 함수 정의",
   "id": "edb00f0ee659bf6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T05:48:46.102499Z",
     "start_time": "2025-04-17T05:48:41.328447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from myrag import PDFRAG\n",
    "\n",
    "\n",
    "# 질문에 대한 답변하는 함수를 생성\n",
    "def ask_question_with_llm(llm):\n",
    "    # PDFRAG 객체 생성\n",
    "    rag = PDFRAG(\n",
    "        \"data/SPRI_AI_Brief_2023년12월호_F.pdf\",\n",
    "        llm,\n",
    "    )\n",
    "\n",
    "    # 검색기(retriever) 생성\n",
    "    retriever = rag.create_retriever()\n",
    "\n",
    "    # 체인(chain) 생성\n",
    "    rag_chain = rag.create_chain(retriever)\n",
    "\n",
    "    def _ask_question(inputs: dict):\n",
    "        # 질문에 대한 컨텍스트 검색\n",
    "        context = retriever.invoke(inputs[\"question\"])\n",
    "        # 검색된 문서들을 하나의 문자열로 결합\n",
    "        context = \"\\n\".join([doc.page_content for doc in context])\n",
    "        # 질문, 컨텍스트, 답변을 포함한 딕셔너리 반환\n",
    "        return {\n",
    "            \"question\": inputs[\"question\"],\n",
    "            \"context\": context,\n",
    "            \"answer\": rag_chain.invoke(inputs[\"question\"]),\n",
    "        }\n",
    "\n",
    "    return _ask_question"
   ],
   "id": "17eb700ab217eb42",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T05:48:53.051514Z",
     "start_time": "2025-04-17T05:48:46.921800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "gpt_chain = ask_question_with_llm(ChatOpenAI(model=\"gpt-4o-mini\", temperature=0))"
   ],
   "id": "1ea19ba310c98217",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# UpstageGroundednessCheck\n",
   "id": "4efff104e81f53f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T05:48:54.392366Z",
     "start_time": "2025-04-17T05:48:53.094450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_upstage import UpstageGroundednessCheck\n",
    "\n",
    "# 업스테이지 Groundness Checker 생성\n",
    "upstage_groundedness_check = UpstageGroundednessCheck()"
   ],
   "id": "c59c4ab79cfc9058",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T05:48:58.678510Z",
     "start_time": "2025-04-17T05:48:58.280130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Groundness Checker 를 실행하여 평가\n",
    "request_input = {\n",
    "    \"context\": \"테디의 성별은 남자이며, 테디노트 유튜브 채널을 운영하고 있습니다.\",\n",
    "    \"answer\": \"테디는 남자다.\",\n",
    "}\n",
    "\n",
    "response = upstage_groundedness_check.invoke(request_input)\n",
    "print(response)"
   ],
   "id": "6428d032770f2da6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grounded\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T05:49:06.112767Z",
     "start_time": "2025-04-17T05:49:05.870552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Groundness Checker 를 실행하여 평가\n",
    "request_input = {\n",
    "    \"context\": \"테디의 성별은 남자이며, 테디노트 유튜브 채널을 운영하고 있습니다.\",\n",
    "    \"answer\": \"테디는 여자다.\",\n",
    "}\n",
    "\n",
    "response = upstage_groundedness_check.invoke(request_input)\n",
    "print(response)"
   ],
   "id": "679d3968e18bf446",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notGrounded\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T05:52:25.201638Z",
     "start_time": "2025-04-17T05:52:25.189411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langsmith.schemas import Run, Example\n",
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "def upstage_groundedness_check_evaluator(run: Run, example: Example) -> dict:\n",
    "    # LLM 생성, 답변, 정답  답변 가져오기\n",
    "    answer = run.outputs.get(\"answer\" ,\"\")\n",
    "    context = run.outputs.get(\"context\", \"\")\n",
    "\n",
    "    # Groundness 체크\n",
    "    groundedness_score = upstage_groundedness_check.invoke(\n",
    "        {\"answer\": answer, \"context\": context}\n",
    "    )\n",
    "    groundedness_score = groundedness_score == \"grounded\"\n",
    "\n",
    "    return {\"key\": \"groundness_score\", \"score\": groundedness_score}"
   ],
   "id": "6a5fd6663fbb6285",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# langchain_teddynote Groundness Checker",
   "id": "69a7931e539025f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T05:53:02.227831Z",
     "start_time": "2025-04-17T05:53:01.485350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langsmith.schemas import Run, Example\n",
    "from langchain_teddynote.evaluator import GroundednessChecker\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# teddynote Groundness Checker 생성\n",
    "groundedness_check = GroundednessChecker(\n",
    "    ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    ").create()\n",
    "\n",
    "\n",
    "def teddynote_groundness_check_evaluator(run: Run, example: Example) -> dict:\n",
    "    # LLM 생성 답변, 정답 답변 가져오기\n",
    "    answer = run.outputs.get(\"answer\", \"\")\n",
    "    context = run.outputs.get(\"context\", \"\")\n",
    "\n",
    "    # Groundness 체크\n",
    "    groundedness_score = groundedness_check.invoke(\n",
    "        {\"answer\": answer, \"context\": context}\n",
    "    )\n",
    "    groundedness_score = groundedness_score.score == \"yes\"\n",
    "\n",
    "    return {\"key\": \"groundness_score\", \"score\": int(groundedness_score)}"
   ],
   "id": "f2267e258b7ec6f6",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T05:53:43.926218Z",
     "start_time": "2025-04-17T05:53:20.886536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "# 데이터셋 이름 설정\n",
    "dataset_name = \"RAG_EVAL_DATASET\"\n",
    "\n",
    "# 실행\n",
    "experiment_results = evaluate(\n",
    "    gpt_chain,\n",
    "    data=dataset_name,\n",
    "    evaluators=[\n",
    "        upstage_groundedness_check_evaluator,\n",
    "        teddynote_groundness_check_evaluator,\n",
    "    ],\n",
    "    experiment_prefix=\"GROUNDEDNESS-EVAL\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"Upstage & teddynote Groundness Checker 를 활용한 Hallucination 평가\",\n",
    "    },\n",
    ")"
   ],
   "id": "d0183e5549e39a14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'GROUNDEDNESS-EVAL-a8c01f81' at:\n",
      "https://smith.langchain.com/o/9b141874-d093-4103-946d-7bc247255f98/datasets/899fb1c5-744d-4f35-a48e-68fe78d807f1/compare?selectedSessions=5ce4ad95-1d30-4a68-9b88-58b0b7d8e70e\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "247fefdb7eaa4d73897e906e825a1783"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Summary Evaluators 를 활용한 데이터셋에 대한 종합 평가\n",
   "id": "5ad0e271c06ce43c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T05:53:50.440658Z",
     "start_time": "2025-04-17T05:53:50.435580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "from langsmith.schemas import Example, Run\n",
    "\n",
    "\n",
    "def upstage_groundness_check_summary_evaluator(\n",
    "    runs: List[Run], examples: List[Example]\n",
    ") -> dict:\n",
    "    def is_grounded(run: Run) -> bool:\n",
    "        context = run.outputs[\"context\"]\n",
    "        answer = run.outputs[\"answer\"]\n",
    "        return (\n",
    "            upstage_groundedness_check.invoke({\"context\": context, \"answer\": answer})\n",
    "            == \"grounded\"\n",
    "        )\n",
    "\n",
    "    groundedness_scores = sum(1 for run in runs if is_grounded(run))\n",
    "    return {\"key\": \"groundness_score\", \"score\": groundedness_scores / len(runs)}\n",
    "\n",
    "\n",
    "def teddynote_groundness_check_summary_evaluator(\n",
    "    runs: List[Run], examples: List[Example]\n",
    ") -> dict:\n",
    "    def is_grounded(run: Run) -> bool:\n",
    "        context = run.outputs[\"context\"]\n",
    "        answer = run.outputs[\"answer\"]\n",
    "        return (\n",
    "            groundedness_check.invoke({\"context\": context, \"answer\": answer}).score\n",
    "            == \"yes\"\n",
    "        )\n",
    "\n",
    "    groundedness_scores = sum(1 for run in runs if is_grounded(run))\n",
    "    return {\"key\": \"groundness_score\", \"score\": groundedness_scores / len(runs)}"
   ],
   "id": "5d476beb4270b05c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T05:55:00.577129Z",
     "start_time": "2025-04-17T05:54:19.713962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "# 평가 실행\n",
    "experiment_result1 = evaluate(\n",
    "    gpt_chain,\n",
    "    data=dataset_name,\n",
    "    summary_evaluators=[\n",
    "        upstage_groundness_check_summary_evaluator,\n",
    "    ],\n",
    "    experiment_prefix=\"GROUNDNESS_UPSTAGE_SUMMARY_EVAL\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"Upstage Groundness Checker 를 활용한 Hallucination 평가\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# 평가 실행\n",
    "experiment_result2 = evaluate(\n",
    "    gpt_chain,\n",
    "    data=dataset_name,\n",
    "    summary_evaluators=[\n",
    "        teddynote_groundness_check_summary_evaluator,\n",
    "    ],\n",
    "    experiment_prefix=\"GROUNDNESS_TEDDYNOTE_SUMMARY_EVAL\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"Teddynote Groundness Checker 를 활용한 Hallucination 평가\",\n",
    "    },\n",
    ")"
   ],
   "id": "aa9b78329827ab40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'GROUNDNESS_UPSTAGE_SUMMARY_EVAL-381af997' at:\n",
      "https://smith.langchain.com/o/9b141874-d093-4103-946d-7bc247255f98/datasets/899fb1c5-744d-4f35-a48e-68fe78d807f1/compare?selectedSessions=cb9c508c-ac7f-49f9-b47b-af9017c94eba\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0243c95b2abe4ffd934b04f89ed6477b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'GROUNDNESS_TEDDYNOTE_SUMMARY_EVAL-0fdd3ae5' at:\n",
      "https://smith.langchain.com/o/9b141874-d093-4103-946d-7bc247255f98/datasets/899fb1c5-744d-4f35-a48e-68fe78d807f1/compare?selectedSessions=1bfcea70-d52e-4db1-8b90-31755ec83e5f\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ecc194decfe548f8ac3bbae872dbe196"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
