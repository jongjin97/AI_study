{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-16T09:12:59.449400Z",
     "start_time": "2025-04-16T09:12:59.428857Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH16-Evaluations\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH16-Evaluations\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# RAG 성능 테스트를 위한 함수 정의",
   "id": "a82351cb555bc055"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T09:13:11.372024Z",
     "start_time": "2025-04-16T09:13:08.448836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from myrag import PDFRAG\n",
    "\n",
    "\n",
    "# 질문에 대한 답변하는 함수를 생성\n",
    "def ask_question_with_llm(llm):\n",
    "    # PDFRAG 객체 생성\n",
    "    rag = PDFRAG(\n",
    "        \"data/SPRI_AI_Brief_2023년12월호_F.pdf\",\n",
    "        llm,\n",
    "    )\n",
    "\n",
    "    # 검색기(retriever) 생성\n",
    "    retriever = rag.create_retriever()\n",
    "\n",
    "    # 체인(chain) 생성\n",
    "    rag_chain = rag.create_chain(retriever)\n",
    "\n",
    "    def _ask_question(inputs: dict):\n",
    "        # 질문에 대한 컨텍스트 검색\n",
    "        context = retriever.invoke(inputs[\"question\"])\n",
    "        # 검색된 문서들을 하나의 문자열로 결합\n",
    "        context = \"\\n\".join([doc.page_content for doc in context])\n",
    "        # 질문, 컨텍스트, 답변을 포함한 딕셔너리 반환\n",
    "        return {\n",
    "            \"question\": inputs[\"question\"],\n",
    "            \"context\": context,\n",
    "            \"answer\": rag_chain.invoke(inputs[\"question\"]),\n",
    "        }\n",
    "\n",
    "    return _ask_question"
   ],
   "id": "e6ec28da35441ff7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T09:13:39.386046Z",
     "start_time": "2025-04-16T09:13:31.221476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "gpt_chain = ask_question_with_llm(ChatOpenAI(model=\"gpt-4o-mini\", temperature=0))\n",
    "gpt_chain2 = ask_question_with_llm(ChatOpenAI(temperature=0))"
   ],
   "id": "1042d3a9bddafe76",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T09:13:51.545575Z",
     "start_time": "2025-04-16T09:13:50.219520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_teddynote.evaluator import OpenAIRelevanceGrader\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "rq_grader = OpenAIRelevanceGrader(\n",
    "    llm=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0), target=\"retrieval-question\"\n",
    ").create()\n",
    "\n",
    "ra_grader = OpenAIRelevanceGrader(\n",
    "    llm=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0), target=\"retrieval-answer\"\n",
    ").create()"
   ],
   "id": "8f70b0976ace38df",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T09:13:58.890992Z",
     "start_time": "2025-04-16T09:13:57.966034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rq_grader.invoke(\n",
    "    {\n",
    "        \"input\": \"삼성전자가 자체 개발한 생성형 AI 의 이름은?\",\n",
    "        \"context\": \"삼성전자 AI 는 빅스비에요\",\n",
    "    }\n",
    ")"
   ],
   "id": "a84a8b2ac0a933e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeRetrievalQuestion(score='no')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T09:14:04.728141Z",
     "start_time": "2025-04-16T09:14:04.053608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ra_grader.invoke(\n",
    "    {\n",
    "        \"input\": \"삼성전자가 자체 개발한 생성형 AI 는 가우스 입니다.\",\n",
    "        \"context\": \"삼성전자 AI 는 빅스비에요\",\n",
    "    }\n",
    ")"
   ],
   "id": "eb00428857dae473",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeRetrievalAnswer(score='no')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 관련성(Relevance) 평가를 종합하는 Summary Evaluator",
   "id": "3897450f918a8b8f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T09:14:26.550192Z",
     "start_time": "2025-04-16T09:14:26.538666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "from langsmith.schemas import Example, Run\n",
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "\n",
    "def relevance_score_summary_evaluator(runs: List[Run], examples: List[Example]) -> dict:\n",
    "    rq_scores = 0  # 질문 관련성 점수\n",
    "    ra_scores = 0  # 답변 관련성 점수\n",
    "\n",
    "    for run, example in zip(runs, examples):\n",
    "        question = example.inputs[\"question\"]\n",
    "        context = run.outputs[\"context\"]\n",
    "        prediction = run.outputs[\"answer\"]\n",
    "\n",
    "        # 질문 관련성 평가\n",
    "        rq_score = rq_grader.invoke(\n",
    "            {\n",
    "                \"input\": question,\n",
    "                \"context\": context,\n",
    "            }\n",
    "        )\n",
    "        # 답변 관련성 평가\n",
    "        ra_score = ra_grader.invoke(\n",
    "            {\n",
    "                \"input\": prediction,\n",
    "                \"context\": context,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # 관련성 점수 누적\n",
    "        if rq_score.score == \"yes\":\n",
    "            rq_scores += 1\n",
    "        if ra_score.score == \"yes\":\n",
    "            ra_scores += 1\n",
    "\n",
    "    # 최종 관련성 점수 계산 (질문 관련성과 답변 관련성의 평균)\n",
    "    final_score = ((rq_scores / len(runs)) + (ra_scores / len(runs))) / 2\n",
    "\n",
    "    return {\"key\": \"relevance_score\", \"score\": final_score}"
   ],
   "id": "46f36528500ecac8",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T09:15:49.089039Z",
     "start_time": "2025-04-16T09:14:55.085326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 평가 실행\n",
    "dataset_name = \"RAG_EVAL_DATASET\"\n",
    "\n",
    "experiment_result1 = evaluate(\n",
    "    gpt_chain,\n",
    "    data=dataset_name,\n",
    "    summary_evaluators=[relevance_score_summary_evaluator],\n",
    "    experiment_prefix=\"SUMMARY_EVAL\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"GPT-4o-mini 사용: summary_evaluator 를 활용한 relevance 평가\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# 평가 실행\n",
    "experiment_result2 = evaluate(\n",
    "    gpt_chain2,\n",
    "    data=dataset_name,\n",
    "    summary_evaluators=[relevance_score_summary_evaluator],\n",
    "    experiment_prefix=\"SUMMARY_EVAL\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"GPT-4o 사용: summary_evaluator 를 활용한 relevance 평가\",\n",
    "    },\n",
    ")"
   ],
   "id": "f74f5e361b52e0c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'SUMMARY_EVAL-0b24e4c2' at:\n",
      "https://smith.langchain.com/o/9b141874-d093-4103-946d-7bc247255f98/datasets/899fb1c5-744d-4f35-a48e-68fe78d807f1/compare?selectedSessions=5a7d5350-5448-4755-bbcb-51485126291b\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a099a0cf8244aee8eec841aa9238df5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'SUMMARY_EVAL-8016af08' at:\n",
      "https://smith.langchain.com/o/9b141874-d093-4103-946d-7bc247255f98/datasets/899fb1c5-744d-4f35-a48e-68fe78d807f1/compare?selectedSessions=bd28fb31-f234-4b28-9c66-27ee21dbb235\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "52a4d5e688dc4024a398d52e943150b9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
