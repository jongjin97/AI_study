{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-14T06:43:00.527619Z",
     "start_time": "2025-04-14T06:43:00.506205Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T06:43:03.181815Z",
     "start_time": "2025-04-14T06:43:03.174590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"LCEL-Advanced\")"
   ],
   "id": "b92aa38ac3c316f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "LCEL-Advanced\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T06:45:40.824928Z",
     "start_time": "2025-04-14T06:45:35.194995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    # 텍스트 데이터로부터 FAISS 벡터 저장소를 생성\n",
    "    [\"Jongjin is an AI engineer who loves programming!\"],\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "\n",
    "# 벡터 저장소를 기반으로 retriever를 생성\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# chain을 생성\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ],
   "id": "7c5495f0cbf47f7a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 그래프 구성 확인\n",
   "id": "24e59ab674e02378"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T06:45:53.392252Z",
     "start_time": "2025-04-14T06:45:53.289328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 체인의 그래프에서 노드를 가져옵니다.\n",
    "chain.get_graph().nodes"
   ],
   "id": "2e5751e0c001a93a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'85e8455874d54a218ed2fac237b7adaf': Node(id='85e8455874d54a218ed2fac237b7adaf', name='Parallel<context,question>Input', data=<class 'langchain_core.runnables.base.RunnableParallel<context,question>Input'>, metadata=None),\n",
       " 'fe9144cf551f4ba88be7ad29aab13960': Node(id='fe9144cf551f4ba88be7ad29aab13960', name='Parallel<context,question>Output', data=<class 'langchain_core.utils.pydantic.RunnableParallel<context,question>Output'>, metadata=None),\n",
       " '3d3fb04b4283424ca2438d39a3b97e5c': Node(id='3d3fb04b4283424ca2438d39a3b97e5c', name='VectorStoreRetriever', data=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000208FA8D8D50>, search_kwargs={}), metadata=None),\n",
       " 'bd0c8a426ec046e6864bf0b51c874308': Node(id='bd0c8a426ec046e6864bf0b51c874308', name='Passthrough', data=RunnablePassthrough(), metadata=None),\n",
       " '6095314b5b0f48399b546057b19d7c01': Node(id='6095314b5b0f48399b546057b19d7c01', name='ChatPromptTemplate', data=ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based only on the following context:\\n{context}\\n\\nQuestion: {question}\\n'), additional_kwargs={})]), metadata=None),\n",
       " '8bdd92784c3441e9bd812ec039cfa01d': Node(id='8bdd92784c3441e9bd812ec039cfa01d', name='ChatOpenAI', data=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000208FAAD6ED0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000208FC29CFD0>, root_client=<openai.OpenAI object at 0x00000208FAB40A10>, root_async_client=<openai.AsyncOpenAI object at 0x00000208FBD40A90>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), metadata=None),\n",
       " '67727a94a81549809171311e01491192': Node(id='67727a94a81549809171311e01491192', name='StrOutputParser', data=StrOutputParser(), metadata=None),\n",
       " '6e840df68dc546f29fea38704b69680c': Node(id='6e840df68dc546f29fea38704b69680c', name='StrOutputParserOutput', data=<class 'langchain_core.output_parsers.string.StrOutputParserOutput'>, metadata=None)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T06:46:02.892305Z",
     "start_time": "2025-04-14T06:46:02.885473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 체인의 그래프에서 엣지를 가져옵니다.\n",
    "chain.get_graph().edges"
   ],
   "id": "d0b93b1c0e52e4aa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Edge(source='262c9305ca9d46c3b176580ba2f82adc', target='40c679d88f3542c5a625ec757da61949', data=None, conditional=False),\n",
       " Edge(source='40c679d88f3542c5a625ec757da61949', target='4adf658cbce04fd09d9a946a71bb288a', data=None, conditional=False),\n",
       " Edge(source='262c9305ca9d46c3b176580ba2f82adc', target='e1681480e64648119656f50564708e72', data=None, conditional=False),\n",
       " Edge(source='e1681480e64648119656f50564708e72', target='4adf658cbce04fd09d9a946a71bb288a', data=None, conditional=False),\n",
       " Edge(source='4adf658cbce04fd09d9a946a71bb288a', target='4d2e228b6ae240539f05a2405e888ff2', data=None, conditional=False),\n",
       " Edge(source='4d2e228b6ae240539f05a2405e888ff2', target='069f3d9f90a540d5b4496f0d0ebbff02', data=None, conditional=False),\n",
       " Edge(source='772c431e8de74b2884d5fbbb846c40b4', target='908273ea4adb46459546756e497f3367', data=None, conditional=False),\n",
       " Edge(source='069f3d9f90a540d5b4496f0d0ebbff02', target='772c431e8de74b2884d5fbbb846c40b4', data=None, conditional=False)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 그래프 출력",
   "id": "2ced49f82ee3cc7e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T06:46:16.946394Z",
     "start_time": "2025-04-14T06:46:16.922700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 체인의 그래프를 ASCII 형식으로 출력합니다.\n",
    "chain.get_graph().print_ascii()"
   ],
   "id": "e5e75ee68ee579ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           +---------------------------------+         \r\n",
      "           | Parallel<context,question>Input |         \r\n",
      "           +---------------------------------+         \r\n",
      "                    **               **                \r\n",
      "                 ***                   ***             \r\n",
      "               **                         **           \r\n",
      "+----------------------+              +-------------+  \r\n",
      "| VectorStoreRetriever |              | Passthrough |  \r\n",
      "+----------------------+              +-------------+  \r\n",
      "                    **               **                \r\n",
      "                      ***         ***                  \r\n",
      "                         **     **                     \r\n",
      "           +----------------------------------+        \r\n",
      "           | Parallel<context,question>Output |        \r\n",
      "           +----------------------------------+        \r\n",
      "                             *                         \r\n",
      "                             *                         \r\n",
      "                             *                         \r\n",
      "                  +--------------------+               \r\n",
      "                  | ChatPromptTemplate |               \r\n",
      "                  +--------------------+               \r\n",
      "                             *                         \r\n",
      "                             *                         \r\n",
      "                             *                         \r\n",
      "                      +------------+                   \r\n",
      "                      | ChatOpenAI |                   \r\n",
      "                      +------------+                   \r\n",
      "                             *                         \r\n",
      "                             *                         \r\n",
      "                             *                         \r\n",
      "                   +-----------------+                 \r\n",
      "                   | StrOutputParser |                 \r\n",
      "                   +-----------------+                 \r\n",
      "                             *                         \r\n",
      "                             *                         \r\n",
      "                             *                         \r\n",
      "                +-----------------------+              \r\n",
      "                | StrOutputParserOutput |              \r\n",
      "                +-----------------------+              \n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 프롬프트 가져오기",
   "id": "974ebcadff8dbfb8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T06:46:43.651009Z",
     "start_time": "2025-04-14T06:46:43.643276Z"
    }
   },
   "cell_type": "code",
   "source": "chain.get_prompts()  # 체인에서 사용되는 프롬프트를 가져옵니다.",
   "id": "f9f599b3eae351fb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based only on the following context:\\n{context}\\n\\nQuestion: {question}\\n'), additional_kwargs={})])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
