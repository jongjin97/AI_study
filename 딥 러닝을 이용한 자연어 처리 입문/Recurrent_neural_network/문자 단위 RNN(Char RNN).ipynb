{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPRLPd5d8hkxXZzCjnLcJi+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 문자 단위 RNN 언어 모델(Char RNNLM)"],"metadata":{"id":"PkOEqMGsJhci"}},{"cell_type":"markdown","source":["## 데이터에 대한 이해와 전처리"],"metadata":{"id":"uZcXLphMJi7J"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"G8ikRHdpJYbc","executionInfo":{"status":"ok","timestamp":1746594631230,"user_tz":-540,"elapsed":6987,"user":{"displayName":"윤종진","userId":"16507458279176135266"}}},"outputs":[],"source":["import numpy as np\n","import urllib.request\n","from tensorflow.keras.utils import to_categorical\n","\n","# 데이터 로드\n","urllib.request.urlretrieve(\"http://www.gutenberg.org/files/11/11-0.txt\", filename=\"11-0.txt\")\n","\n","f = open('11-0.txt', 'rb')\n","sentences = []\n","for sentence in f: # 데이터로부터 한 줄씩 읽는다.\n","    sentence = sentence.strip() # strip()을 통해 \\r, \\n을 제거한다.\n","    sentence = sentence.lower() # 소문자화.\n","    sentence = sentence.decode('ascii', 'ignore') # \\xe2\\x80\\x99 등과 같은 바이트 열 제거\n","    if len(sentence) > 0:\n","        sentences.append(sentence)\n","f.close()"]},{"cell_type":"code","source":["sentences[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q2RS0_P6Jplq","executionInfo":{"status":"ok","timestamp":1746594631270,"user_tz":-540,"elapsed":9,"user":{"displayName":"윤종진","userId":"16507458279176135266"}},"outputId":"31c800c6-e2e2-4e9c-e224-84dee23708cf"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['*** start of the project gutenberg ebook 11 ***',\n"," '[illustration]',\n"," 'alices adventures in wonderland',\n"," 'by lewis carroll',\n"," 'the millennium fulcrum edition 3.0']"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["total_data = ' '.join(sentences)\n","print('문자열의 길이 또는 총 문자의 개수: %d' % len(total_data))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y0fDRKeGJsLW","executionInfo":{"status":"ok","timestamp":1746594631283,"user_tz":-540,"elapsed":5,"user":{"displayName":"윤종진","userId":"16507458279176135266"}},"outputId":"e15ccb5b-724e-4533-93f5-73265ba2fd04"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["문자열의 길이 또는 총 문자의 개수: 140262\n"]}]},{"cell_type":"code","source":["print(total_data[:200])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bwhgSJDNJtdL","executionInfo":{"status":"ok","timestamp":1746594631298,"user_tz":-540,"elapsed":13,"user":{"displayName":"윤종진","userId":"16507458279176135266"}},"outputId":"b65163f6-6862-410a-d01c-bbcacfd7fe82"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["*** start of the project gutenberg ebook 11 *** [illustration] alices adventures in wonderland by lewis carroll the millennium fulcrum edition 3.0 contents chapter i.     down the rabbit-hole chapter \n"]}]},{"cell_type":"code","source":["char_vocab = sorted(list(set(total_data)))\n","vocab_size = len(char_vocab)\n","print ('문자 집합의 크기 : {}'.format(vocab_size))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w5mR2exPJvK6","executionInfo":{"status":"ok","timestamp":1746594631314,"user_tz":-540,"elapsed":14,"user":{"displayName":"윤종진","userId":"16507458279176135266"}},"outputId":"f303e89f-d31d-4d89-dc75-5442e4883472"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["문자 집합의 크기 : 43\n"]}]},{"cell_type":"code","source":["# 문자에 고유한 정수 부여\n","char_to_index = dict((char, index) for index, char in enumerate(char_vocab))\n","print('문자 집합 :',char_to_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5kbmDhi9JzlA","executionInfo":{"status":"ok","timestamp":1746594643646,"user_tz":-540,"elapsed":15,"user":{"displayName":"윤종진","userId":"16507458279176135266"}},"outputId":"012b80ee-5970-4fff-acc3-9341de86aad5"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["문자 집합 : {' ': 0, '!': 1, '(': 2, ')': 3, '*': 4, ',': 5, '-': 6, '.': 7, '0': 8, '1': 9, '3': 10, ':': 11, ';': 12, '?': 13, '[': 14, ']': 15, '_': 16, 'a': 17, 'b': 18, 'c': 19, 'd': 20, 'e': 21, 'f': 22, 'g': 23, 'h': 24, 'i': 25, 'j': 26, 'k': 27, 'l': 28, 'm': 29, 'n': 30, 'o': 31, 'p': 32, 'q': 33, 'r': 34, 's': 35, 't': 36, 'u': 37, 'v': 38, 'w': 39, 'x': 40, 'y': 41, 'z': 42}\n"]}]},{"cell_type":"code","source":["index_to_char = {}\n","for key, value in char_to_index.items():\n","    index_to_char[value] = key"],"metadata":{"id":"nhyr1FFEJ2Yb","executionInfo":{"status":"ok","timestamp":1746594655187,"user_tz":-540,"elapsed":39,"user":{"displayName":"윤종진","userId":"16507458279176135266"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# appl (입력 시퀀스) -> pple (예측해야하는 시퀀스)\n","train_X = 'appl'\n","train_y = 'pple'"],"metadata":{"id":"wYIQs-QoJ3rq","executionInfo":{"status":"ok","timestamp":1746594660600,"user_tz":-540,"elapsed":3,"user":{"displayName":"윤종진","userId":"16507458279176135266"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["seq_length = 60\n","\n","# 문자열의 길이를 seq_length로 나누면 전처리 후 생겨날 샘플 수\n","n_samples = int(np.floor((len(total_data) - 1) / seq_length))\n","print ('샘플의 수 : {}'.format(n_samples))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ci6dypO1J44U","executionInfo":{"status":"ok","timestamp":1746594665012,"user_tz":-540,"elapsed":12,"user":{"displayName":"윤종진","userId":"16507458279176135266"}},"outputId":"3224dcc8-2c74-4f4e-bd4b-d9757a110025"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["샘플의 수 : 2337\n"]}]},{"cell_type":"code","source":["train_X = []\n","train_y = []\n","\n","for i in range(n_samples):\n","    # 0:60 -> 60:120 -> 120:180로 loop를 돌면서 문장 샘플을 1개씩 pick.\n","    X_sample = total_data[i * seq_length: (i + 1) * seq_length]\n","\n","    # 정수 인코딩\n","    X_encoded = [char_to_index[c] for c in X_sample]\n","    train_X.append(X_encoded)\n","\n","    # 오른쪽으로 1칸 쉬프트\n","    y_sample = total_data[i * seq_length + 1: (i + 1) * seq_length + 1]\n","    y_encoded = [char_to_index[c] for c in y_sample]\n","    train_y.append(y_encoded)"],"metadata":{"id":"vTwDyxnbJ6bI","executionInfo":{"status":"ok","timestamp":1746594671770,"user_tz":-540,"elapsed":11,"user":{"displayName":"윤종진","userId":"16507458279176135266"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["print('X 데이터의 첫번째 샘플 :',train_X[0])\n","print('y 데이터의 첫번째 샘플 :',train_y[0])\n","print('-'*50)\n","print('X 데이터의 첫번째 샘플 디코딩 :',[index_to_char[i] for i in train_X[0]])\n","print('y 데이터의 첫번째 샘플 디코딩 :',[index_to_char[i] for i in train_y[0]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P3nTKTYBJ774","executionInfo":{"status":"ok","timestamp":1746594682711,"user_tz":-540,"elapsed":57,"user":{"displayName":"윤종진","userId":"16507458279176135266"}},"outputId":"17ef14aa-80c2-424e-af31-6a6cef8b1584"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["X 데이터의 첫번째 샘플 : [4, 4, 4, 0, 35, 36, 17, 34, 36, 0, 31, 22, 0, 36, 24, 21, 0, 32, 34, 31, 26, 21, 19, 36, 0, 23, 37, 36, 21, 30, 18, 21, 34, 23, 0, 21, 18, 31, 31, 27, 0, 9, 9, 0, 4, 4, 4, 0, 14, 25, 28, 28, 37, 35, 36, 34, 17, 36, 25, 31]\n","y 데이터의 첫번째 샘플 : [4, 4, 0, 35, 36, 17, 34, 36, 0, 31, 22, 0, 36, 24, 21, 0, 32, 34, 31, 26, 21, 19, 36, 0, 23, 37, 36, 21, 30, 18, 21, 34, 23, 0, 21, 18, 31, 31, 27, 0, 9, 9, 0, 4, 4, 4, 0, 14, 25, 28, 28, 37, 35, 36, 34, 17, 36, 25, 31, 30]\n","--------------------------------------------------\n","X 데이터의 첫번째 샘플 디코딩 : ['*', '*', '*', ' ', 's', 't', 'a', 'r', 't', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'p', 'r', 'o', 'j', 'e', 'c', 't', ' ', 'g', 'u', 't', 'e', 'n', 'b', 'e', 'r', 'g', ' ', 'e', 'b', 'o', 'o', 'k', ' ', '1', '1', ' ', '*', '*', '*', ' ', '[', 'i', 'l', 'l', 'u', 's', 't', 'r', 'a', 't', 'i', 'o']\n","y 데이터의 첫번째 샘플 디코딩 : ['*', '*', ' ', 's', 't', 'a', 'r', 't', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'p', 'r', 'o', 'j', 'e', 'c', 't', ' ', 'g', 'u', 't', 'e', 'n', 'b', 'e', 'r', 'g', ' ', 'e', 'b', 'o', 'o', 'k', ' ', '1', '1', ' ', '*', '*', '*', ' ', '[', 'i', 'l', 'l', 'u', 's', 't', 'r', 'a', 't', 'i', 'o', 'n']\n"]}]},{"cell_type":"code","source":["train_X = to_categorical(train_X)\n","train_y = to_categorical(train_y)\n","\n","print('train_X의 크기(shape) : {}'.format(train_X.shape)) # 원-핫 인코딩\n","print('train_y의 크기(shape) : {}'.format(train_y.shape)) # 원-핫 인코딩"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iQhkr3CVJ-40","executionInfo":{"status":"ok","timestamp":1746594689821,"user_tz":-540,"elapsed":124,"user":{"displayName":"윤종진","userId":"16507458279176135266"}},"outputId":"5de0c7bd-43f0-4f88-a604-c2cdbb78be71"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["train_X의 크기(shape) : (2337, 60, 43)\n","train_y의 크기(shape) : (2337, 60, 43)\n"]}]},{"cell_type":"markdown","source":["## 모델 설계하기"],"metadata":{"id":"rcr6JqFzKA_7"}},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LSTM, TimeDistributed\n","\n","hidden_units = 256\n","\n","model = Sequential()\n","model.add(LSTM(hidden_units, input_shape=(None, train_X.shape[2]), return_sequences=True))\n","model.add(LSTM(hidden_units, return_sequences=True))\n","model.add(TimeDistributed(Dense(vocab_size, activation='softmax')))\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.fit(train_X, train_y, epochs=80, verbose=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y2DpWQZFKBU0","executionInfo":{"status":"ok","timestamp":1746594825716,"user_tz":-540,"elapsed":122266,"user":{"displayName":"윤종진","userId":"16507458279176135266"}},"outputId":"1e72081e-74d6-485a-e0e7-469862fcf762"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/80\n","74/74 - 10s - 131ms/step - accuracy: 0.1881 - loss: 3.0248\n","Epoch 2/80\n","74/74 - 2s - 25ms/step - accuracy: 0.2636 - loss: 2.6700\n","Epoch 3/80\n","74/74 - 1s - 16ms/step - accuracy: 0.3418 - loss: 2.3294\n","Epoch 4/80\n","74/74 - 2s - 21ms/step - accuracy: 0.3741 - loss: 2.1901\n","Epoch 5/80\n","74/74 - 2s - 30ms/step - accuracy: 0.4012 - loss: 2.0904\n","Epoch 6/80\n","74/74 - 1s - 16ms/step - accuracy: 0.4250 - loss: 1.9940\n","Epoch 7/80\n","74/74 - 1s - 16ms/step - accuracy: 0.4420 - loss: 1.9251\n","Epoch 8/80\n","74/74 - 1s - 16ms/step - accuracy: 0.4606 - loss: 1.8569\n","Epoch 9/80\n","74/74 - 2s - 21ms/step - accuracy: 0.4770 - loss: 1.7961\n","Epoch 10/80\n","74/74 - 1s - 16ms/step - accuracy: 0.4900 - loss: 1.7442\n","Epoch 11/80\n","74/74 - 1s - 17ms/step - accuracy: 0.5032 - loss: 1.6963\n","Epoch 12/80\n","74/74 - 1s - 17ms/step - accuracy: 0.5156 - loss: 1.6502\n","Epoch 13/80\n","74/74 - 2s - 21ms/step - accuracy: 0.5264 - loss: 1.6090\n","Epoch 14/80\n","74/74 - 2s - 30ms/step - accuracy: 0.5364 - loss: 1.5690\n","Epoch 15/80\n","74/74 - 1s - 17ms/step - accuracy: 0.5445 - loss: 1.5373\n","Epoch 16/80\n","74/74 - 1s - 17ms/step - accuracy: 0.5533 - loss: 1.5046\n","Epoch 17/80\n","74/74 - 1s - 17ms/step - accuracy: 0.5609 - loss: 1.4768\n","Epoch 18/80\n","74/74 - 1s - 17ms/step - accuracy: 0.5701 - loss: 1.4446\n","Epoch 19/80\n","74/74 - 1s - 17ms/step - accuracy: 0.5785 - loss: 1.4118\n","Epoch 20/80\n","74/74 - 1s - 17ms/step - accuracy: 0.5876 - loss: 1.3852\n","Epoch 21/80\n","74/74 - 1s - 18ms/step - accuracy: 0.5939 - loss: 1.3602\n","Epoch 22/80\n","74/74 - 2s - 33ms/step - accuracy: 0.6014 - loss: 1.3306\n","Epoch 23/80\n","74/74 - 1s - 17ms/step - accuracy: 0.6088 - loss: 1.3038\n","Epoch 24/80\n","74/74 - 1s - 17ms/step - accuracy: 0.6162 - loss: 1.2808\n","Epoch 25/80\n","74/74 - 1s - 16ms/step - accuracy: 0.6246 - loss: 1.2518\n","Epoch 26/80\n","74/74 - 1s - 16ms/step - accuracy: 0.6323 - loss: 1.2240\n","Epoch 27/80\n","74/74 - 1s - 17ms/step - accuracy: 0.6410 - loss: 1.1958\n","Epoch 28/80\n","74/74 - 1s - 17ms/step - accuracy: 0.6484 - loss: 1.1721\n","Epoch 29/80\n","74/74 - 1s - 17ms/step - accuracy: 0.6563 - loss: 1.1454\n","Epoch 30/80\n","74/74 - 2s - 21ms/step - accuracy: 0.6607 - loss: 1.1256\n","Epoch 31/80\n","74/74 - 1s - 19ms/step - accuracy: 0.6761 - loss: 1.0809\n","Epoch 32/80\n","74/74 - 2s - 32ms/step - accuracy: 0.6808 - loss: 1.0611\n","Epoch 33/80\n","74/74 - 1s - 17ms/step - accuracy: 0.6908 - loss: 1.0302\n","Epoch 34/80\n","74/74 - 1s - 17ms/step - accuracy: 0.6888 - loss: 1.0315\n","Epoch 35/80\n","74/74 - 1s - 16ms/step - accuracy: 0.7037 - loss: 0.9837\n","Epoch 36/80\n","74/74 - 1s - 16ms/step - accuracy: 0.7155 - loss: 0.9477\n","Epoch 37/80\n","74/74 - 1s - 16ms/step - accuracy: 0.7260 - loss: 0.9188\n","Epoch 38/80\n","74/74 - 1s - 19ms/step - accuracy: 0.7299 - loss: 0.9002\n","Epoch 39/80\n","74/74 - 2s - 21ms/step - accuracy: 0.7418 - loss: 0.8662\n","Epoch 40/80\n","74/74 - 2s - 29ms/step - accuracy: 0.7514 - loss: 0.8347\n","Epoch 41/80\n","74/74 - 1s - 16ms/step - accuracy: 0.7554 - loss: 0.8196\n","Epoch 42/80\n","74/74 - 1s - 16ms/step - accuracy: 0.7699 - loss: 0.7804\n","Epoch 43/80\n","74/74 - 1s - 16ms/step - accuracy: 0.7769 - loss: 0.7571\n","Epoch 44/80\n","74/74 - 1s - 17ms/step - accuracy: 0.7910 - loss: 0.7156\n","Epoch 45/80\n","74/74 - 1s - 17ms/step - accuracy: 0.7964 - loss: 0.6993\n","Epoch 46/80\n","74/74 - 1s - 17ms/step - accuracy: 0.8074 - loss: 0.6679\n","Epoch 47/80\n","74/74 - 1s - 18ms/step - accuracy: 0.8124 - loss: 0.6486\n","Epoch 48/80\n","74/74 - 2s - 32ms/step - accuracy: 0.8213 - loss: 0.6221\n","Epoch 49/80\n","74/74 - 1s - 16ms/step - accuracy: 0.8261 - loss: 0.6036\n","Epoch 50/80\n","74/74 - 1s - 17ms/step - accuracy: 0.8309 - loss: 0.5881\n","Epoch 51/80\n","74/74 - 1s - 17ms/step - accuracy: 0.8365 - loss: 0.5697\n","Epoch 52/80\n","74/74 - 1s - 16ms/step - accuracy: 0.8481 - loss: 0.5376\n","Epoch 53/80\n","74/74 - 1s - 16ms/step - accuracy: 0.8581 - loss: 0.5094\n","Epoch 54/80\n","74/74 - 1s - 17ms/step - accuracy: 0.8677 - loss: 0.4823\n","Epoch 55/80\n","74/74 - 1s - 16ms/step - accuracy: 0.8808 - loss: 0.4486\n","Epoch 56/80\n","74/74 - 2s - 22ms/step - accuracy: 0.8853 - loss: 0.4334\n","Epoch 57/80\n","74/74 - 2s - 30ms/step - accuracy: 0.8933 - loss: 0.4088\n","Epoch 58/80\n","74/74 - 1s - 17ms/step - accuracy: 0.8958 - loss: 0.3982\n","Epoch 59/80\n","74/74 - 1s - 16ms/step - accuracy: 0.8898 - loss: 0.4072\n","Epoch 60/80\n","74/74 - 2s - 21ms/step - accuracy: 0.9024 - loss: 0.3749\n","Epoch 61/80\n","74/74 - 2s - 30ms/step - accuracy: 0.9079 - loss: 0.3569\n","Epoch 62/80\n","74/74 - 1s - 17ms/step - accuracy: 0.9223 - loss: 0.3192\n","Epoch 63/80\n","74/74 - 1s - 19ms/step - accuracy: 0.9275 - loss: 0.3019\n","Epoch 64/80\n","74/74 - 2s - 21ms/step - accuracy: 0.9323 - loss: 0.2881\n","Epoch 65/80\n","74/74 - 1s - 16ms/step - accuracy: 0.9326 - loss: 0.2829\n","Epoch 66/80\n","74/74 - 1s - 17ms/step - accuracy: 0.9321 - loss: 0.2812\n","Epoch 67/80\n","74/74 - 1s - 16ms/step - accuracy: 0.9297 - loss: 0.2838\n","Epoch 68/80\n","74/74 - 1s - 16ms/step - accuracy: 0.9356 - loss: 0.2661\n","Epoch 69/80\n","74/74 - 1s - 17ms/step - accuracy: 0.9426 - loss: 0.2453\n","Epoch 70/80\n","74/74 - 1s - 16ms/step - accuracy: 0.9441 - loss: 0.2375\n","Epoch 71/80\n","74/74 - 1s - 17ms/step - accuracy: 0.9443 - loss: 0.2340\n","Epoch 72/80\n","74/74 - 1s - 16ms/step - accuracy: 0.9470 - loss: 0.2242\n","Epoch 73/80\n","74/74 - 1s - 20ms/step - accuracy: 0.9464 - loss: 0.2249\n","Epoch 74/80\n","74/74 - 1s - 19ms/step - accuracy: 0.9469 - loss: 0.2215\n","Epoch 75/80\n","74/74 - 1s - 16ms/step - accuracy: 0.9550 - loss: 0.1960\n","Epoch 76/80\n","74/74 - 1s - 16ms/step - accuracy: 0.9533 - loss: 0.1980\n","Epoch 77/80\n","74/74 - 1s - 17ms/step - accuracy: 0.9265 - loss: 0.2644\n","Epoch 78/80\n","74/74 - 1s - 16ms/step - accuracy: 0.9454 - loss: 0.2168\n","Epoch 79/80\n","74/74 - 1s - 16ms/step - accuracy: 0.9467 - loss: 0.2108\n","Epoch 80/80\n","74/74 - 1s - 18ms/step - accuracy: 0.9551 - loss: 0.1850\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7e2ffd23a3d0>"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["def sentence_generation(model, length):\n","    # 문자에 대한 랜덤한 정수 생성\n","    ix = [np.random.randint(vocab_size)]\n","\n","    # 랜덤한 정수로부터 맵핑되는 문자 생성\n","    y_char = [index_to_char[ix[-1]]]\n","    print(ix[-1],'번 문자',y_char[-1],'로 예측을 시작!')\n","\n","    # (1, length, 55) 크기의 X 생성. 즉, LSTM의 입력 시퀀스 생성\n","    X = np.zeros((1, length, vocab_size))\n","\n","    for i in range(length):\n","        # X[0][i][예측한 문자의 인덱스] = 1, 즉, 예측 문자를 다음 입력 시퀀스에 추가\n","        X[0][i][ix[-1]] = 1\n","        print(index_to_char[ix[-1]], end=\"\")\n","        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n","        y_char.append(index_to_char[ix[-1]])\n","    return ('').join(y_char)"],"metadata":{"id":"Sg4K7ViQKGey","executionInfo":{"status":"ok","timestamp":1746594825735,"user_tz":-540,"elapsed":14,"user":{"displayName":"윤종진","userId":"16507458279176135266"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["result = sentence_generation(model, 100)\n","print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uLtgzAnZKH8Z","executionInfo":{"status":"ok","timestamp":1746594838000,"user_tz":-540,"elapsed":12260,"user":{"displayName":"윤종진","userId":"16507458279176135266"}},"outputId":"b660838d-60f4-492c-e8ab-6365dd67f1d0"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["27 번 문자 k 로 예측을 시작!\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","ke telescopes: this time she found a little bottle on it, (why, she did not here what some time with \n"]}]}]}